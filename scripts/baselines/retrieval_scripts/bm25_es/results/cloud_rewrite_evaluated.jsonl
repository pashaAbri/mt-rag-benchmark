{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09544-4-2227","score":19.469707,"text":"\n* UI\n* CLI\n\n\n\n\n\nThis document outlines the process for using context-based restrictions to protect your Cloud Databases resources. Use this document to prepare your resources for context-based restrictions. Cloud Databases doesn't offer scoping rules to the control plane in this current phase of implementation.\n\n\n\n Protecting Cloud Databases resources with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with context-based restrictions and Identity and Access Management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the Cloud Databases service to create, update, or delete rules. A user must also have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule.\n\nAny IBM Cloud Activity Tracker or audit log events generated come from the context-based restrictions service, not Cloud Databases. Cloud Databases supports audit events only for customer interactions with context-based restrictions-protected platform endpoint calls. Cloud Databases does not support audit events when you enable context-based restrictions rules on the control plane API for your instances. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-cbr"},{"document_id":"ibmcld_06618-4-2239","score":19.469707,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\nThis document outlines the process for using context-based restrictions to protect your Cloud Databases resources. Use this document to prepare your resources for context-based restrictions. Cloud Databases doesn't offer scoping rules to the control plane in this current phase of implementation.\n\n\n\n Protecting Cloud Databases resources with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with context-based restrictions and Identity and Access Management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the Cloud Databases service to create, update, or delete rules. A user must also have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule.\n\nAny IBM Cloud Activity Tracker or audit log events generated come from the context-based restrictions service, not Cloud Databases. Cloud Databases supports audit events only for customer interactions with context-based restrictions-protected platform endpoint calls. Cloud Databases does not support audit events when you enable context-based restrictions rules on the control plane API for your instances. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-cbr"},{"document_id":"ibmcld_06686-4-2239","score":19.469707,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\nThis document outlines the process for using context-based restrictions to protect your Cloud Databases resources. Use this document to prepare your resources for context-based restrictions. Cloud Databases doesn't offer scoping rules to the control plane in this current phase of implementation.\n\n\n\n Protecting Cloud Databases resources with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to Cloud Databases resources can be controlled with context-based restrictions and Identity and Access Management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the Cloud Databases service to create, update, or delete rules. A user must also have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule.\n\nAny IBM Cloud Activity Tracker or audit log events generated come from the context-based restrictions service, not Cloud Databases. Cloud Databases supports audit events only for customer interactions with context-based restrictions-protected platform endpoint calls. Cloud Databases does not support audit events when you enable context-based restrictions rules on the control plane API for your instances. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-cbr"},{"document_id":"ibmcld_00576-7385-9302","score":16.263298,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00550-7-2005","score":16.082952,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_00512-1696-3972","score":15.359576,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00580-9670-11721","score":14.680608,"text":"\nThat's the end of this part. The next part is called The Document ID.\n\n\n\n\n\n\n\n The _id video \n\nLearn how _ids work in IBM Cloudant, how they are different from relational databases, and how you can define your own _id.\n\n\n\n* The _id video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 3 - The Document _id.\n\nIn the previous section, we saw how data is stored in IBM Cloudant documents with flexibility on how your application stores JSON objects in IBM Cloudant databases. However, a few hard and fast rules exist.\n\nOne rule is that every document must contain a unique identifier that is called _id, which is a string. Two documents in the same database can have the same _id field. In other databases, you specify which column is the unique identifier, but in IBM Cloudant, it's always _id and can't be changed.\n\nAlso, unlike relational databases, IBM Cloudant does not have \"auto-incrementing IDs\" that is, an ID field that starts at 1 and increments for each document added.\n\nIBM Cloudant's _id field is one of the following strings:\n\n\n\n* A 32-character string generated by IBM Cloudant. The ID is a meaningless sequence of numbers and letters that are guaranteed to be unique.\n* A string that is defined by you (if you know something unique about your data).\n\n\n\nThe following examples show how to supply your own document _id:\n\nUsing it to store something that you know is unique that is, the email address of a user. Your registration mechanism can enforce a one-user-per-email address policy. Some users choose to encode the document type in the _id, for example, user:56, book:55. The last example shows with a 32-digit string (generated in your app) that is designed to sort in approximate date and time order. This method makes it easy to retrieve the latest documents from the database, without a secondary index.\n\nIBM Cloudant takes your document _ids and stores them in an index (like the contents page of book).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00513-7-2197","score":14.605831,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00626-3414-5513","score":14.3796835,"text":"\nThe _replicator database is a special database within your account, where you can PUT or POST replication documents to specify the replications you want.\n\nBefore you start a replication, you must create the _replicator database. To create a database, send a PUT request to:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/_replicator\n\nFor more information, see [Databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases).\n\nTo cancel a replication, you DELETE the replication document. The fields that are supplied in the replication document are described in the [Create or modify a replication operation](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) description under Request information.\n\nAll design documents and _local documents that are added to the \/_replicator database are ignored.\n\n\n\n\n\n Important notes \n\n\n\n* A new and more powerful [replication scheduler](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replicationthe-replication-scheduler) changes the previous behavior of the IBM Cloudant replication mechanisms. Ensure that your applications are updated.\n* Replications can severely impact the performance of an IBM Cloudant instance. Performance testing helps you understand the impact on your environment under an increasing number of concurrent replications.\n* [Continuous replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicontinuous-replication) can result in many internal calls. Requiring many calls might affect the costs for multi-tenant users of IBM Cloudant systems. By default, continuous replication is not enabled.\n* The target database must exist. It is not automatically created if it does not exist. Add \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api"},{"document_id":"ibmcld_06514-4-1824","score":13.946752,"text":"\n* API\n* Terraform\n\n\n\n\n\n\n\n MongoDB Enterprise Edition Analytics Add-On \n\nThe Databases for MongoDB EE (Enterprise Edition) Analytics Add-On allows you to run long-running analytical queries or provision a [MongoDB Connector for business intelligence(BI)](https:\/\/docs.mongodb.com\/bi-connector\/current\/) to make your query data compatible with BI tools, such as [Tableau](https:\/\/www.tableau.com\/).\n\nThe Databases for MongoDB EE Analytics Add-On is made up of two components:\n\n\n\n* [The Analytics node](https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-mongodbee-analyticsmongodbee-analytics-node)\n* [The connector for Business Intelligence (BI)](https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-mongodbee-analyticsmongodbee-analytics-connector-bi)\n\n\n\n\n\n What problems does the Databases for MongoDB EE Analytics Add-On solve? \n\n\n\n1. Most BI tools do not work with the MongoDB document data model.\n\nMongoDB's document data model is made up of complex documents with arbitrary, nested data. This schema makes storing data flexible, easy, and scalable. However, most BI tools require data to be in tabular format, which is rigidly defined and stored in tables, not documents. The Databases for MongoDB EE Analytics Add-On converts MongoDB document data into SQL-readable tabular data that can be queried and displayed by BI tools.\n2. BI queries are expensive and can degrade database performance.\n\nLong-running queries can negatively impact the operational workflow of your deployment. The Databases for MongoDB EE Analytics Add-On introduces an extra data member, which isolates analytics workloads from operational workloads. The Analytics Node data is kept in sync with the other nodes, so any queries run against it produce the same results.\n\n\n\n\n\n The Analytics Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-mongodbee-analytics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00579-1483-3406","score":27.32929,"text":"\nSince the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.\n\n\n\nThis example also means that a potential race condition exists here. The document might change, or be deleted, between the index and document read (although unlikely in practice).\n\nEmitting data into the index (a so-called \u201cprojection\u201d in relational algebra terms) means that you can fine-tune the exact subset of the document that you need. In other words, you don\u2019t need to emit the whole document. Emit a value that represents only the data you need in the app that is a cut-down object with minimal details, for example:\n\nemit(doc.indexed_field, {name: doc.name, dob: doc.dob});\n\nIf you change your mind on what fields you want to emit, the index needs rebuilding.\n\nIBM Cloudant Query\u2019s JSON indexes use views this way under the hood. IBM Cloudant Query can be a convenient replacement for some types of view queries, but not all. Do take the time to understand when to use one or the other.\n\n\n\n* IBM Cloudant Query [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00639-7-2032","score":25.70661,"text":"\nSelector syntax \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query language is expressed as a JSON object that describes documents of interest. Within this structure, you can apply conditional logic by using specially named fields.\n\nThe IBM Cloudant Query language has some similarities with MongoDB query documents, but these similarities arise from a commonality of purpose and don't necessarily extend to equivalence of function or result.\n\n\n\n Selector basics \n\nElementary selector syntax requires you to specify one or more fields, and the corresponding values needed for those fields. The following example selector matches all documents that have a director field that contains the value Lars von Trier.\n\nSee the following example of a simple selector:\n\n{\n\"selector\": {\n\"director\": \"Lars von Trier\"\n}\n}\n\nIf you created a full text index by specifying \"type\":\"text\" when the index was created, you can use the $text operator to select matching documents. In the following example, the full text index is inspected to find any document that contains the word Bond.\n\nSee the following example of a simple selector for a full_text index:\n\n{\n\"selector\": {\n\"$text\": \"Bond\"\n}\n}\n\nYou can create more complex selector expressions by combining operators. However, for IBM Cloudant Query indexes of type json, you can't use \"combination\" or \"array logical\" operators such as $regex as the basis of a query. Only the equality operators such as $eq, $gt, $gte, $lt, and $lte - but not$ne - can be used as the basis of a more complex query. For more information about creating complex selector expressions, see [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntaxcreating-selector-expressions).\n\n\n\n\n\n Selector with two fields \n\nIn the following example, the selector matches any document with a name field that contains Paul, and that also has a location field with the value \"Boston\".\n\nSee the following example of a more complex selector:\n\n{\n\"selector\": {\n\"name\": \"Paul\",\n\"location\": \"Boston\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax"},{"document_id":"ibmcld_00579-2977-4822","score":23.738981,"text":"\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00579-4284-6271","score":23.595371,"text":"\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search. Stored fields are retrieved in the query without doing include_docs=true so the tradeoff is similar to the [Understand the tradeoffs in emitting data or not into a view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-queryingtradeoffs-emit-data-or-not-in-view) section. For more information, see IBM Cloudant Search [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search).\n\n\n\n\n\n Design document management requires some flair \n\nAs your data set grows, and your number of views goes up, sooner or later you want to ponder how you organize your views across design documents. A single design document can be used to form a so-called view group: a set of views that belong together by some metric that makes sense for your use case. If your views are static, that makes your view query URLs semantically similar for related queries. It\u2019s also more performant at index time because the index loads the document once and generates multiple indexes from it.\n\nDesign documents themselves are read and written by using the same read\/write endpoints as any other document. With these endpoints, you can create, inspect, modify, and delete design documents from within your application. However, even small changes to design documents can have significant effects on your database. When you update a design document, all views in it become unavailable until indexing is complete. This lag can be problematic in production.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00539-2548-4016","score":23.497448,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00539-4998-6652","score":23.130129,"text":"\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...\n\"execution_stats\": {\n\"total_keys_examined\": 0,\n\"total_docs_examined\": 1000000,\n\"total_quorum_docs_examined\": 0,\n\"results_returned\": 2,\n\"execution_time_ms\": 4400.699\n}\n}\n\nThe ratio between total_docs_examined and results_returned is key here: a high value indicates that too many documents are being scanned per document that is returned.\n\nFor more information, see [Blog post on Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html).\n\n\n\n\n\n Which IBM Cloudant Query operators defeat the use of an index? \n\nAny of the [combination operators](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryoperators) other than $and can make a query do a full database scan without the help of a secondary index. For example, if an $or operator is used, then no secondary index can be used to assist the query. If in doubt, use the [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00639-1531-2607","score":22.806293,"text":"\nFor more information about creating complex selector expressions, see [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntaxcreating-selector-expressions).\n\n\n\n\n\n Selector with two fields \n\nIn the following example, the selector matches any document with a name field that contains Paul, and that also has a location field with the value \"Boston\".\n\nSee the following example of a more complex selector:\n\n{\n\"selector\": {\n\"name\": \"Paul\",\n\"location\": \"Boston\"\n}\n}\n\n\n\n\n\n Subfields \n\nUse a more complex selector to specify the values for a field of nested objects, or subfields. For example, you might use a standard JSON structure for specifying a field and a subfield.\n\nSee the following example of a field and subfield selector within a JSON object:\n\n{\n\"selector\": {\n\"imdb\": {\n\"rating\": 8\n}\n}\n}\n\nAn abbreviated equivalent uses a dot notation to combine the field and subfield names into a single name.\n\nSee the following example of an equivalent field and subfield selector that uses dot notation:\n\n{\n\"selector\": {\n\"imdb.rating\": 8\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax"},{"document_id":"ibmcld_00623-7-1781","score":22.490423,"text":"\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to \/$DATABASE\/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST \/$DATABASE\/_index HTTP\/1.1\nContent-Type: application\/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"},{"document_id":"ibmcld_00576-4469-6377","score":22.343004,"text":"\nContinuous replication can be used for backups of data, aggregating data across many databases, or for sharing data.\n\nHowever, continuous replication means testing continuously for any source database changes. This testing requires continuous internal calls, which might impact performance or the cost of using the database.\n\nContinuous replication can result in many internal calls. These calls might affect costs for multi-tenant users of IBM Cloudant systems. Continuous replication is disabled by default.\n\n\n\n\n\n Using the proper tool for the job \n\nIBM Cloudant is a scalable, durable, highly available, operational JSON document store with an HTTP API. It's suitable for the following purposes:\n\n\n\n* Powering your always-on web application.\n* Being the server-side data store for mobile applications.\n* Storing time-series data in time-boxed databases before you archive to object storage and delete the original.\n* Storing application objects as JSON while queries are delivered from secondary indexes.\n* Replicating data sets across geographies for disaster recovery, extra capacity, or moving data nearer to your users.\n\n\n\nIBM Cloudant doesn't include the following features:\n\n\n\n* Low latency, in-memory data store. For more information, see [IBM Cloud\u00ae Databases for Redis](https:\/\/www.ibm.com\/uk-en\/cloud\/databases-for-redis).\n* Limitless object store for archiving data. For more information, see [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage).\n* Relational database with SQL querying, stored procedures, and constraints and triggers. For more information, see [IBM Cloud Databases for PostgreSQL](https:\/\/www.ibm.com\/cloud\/databases-for-postgresql).\n* Data warehouse for ad hoc querying. For more information, see [IBM\u00ae Db2\u00ae Warehouse on Cloud](https:\/\/www.ibm.com\/products\/db2-warehouse).\n* A queue. For more information, see [IBM MQ](https:\/\/www.ibm.com\/uk-en\/products\/mq).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-3166-5282","score":22.248981,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00580-7-1957","score":28.4599,"text":"\nLearning Center \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Learning Center offers a video series to help you learn to use IBM Cloudant. The videos start with the basics of using IBM Cloudant. Then the videos walk you through document structure, the API, indexing and querying, and include an Under the Hood topic that highlights the architecture that powers the service.\n\nYou can use the [playlist](https:\/\/www.youtube.com\/embed\/playlist?list=PLzpeuWUENMK3F93hGaS4ezGmlX4Bipt4S) to go through the courses, or navigate directly to the topic of your choosing.\n\n\n\n Introduction to IBM Cloudant video \n\nLearn about the IBM Cloudant 17-part video series that provides an overview of the IBM Cloudant database-as-a-service.\n\n\n\n* Introduction to IBM Cloudant video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 1 - What is IBM Cloudant?\n\nIBM Cloudant is a database, run as a service in the IBM Cloud\u00ae. Its job is to store your application's data securely and make it possible for you to retrieve it quickly and efficiently. IBM Cloudant's key features are shown in the following list:\n\nDatabase\n: Stores and retrieves data. More specifically, it is a JSON document store. JSON comes from JavaScript and represents simple objects in a universal file format.\n\nDocument\n: The unit of storage in IBM Cloudant. Documents are added, updated, and deleted in their entirety.\n\nHTTP API\n: Any IBM Cloudant operation can be achieved by using HTTPS. HTTP is the protocol that powers the World Wide Web and IBM Cloudant is a database that is built for the web. Most databases are hidden in a private network, inaccessible but to a handful of machines. The IBM Cloudant service sits (mainly) on the public internet where it can be accessed by anyone with an internet connection (and permission to do so).\n\nIBM Cloudant wasn't written entirely by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00579-7-1988","score":27.328827,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00542-7820-9775","score":26.689402,"text":"\nIBM Cloudant keeps a history of _id and _rev to enable replication, but not old document bodies.\n\nIBM Cloudant doesn't expose the CouchDB compaction API.\n\nIBM Cloudant doesn't guarantee that a database is compacted in a specific time. Compaction is done as a background process across the storage tier. Databases are always being compacted. It isn't guaranteed that the data compacted is the data that you deleted or changed.\n\nIBM Cloudant is accepting the right to be forgotten requests through the [IBM Data Privacy Office (DPO)](https:\/\/w3.ibm.com\/ibm\/privacy\/). When a right to be forgotten request is made from the IBM DPO, IBM Cloudant verifies the request, explicitly triggers database compaction, and verifies that compaction occurred. At the end of this process, the only version of the document is its tombstone ( _id, _rev, _deleted, and any fields your application includes there).\n\n\n\n\n\n Removal of tombstones \n\nIBM Cloudant can completely remove all references and data for a document when required. This task is an operator-managed process called purging. Before you request that documents be purged, it's important to understand that purged documents cannot be recovered by IBM Cloudant once the process is complete.\n\nThe CouchDB purge API is not supported by IBM Cloudant.\n\nIn the context of GDPR, purging is only required if PI is used in a document ID. It's a bad idea for an _id to store PI for lots of reasons, but a handful of semi-valid use cases exist (for example, a unique email). If possible, encrypt or pseudonymize data so it's opaque to IBM Cloudant.\n\nIf a document needs removal through a right to be forgotten request, follow these steps:\n\n\n\n1. File a request with the [IBM DPO](https:\/\/w3-03.ibm.com\/ibm\/privacy\/index.html) to request purging of specific document _id values along with the reason.\n2. On receipt of a formal request by the IBM DPO, IBM Cloudant operations verifies the request to confirm the id contains PI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-general-data-protection-regulation-gdpr-"},{"document_id":"ibmcld_00510-7123-9213","score":25.993341,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00500-11669-13562","score":25.834473,"text":"\n\"reason\": \"The _sum function requires that map values be numbers, arrays of numbers, or objects. Objects can't be mixed with other data structures. Objects can be arbitrarily nested, if the values for all fields are themselves numbers, arrays of numbers, or objects.\",\n\"caused_by\":\n{\n\"a\": 1\n},\n{\n\"a\": 2\n},\n{\n\"a\": 3\n},\n{\n\"a\": 4\n}\n]\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Map and reduce function restrictions \n\nMap and reduce function restrictions are described here.\n\n\n\n Referential transparency \n\nThe map function must be referentially transparent. Referential transparency means that an expression can be replaced with the same value without changing the result, in this case, a document, and a key-value pair. Because of referential transparency, IBM Cloudant views can be updated incrementally and reindex only the delta since the last update.\n\n\n\n\n\n Commutative and associative properties \n\nIn addition to referential transparency, the reduce function must also have commutative and associative properties for the input. These properties make it possible for the MapReduce function to reduce its own output and produce the same response, for example:\n\nf(Key, Values) == f(Key, [ f(Key, Values) ] )\n\nAs a result, IBM Cloudant can store intermediate results to the inner nodes of the B-tree indexes. These restrictions also make it possible for indexes to spread across machines and reduce at query time.\n\n\n\n\n\n Document partitioning \n\nDue to sharding, IBM Cloudant offers no guarantees that the output of any two specific map functions passes to the same instance of a reduce call. You must not rely on any ordering. The reduce function that you use must consider all the values that are passed to it and return the correct answer irrespective of ordering. IBM Cloudant is also guaranteed to call your reduce function with rereduce=true at query time even if it didn't need to do so when it built the index.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce"},{"document_id":"ibmcld_00580-16038-18196","score":25.559862,"text":"\nGenerally, the revision number increases by one each time, but more complex scenarios are possible (we cover these scenarios later). Older document bodies are discarded or compacted (don't rely on being able to get them back). All IBM Cloudant operations that change a document need the document's _id and its _rev (this scenario is unlike most databases).\n\nThat's the end of this part. The next part is called Authentication.\n\n\n\n\n\n\n\n Authentication video \n\nLearn how Legacy authentication and IAM authentication work. You can also learn how IBM Cloudant generates credentials, and how the three official IBM Cloudant libraries handle authentication.\n\n\n\n* Authentication video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 5 - Authentication.\n\nWe said earlier that IBM Cloudant is a web-based service on the public internet. How can we be sure that our data is safe and that only our code can access it? This scenario is where authentication comes in.\n\nIBM Cloudant supports two types of authentication.\n\nLegacy authentication is where a username or api-key and password are supplied with each request that uses HTTP Basic Authentication or exchanged for a cookie that uses a one-off session API call. A session cookie is cycled regularly, so your client code needs to capture the refreshed cookie and store it for subsequent requests. IAM authentication is the access management system that underpins all of the IBM Cloud services. To authenticate with IAM, you need an IAM API key and the hostname of the IBM Cloudant service. The API key is exchanged for a bearer token by using the IAM API and the bearer token is passed to IBM Cloudant with each request. The bearer token lasts only an hour, so must be renewed with the IAM service periodically. When an IBM Cloudant service is provisioned, you can generate IAM only credentials, or both IAM and Legacy credentials - you decide.\n\nHow are credentials generated?\n\nIn the IBM Cloud Dashboard under your IBM Cloudant service, in the Service Credentials tab, click New Credential.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-3166-5282","score":25.227493,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00556-10831-12062","score":24.76176,"text":"\nThe content must be provided by using [BASE64](https:\/\/en.wikipedia.org\/wiki\/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image\/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00636-1682-3261","score":24.679537,"text":"\nFor more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication). \n Authorization IBM Cloudant supports both legacy and IAM access controls. The IBM Cloudant team recommends that you use IAM access controls for authentication whenever possible. If you're using IBM Cloudant legacy authentication, it is recommended that you use [API keys](https:\/\/cloud.ibm.com\/apidocs\/cloudantintroduction) rather than account-level credentials for programmatic access and replication jobs. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) and the legacy [Authorization document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization). \n At-rest encryption All data that is stored in an IBM Cloudant instance is encrypted at rest by using LUKS1 with 256-bit Advanced Encryption Standard (AES-256). By default, IBM Cloudant manages the encryption keys for all environments. If you require bring-your-own-key (BYOK) encryption for encryption-at-rest, you enable it by using your encryption key that is stored in an IBM Cloud Key Protect instance. IBM Cloudant supports the BYOK feature for new IBM Cloudant Dedicated Hardware plan instances that are deployed in all regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-securing-your-data-in-cloudant"},{"document_id":"ibmcld_00533-1561-3443","score":24.553402,"text":"\nAt those times, IBM Cloudant returns the document normally, as though no conflict exists. However, the version that is returned isn't necessarily the most current version. Instead, the version is selected based on an internal algorithm that considers multiple factors. You must not assume that when documents are returned they're always the most current.\n\n\n\n\n\n How do I identify a document with a conflict? \n\nIf a conflict with a document exists and you try to update it, IBM Cloudant returns a 409 response. If you try to update a document while you're offline, IBM Cloudant can't check for potential conflicts, and you don't receive a 409 response.\n\nWhen this situation happens, it's best to check for document conflicts when you're back online. If you need to find document conflicts, use the following example map function:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}\n\nIf you want to find conflicts within multiple documents in a database, write a [view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce).\n\n\n\n\n\n What happens if I ignore conflicts? \n\nIf you don't check for conflicts, or don't fix them, your IBM Cloudant database has the following problems:\n\n\n\n* Document inconsistency increases because conflicting documents continue to multiply.\n* Database size increases because documents with conflicts must be kept until the conflict is resolved.\n* Performance degrades because it takes more work for IBM Cloudant to respond to each request since it has to go through all the conflicted documents to find the \"best possible\" version.\n\n\n\n\n\n\n\n How do I resolve conflicts? \n\nAfter you find a conflict, follow these four steps to resolve it.\n\n\n\n1. [Get](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccget-conflicting-revisions-mvcc) the conflicting revisions.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-document-versioning-conflicts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-5537-7566","score":30.146584,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00558-23465-25360","score":26.16928,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":26.16928,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00510-7123-9213","score":24.292753,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-7-1696","score":23.694828,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00629-29811-31959","score":22.276833,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_00581-0-1268","score":21.261312,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00450-12974-14850","score":20.829372,"text":"\nThis period doubles between each consecutive retry, and never goes beyond 5 minutes. The minimum value before the first retry is 0.25 seconds. The default value is 10 retries.\n\nsocket_options\n: A list of options to pass to the connection sockets. The available options can be found in the [documentation for the Erlang function setopts of the inet module](https:\/\/www.erlang.org\/doc\/man\/inet.htmlsetopts-2). Default value is [{keepalive, true},{nodelay, false}].\n\nworker_batch_size\n: Worker processes run batches of replication tasks, where the batch size is defined by this parameter. The size corresponds to the number of _changes feed rows. Larger values for the batch size might result in better performance. Smaller values mean that checkpointing is done more frequently. Default value is 500.\n\nworker_processes\n: The number of processes the replicator uses in each replication task to transfer documents from the source to the target database. Higher values might produce better throughput because of greater parallelism in network and disk IO activities, but this improvement comes at the cost of requiring more memory and potentially CPU time. Default value is 4.\n\nSee the following example that includes performance options in a replication document:\n\n{\n\"source\": \"https:\/\/$ACCOUNT1:$PASSWORD1@example.com\/example-database\",\n\"target\": \"https:\/\/$ACCOUNT2:$PASSWORD2@example.org\/example-database\",\n\"connection_timeout\": 60000,\n\"retries_per_request\": 20,\n\"http_connections\": 30\n}\n\n\n\n\n\n The effect of large attachments \n\nHaving large numbers of attachments on documents might cause an adverse effect on replication performance.\n\nFor more information about the effect of attachments on replication performance, see [Performance considerations](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-attachmentsperformance-considerations).\n\n\n\n Avoiding the \/_replicate endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replication"},{"document_id":"ibmcld_01234-7-2066","score":19.62305,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_00553-6057-7460","score":19.360624,"text":"\n* [Design document management](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-document-management)\n* [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant)\n* [How to use attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n\n\n\n* Monitoring your instance\n\n\n\n* [Monitoring an IBM Cloudant cluster](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster)\n* [Capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-capacity)\n* [Active tasks](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks)\n* [Managing tasks](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-tasks)\n\n\n\n* Querying the database\n\n\n\n* [Working with IBM Cloudant Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* [IBM Cloudant Query Parameters](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-query-parameters)\n* [Working with indexes](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-indexes)\n* [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-selector-expressions)\n* [Selector syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax)\n* [IBM Cloudant Operators](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-operators)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-http-works-with-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1268470-1270517","score":18.746643,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1271119-1273166","score":18.746643,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01234-7-2066","score":18.58851,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_00581-0-1268","score":18.33998,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00391-1557-3407","score":17.50516,"text":"\nTokens are constantly added to this bucket based on the sustained rate (X-RateLimit-Purge-Paths-Limit-Per-Second). However, if the bucket is full, no more tokens can be added.\n\nWhen a multiple file purge request is made, the remaining number of tokens is checked against the number of file paths. The paths bucket must contain enough tokens to satisfy all of the paths in the request. If there are enough tokens in the purge bucket, the tokens are removed from the bucket and the request is accepted. If there are not enough tokens, tokens are not removed, and the request is denied.\n\nThis [example](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-apicreate-group-example) shows the rate limiting response headers returned by the purge group API.\n\nThe following table lists the default values for rate limit headers:\n\n\n\nTable 1. Default values for rate limit headers\n\n Rate Header Value Description \n\n X-RateLimit-Purge-Paths-Limit-Per-Second 20 The token number added into the bucket per second. \n X-RateLimit-Purge-Paths-Limit-Burst 1000 The maximum paths can be purged in a burst. Capability of the bucket. \n X-RateLimit-Purge-Paths-Remaining N\/A Number of paths remaining before the rate limit is exceeded. \n\n\n\n\n\n\n\n Is there a limit on the number of purge group entries? \n\nThe number of purge group entries doesn't have any restrictions.\n\n\n\n\n\n What is the maximum size for purge group name? \n\nThe maximum purge group name size is 999 characters.\n\n\n\n\n\n I received an error similar to \"Could not allocate more resource to build new rule in Akamai: x behaviors are needed while only x can be used.\" What should I do? \n\nWhen you reach the maximum resource limit, the console shows this error message. To resolve this issue, you can:\n\n\n\n* Delete unused resources (TTL, origin, and so on).\n* Create a domain to store new resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-limits-and-maximum-values"},{"document_id":"ibmcld_04826-38948-40745","score":17.004839,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage-cli-plugin?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_04457-38780-40577","score":17.004839,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ic-cos-cli"},{"document_id":"ibmcld_04981-38915-40712","score":17.004839,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_12297-157392-158750","score":16.954464,"text":"\n* [Can I update the Terraform version (TF_VERSION) using a JSON file?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqtf-version-update)\n* [Can start with a new Terraform state file on each job run?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqwks-job-trigger)\n* [Can I import an existing Terraform state file?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqtf-state-argument)\n* [What is the maximum variable size?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqwks-name-maxlength)\n* [What is the maximum state file size of import?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqwks-statefile-limit)\n* [How do I fix authentication errors when using the API?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqcreateworkspace-authentication-error)\n\n\n\n\n\n\n\n Troubleshooting \n\n\n\n Troubleshooting Schematics workspace errors \n\n[Why do Schematics Workspaces create using the API\/UI\/CLI fails?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-wks-create-apiwks-create-api)\n\n[Workspace failures](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-wks-failurewks-failure)\n\n\n\n* [Workspace create fails with message Request Entity Too Large](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-wks-failurewks-new-fails1)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_12748-0-2435","score":16.347113,"text":"\n\n\n\n\n\n\n  Limits \n\nIBM Cloud\u00ae Security and Compliance Center has the following known limits that might impact your experience.\n\n\n\nTable 1. Security and Compliance Center limits\n\n                            Limit                                                        \n\n Custom rules               500 per enterprise account  <br>100 per stand-alone account  \n Rule description           256 characters                                               \n Rule size                  4096 characters                                              \n Target                     1 per rule                                                   \n Condition                  16 per rule                                                  \n Property                   24 per condition                                             \n Label                      32 per rule                                                  \n Custom libraries           10 per enterprise account  <br>5 per stand-alone account     \n Library name               64 Characters                                                \n Library description        256 characters                                               \n Library size               Less than 1 MB                                               \n Profile name               64 characters                                                \n Profile description        256 Characters                                               \n Profile size               Less than 1 MB                                               \n Custom profiles            20 per enterprise account  <br>5 per stand-alone account     \n Control                    1200 per library  <br>600 per profile                        \n Control name               64 characters                                                \n Control description        256 characters                                               \n Specification              100 per control per library  <br>400 per control per profile \n Specification description  256 characters                                               \n Assessment                 10 per specification per library or profile                  \n Attachment                 50 per account                                               \n Exclusion                  8 per attachment                                             \n Scan                       1 per attachment - at any time                               \n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-service-limits"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00620-25943-27384","score":20.642282,"text":"\n* IBM Cloudant provides an array of 10 IBM Cloudant documents and a bookmark, an opaque key that represents a pointer to the next documents in the result set. * When the next set of results is required, the search is repeated. However, the query is sent, with the bookmark from the first response, to IBM Cloudant in the request. * IBM Cloudant replies with the second set of documents and another bookmark, which can be used to get a third page of results. * Repeat<-- <\/ul> -->Now you can see how to do that with code.<-- <\/section \"id=\"section-how-do-cloudant-bookmarks-work\" \"> --><-- <section \"id=\"section-use-cloudant-query-search\" \"> --> How can I use IBM Cloudant Query to search? First, you search for all the cities in the US. You're using IBM Cloudant Query]IBM Cloudant Query 1] , so the operation is specified as a block of JSON: {\n\"selector\": {\n\"$eq\": {\n\"country\": \"US\"\n}\n},\n\"limit\": 5\n}\nBy using the \/db\/_find]IBM Cloudant Query] ! ! API endpoint, the results are passed to IBM Cloudant.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -X POST -H \"Authorization: Bearer $API_BEARER_TOKEN\" -H 'Content-type: application\/json' -d '{\"selector\":{\"country\":{\"$eq\": \"US\"}},\"limit\":5}' \"$SERVICE_URL\/cities\/_find\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.FindResult;\nimport com.ibm.cloud.cloudant.v1.model.PostFindOptions;\n\nimport java.util.Collections;\nimport java.util.Map;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00517-7-2102","score":20.634527,"text":"\nService Changes and Deprecations for IBM Cloudant \n\nYou can see the deprecations for IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae here.\n\n\n\n IBM Cloudant Deprecation of Cloudant instances that are created as Cloud Foundry service instances \n\n\n\n Details \n\nDue to the end of the Cloud Foundry service, IBM Cloudant instances that are created as Cloud Foundry service instances are being deprecated and must be migrated to an IBM Cloud [resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs&interface=ui).\n\nMigration to a resource group provides the added capability to use [IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverview) to control access. When migrating the Cloudant instance, you can choose which of your IBM Cloud resource groups to migrate it to. For example, you might have one resource group for production and a different one for Dev\/Test.\n\nStandard Plan instances that are not migrated before 1 September 2023 will be migrated by IBM.\n\nShould IBM be required to migrate a Cloudant instance to a resource group, it will be migrated to the default resource group for the IBM Cloud account. The assignment of the Cloudant instance to the default resource group cannot be changed later.\n\nLite plan instances that are not migrated before 1 August 2023 will be disabled for 30 days and deleted on 1 September 2023.\n\n\n\n\n\n How do I know if my instances use Cloud Foundry? \n\n\n\n* Display the list of Cloudant instances in the IBM Cloud GUI\n* The presence of the migrate icon after the instance name identifies instances that need to be migrated\n\n\n\n\n\n\n\n How do I migrate the instance to an IBM Cloud resource group? \n\n\n\n* To complete the migration, follow these [IBM Cloudant instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migratemigrate_instances).\n\n\n\n\n\n1. Open the More actions menu.\n2. Select Migrate to a resource group to get started.\n3. Select a resource group.\n4. Click Migrate and the instance is migrated for you.\n5. Since you can migrate only one instance at a time, you can continue migrating eligible instances after you migrate the first one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-deprecations-for-ibm-cloudant"},{"document_id":"ibmcld_00646-7-1813","score":20.411263,"text":"\nCreating a web-based To-Do list \n\nCreate a simple web-based to-do list to get familiar with the basic IBM Cloud features.\n\n\n\n Objectives \n\n\n\n1. From this tutorial, you learn how to create a basic website that interfaces with your IBM Cloud database to read and write data.\n\nThe project is a simple to-do list, where you can see a list of notes. You can add and delete notes. Each of your notes has a tag, and you can filter your notes by tag.\n2. To create this to-do list, your application needs to be able to read and write to the database. To read to-dos in \"newest first\" order and to filter by tag, your database needs to have some secondary indexes. Now, we can create all of that.\n\n\n\nYou can complete the tutorial in less than an hour. It doesn't cost you anything over your current IBM Cloudant bill (so it's free if you are on the IBM Cloudant Lite plan).\n\nThe website that you create is served from your local machine, so no other services are required apart from IBM Cloud.\n\nAfter you complete it, you have a basic understanding of how applications can interface with IBM Cloudant through an IBM Cloudant SDK (in this case, NodeJS).\n\n\n\n\n\n Before you begin \n\nYou need the following implements to complete this tutorial:\n\n\n\n1. An IBM Cloudant service instance and some service credentials. You can create the instance and credentials in the IBM Cloudant Dashboard by following the [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial. Be sure to make a note of the APIKey and URL when you create your service credentials.\n2. Ensure you have access to a Mac or Linux\u2122 terminal.\n3. Download [Git](https:\/\/git-scm.com\/downloads).\n4. Download [Node.js and npm](https:\/\/docs.npmjs.com\/downloading-and-installing-node-js-and-npm).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-web-based-todo-list"},{"document_id":"ibmcld_07578-331171-333153","score":19.918558,"text":"\n* Offers administrators, DevOps teams, and developers full stack telemetry with advanced features to monitor and troubleshoot, define alters, and design custom dashboards.\n\n\n\n* How does IBM Cloud Monitoring pricing work?\n\nIBM Cloud Monitoring offers different pricing plans.\n\n\n\n* Light plan\n* Graduated Tier plan\n\n\n\nFor more information about plans and pricing, see [IBM Cloud Monitoring pricing](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans).\n* How do I install IBM Cloud Monitoring?\n\nYou can install and configure an IBM Cloud Monitoring agent for any of the following environments:\n\n\n\n* Kubernetes, GKE, and OpenShift\n* Docker containers or for non-containerized services\n* Mesos, Marathon, and DCOS\n* Linux installations\n\n\n\nIn addition to the previously listed environments, you can see all of the IBM Cloud services that are IBM Cloud Monitoring-enabled [here](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services).\n\nFor information about installing IBM Cloud Monitoring, see [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* How do I get started with IBM Cloud Monitoring?\n\nFor information about provisioning, configuring your agent, managing data, and alerting, see IBM Cloud Monitoring, see [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* What if I used custom images with Advanced Monitoring by Nimsoft?\n\nTo simplify this transition, IBM Cloud automatically removed the \"Advanced Monitoring\" attribute from all of your custom images to prevent provisioning failures after 8 May 2020 when Advanced Monitoring by Nimsoft is no longer available. By removing this attribute, you can continue to use custom images without interruption. If you want to continue with resource monitoring, you need to manually install IBM Cloud Monitoring after a new resource is provisioned.\n* How do I get help if I have issues with this transition?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-331145-333127","score":19.918558,"text":"\n* Offers administrators, DevOps teams, and developers full stack telemetry with advanced features to monitor and troubleshoot, define alters, and design custom dashboards.\n\n\n\n* How does IBM Cloud Monitoring pricing work?\n\nIBM Cloud Monitoring offers different pricing plans.\n\n\n\n* Light plan\n* Graduated Tier plan\n\n\n\nFor more information about plans and pricing, see [IBM Cloud Monitoring pricing](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans).\n* How do I install IBM Cloud Monitoring?\n\nYou can install and configure an IBM Cloud Monitoring agent for any of the following environments:\n\n\n\n* Kubernetes, GKE, and OpenShift\n* Docker containers or for non-containerized services\n* Mesos, Marathon, and DCOS\n* Linux installations\n\n\n\nIn addition to the previously listed environments, you can see all of the IBM Cloud services that are IBM Cloud Monitoring-enabled [here](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services).\n\nFor information about installing IBM Cloud Monitoring, see [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* How do I get started with IBM Cloud Monitoring?\n\nFor information about provisioning, configuring your agent, managing data, and alerting, see IBM Cloud Monitoring, see [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* What if I used custom images with Advanced Monitoring by Nimsoft?\n\nTo simplify this transition, IBM Cloud automatically removed the \"Advanced Monitoring\" attribute from all of your custom images to prevent provisioning failures after 8 May 2020 when Advanced Monitoring by Nimsoft is no longer available. By removing this attribute, you can continue to use custom images without interruption. If you want to continue with resource monitoring, you need to manually install IBM Cloud Monitoring after a new resource is provisioned.\n* How do I get help if I have issues with this transition?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00533-1561-3443","score":19.857439,"text":"\nAt those times, IBM Cloudant returns the document normally, as though no conflict exists. However, the version that is returned isn't necessarily the most current version. Instead, the version is selected based on an internal algorithm that considers multiple factors. You must not assume that when documents are returned they're always the most current.\n\n\n\n\n\n How do I identify a document with a conflict? \n\nIf a conflict with a document exists and you try to update it, IBM Cloudant returns a 409 response. If you try to update a document while you're offline, IBM Cloudant can't check for potential conflicts, and you don't receive a 409 response.\n\nWhen this situation happens, it's best to check for document conflicts when you're back online. If you need to find document conflicts, use the following example map function:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}\n\nIf you want to find conflicts within multiple documents in a database, write a [view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce).\n\n\n\n\n\n What happens if I ignore conflicts? \n\nIf you don't check for conflicts, or don't fix them, your IBM Cloudant database has the following problems:\n\n\n\n* Document inconsistency increases because conflicting documents continue to multiply.\n* Database size increases because documents with conflicts must be kept until the conflict is resolved.\n* Performance degrades because it takes more work for IBM Cloudant to respond to each request since it has to go through all the conflicted documents to find the \"best possible\" version.\n\n\n\n\n\n\n\n How do I resolve conflicts? \n\nAfter you find a conflict, follow these four steps to resolve it.\n\n\n\n1. [Get](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccget-conflicting-revisions-mvcc) the conflicting revisions.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-document-versioning-conflicts"},{"document_id":"ibmcld_00538-7-1491","score":19.654858,"text":"\nUsing the IBM Cloudant changes feed FAQ \n\nAn IBM Cloudant database's changes feed's primary use-case is to power the replication of data from a source to a target database. The IBM Cloudant replicator is built to handle the changes feed and runs the necessary checks to ensure data is copied accurately to its destination.\n\nIBM Cloudant has a raw [changes feed API](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetchanges-changes) that can be used to consume a single database's changes but it must be used with care.\n\nThe _changes API endpoint can be used in several ways and can output data in various formats. But here we focus on best practice and how to avoid some pitfalls when you develop against the _changes API.\n\n\n\n How do I consume the changes feed? \n\nGiven a single database orders, I can ask the database for a list of changes, in this case, limiting the result set to five changes with ?limit=5:\n\nGET \/orders\/_changes?limit=5\n{\n\"results\": [\n{\n\"seq\": \"1-g1AAAAB5eJzLYWBg\",\n\"id\": \"00002Sc12XI8HD0YIBJ92n9ozC0Z7TaO\",\n\"changes\":\n{\n\"rev\": \"1-3ef45fdbb0a5245634dc31be69db35f7\"\n}\n]\n},\n....\n],\n\"last_seq\": \"5-g1AAAAB5eJzLYWBg\"\n}\nShow more\n\nThe API call returns the following changes:\n\nresults\n: An array of changes.\n\nlast_seq\n: A token that can be supplied to the changes endpoint in a subsequent API call to get the next batch of changes.\n\nSee how to fetch the next batch of changes in the following example:\n\nGET \/orders\/_changes?limit=5&since=5-g1AAAAB5eJzLYWBg\n{\n\"results\": [ ...],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-changes-feed"},{"document_id":"ibmcld_00533-2991-3909","score":19.391811,"text":"\n* Performance degrades because it takes more work for IBM Cloudant to respond to each request since it has to go through all the conflicted documents to find the \"best possible\" version.\n\n\n\n\n\n\n\n How do I resolve conflicts? \n\nAfter you find a conflict, follow these four steps to resolve it.\n\n\n\n1. [Get](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccget-conflicting-revisions-mvcc) the conflicting revisions.\n2. [Merge](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccmerge-the-changes-mvcc) them into your application or ask the owner what to do.\n3. [Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-document-versioning-conflicts"},{"document_id":"ibmcld_12889-3-1157","score":19.228695,"text":"\nIBM Cloudant docs \n\nThe IBM Cloudant portfolio includes two complementary, document-oriented NoSQL database-as-a-service offerings on the IBM Cloud. In addition to the comprehensive information in the IBM Cloudant docs, links to additional sources of information are provided below.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/cloudantintroduction)[CLI reference](https:\/\/cloud.ibm.com\/docs\/Cloudant-cli-plugin\/Cloudant-cli-plugin-cloudant-cli)[Terraform reference](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cloudant)\n\n Recommended content \n\n[IBM Cloudant plans Describes the plans you can use with IBM Cloudant and how IBM Cloudant calculates usage.](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public)[IBM Cloudant security Describes IAM, security compliance, and securing your connection and data.](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant)[Try IBM Cloudant for free Describes the steps to get started with IBM Cloudant for free.](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant)\n\n Video library \n\n[!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant\/getting-started.html"},{"document_id":"ibmcld_07578-446226-447852","score":19.100735,"text":"\nIf you need to find document conflicts, use the following example map function:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}\n\nIf you want to find conflicts within multiple documents in a database, write a [view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce).\n* What happens if I ignore conflicts?\n\nIf you don't check for conflicts, or don't fix them, your IBM Cloudant database has the following problems:\n\n\n\n* Document inconsistency increases because conflicting documents continue to multiply.\n* Database size increases because documents with conflicts must be kept until the conflict is resolved.\n* Performance degrades because it takes more work for IBM Cloudant to respond to each request since it has to go through all the conflicted documents to find the \"best possible\" version.\n\n\n\n* How do I resolve conflicts?\n\nAfter you find a conflict, follow these four steps to resolve it.\n\n\n\n1. [Get](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccget-conflicting-revisions-mvcc) the conflicting revisions.\n2. [Merge](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccmerge-the-changes-mvcc) them into your application or ask the owner what to do.\n3. [Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-112397-114109","score":32.92601,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01150-4410-6468","score":32.117878,"text":"\nWhat is Event Streams's maximum message size? \n\nEvent Streams's maximum message size is 1 MB, which is the Kafka default.\n\n\n\n\n\n What are Event Streams's replication settings? \n\nEvent Streams is configured to provide strong availability and durability. The following configuration settings apply to all topics and cannot be changed:\n\n\n\n* replication.factor = 3\n* min.insync.replicas = 2\n\n\n\n\n\n\n\n What are the restrictions and defaults for topics and partitions? \n\n\n\n* Topic names are restricted to a maximum of 100 characters.\n* The default number of partitions for a topic is one.\n* Each IBM Cloud space has a limit of 100 partitions. To create more partitions, you must use a new IBM Cloud space.\n\n\n\n\n\n\n\n How do I check which Event Streams plan I've provisioned? \n\nTo confirm which type of Event Streams plan you've provisioned (Lite, Standard, or Enterprise), complete the following steps:\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams that you want to check.\n2. Click the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n\n\n\n\n Can I change my Event Streams plan using the IBM Cloud console? \n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_00532-0-1979","score":32.0427,"text":"\n\n\n\n\n\n\n  Availability zones FAQ \n\nYou can create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance on IBM Cloud in a multi-zone or single-zone region.\n\nThe following tutorials demonstrate how to create an instance:\n\n\n\n*  Using the dashboard. For more information, see [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant).\n\n\n\nIf you want to create an IBM Cloudant Dedicated Hardware plan instance, follow the [Creating and leveraging an IBM Cloudant Dedicated Hardware plan instance on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloudcreating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud) tutorial.\n\n\n\n  What is an availability zone? \n\nWhen you create an instance, after you select the IBM Cloudant tile, you must select a region. These locations are called availability zones. An availability zone is an IBM Cloud\u00ae Public location that hosts your data. All Lite and Standard plans automatically deploy into a multi-zone region. Dedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/).\n\n\n\n\n\n  What is the difference between a single-zone and a multi-zone region? \n\nA multi-zone region includes three availability zones that can be used by an instance that is deployed to that region. The multi-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Dallas\n*  Frankfurt\n*  London\n*  Osaka\n*  Sydney\n*  Tokyo\n*  Washington DC\n\n\n\nA single-zone region offers only one availability zone for that region. The single-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Seoul\n*  Chennai\n\n\n\nFor more information, see [Plans and provisioning](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclocations-and-tenancy).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-availability-zones"},{"document_id":"ibmcld_07578-699255-701206","score":31.190025,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-699213-701164","score":31.190025,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-448564-450242","score":30.796263,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":30.796263,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":30.71864,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-447531-449109","score":30.041996,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":30.041996,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01025-1621-3657","score":28.695467,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n\n\n\n\n\n I'm getting an error when creating a new instance. What's the problem? \n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n\n\n\n\n\n I'm getting an error when creating a new schema or database. What's the problem? \n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n\n\n\n\n\n Why can\u2019t I open the web console? \n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-496072-498088","score":28.695467,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-496054-498070","score":28.695467,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05374-3238-5027","score":28.089344,"text":"\nI've already deployed it and we can check out right here We have our amazing production app at heroku.com. It says \u201chello world\u201d and we want to go ahead and change it. We wanted to update it so I'm going to go ahead and quickly update it to \u201cHello Moving from Heroku to Code Engine\u201d.\n\nLet\u2019s go ahead and come out of it. git add .git commit -m \u201cupdate hello line\u201d. Then I'm going to go ahead and push and just like you would normally do to push code to Heroku. I want to show you that this is the exact same process inside of Code Engine. What we'll do is, we'll create a new \u2026 we'll log in to IBM Cloud first and then from there we'll create a new project and then we'll go ahead and deploy it to see that it works.\n\nSo there we go, we've gone ahead and deployed it to Heroku first ,just to make sure that we all have our working code and I go ahead and reload this and there we go we're moving from Heroku to Code Engine so we know our code works. This is great.\n\nSo now actually let's get Code Engine as part of this, so first thing first, we need to IBM Cloud log in. So I'm going to go ahead and log in to IBM Cloud. If you haven't set up IBM Cloud video or if you haven't set up your IBM Cloud account, if you look above, me you should see a link to it, which I will put into the video.\n\nI'll go ahead and copy my name here and then I'll take my password, log in just fine, which is great to see, perfect. And now what I'll do is ibmcloud ce project create \u2014name amazing product production app. So this create our nice, little\u2026 Target first. I\u2019ll get my default resource group and then I'll go ahead and create the project. There we go. Should only take a moment - perfect. Now you can change your name to whatever you like. This is just a catch-all for your project, which is useful.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-heroku-migrate"},{"document_id":"ibmcld_03313-7474-9676","score":24.608767,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n\n\n\n\n I'm being asked to log in repeatedly \n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n I'm getting a 401 response \n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n\n\n\n\n Getting Unable to fetch access token for account message \n\nThe full message is, Assistants could not be loaded at this time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_07578-7341-9464","score":24.608126,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-7341-9464","score":24.608126,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":24.195145,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-448564-450242","score":23.169523,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":23.169523,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12343-7-1769","score":21.454494,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_02693-7-1869","score":20.275099,"text":"\nApp Configuration server SDK for Python \n\nApp Configuration service provides SDK to integrate with your Python application.\n\n\n\n Integrating server SDK for Python \n\nApp Configuration service provides SDK to integrate with your Python application. You can evaluate the values of your feature flag or property by integrating the App Configuration SDK.\n\n\n\n1. Use either one of the following methods to install the SDK:\n\nUsing pip\n\npip install --upgrade ibm-appconfiguration-python-sdk\n\nUsing easy_install\n\neasy_install --upgrade ibm-appconfiguration-python-sdk\n2. In your Python application code, include the SDK module with:\n\nfrom ibm_appconfiguration import AppConfiguration, Feature, Property, ConfigurationType\n3. Initialize the sdk to connect with your App Configuration service instance.\n\nappconfig_client = AppConfiguration.get_instance()\nappconfig_client.init(region=AppConfiguration.REGION_US_SOUTH, guid='GUID', apikey='APIKEY')\nappconfig_client.set_context(collection_id='collection_id', environment_id='environment_id')\n\nWhere:\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: GUID of the App Configuration service. Obtain it from the service credentials section of the App Configuration service dashboard.\n* apikey: ApiKey of the App Configuration service. Obtain it from the service credentials section of the App Configuration service dashboard.\n* collection_id: ID of the collection created in App Configuration service instance.\n* environment_id: ID of the environment created in App Configuration service instance.\n\n\n\nThe init() and set_context() are the initialisation methods and should be invoked only once by using appconfig_client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-python"},{"document_id":"ibmcld_02680-7-1762","score":20.165766,"text":"\nApp Configuration client SDK for Android \n\nApp Configuration service provides Android client SDK to integrate with your Android application that is written in Kotlin or Java programming language.\n\n\n\n Prerequisites \n\nFollowing are the prerequisites for using the App Configuration service SDK for Android:\n\n\n\n* Android API level 22 or later\n* [Android Studio](https:\/\/developer.android.com\/studio\/index.html)\n* [Gradle](https:\/\/gradle.org\/install)\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Kotlin \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding the:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Initialize the SDK.\n\nval appConfiguration = AppConfiguration.getInstance()\n\nappConfiguration.init( application,\n\"region\",\n\"guid\",\n\"apikey\")\n\n\/\/To start the configuration fetching operation, set the collectionId and environmentId in the following way.\nappConfiguration.setContext(\"collectionId\",\"environmentId\")\n\nWhere:\n\n\n\n* region - Region name where the service instance is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_02693-1343-3201","score":19.365133,"text":"\nObtain it from the service credentials section of the App Configuration service dashboard.\n* apikey: ApiKey of the App Configuration service. Obtain it from the service credentials section of the App Configuration service dashboard.\n* collection_id: ID of the collection created in App Configuration service instance.\n* environment_id: ID of the environment created in App Configuration service instance.\n\n\n\nThe init() and set_context() are the initialisation methods and should be invoked only once by using appconfig_client. The appconfig_client, when initialized, can be obtained across modules by using AppConfiguration.get_instance(). For more information, see [Fetching the appconfig_client across other modules](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-pythonfetching-the-appconfig_client-across-other-modules).\n\n\n\n\n\n Using private endpoints \n\nSet the SDK to connect to App Configuration service by using a private endpoint that is accessible only through the IBM Cloud private network.\n\nappconfig_client.use_private_endpoint(True);\n\nThis must be done before calling the init function on the SDK.\n\n\n\n\n\n Option to use a persistent cache for configuration \n\nFor your application and SDK to continue operations even during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n 1. default (without persistent cache)\nappconfig_client.set_context(collection_id='airlines-webapp', environment_id='dev')\n\n 2. optional (with persistent cache)\nappconfig_client.set_context(collection_id='airlines-webapp', environment_id='dev', options={\n'persistent_cache_dir': '\/var\/lib\/docker\/volumes\/'\n})\n\nWhere:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-python"},{"document_id":"ibmcld_12463-25842-27664","score":19.145332,"text":"\n: Secrets Manager is now available in the London (eu-gb), Tokyo (jp-tok), and Washington DC (us-east) regions.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 15 February 2021 \n\nNow available: Secrets Manager Java SDK\n: You can now use the IBM Cloud Secrets Manager Java SDK to connect to your Secrets Manager service instance.\n\nFor more information, check out the [IBM Cloud Secrets Manager Java SDK repository in GitHub](https:\/\/github.com\/IBM\/secrets-manager-java-sdk).\n\n\n\n\n\n 27 January 2021 \n\nNow available: Secrets Manager Go and Python SDKs\n: You can now use the IBM Cloud Secrets Manager Go and Python SDKs to connect to your Secrets Manager service instance.\n\nFor more information, check out the SDK repositories in GitHub:\n\n\n\n* [IBM Cloud Secrets Manager Go SDK](https:\/\/github.com\/IBM\/secrets-manager-go-sdk)\n* [IBM Cloud Secrets Manager Python SDK](https:\/\/github.com\/IBM\/secrets-manager-python-sdk)\n\n\n\n\n\n\n\n 18 December 2020 \n\nAnnouncing Secrets Manager general availability\n: Secrets Manager is now generally available in the IBM Cloud catalog!\n\nTo find out more about this release, check out the [announcement blog](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-secrets-manager-is-now-generally-available).\n\n\n\n\n\n 15 December 2020 \n\nSydney availability\n: You can now create a Secrets Manager service instance in the Sydney (au-syd) region.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 14 December 2020 \n\nNow available: Secrets Manager CLI plug-in\n: The Secrets Manager CLI plug-in is now available for download!\n\nYou can use the Secrets Manager CLI to interact with the secrets that you store in your Secrets Manager instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes"},{"document_id":"ibmcld_02683-1274-3285","score":19.090187,"text":"\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: GUID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.\n* apiKey: ApiKey of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.\n* collectionId: ID of the collection created in App Configuration service instance under the Collections section.\n* environmentId: ID of the environment created in App Configuration service instance under the Environments section.\n\n\n\n\n\nThe init() and setContext() are the initialization classes and must be invoked only once by using appConfigClient. The appConfigClient, when initialized, can be obtained across classes by using AppConfiguration.getInstance(). For more information, see [Fetching the appConfigClient across other classes](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-javafetching-the-appConfigClient-across-other-classes).\n\n\n\n Using private endpoints \n\nSet the SDK to connect to App Configuration service by using a private endpoint that is accessible only through the IBM Cloud private network.\n\nappConfigClient.usePrivateEndpoint(true);\n\nThis must be done before calling the init function on the SDK.\n\n\n\n\n\n Option to use a persistent cache for configuration \n\nFor your application and SDK to continue operations during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n\/\/ 1. default (without persistent cache)\nappConfigClient.setContext(collectionId, environmentId);\n\n\/\/ 2. optional (with persistent cache)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_00462-7-1647","score":18.896448,"text":"\nClient libraries \n\nClient libraries are the tools that you use to develop your own applications to work with IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases.\n\nThe following client libraries are formally supported by IBM Cloudant: Java\u2122, Node.js, Python, and Go.\n\nA supported library is one where you can contact IBM Cloudant if you come across a specific, reproducible problem in the current version of the library.\n\n\n\n Java \n\nThe IBM Cloudant SDK for Java\u2122 is the official IBM Cloudant library for Java\u2122.\n\nTo install the IBM Cloudant SDK for the Java\u2122 library, see [Installation](https:\/\/github.com\/ibm\/cloudant-java-sdkinstallation) about installing the library by adding it as a dependency to your Maven or Gradle builds. You can also see details and examples of how to use the library in the guide.\n\n\n\n Library for Java \n\n\n\n* [IBM Cloudant SDK for Java\u2122](https:\/\/github.com\/ibm\/cloudant-java-sdk)\n\n\n\n\n\n\n\n\n\n Node.js \n\nThe IBM Cloudant SDK for the Node.js library is the official IBM Cloudant library for Node.js.\n\nInstall the [IBM Cloudant SDK for Node.js](https:\/\/www.npmjs.com\/package\/@ibm-cloud\/cloudant) library by running the following command:\n\nnpm install @ibm-cloud\/cloudant\n\n\n\n Library for Node.js \n\n\n\n* [IBM Cloudant SDK for Node.js](https:\/\/github.com\/ibm\/cloudant-node-sdk)\n\n\n\n\n\n\n\n\n\n Python \n\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_02674-11255-12899","score":18.77618,"text":"\nThe SDK uses the attribute values to determine if the specified entity satisfies the targeting rules, and returns the appropriate property value.\n\n\n\n\n\n\n\n How to access the payload secret data from the response \n\n\/\/make sure this import statement is added\nimport (sm \"github.com\/IBM\/secrets-manager-go-sdk\/secretsmanagerv1\")\n\nsecret := getSecretRes.Resources[0].(sm.SecretResource)\nsecretData := secret.SecretData.(map[string]interface{})\npayload := secretData[\"payload\"]\n\nThe GetCurrentValue will be sending the three objects as part of response.\n\n\n\n* getSecretRes: this will give the meta data and payload.\n* detailedResponse: this will give entire data which includes the http response header data, meta data and payload.\n* err: this will give the error response if the request is invalid or failed for some reason.\n\n\n\nsecretData[\"payload\"] will return interface{} so based on the data you need to do the type casting.\n\n\n\n\n\n Fetching the appConfigClient across other modules \n\nOnce the SDK is initialized, the appConfigClient can be obtained across other modules as shown below:\n\n\/\/ other modules\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nappConfigClient := AppConfiguration.GetInstance()\nfeature, err := appConfigClient.GetFeature(\"online-check-in\")\nif (err == nil) {\nenabled := feature.IsEnabled()\nfeatureValue := feature.GetCurrentValue(entityId, entityAttributes)\n}\n\n\n\n\n\n\n\n\n\n Supported data types \n\nYou can configure feature flags and properties with App Configuration, supporting the following data types: Boolean, Numeric, String, and SecretRef. The String data type can be a text string, JSON, or YAML.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_00090-10845-11677","score":18.612299,"text":"\n4 14 13.994738 12.336533 15.652943 0.643756\nShow more\n\n\n\n\n\n Time series SQL \n\nThe time series library is tightly integrated with Apache Spark. By using new data types in Spark Catalyst, you are able to perform time series SQL operations that scale out horizontally using Apache Spark. This enables you to easily use time series extensions in IBM Analytics Engine or in solutions that include IBM Analytics Engine functionality like the Watson Studio Spark environments.\n\nSQL extensions cover most aspects of the time series functions, including segmentation, transformations, reducers, forecasting, and I\/O. See [Analyzing time series data](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-ts_intro).\n\n\n\n\n\n Learn more \n\nTo use the tspy Python SDK, see the [tspy Python SDK documentation](https:\/\/ibm-cloud.github.io\/tspy-docs\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-time-series-functions-non-classic"},{"document_id":"ibmcld_13481-6212-7871","score":18.436405,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":35.477856,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":34.44937,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16295-1365-2938","score":33.630547,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03421-4-1877","score":33.459015,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-7-1721","score":33.365517,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16326-1697-3495","score":33.22563,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16365-12876-14604","score":33.169487,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03166-4-2012","score":33.042156,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03421-1518-3290","score":32.58899,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":31.886469,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":30.507622,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16295-7-1721","score":28.608263,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03422-13387-15045","score":28.32518,"text":"\nconnect-src *.watsonplatform.net *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watsonplatform.net .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements, such as <script> and <style> tags, to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'nonce- ';connect-src *.watsonplatform.net *.watson.appdomain.cloud\"\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_03080-7-1901","score":28.121063,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":28.039541,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16365-12876-14604","score":27.331156,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-1889-3334","score":27.181189,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03421-1518-3290","score":27.026564,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":26.705935,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16365-11574-13329","score":25.948034,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":32.14076,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16368-7-2072","score":29.046741,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-7-2422","score":28.572796,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16299-1512-2608","score":26.542955,"text":"\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)\n* [Extending your assistant using webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview): You use webhooks to call external services that extend the capabilities of your assistant or log activity.\n* Developing a custom channel: If none of the built-in channel integrations meet your needs, you can use the Watson Assistant REST API and SDKs to develop a custom client application that interacts with your assistant. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_16299-7-2120","score":26.005606,"text":"\nOverview: Customizing and developing \n\nThe Watson Assistant user interface makes it easy to build an assistant and deploy it to your customers without writing any code. For advanced users and developers, there are powerful ways you can further customize and extend the capabilities of your assistant.\n\nA deployed assistant includes numerous components that work together to deliver the help your customers need over the channels they use.\n\n![Watson Assistant architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant using a channel such as the web chat or phone integration.\n* Based on natural language understanding, the assistant makes a decision about how to route the customer's request to the appropriate resolution mechanism, which might be an action or a search of existing content.\n* The assistant might also need to communicate with external services or hand off the conversation to a human agent.\n\n\n\nThere are multiple points at which a developer can customize and extend how the assistant behaves, or how it interacts with external services. These customization points include the following:\n\n\n\n* Customizing actions: By writing expressions and editing JSON data, you can extensively customize how an action evaluates step conditions, how it stores data, how it responds to customer input, and how it interacts with channels. (More information coming soon.)\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_08056-2371-4275","score":25.067986,"text":"\nUsers with Lite or Trial accounts can view the [IBM Cloud documentation](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar), Chat with Watson, and use [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).\n\n\n\n\n\n\n\n How do I escalate support cases? \n\nAs an IBM Cloud customer, you can escalate support cases to surface critical issues. After a case is escalated, the IBM Cloud Support team reviews the information and responds with updates. For information about case severity, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nTo escalate a case, complete the following steps:\n\n\n\n1. Contact IBM Cloud Support by phone or chat:\n\n\n\n* Pay-as-you-go or subscription accounts can contact support by phone and can find the number in the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Contact by chat from the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Chat with IBM from the Chat with a support agent tile.\n\n\n\n2. Provide your existing case number and a request to escalate the case.\n3. Provide the justification an escalation and explain the business impact of your problem or issue.\n\n\n\nIf your support inquiry requires a more immediate response, consider upgrading to the premium or advanced support plan so that you can open severity 1-4 support cases. To upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https:\/\/cloud.ibm.com\/user\/notifications) in your profile settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-get-supportfaq"},{"document_id":"ibmcld_02855-6718-8435","score":25.00261,"text":"\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03166-8640-10452","score":24.720222,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_02875-7-2073","score":24.539242,"text":"\nAdding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nThe context object that is passed as part of the v2 \/message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-integrations"},{"document_id":"ibmcld_03188-4819-6738","score":24.46188,"text":"\nFor more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored. The information is stored in the context.integrations.chat.browser_info object.\n\nYou can design your dialog to take advantage of details about the web browser in use. The following properties are taken from the window object that represents the window in which the web chat is running:\n\n\n\n* browser_name: The browser name, such as chrome, edge, or firefox.\n* browser_version: The browser version, such as 80.0.0.\n* browser_OS: The operating system of the customer's computer, such as Mac OS.\n* language: The default locale code of the browser, such as en-US.\n* page_url: Full URL of the web page in which the web chat is embedded. For example: https:\/\/www.example.com\/products\n* screen_resolution: Specifies the height and width of the browser window in which the web page is displayed. For example: width: 1440, height: 900\n* user_agent: Content from the User-Agent request header.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03180-5630-7213","score":26.308552,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03080-1529-3357","score":24.302889,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03080-5624-7473","score":24.20786,"text":"\nFor more information about how to customize it, see [HTML content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml).\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-set-context)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_02855-13982-15842","score":23.998089,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-16710-18404","score":23.911566,"text":"\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16298-4831-6878","score":23.803957,"text":"\nAgent status is set to Invisible unless it is explicitly changed.\n\n\n\n\n\n Turn on Agent Workspace \n\nZendesk Agent Workspace brings Zendesk Chat and Zendesk Support together, so all your customer interactions are in one place, and communication is seamless, personal, and efficient. That means more productive agents and happy customers.\n\nIn Zendesk:\n\n\n\n1. Click the Products icon and go to the Admin Center.\n2. Click Workspaces.\n3. Click the Turn on Agent Workspace button. The green On box should display.\n\n\n\nAgent Workspace should now feature on several screens in Zendesk Support, including on the Dashboard with tickets, the Visitors page, and in the top menu as Conversations where agents can accept chats from customers waiting for assistance.\n\n\n\n\n\n\n\n Securing the transfer to Zendesk \n\nYou must collect the name and email address of each user, if enabling security in Zendesk. This information must be passed to the web chat so it can be provided to Zendesk when the conversation is transferred.\n\nWhen you add security to your Zendesk integration, you ensure that the visitors you are helping are legitimate customers. Enabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Enabling authenticated visitors in Zendesk](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_02875-7-2073","score":23.62325,"text":"\nAdding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nThe context object that is passed as part of the v2 \/message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-integrations"},{"document_id":"ibmcld_16387-7-1890","score":23.297943,"text":"\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public\/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https:\/\/www.npmjs.com\/package\/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"},{"document_id":"ibmcld_16388-7-1918","score":23.15068,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_02855-25179-26743","score":23.134153,"text":"\nfunction mockLogin() {\nconst payload = {\n\/\n* Even if this is an unauthenticated user, add a userID in the sub claim that can be used\n* for billing purposes.\n* This ID will help us keep track \"unique users\". For unauthenticated users, drop a\n* cookie in the browser so you can make sure the user is counted uniquely across visits.\n\/\nsub: 'some-user-id', \/\/ Required\niss: 'yourdomain.com' \/\/ Required\n};\n\/\/ The \"expiresIn\" option adds an \"exp\" claim to the payload.\nreturn jwt.sign(payload, process.env.YOUR_PRIVATE_RSA_KEY, { algorithm: 'RS256', expiresIn: '10000ms' });\n}\nShow more\n\n\n\nTo enable security, complete the following steps:\n\n\n\n1. From the web chat integration page in Watson Assistant, set the Secure your web chat switch to On.\n2. Add your public key to the Your public key field.\n\nThe public key that you add is used to verify that data which claims to come from your web chat instance is coming from your web chat instance.\n3. To prove that a message is coming from your website, each message that is submitted from your web chat implementation must include the JSON Web Token (JWT) that you created earlier.\n\nAdd the token to the web chat code snippet that you embed in your website page. Specify the token in the identityToken property.\n\nFor example:\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nidentityToken: 'YOUR_JWT',\nonLoad: function(instance) {\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":42.54145,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":42.18434,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16377-7-1723","score":37.00779,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16295-7-1721","score":31.816465,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16375-7-1735","score":31.220493,"text":"\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n<\/head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16365-1312-3051","score":30.732914,"text":"\nFor more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16315-9405-10024","score":30.719557,"text":"\n* Journeys currently do not meet accessibility requirements.\n* Journeys are not supported if you are using the [element configuration option](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationoptionselement) to render the web chat in a custom DOM element.\n* When the customer starts a journey, the web chat window temporarily closes, but will reopen when the journey finishes. If you are using the window:close event to trigger the display of a post-chat form, your code should check the value of the new event.reason parameter of the event and verify that it is not set to open_tour.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-journeys"},{"document_id":"ibmcld_03422-13387-15045","score":29.74751,"text":"\nconnect-src *.watsonplatform.net *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watsonplatform.net .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements, such as <script> and <style> tags, to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'nonce- ';connect-src *.watsonplatform.net *.watson.appdomain.cloud\"\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_16334-20193-22029","score":27.901415,"text":"\n* \"User is typing\" support: The web chat now supports displaying the \"user is typing\" message for service desks. This feature is supported for the Salesforce and Zendesk integrations, as well as any [starter kit](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter) integration that implements it.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.1.0 \n\nRelease date: 28 October 2021\n\n\n\n* Custom Panels: The web chat now supports customizable panels you can use to display any custom HTML content (for example, a feedback form or a multistep process). Your code can use instance methods to dynamically populate a custom panel, as well as open and close it. For more information, see [Custom Panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodscustompanels).\n\n\n\n\n\n\n\n 5.0.2 \n\nRelease date: 4 October 2021\n\n\n\n* A [new tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-react-portals) is now available that shows how to use Carbon components to customize user-defined responses and writeable elements.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.1 \n\nRelease date: 20 September 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.0 \n\nRelease date: 16 September 2021\n\n\n\n* New response types: The web chat now supports the new video, audio, and iframe response types. For more information about these response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n* Link to start web chat: You can now create a set of HTML links that go directly to your web chat and start conversations on specific topics. For example, you might want to send an email inviting customers to update their account information; you can include a link that opens the web chat on your site and sends the initial message I want to update my account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16365-12876-14604","score":27.614853,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06953-7-2041","score":23.506542,"text":"\nSearching Discovery data from Watson Assistant \n\nYour Discovery project can provide answers to questions that stump your assistant. Instead of answering with \u201cI don't know\u201d, your assistant can say, \u201cI'm not sure, but I searched my knowledge base and found these answers which might help.\u201d\n\nFor more information about how to search a Discovery project from an assistant, read the appropriate Watson Assistant documentation for your situation.\n\n\n\n* From the new experience user interface, see [Search trigger](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-addsearch-add-trigger).\n* From an actions skill in the classic user interface, see [Configuring the search for an answer](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-what-next-search).\n* From a dialog skill, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\n\n\nIf you use the built-in web chat, you can use answer finding by enabling the Emphasize the answer feature. Answer finding highlights the word or phrase in the search result that is determined to be the exact answer to the customer's question.\n\nFor a more detailed look at the steps to take to connect to a Discovery project from Watson Assistant, take a tutorial that walks you through them. For more information, see [Power your assistant with answers from web resources](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred).\n\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_01495-0-1996","score":23.005264,"text":"\n\n\n\n\n\n\n  Why am I getting Access denied errors? \n\nYou have a valid IAM API key or OAuth token, but you still get Access denied errors in IBM Cloud\u00ae Container Registry.\n\nWhen you try to access Container Registry, you get one of the following messages.\n\nYou are not authorized to access the specified resource.\n:   For more information, see [Why am I getting Access denied errors for a resource](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-resource).\n\nInsufficient scope\n:   You might see this message if you are trying to access Container Registry by using a client such as Docker. For more information, see [Why am I getting Access denied errors about insufficient scope](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-scope).\n\nYour account has exceeded its pull traffic quota for the current month.\n:   For more information, see [Why am I getting Access denied errors about my quota](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-quota).\n\nYour account has exceeded its image storage quota for the current month.\n:   For more information, see [Why am I getting Access denied errors about my quota](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-quota).\n\nYou must access this account over the private network.\n:   For more information, see [Why am I getting Access denied errors over a private network](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-private).\n\nStatus code 403 Forbidden\n:   You might see this message if you are using IBM Cloud Code Engine. For more information, see [Why am I getting a Forbidden error when I'm using Code Engine](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-forbidden-ce).\n\nImagePullBackoff\n:   You might see this status when you start containers in Kubernetes. For more information, see [Why do images fail to pull from registry with ImagePullBackOff or authorization errors](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ts-app-image-pull).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-access-denied"},{"document_id":"ibmcld_05713-587220-588668","score":22.761225,"text":"\n[Why am I running out of SNAT ports for egress connections from pods in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-network-snat-125ts-network-snat-125)\n\n[Why am I seeing egress connection failures from pods?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-network-egress-124ts-network-egress-124)\n\n[Why can't I install a new strongSwan Helm chart release?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_strongswan_releasecs_strongswan_release)\n\n[Why does strongSwan VPN connectivity fail after I add or delete worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_vpn_fails_worker_addcs_vpn_fails_worker_add)\n\n[After upgrading my classic cluster to version 1.21, I'm finding connectivity issues](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-network-classic121ts-network-classic121)\n\n[Why are certain packets dropped on the public VLAN?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-mangle-tablemangle-table)\n\n[Why do OpenSSL connections to Let's Encrypt fail after 30 September 2021?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-letsencryptts-letsencrypt)\n\n[Debugging Calico components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-calico_log_levelcalico_log_level)\n\n\n\n* [Increasing the log level for the calico-typha components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-calico_log_levelcalico-increase-logging-typha)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_13338-8044-10162","score":22.471672,"text":"\nThe smart formatting feature understands and returns the multigram units that the model generates. If you apply your own post-processing to transcription results, you need to handle these units appropriately.\n\n\n\n\n\n\n\n\n\n Smart formatting results \n\nThe following table shows examples of final transcripts both with and without smart formatting. The transcripts are based on US English audio.\n\n\n\nTable 2. Smart formatting example transcripts\n\n Information Without smart formatting With smart formatting \n\n Dates I was born on ten oh six nineteen seventy I was born on 10\/6\/1970 \n I was born on the ninth of December nineteen hundred I was born on 12\/9\/1900 \n Today is June sixth Today is June 6 \n Times The meeting starts at nine thirty AM The meeting starts at 9:30 AM \n I am available at seven EST I am available at 7:00 EST \n We meet at oh seven hundred hours We meet at 0700 hours \n Numbers The quantity is one million one hundred and one The quantity is 1000101 \n One point five is between one and two 1.5 is between 1 and 2 \n Phone numbers Call me at nine one four two three seven one thousand Call me at 914-237-1000 \n Call me at one nine one four nine oh nine twenty six forty five Call me at 1-914-909-2645 \n Currency values You owe me three thousand two hundred two dollars and sixty six You owe me $3202.66 \n The dollar rose to one hundred and nine point seven nine yen from one hundred and nine point seven two yen The dollar rose to 109.79 yen from 109.72 yen \n Internet email and web addresses My email address is john dot doe at foo dot com My email address is [john.doe@foo.com](mailto:john.doe@foo.com) \n I saw the story on yahoo dot com I saw the story on yahoo.com \n Combinations The code is zero two four eight one and the date of service is May fifth two thousand and one The code is 02481 and the date of service is 5\/5\/2001 \n There are forty seven links on Yahoo dot com now There are 47 links on Yahoo.com now \n\n\n\n\n\n\n\n Smart formatting results for long pauses \n\nIn cases where an utterance contains long enough pauses of silence, the service can split the transcript into two or more final results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formatting"},{"document_id":"ibmcld_16365-14167-16117","score":22.45942,"text":"\n{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use a Content Security Policy (CSP), and implement other basic web security precautions.\n\n\n\n\n\n\n\n Billing \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nBy default, the web chat creates a unique, anonymous ID the first time a new user starts a session. This identifier is stored in a first-party cookie, which remains active for 45 days. If the same user returns to your site and chats with your assistant again while this cookie is still active, the web chat integration recognizes the user and uses the same user ID. This means that you are charged only once per month for the same anonymous user.\n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_05010-20606-22604","score":22.449968,"text":"\nHow do I access the reclaimed resources? \n\nCreate a new set of credentials to access the restored resources.\n\n\n\n\n\n Can I host a website using a Object Storage bucket? \n\nYou can use Object Storage bucket to host a static website. For details, see [Hosting Website using COS](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-static-website-tutorial).\n\n\n\n\n\n Are REST and cURL commands supported for Object Storage bucket creation using HMAC credentials? \n\nYes, you should setup an authorization header. For details, see [Using HMAC Signature](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-hmac-signature).\n\n\n\n\n\n What kind of IAM authorization is required to edit a bucket's authorized IPs list? \n\nYou must have 'Manager' privilege on the bucket to manage the firewall and to set the authorizations.\n\n\n\n\n\n Can I convert a single region Object Storage bucket to cross region without having to copy objects? \n\nNo, you must copy objects to the target bucket. For details, see [COS Region Copy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-region-copy).\n\n\n\n\n\n Is there a way to verify an object\u2019s integrity during an upload to Object Storage? \n\nObject Storage supports object integrity and ensures that the payload is not altered during transit.\n\n\n\n\n\n How can I set a notification when usage in a Object Storage instance is near a certain billing amount? \n\nYou can use a \"soft\" bucket quota feature by integrating with Metrics Monitoring and configuring for notifications. For details on establishing a hard quota that prevents usage beyond a set bucket size, see [Using Bucket Quota](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-quota).\n\n\n\n\n\n Why am I unable to delete a Object Storage instance? \n\nIt isn't possible to delete an instance if the API key or Service ID being used is locked. You'll need to navigate in the console to Manage > Access (IAM) and unlock the API Key or Service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_07578-494591-496583","score":22.400566,"text":"\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-494573-496565","score":22.400566,"text":"\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01025-7-2061","score":22.3908,"text":"\nFAQs - Lite plan \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae on Cloud Lite plan.\n\n\n\n Will my free plan expire? \n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n\n\n\n\n\n Will my data be deleted? \n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n\n\n\n\n\n How can I download a backup of my data on the Lite plan? \n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n\n\n\n\n Can I change the email I use for reactivation? \n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_16387-2916-4646","score":22.142971,"text":"\n\/\/ Returns a signed JWT signed with the RS256 algorithm.\nfunction createJWT() {\nconst payload = {\nsub: 'some-user-id', \/\/ Identifies user for billing purposes\n};\n\/\/ The \"expiresIn\" option adds an \"exp\" claim to the payload.\nreturn jwt.sign(payload,\nprocess.env.YOUR_PRIVATE_RSA_KEY,\n{ algorithm: 'RS256', expiresIn: '1h' });\n}\n\n\n\n\n\n Configuring the web chat to include JWTs \n\nNow that you have implemented a function to generate a signed JWT, you must update your web chat instance to include the signed JWT with each message it sends. After you enable web chat security, any messages that are not signed with the proper private key are rejected.\n\nIn your website HTML, update the web chat embed script to specify a new JWT at the beginning of each session, and also whenever the existing JWT expires. The simplest way to do this is to subscribe to the [identityTokenExpired](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventsidentityexpired) event and generate a new JWT when that event is received. The identityTokenExpired event is fired in both of the following situations:\n\n\n\n* At the beginning of a new session, if no JWT was provided using the identityToken configuration option.\n* When the previously specified JWT expires.\n\n\n\nIn your onLoad event handler, use the [on()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodson) instance method to subscribe to the identityTokenExpired event.\n\nIn the callback, call the function on your server that you implemented to generate a new JWT. Then use the identityToken parameter of the event to specify the new JWT, as in this example:\n\ninstance.on({ type: 'identityTokenExpired',\nhandler: async function(event) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02774-5358-7120","score":12.742027,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_02750-7-2278","score":12.353834,"text":"\nCustom identity \n\nYou can use your own custom identity provider when you are authenticating. Your identity provider can conform to any authentication mechanism alternate to those supported by IBM Cloud\u00ae App ID, including proprietary or legacy.\n\n\n\n Overview \n\nBy bringing your own identity provider, you can create a custom authentication flow that uses your own protocols. You have more control, such as information that you want to share or information that is stored.\n\nBe sure to [configure your custom provider](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-custom-identity) before you add it to your application.\n\n\n\n When would I want to use this flow? \n\nWhen App ID does not provide direct support for a particular identity provider, you can use the custom identity flow to bridge the authentication protocol to App ID's existing authentication flow. For example, you want to use GitHub or LinkedIn to allow your users to sign in. You can use the identity provider's existing SDK to facilitate user authentication information before packaging and exchanging it with App ID.\n\nThere are many scenarios where a different authentication flow is necessary:\n\n\n\n* Proprietary, in-house identity providers\n* Third-party identity providers\n* Complicated authentication flows, which can include proprietary multi-factor mechanisms\n\n\n\nOccasionally, a legacy provider might use their own custom authentication protocol. Because the custom identity flow completely decouples authentication from authorization, you can adopt any authentication mechanism of your choice and then provide the resulting authentication information to App ID. All without exposing user credentials.\n\n\n\n\n\n Technically, how does this flow work? \n\nThe custom identity workflow is built on the JWT-Bearer extension grant type that is defined in Assertion Framework for OAuth 2.0 Authorization Grants [[RFC7521]](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7523section-2.1). To exchange user information for App ID tokens, your authentication architecture creates a trust relationship with App ID by using an asymmetric RSA key pair. Once trust is established, you can use the JWT-Bearer grant type to exchange verified user information within a signed JWT for App ID tokens.\n\n\n\n\n\n What does the flow look like?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-custom-auth"},{"document_id":"ibmcld_02766-7-2005","score":11.8168335,"text":"\nManaging authentication \n\nIdentity providers (IdP's) add a level of security for your mobile and web apps, through authentication. With IBM Cloud\u00ae App ID, you can configure one or several identity providers to create a custom sign-in experience for your users.\n\nApp ID interacts with identity providers by using various protocols such as OpenID Connect, SAML, and more. For example, OpenID Connect is the protocol that is used with many social providers such as Facebook, Google. Enterprise providers such as [Azure Active Directory](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-azure-active-directory) or [Active Directory Federation Service](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-active-directory-federation-service), generally use SAML as their identity protocol. For [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), the service uses SCIM to verify identity information.\n\nWhen you use social or enterprise identity providers, App ID reads user account information. Because the service never has write access to the information, users must go through their chosen identity provider to do actions, such as resetting their password. For example, if a user signs in to your app with Facebook, and then wanted to change their password, they must go to www.facebook.com to do so.\n\nWhen you use [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), App ID is the identity provider. The service uses your registry to verify your users identity. Because App ID is the identity provider, users can take advantage of advanced functionality, such as resetting their password, directly in your app.\n\nWorking with application identity? Check out [Application identity](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-app).\n\nSeveral identity providers can be configured to be used by App ID. Check out the following table to learn about your options.\n\n\n\nTable 1. Identity provider options\n\n Identity provider Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_06966-6860-8310","score":11.684044,"text":"\nFor more information, see [Giving users access to a Watson Discovery instance](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-discovery\/discovery-admin-add-users.html).\n3. Enable document-level security for the data source when you connect to it.\n\n\n\n\n\n Creating users for document-level security \n\nYou must create users that match the users available on the source system that Discovery is connecting to so that they can query with document-level security enabled.\n\n\n\n1. Log in to Discovery as an administrator.\n2. Create users who match the users available on your source or who are connected to the identity provider that your source system uses. If you create users for document-level security, keep the following points in mind:\n\n\n\n* Optional: For each user that you want to have access to query results, you must add users. The username must match the username that the source uses. This option is only for development and testing purposes. To create users individually, see [Managing users](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/users.html).\n* To connect to an identity provider that the source is using, see [Connecting to your identity provider](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/ldap.html).\n\n\n\n\n\nDiscovery does not synchronize changes that are made to the users in the identity provider with the user list for the service. Discovery administrators must ensure that the user list is current and remove any noncurrent users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-types"},{"document_id":"ibmcld_02750-3104-4701","score":11.638371,"text":"\nJust as with traditional OAuth 2.0 flows, the most secure trust model creates a relationship between your identity provider and authorization server; in this case App ID) directly. Under this model, your identity provider is responsible for storing the private key and signing JWT assertions. When passed to App ID, these assertions are validated with the matching public key, which ensures that the user information from your identity provider was not maliciously altered during transport. \n\n\n\n\n\n\n\n\n\n Generating a JSON web token \n\nYou can convert your verified user data to a custom identity JWT by generating a [JSON web token](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7515). The token must be signed with the private key that matches your preconfigured public key. For a list of token signing libraries, check out [https:\/\/jwt.io\/](https:\/\/jwt.io\/).\n\n\n\n Example JWT format \n\n{\n\/\/ Header\n\"alg\": \"RS256\",\n\"typ\": \"JOSE\",\n\/\/ Payload\n\/\/ Required\n\"iss\": \"String\", \/\/ Should reference your identity provider\n\"aud\": \"String\", \/\/ Must be the OAuth server URL name\n\"exp\": \"Int\", \/\/ Should be a value with a short lifespan\n\"sub\": \"String\", \/\/ Must be the unique user ID provided by your identity provider\n\n\/\/ Normalized claims (optional)\n\"name\": \"String\",\n\"email\": \"String\",\n\"locale\": \"String\",\n\"picture\": \"String\",\n\"gender\": \"String\",\n\n\/\/ Custom Scopes to add to access token (optional)\nscope=\"custom_scope1 custom_scope2\"\n\n\/\/ Other custom claims (optional)\nrole=\"admin\"\n}\n\n\n\nTable 1. JWS fields\n\n Field Description \n\n iss Should contain a reference to your identity provider. \n aud The OAuth server URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-custom-auth"},{"document_id":"ibmcld_02766-3003-4951","score":11.333839,"text":"\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.\n3. On the Identity Providers tab, set the providers that you want to use, to On.\n4. Optional: Decide whether to turn off Anonymous users, or leave the default, which is On. When set to On, user attributes are associated with the user from the moment they begin interacting with your app. For more information about the path to becoming an identified user, see [Progressive authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymousprogressive).\n\n\n\nApp ID provides default credentials to help with your initial setup of Facebook and Google+. You are limited to 20 uses of the credentials per instance, per day. Because they are IBM credentials, they are meant to be used only for development. Before you publish your app, update the configuration to your own credentials.\n\n\n\n\n\n Adding redirect URIs \n\nYour application redirects users to App ID for authentication. After authentication completes, App ID redirects users back to your application. In order for App ID to be able to redirect users back to your app, you need to register the redirect URI. During the sign-in flow, App ID validates the URIs before it allows clients to participate in the authorization workflow, which helps to prevent phishing attacks and grant code leakage. By registering your URI, you're telling App ID that the URI is trusted and it's OK to redirect your users.\n\n\n\n1. Click Authentication Settings to see your URI and token configuration options.\n2. In the Add web redirect URI field, type the URI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_14780-7-2222","score":11.177355,"text":"\nvCenter identity and access management \n\nInside IBM Cloud\u00ae for VMware\u00ae Regulated Workloads, multiple levels of access are available. The automation uses a set of user IDs to perform operations such as adding hosts, clusters, or storage to your VMware instance.\n\n\n\n vCenter and Platform Services Controller user IDs \n\nThe following user IDs are used to add an identity source, which is embedded by default, into vCenter.\n\n\n\nTable 1. vCenter and Platform Services Controller user IDs\n\n User User ID Method Description \n\n Privileged user root SSH Used for VMware configuration such as setting up VMware High Availability and creating distributed switches. Used post deployment to pair primary and secondary vCenter Server instances. \n Privileged user customerroot SSH Created for customer use only. \n IBM automation automation@root_domain <br>(Active Directory user) HTTPS Used post deployment to add and remove hosts and clusters and to deploy and configure virtual machines (VMs) for add-on services. \n Privileged user cloudadmin@root_domain <br>(Active Directory user) HTTPS Created for customer use only. \n\n\n\nHTTPS is used for vCenter setup and configuration, and for VMware operations such as adding hosts, clusters, or storage for vCenter management of resources.\n\n\n\n vCenter access \n\nPrivileged users are granted cloudadmin access to vCenter Server through the vCetner roles.\n\n\n\n\n\n\n\n NSX Manager user IDs \n\n\n\nTable 2. NSX Manager user IDs\n\n User User ID Description \n\n IBM automation ibm_automation <br>(NSX-T\u2122 principal identity user) Used post deployment to manage NSX VTEP IP addresses and to manage host and cluster configuration when hosts and clusters are added or removed. Also used to manage ESG configuration for add-on services that require public network access for licensing, activation, or usage reporting. \n Privileged user admin Created for customer use only. \n\n\n\n\n\n\n\n ESXi host user IDs \n\n\n\nTable 3. ESXi host user IDs\n\n User User ID Description \n\n Privileged user ic4vroot Used post deployment to add more NFS storage, configure routes for that storage, and to run all server validation code. \n Privileged user root Created for customer use only. \n\n\n\n\n\n\n\n Active Directory user IDs \n\n\n\nTable 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-iam-vsphere"},{"document_id":"ibmcld_02734-7-2170","score":11.119856,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02777-1581-3292","score":11.019477,"text":"\nThe endpoint that you choose to call can vary depending on your use case.\n\nNot sure which one works best? Join our [Slack channel](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/get-help-with-ibm-cloud-app-id-related-questions-on-slack) and get advice directly from our development team.\n\nIf you need to work with an API, check out the following image and corresponding information to see how the information is pulled.\n\nZoom\n\n![App ID user profile endpoint options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/user-profile-endpoints.png)\n\nFigure 2. Endpoint options that can be used to access user information\n\n\/oauth\/v4\/<tenantID>\/token\n: After a successful authentication, you receive access and identity tokens that contain the most common user information - a name, picture, or email for example. If you want to add additional information, you can use [custom claims-mapping](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-customizing-tokens) to configure App ID to inject the information to the token before it is returned to you.\n\n\/oauth\/v4\/<tenantID>\/userinfo\n: If you need to see an in-depth view of the user profile information that is returned by an identity provider, you can call the [\/userinfo endpoint](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Authorization_Server_V4\/userInfo). It's recommended to use this endpoint only if the information cannot be mapped to the token as it requires extra network calls.\n\n\/api\/v1\/attributes\n: If your application requires reading and updating custom profile attributes for a currently logged in user, then you can use the \/attributes endpoint. For example, the user wants to update a food preference.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles"},{"document_id":"ibmcld_03966-9450-11507","score":10.9912195,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":19.25574,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16299-7-2120","score":19.215433,"text":"\nOverview: Customizing and developing \n\nThe Watson Assistant user interface makes it easy to build an assistant and deploy it to your customers without writing any code. For advanced users and developers, there are powerful ways you can further customize and extend the capabilities of your assistant.\n\nA deployed assistant includes numerous components that work together to deliver the help your customers need over the channels they use.\n\n![Watson Assistant architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant using a channel such as the web chat or phone integration.\n* Based on natural language understanding, the assistant makes a decision about how to route the customer's request to the appropriate resolution mechanism, which might be an action or a search of existing content.\n* The assistant might also need to communicate with external services or hand off the conversation to a human agent.\n\n\n\nThere are multiple points at which a developer can customize and extend how the assistant behaves, or how it interacts with external services. These customization points include the following:\n\n\n\n* Customizing actions: By writing expressions and editing JSON data, you can extensively customize how an action evaluates step conditions, how it stores data, how it responds to customer input, and how it interacts with channels. (More information coming soon.)\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_02855-20684-22621","score":18.73829,"text":"\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2. To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3. To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Securing the web chat \n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16374-0-2178","score":18.531384,"text":"\n\n\n\n\n\n\n  Supporting global audiences \n\nYou can build an assistant that understands customer messages in any of the languages that are supported by the service. The responses from your assistant are defined by you and can be written in any language you want.\n\nHowever, some of the phrases that are displayed in the web chat widget are part of the web chat itself and do not come from the assistant. By default, these hardcoded phrases are specified in English, but you can apply a different language by adding lines to the embedded web chat script.\n\nThe hardcoded phrases used by the web chat widget are specified in language pack files. The web chat provides language packs that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1.  To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.  To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3.  To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global"},{"document_id":"ibmcld_03166-4588-6408","score":18.461107,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":18.318163,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":18.235495,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03418-1763-3833","score":18.170376,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_16368-14455-16070","score":17.946589,"text":"\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.\n\nFor more information about how user identity information is specified and how it is used, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\n\n\n\n\n Security and administration \n\nSecuring the web chat\n: To secure the web chat, you can use JSON Web Token (JWT) to authenticate users and encrypt private data. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\nControlling the web chat version\n: The web chat code hosted by IBM Cloud is regularly updated with improvements and new features. By default, the embed script automatically uses the latest version of the web chat. To avoid unexpected changes that might affect your website, you might want to control which version of the web chat your website uses, giving you an opportunity to test each new version before you deploy in in production., in order to avoid unexpected changes when a new version is released.\n\nFor more information about web chat versioning, see [Controlling the web chat version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16387-5526-6556","score":17.881798,"text":"\nThis means that enabling web chat security disables the shareable preview link, which does not send JWTs with messages. For more information about the preview link, see [Copying a link to share](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-share-link).\n\nTo enable security, complete the following steps:\n\n\n\n1. On the Security tab of the web chat integration settings, set the Secure your web chat switch to On.\n2. In the Your public key field, paste your [public key](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enableweb-chat-security-enable-prereq).\n\nWatson Assistant uses the public key to verify that incoming messages originate from your website.\n\n\n\nThe following diagram shows the flow of messages between the web chat and the assistant when web chat security is enabled:\n\n![Web chat security message flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-security.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":32.637753,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":32.637753,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":26.849693,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":26.07235,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":24.549196,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":24.007772,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":23.9859,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":23.752748,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-581893-583377","score":23.397375,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_06160-10037-11653","score":22.486937,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10642-18947-20676","score":21.584684,"text":"\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_updateportworx_vpc_up).\n\nIf you have OpenShift Data Foundation deployed in your cluster, follow the steps to [update VPC worker nodes with OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":20.601887,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-9304-11080","score":20.536613,"text":"\nYou can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only. These rules do not impact worker node reloads which means reloading happens immediately when requested.\n\nWhat if I choose not to define a config map?\n: When the config map is not defined, the default is used. By default, a maximum of 20% of all your worker nodes in each cluster can be unavailable during the update process.\n\n\n\n Prerequisites \n\nBefore you update your classic infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is reimaged, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-6354-8294","score":20.483845,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10394-7-1848","score":20.344103,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-9632-11487","score":20.019117,"text":"\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only. These rules do not impact worker node reloads which means reloading happens immediately when requested.\n\nWhat if I choose not to define a config map?\n: When the config map is not defined, the default is used. By default, a maximum of 20% of all your worker nodes in each cluster can be unavailable during the update process.\n\n\n\n Prerequisites \n\nBefore you update your classic infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is reimaged, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10197-7-2062","score":19.673141,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For Red Hat Openshift clusters, check the Red Hat OpenShift on IBM Cloud component.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_05762-7-1980","score":19.671701,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes"},{"document_id":"ibmcld_10642-21503-23376","score":19.58739,"text":"\nTo avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node. However, the replacement worker node is assigned a new private IP address, and loses any custom labels or taints that you applied to the old worker node (worker pool labels and taints are still applied to the replacement worker node).\n\nWhat if I replace multiple worker nodes at the same time?\n: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n\nWhat if a replacement worker node is not created?\n: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off).\n\n\n\n Prerequisites \n\nBefore you update your VPC infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is removed, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-8154-10055","score":19.578886,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.383649139,"ndcg_cut_10":0.383649139}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06209-8154-10055","score":34.148674,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-6354-8294","score":30.088154,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":30.065619,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-7855-9754","score":29.719065,"text":"\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-19911-21816","score":27.261864,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-24247-25944","score":25.894835,"text":"\nOptional: Add capacity to your cluster by [resizing the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool). The pods on the worker node can be rescheduled and continue running on the added worker nodes during the update.\n3. List the worker nodes in your cluster and note the ID and Primary IP of the worker node that you want to update.\n\nibmcloud oc worker ls --cluster CLUSTER\n4. Replace the worker node to update either the patch version or the major.minor version that matches the master version.\n\n\n\n* To update the worker node to the same major.minor version as the master, include the --update option.\n\nibmcloud oc worker replace --cluster CLUSTER --worker WORKER-NODE-ID --update\n* To update the worker node to the latest patch version at the same major.minor version, don't include the --update option.\n\nibmcloud oc worker replace --cluster CLUSTER --worker WORKER-NODE-ID\n\n\n\n5. Repeat these steps for each worker node that you must update.\n6. Optional: After the replaced worker nodes are in a Ready status, [resize the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool) to meet the cluster capacity that you want.\n\n\n\nIf you are running Portworx in your VPC cluster, you must [manually attach your Block Storage for VPC volume to your new worker node.](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_update)\n\n\n\n\n\n Updating VPC worker nodes in the console \n\nYou can update your VPC worker nodes in the console. Before you begin, consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) to the cluster to help avoid downtime for your apps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-20176-22071","score":25.765514,"text":"\nFor more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the VPC worker node to the same patch by using the ibmcloud oc worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-24291-25925","score":25.569016,"text":"\n* If you want to apply a patch update, review the [Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) version change log.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating VPC worker nodes in the CLI \n\nComplete the following steps to update your worker nodes by using the CLI.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs).\n2. Optional: Add capacity to your cluster by [resizing the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool). The pods on the worker node can be rescheduled and continue running on the added worker nodes during the update.\n3. List the worker nodes in your cluster and note the ID and Primary IP of the worker node that you want to update.\n\nibmcloud ks worker ls --cluster CLUSTER\n4. Replace the worker node to update either the patch version or the major.minor version that matches the master version.\n\n\n\n* To update the worker node to the same major.minor version as the master, such as from 1.25 to 1.26, include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID --update\n* To update the worker node to the latest patch version at the same major.minor version, such as from 1.25.8_1530 to 1.25.9_1533, don't include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID\n\n\n\n5. Repeat these steps for each worker node that you must update.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-18717-20364","score":23.828575,"text":"\nComplete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-17950-19477","score":23.354124,"text":"\nComplete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/icons\/icon_hamburger.svg), click Red Hat OpenShift.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.4981892575}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16471-73103-74976","score":15.47677,"text":"\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_07043-1723-3942","score":14.470985,"text":"\nDomain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant. For example, when you apply the Entity enrichment, terms that mention city names or famous people are tagged as locations or people of interest. \n Facet A category by which you can filter search query results. Automatically, facets based on entity types are applied to the query results for Document Retrieval projects and facets based on the parts of speech are applied to Content Mining projects. You can define your own facet categories based on document fields, including fields generated by enrichments, or based on dictionaries or patterns. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets) \n Index As you upload data or connect to data that is stored in an external repository, the data is crawled and ingested. As part of the processing, an index is created to keep track of important information that is recognized from the source. The main difference between a data source and a collection is that content in the data source is crawled, normalized, and indexed as it is added to a collection. \n Project A container for the collections of data that fuel your research or search applications. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects). \n Regular expression A regular expression, also known as a regex, is a standardized format for defining search patterns. You can define patterns with special significance to your application. For example, the bill of materials (BOM) numbers for parts that you manufacture might have a standard syntax of two uppercase letters followed by four numbers (GT2345). You can teach Discovery to recognize BOM mentions by adding a regular expression that can recognize and tag occurrences of the pattern in text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-glossary"},{"document_id":"ibmcld_16471-71623-73502","score":14.382904,"text":"\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_04826-38948-40745","score":14.021113,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage-cli-plugin?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_04457-38780-40577","score":14.021113,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ic-cos-cli"},{"document_id":"ibmcld_04981-38915-40712","score":14.021113,"text":"\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request\/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:\/\/ prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli"},{"document_id":"ibmcld_04996-1622-3532","score":13.327729,"text":"\nInvalidBucketName The specified bucket is not valid. 400 Bad Request \n InvalidBucketState The request is not valid with the current state of the bucket. 409 Conflict \n InvalidDigest The Content-MD5 that you specified is not valid. 400 Bad Request \n InvalidLocationConstraint The specified location constraint is not valid. For more information about regions, see How to Select a Region for Your Buckets. 400 Bad Request \n InvalidObjectState The operation is not valid for the current state of the object. 403 Forbidden \n InvalidPart One or more of the specified parts might not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag. 400 Bad Request \n InvalidPartOrder The list of parts was not in ascending order. Parts list must specified in order by part number. 400 Bad Request \n InvalidRange The requested range cannot be satisfied. 416 Requested Range Not Satisfiable \n InvalidRequest Please use AWS4-HMAC-SHA256. 400 Bad Request \n InvalidSecurity The provided security credentials are not valid. 403 Forbidden \n InvalidURI Mightn't parse the specified URI. 400 Bad Request \n KeyTooLong Your key is too long. 400 Bad Request \n MalformedPOSTRequest The body of your POST request is not well-formed multipart\/form-data. 400 Bad Request \n MalformedXML The XML you provided was not well-formed or did not validate against our published schema. 400 Bad Request \n MaxMessageLengthExceeded Your request was too large. 400 Bad Request \n MaxPostPreDataLengthExceededError Your POST request fields preceding the upload file were too large. 400 Bad Request \n MetadataTooLarge Your metadata headers exceed the maximum allowed metadata size. 400 Bad Request \n MethodNotAllowed The specified method is not allowed against this resource. 405 Method Not Allowed \n MissingContentLength You must provide the Content-Length HTTP header. 411 Length Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-common"},{"document_id":"ibmcld_07070-7-1856","score":12.901529,"text":"\nUse built-in Watson NLP to find common terms \n\nTake advantage of award-winning Watson Natural Language Processing (NLP) capabilities by adding prebuilt enrichments to your documents.\n\nWith Watson NLP, you can identify and tag meaningful information in your collections so you can understand what it all means and make more informed decisions.\n\nThe following Watson NLP enrichments are available:\n\n\n\n* [Entities](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlunlu-entities): Recognizes proper nouns such as people, cities, and organizations that are mentioned in the content.\n* [Keywords](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlunlu-keywords): Recognizes significant terms in your content.\n* [Part of Speech](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlunlu-pos): Identifies the parts of speech (nouns and verbs, for example) in the content.\n* [Sentiment](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlu-sentiment): Understands the overall sentiment of the content.\n\n\n\nThe following other pretrained enrichments are available with Discovery:\n\n\n\n* [Contracts](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-contracts-schema)\n* [Document structure](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-sdu-pretrained)\n* [Table understanding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-understanding_tables)\n\n\n\n\n\n Watson NLP enrichments \n\nFor example, the following screen capture shows a transcript of the US Declaration of Independence that was added to a Discovery collection where the Entities and Keywords enrichments are enabled. The mentions that are recognized by the enrichments are highlighted in the document text.\n\nZoom\n\n![Shows an excerpt of the US Declaration of Independence with several terms highlighted.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlu"},{"document_id":"ibmcld_10087-30532-32033","score":12.899618,"text":"\nibmcloud oc worker ls --cluster <cluster_name_or_ID>\n\nWhen the worker nodes are ready, the worker node State changes to normal and the Status changes to Ready. When the node Status changes to Ready, you can access the cluster. Note that even if the cluster is ready, some parts of the cluster that are used by other services, such as Ingress secrets or registry image pull secrets, might still be in process.\n\nID Public IP Private IP Flavor State Status Zone Version\nkube-blrs3b1d0p0p2f7haq0g-mycluster-default-000001f7 169.xx.xxx.xxx 10.xxx.xx.xxx b3c.4x16.encrypted normal Ready dal10 4.11.42_1544_openshift\n\nEvery worker node is assigned a unique worker node ID and domain name that must not be changed manually after the cluster is created. If you change the ID or domain name, the Red Hat OpenShift master cannot manage your cluster.\n\n\n\nYour cluster is ready for your workloads! You might also want to [add a tag to your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workerscluster_tags), such as the team or billing department that uses the cluster, to help manage IBM Cloud resources. For more ideas of what to do with your cluster, review the [Next steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clustersnext_steps).\n\n\n\n\n\n Example commands to create VPC clusters \n\nVPC Gen 2 cluster flavors with instance storage are available for allowlisted accounts. To get added to the allowlist, [open a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) with support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2"},{"document_id":"ibmcld_10088-30545-32046","score":12.899618,"text":"\nibmcloud oc worker ls --cluster <cluster_name_or_ID>\n\nWhen the worker nodes are ready, the worker node State changes to normal and the Status changes to Ready. When the node Status changes to Ready, you can access the cluster. Note that even if the cluster is ready, some parts of the cluster that are used by other services, such as Ingress secrets or registry image pull secrets, might still be in process.\n\nID Public IP Private IP Flavor State Status Zone Version\nkube-blrs3b1d0p0p2f7haq0g-mycluster-default-000001f7 169.xx.xxx.xxx 10.xxx.xx.xxx b3c.4x16.encrypted normal Ready dal10 4.11.42_1544_openshift\n\nEvery worker node is assigned a unique worker node ID and domain name that must not be changed manually after the cluster is created. If you change the ID or domain name, the Red Hat OpenShift master cannot manage your cluster.\n\n\n\nYour cluster is ready for your workloads! You might also want to [add a tag to your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workerscluster_tags), such as the team or billing department that uses the cluster, to help manage IBM Cloud resources. For more ideas of what to do with your cluster, review the [Next steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clustersnext_steps).\n\n\n\n\n\n Example commands to create VPC clusters \n\nVPC Gen 2 cluster flavors with instance storage are available for allowlisted accounts. To get added to the allowlist, [open a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) with support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":26.871807,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":26.871807,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":20.808775,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":20.05133,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":19.942472,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":19.498564,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":19.138182,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10596-9883-11854","score":19.105062,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10382-0-1086","score":18.764347,"text":"\n\n\n\n\n\n\n  What if my OpenShift Data Foundation issue is still unresolved? \n\nIf your ODF issue is still unresolved or is not addressed in the troubleshooting steps, contact ODF support by raising a case in the Red Hat customer portal.\n\n\n\n1.  [Access the Red Hat Customer Portal](https:\/\/access.redhat.com) and sign in with your support credentials.\n2.  Find the Troubleshoot a product issue section and select Red Hat OpenShift Data Foundation.\n3.  Select the version of your ODF instance.\n4.  Click Continue.\n5.  Use the Red Hat must-gather tool to collect data about your cluster in a compressed file. For more information, see [Gathering data about your cluster](https:\/\/docs.openshift.com\/container-platform\/4.6\/support\/gathering-cluster-data.htmlgathering-data-specific-features_gathering-cluster-data).\n\noc adm must-gather --image=registry.redhat.io\/ocs4\/ocs-must-gather-rhel8:latest --dest-dir=ocs_mustgather\n6.  Follow the prompts to describe the issue you have. Attach the file with the must-gather data you collected earlier.\n7.  Click Open a case to submit your issue.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ocs-error-unresolved"},{"document_id":"ibmcld_05713-581893-583377","score":18.72373,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":20.08187,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-1330-3318","score":15.411225,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-4083-5561","score":10.972211,"text":"\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https:\/\/docs.datastax.com\/en\/dsbulk\/doc\/dsbulk\/reference\/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https:\/\/docs.datastax.com\/en\/dse\/6.0\/cql\/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https:\/\/docs.datastax.com\/en\/astra\/docs\/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_08671-105421-106674","score":6.089968,"text":"\n* [Hyper Protect Crypto Services notices and information](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-open-source-licensesnotice)\n* [Hosting appliance notices and information](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-open-source-licenseshosting-appliance-notice)\n\n\n\n\n\n\n\n FAQs \n\n[General FAQs](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-basics)\n\n\n\n* [What's IBM Cloud Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-is-hpcs)\n* [What is Unified Key Orchestrator?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-is-uko)\n* [What is a key management service?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-key-management)\n* [What is Hardware Security Module?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-is-hsm)\n* [What is a cloud HSM?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-is-cloud-hsm)\n* [How does Hyper Protect Crypto Services provide a single-tenant cloud service?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-single-tenant)\n* [What are the responsibilities of users and IBM Cloud for Hyper Protect Crypto Services?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08671-32820-34040","score":5.886618,"text":"\n* [Added: Hyper Protect Crypto Services expands into the Frankfurt region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadded-frankfurt-region)\n* [Added: IBM Cloud service integration](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadded-service-integration)\n\n\n\n* [30 June 2019](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-June2019)\n\n\n\n* [Added: Hyper Protect Crypto Services expands into Sydney region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadded-sydney-region)\n\n\n\n* [31 March 2019](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-March2019)\n\n\n\n* [Hyper Protect Crypto Services is generally available](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newga-201903)\n* [High availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newha-dr-new)\n* [Scalability](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newscalability-new)\n\n\n\n* [28 February 2019](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-Feb2019)\n\n\n\n* [Hyper Protect Crypto Services Beta is available](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newbeta-201902)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_10534-1033-2260","score":5.732506,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_08671-27813-28990","score":5.681277,"text":"\n* [Added: Synchronizing protected resources associated with root keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadd-sync-resources)\n* [Added: Using Virtual Private Endpoints for VPC](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadd-vpe-for-vpc)\n* [Updated: The cryptography algorithm that is used to generate signature keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newupdate-signature-key-algorithm)\n\n\n\n* [28 February 2021](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-february2021)\n\n\n\n[Added: Key verification by using the PKCS #11 API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadd-key-verification)\n* [Added: Support for the Schnorr algorithm](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadd-schnorr)\n\n\n\n* [31 January 2021](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-january2021)\n\n\n\n* [Added: Support for a single-tenant KMIP adapter](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newadd-support-kmip-adapter)\n\n\n\n* [31 December 2020](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-newhs-crypto-december2020)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_10534-148466-149913","score":5.60664,"text":"\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-owner)\n* [How does my worker node setup look?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-setup)\n\n\n\n* [Network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork)\n\n\n\n* [Network segmentation and privacy for classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation)\n* [What network traffic is allowed for my Classic cluster by default?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitydefault-network-traffic-allowed)\n* [What is network segmentation and how can I set it up for a Classic cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork-segmentation-setup)\n* [What else can I do to reduce the surface for external attacks for Classic clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityexternal-what-else)\n* [What if I want to connect my cluster to an on-prem data center?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-284670-286038","score":5.60664,"text":"\n[Adding services by using Helm charts](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmhelm)\n\n\n\n* [About Helm in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmabout-helm)\n\n\n\n* [What is Helm and how do I use it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmwhat-is-helm)\n* [What Helm charts are supported in Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmsupported-charts)\n\n\n\n* [Installing Helm v3 in your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helminstall_v3)\n\n\n\n[Adding services by using IBM Cloud service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingservice-binding)\n\n\n\n* [About service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-about)\n\n\n\n* [What types of services can I bind to my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-types)\n* [What is IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-what)\n* [I already have an IBM Cloud service. Can I still use IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-existing)\n* [What if I want to use service credentials that use the private cloud service endpoint?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-151674-153233","score":5.60664,"text":"\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-owner)\n* [How does my worker node setup look?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-setup)\n\n\n\n* [Network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork)\n\n\n\n* [Network segmentation and privacy for classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation)\n* [What network traffic is allowed for my Classic cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitydefault-network-traffic-allowed)\n* [What is network segmentation and how can I set it up for a Classic cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork-segmentation-setup)\n* [What else can I do to reduce the surface for external attacks for Classic clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityexternal-what-else)\n* [What if I want to connect my cluster to an on-prem data center?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-network-traffic-default)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-541541-542782","score":9.289173,"text":"\n[Worker node states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-state-reference)\n\n\n\n* [Critical state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-critical)\n* [Deleting state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-deleting)\n* [Deleted state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-deleted)\n* [Deployed state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-deployed)\n* [Deploying state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-deploying)\n* [Deploy_failed state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-deploy-failed)\n* [Normal state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-normal)\n* [Provisioned state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provisioned)\n* [Provisioning state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provisioning)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-577485-578919","score":9.270572,"text":"\n* [Step 4: Review the infrastructure provider for the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodesworker-debug-rev-infra)\n\n\n\n\n\n[Debugging worker nodes with Kubernetes API](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-kube-nodesdebug-kube-nodes)\n\n[Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-state-reference)\n\n\n\n* [Critical state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-critical)\n* [Deleting state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deleting)\n* [Deleted state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deleted)\n* [Deployed state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deployed)\n* [Deploying state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deploying)\n* [Deploy_failed state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deploy-failed)\n* [Normal state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-normal)\n* [Provisioned state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-provisioned)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05713-578539-579971","score":9.258048,"text":"\n* [Deploy_failed state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-deploy-failed)\n* [Normal state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-normal)\n* [Provisioned state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-provisioned)\n* [Provisioning state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-provisioning)\n* [Provision pending state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-provision-pending)\n* [Provision_failed state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-provision-failed)\n* [Reloading state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-reloading)\n* [Reloading_failed state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-reloading-failed)\n* [Reload_pending state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-reload-pending)\n* [Unknown state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-unknown)\n* [Warning state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-referenceworker-node-warning)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05891-109363-111311","score":9.225505,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5. Make your worker node available for pod scheduling.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_10534-542410-543689","score":9.224735,"text":"\n* [Normal state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-normal)\n* [Provisioned state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provisioned)\n* [Provisioning state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provisioning)\n* [Provision pending state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provision-pending)\n* [Provision_failed state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-provision-failed)\n* [Reloading state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-reloading)\n* [Reloading_failed state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-reloading-failed)\n* [Reload_pending state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-reload-pending)\n* [Unknown state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-unknown)\n* [Warning state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-worker-node-state-referenceworker-node-warning)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10290-111044-112870","score":9.212525,"text":"\nDuring the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10290-107432-109320","score":9.199092,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\noc adm drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_04489-110010-111892","score":9.199092,"text":"\nThe worker node IP address remains the same after the reboot operation.\n\nRebooting a worker node can cause data corruption on the worker node. Use this command with caution and when you know that a reboot can help recover your worker node. In all other cases, [reload your worker node](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clics_worker_reload) instead.\n\nBefore you reboot your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to remove.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Force pods to be removed from your worker node and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Replace <worker_name> with the private IP address of the worker node that you previously retrieved.\n\nkubectl drain <worker_name>\n\nThis process can take a few minutes.\n3. Reboot the worker node. Use the worker ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reboot --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n4. Wait about 5 minutes before you make your worker node available for pod scheduling to ensure that the reboot is finished. During the reboot, the state of your worker node does not change. The reboot of a worker node is usually completed in a few seconds.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-113289-115164","score":9.191897,"text":"\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.\n\n\n\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-113908-115783","score":9.191897,"text":"\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node. Rescheduling pods helps to avoid downtime for your app or data corruption on your worker node.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to reload.\n\nkubectl get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Reload the worker node. As part of the reload process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud ks worker reload --cluster <cluster_name_or_ID> --worker <worker_name_or_ID>\n3. Wait for the reload to complete. When your worker node is in a Normal state, the worker node becomes available for pod scheduling again.\n\n\n\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10422-7-1877","score":21.224686,"text":"\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_11439-13936-14359","score":21.171253,"text":"\n(https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqssnap-storage-req)\n* [Does the snapshot and volume clone supports any safeguard policy?](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqssnap-clone-safeguard)\n* [Can you tell me more about the backup process using the PowerHA Toolkit for IBM i?](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqspoweha-toolkit)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-volume-snapshot-clone"},{"document_id":"ibmcld_14492-7270-9227","score":20.844696,"text":"\n* If the cluster is not attached to a subscription, a message is displayed with a link that you can use to find this cluster in the Red Hat customer portal. Use the link to assign the appropriate subscription and entitlement to the cluster.\n\n\n\nIf you do not have enough subscriptions and entitlements, contact a Red Hat Sales representative.\n\n\n\nFor more information, see [Red Hat OpenShift subscriptions information and known issues](https:\/\/access.redhat.com\/articles\/4105561).\n\n\n\n\n\n Configuring authentication \n\nBy default, the Red Hat OpenShift installer creates a kubeadmin user that you can use to log in to the cluster. Create authentication backends or more users, as needed, for security purposes.\n\nFor more information about how to configure Red Hat OpenShift authentication, see [Understanding authentication](https:\/\/docs.openshift.com\/container-platform\/4.7\/authentication\/understanding-authentication.html).\n\n\n\n\n\n Updating your Red Hat OpenShift cluster \n\nFor more information about updating Red Hat OpenShift, see:\n\n\n\n* [Updating a cluster within a minor version using the web console](https:\/\/docs.openshift.com\/container-platform\/4.7\/updating\/updating-cluster-within-minor.html).\n* [Updating a cluster within a minor version using the CLI](https:\/\/docs.openshift.com\/container-platform\/4.7\/updating\/updating-cluster-cli.html).\n\n\n\n\n\n\n\n Considerations when you install Red Hat OpenShift for VMware \n\n\n\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10575-6525-7331","score":20.793709,"text":"\nFor more information about how to set up IBM Blockchain in Red Hat OpenShift on IBM Cloud, see [About IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-get-started-ibp). \n Other third-party integrations You can install many other integrations into your Red Hat OpenShift cluster, such as through the Red Hat OpenShift catalog, the [Red Hat Marketplace](https:\/\/marketplace.redhat.com\/en-us\/documentation\/getting-started), Operators, Helm charts, or do-it-yourself open source software installations. Make sure that these apps are compatible with your Red Hat OpenShift cluster and Kubernetes version. For example, you might need to [update the app](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) for the installation to succeed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-supported_integrations"},{"document_id":"ibmcld_14492-1397-3188","score":20.75267,"text":"\nFor more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS\n\n\n\nFor more information about the architecture, see [Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch).\n\n\n\n Technical specifications for Red Hat OpenShift for VMware \n\nThe following capacity requirements apply only if your vCenter Server instance is using vSAN\u2122 storage. If you are using NFS, a new 2-TB NFS datastore, which is dedicated to Red Hat OpenShift, is ordered.\n\nThe solution topology has the following requirements:\n\n\n\n* 9 CPUs\n* 120 GB RAM\n* 1,170 GB storage\n\n\n\nFor more information about resource requirements and capacity checking, see [Resource requirements for services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-resource-requirements).\n\nTo successfully deploy Red Hat OpenShift for VMware on vCenter Server, you must have a Red Hat account and the pull secret key from your account. All Red Hat accounts have an associated pull secret, which you can retrieve by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned). You must purchase Red Hat support entitlements through Red Hat and, if needed, send information for all Red Hat OpenShift support issues to Red Hat.\n\n\n\n Selection of the target cluster for installation \n\nDuring deployment and Day 2 operations, you are prompted for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10495-9135-10569","score":20.72634,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_07578-408722-410595","score":20.627693,"text":"\nAlso, note that after resizing a worker pool to 2, you can't later resize back down to 1 worker node.\n* Which Red Hat OpenShift versions does the service support?\n\nRed Hat OpenShift on IBM Cloud concurrently supports multiple versions of Red Hat OpenShift. When a new version (n) is released, versions up to 2 behind (n-2) are supported. Versions more than 2 behind the latest (n-3) are first deprecated and then unsupported.\n\nFor more information about supported versions and update actions that you must take to move from one version to another, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Which worker node operating systems does the service support?\n\nFor a list of supported worker node operated systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Where is the service available?\n\nRed Hat OpenShift on IBM Cloud is available worldwide. You can create clusters in every supported Red Hat OpenShift on IBM Cloud region.\n\nFor more information about supported regions, see [Locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zonesregions-and-zones).\n* Is the service highly available?\n\nYes. By default, Red Hat OpenShift on IBM Cloud sets up many components such as the cluster master with replicas, anti-affinity, and other options to increase the high availability (HA) of the service. You can increase the redundancy and failure toleration of your cluster worker nodes, storage, networking, and workloads by configuring them in a highly available architecture. For an overview of the default setup and your options to increase HA, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-408696-410569","score":20.627693,"text":"\nAlso, note that after resizing a worker pool to 2, you can't later resize back down to 1 worker node.\n* Which Red Hat OpenShift versions does the service support?\n\nRed Hat OpenShift on IBM Cloud concurrently supports multiple versions of Red Hat OpenShift. When a new version (n) is released, versions up to 2 behind (n-2) are supported. Versions more than 2 behind the latest (n-3) are first deprecated and then unsupported.\n\nFor more information about supported versions and update actions that you must take to move from one version to another, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Which worker node operating systems does the service support?\n\nFor a list of supported worker node operated systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Where is the service available?\n\nRed Hat OpenShift on IBM Cloud is available worldwide. You can create clusters in every supported Red Hat OpenShift on IBM Cloud region.\n\nFor more information about supported regions, see [Locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zonesregions-and-zones).\n* Is the service highly available?\n\nYes. By default, Red Hat OpenShift on IBM Cloud sets up many components such as the cluster master with replicas, anti-affinity, and other options to increase the high availability (HA) of the service. You can increase the redundancy and failure toleration of your cluster worker nodes, storage, networking, and workloads by configuring them in a highly available architecture. For an overview of the default setup and your options to increase HA, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10173-3883-5592","score":20.517136,"text":"\nFor more information about the pod security admission controller, see [Configuring Pod Security admission](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod-security-admission).\n\n\n\n Update before master \n\nThe following table shows the actions that you must take before you [update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster).\n\n\n\nChanges to make before you update the master to Red Hat OpenShift 4.11\n\n Type Description \n\n Unsupported: Deprecated and removed Red Hat OpenShift features For more information, review the [Red Hat OpenShift version 4.11 deprecated and removed features](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-deprecated-removed-features). \n Known Red Hat OpenShift issues For more information about possible required actions, review [Red Hat OpenShift version 4.11 known issues](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-known-issues). \n LegacyServiceAccountTokenNoAutoGeneration feature gate is enabled For more information, review possible required actions in the LegacyServiceAccountTokenNoAutoGeneration is on by default section of the[Red Hat OpenShift version 4.11 notable technical changes](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-notable-technical-changes). \n Red Hat OpenShift web console redirect changed Cluster server URL no longer redirects to the Red Hat OpenShift web console. You must add \/console to the URL for the redirect. \n\n\n\n\n\n\n\n Update after master \n\n\n\nChanges to make after you update the master to Red Hat OpenShift 4.11\n\n Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_411"},{"document_id":"ibmcld_10214-7502-9481","score":20.514557,"text":"\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference) or in the following table's links.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.167160455}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14913-0-1238","score":17.949188,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_07953-7-2429","score":17.305914,"text":"\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_07717-6101-8054","score":17.102087,"text":"\nin deployed artifacts<br> * Check whether Virtual Private Cloud (VPC) has no rules in the default security group<br> * Check whether App ID Cloud Directory users aren't able to self-sign up to applications<br> * Check whether all network interfaces of a virtual server instance have at least one Virtual Private Cloud (VPC) security group attached<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether Virtual Servers for VPC instance has the minimum # interfaces<br> * Check whether App ID redirect URIs are using HTTPS only<br> * Check whether Cloud Internet Services (CIS) has TLS mode set to End-to-End CA signed<br> * Check whether Application Load Balancer for VPC pool uses the HTTPS protocol for HTTPS listeners<br> * Check whether Application Load Balancer for VPC uses HTTPS (SSL & TLS) instead of HTTP<br> * Check whether Cloud Object Storage public access is disabled in IAM settings (not applicable to ACLs managed using S3 APIs)<br> * Check whether App ID anonymous authentication is disabled<br> * Check whether App ID avoid password reuse policy is enabled<br> * Check whether App ID user profile updates from client apps is disabled<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0\/0 to RDP port<br> * Check whether App ID redirect URIs are not using localhost or 127.0.0.1<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0\/0 to SSH port<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0\/0 to any port<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nInformation systems can provide a wide variety of functions and services. Some of the functions and services, provided by default, may not be necessary to support essential organizational operations (e.g., key missions, functions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-7"},{"document_id":"ibmcld_11340-1665-3637","score":16.43985,"text":"\nYou can use the service access roles to define what users can do with Power Systems Virtual Server functions. The following table displays the IAM service access roles and the corresponding actions a user can complete with Power Systems Virtual Server:\n\n\n\nTable 2. IAM service access roles\n\n Service access role Description of actions \n\n Reader View all resources (such as SSH keys, storage volumes, and network settings). You cannot make any changes to the resources. \n Manager You can configure all resources. The following are some of the actions you can perform:<br><br><br><br> * Create instances<br> * Increase storage volume sizes<br> * Create SSH keys<br> * Modify network settings<br> * Create boot images<br> * Delete storage volumes<br><br><br> \n\n\n\n\n\n\n\n Access roles requirements for Power System Virtual Server \n\nPower Systems Virtual Server requires additional access for features such as Direct Link, Transit Gateway service, Virtual Private Cloud, and so on. You may require additional access based on your resource requirements. For example, to create a Cloud connection you will need Editor access to Direct Link service.\n\nThe following table displays the additional access roles required for the corresponding type of services that is allowed by Power Systems Virtual Server:\n\n\n\nTable 3. Additional access roles\n\n Additional access role Resources Attributes \n\n Editor, Manager, Operator, Reader, Viewer Power Systems Virtual Server service \n Editor, Manager, Operator, Reader, Viewer, VPN Client VPC Infrastructure Services service \n Editor, Operator, Viewer Transit Gateway service \n Reader, Viewer All resources in account (Including future IAM enabled services) \n Editor, Operator, Viewer Direct Link service \n Viewer All resource group \n\n\n\n\n\n\n\n User access scenarios \n\nSee [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources) for information on how to manage or assign access by using IAM policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-managing-resources-and-users"},{"document_id":"ibmcld_04709-1717-3966","score":15.689822,"text":"\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"},{"document_id":"ibmcld_15810-70646-72492","score":15.57501,"text":"\nApplication Load Balancer (ALB) for VPC\n: Application load balancers now support HTTP\/HTTPS compression, which you use to compress data that is transmitted to your users. For more information, see [Compression (HTTP\/HTTPS only)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-advanced-traffic-managementcompression).\n\nHigh Availability (HA) Virtual Network Function (VNF) support\n: Support for a highly available, highly resilient virtual network functions can be achieved by using the \"routing mode\" feature of the IBM Cloud Network Load Balancer (NLB) for VPC. For more information, see [About virtual network functions over VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf) and [About HA VNF deployments](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf-ha).\n\nUpdates to Getting started with IBM Cloud VPC button\n: The \"Getting started with IBM Cloud VPC\" button now includes access to tours that are specific to what you are doing on the IBM console. If a tour is not available, the button takes you to the VPC List view.\n\n\n\n\n\n 06 January 2022 \n\nUI update when you create a virtual server\n: When you create a virtual server, the UI is updated to include a link in the Operating system section that opens a panel that contains information about the image lifecycle.\n\n\n\n\n\n\n\n December 2021 \n\n\n\n 16 December 2021 \n\nFile Storage for VPC (LA)\n: IBM Cloud\u00ae File Storage for VPC is now available for customers with special approval to preview this service in the Washington, Dallas, Frankfurt, London, Sydney, and Tokyo regions.\n: For more information about this service, see [About File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n\n\n\n\n\n 09 December 2021 \n\nSecurity updates\n: The following stock images were refreshed with the most recent fixes and security updates.\n\n\n\n* Debian version 10\n* CentOS version 7","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-release-notes"},{"document_id":"ibmcld_14282-9296-10826","score":15.483454,"text":"\nThe NSX Controller uses Unicast mode with virtual tunnel endpoints (VTEPS) to provide MAC learning and other functions to allow VXLAN Broadcast, Unknown unicast, and Multicast (BUM) traffic within a logical switch. The unicast mode replicates all the BUM traffic locally on the host and requires no physical network configuration outside of Layer 3 connectivity between VTEPS. NSX Controllers are deployed by the NSX Manager as a minimum set of three controller nodes, and various other nodes to support (distributed) Layer 3 routing services. All of the nodes are deployed as virtual machines and are managed by the NSX Manager on an ESX Management Cluster at IBM Cloud.\n\n\n\n\n\n NSX Edge \n\nNSX Edge provides network edge security and gateway services to isolate a virtualized network. You can install an NSX Edge either as a logical (distributed) router or as a services gateway. The NSX Edge logical (distributed) router provides East-West distributed routing with tenant IP address space and data path isolation. Virtual machines or workloads that reside on the same host on different subnets can communicate with one another without having to traverse a traditional routing interface. The NSX Edge Gateway connects isolated stub networks to shared (uplink) networks by providing common gateway services such as DHCP, VPN, NAT, dynamic routing, and Load Balancing. Common deployments of NSX Edge include in the DMZ, VPN extranets, and multi-tenant cloud environments where the NSX Edge creates virtual boundaries for each tenant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_13146-3104-5201","score":15.36057,"text":"\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.\n\nWith ibmcloud and its plugins, you can automate the creation and configuration of your cloud resources. Virtual Servers, Kubernetes clusters, Cloud Functions, Code Engine, and services, you can provision all of them from the command line.\n\nTerraform enables you to safely and predictably create, change, and improve infrastructure. It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned. It is infrastructure as code. You write down what your infrastructure should look like and Terraform will create, update, remove cloud resources as needed.\n\nTo support a multi-cloud approach, Terraform works with providers. A provider is responsible for understanding API interactions and exposing resources. IBM Cloud has [its provider for Terraform](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs), enabling users of IBM Cloud to manage resources with Terraform. Although Terraform is categorized as infrastructure as code, it is not limited to Infrastructure-As-A-Service resources. The IBM Cloud Provider for Terraform supports IaaS (bare metal, virtual machine, network services, etc.), CaaS (Kubernetes Service and Kubernetes clusters), PaaS services, and serverless (Cloud Functions and Code Engine) resources.\n\n\n\n\n\n Step 2: Write scripts to automate the deployment \n\nAs you start describing your infrastructure-as-code, it is critical to treat files you create as regular code. Thus, store them in a source control management system. Over time this will bring benefits such as using the source control review workflow to validate changes and continuous integration to automatically deploy infrastructure changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-plan-create-update-deployments"},{"document_id":"ibmcld_11109-5333-7558","score":15.172126,"text":"\nFor short-term emergencies where the original site is unavailable for a period of time, but servers and storage remain intact, a delta-resynch might fit the need to bring the operation back to on premises.\n\nFor other emergencies, that have forced a change to the site, server, or storage in the original on premises, it might require a full resynchronization of data, so the fallback will happen tidily at the most convenient time after the sync point has been achieved.\n\n\n\n\n\n Cloud networking (LAN) \n\nHaving a DR on cloud might also imply that you need to rebuild your network structures to adapt to the network structures and constraints on the cloud provider. In some cases, you are be forced to use Software Defined Network (SDN) and Network Functions Virtualization (NFV) to reproduce your complex enterprise network layout. A careful planning and evaluation of performance and scalability limitation is essential to assure your reprovisioned compute can work properly.\n\n\n\n\n\n Cloud networking (WAN) \n\nAll the external networks connected to your primary (failed) site must be rerouted to the alternative cloud site. Different options are available, and you need to evaluate what options best fit your requirements. Consider the charges associated with the use of the network, such as download and upload charges, when using the cloud provider resources, as they might add a substantial cost to your DR total cost of ownership (TCO).\n\nWhen implementing a DR on cloud, the solution is simplified by leveraging the same technology in the primary and secondary sites.\n\n\n\n\n\n Full versus partial failover \n\nPartial failover is used to potentially increase the availability of the services by allowing to run and recover some of the services in DR while all the others are still running production on the customer data center.\n\nPartial failover carries a lot more complexity in the network design that is associated with the solution, as it requires an extension of production site networks to the DR site that can happen on Layer 2 (such as L2TPv3, Cisco Overlay Transport Virtualization), Layer 3 (such as Cisco Locator\/ID Separation protocol (LISP), Virtual Private LAN Services (VPLS), or Software Defined Network technique.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-networking-aspects"},{"document_id":"ibmcld_07578-959019-961143","score":15.169215,"text":"\nPrivate load balancer names can be resolved publicly, but the addresses they resolve to are not routable from the internet, and can only be reached from inside your own private network environment.\n* Does the NLB support layer 7 switching?\n\nNo. The network load balancer does not support layer 7 switching.\n* What's the maximum number of front-end listeners I can define with my load balancer?\n\nYou can define a maximum of ten front-end listeners for an NLB.\n* What's the maximum number of virtual server instances I can attach to my back-end pool?\n\nYou can attach a maximum of 50 virtual server instances to your back-end pool for a network load balancer.\n* Is an NLB horizontally scalable?\n\nNo. A network load balancer is not horizontally scalable.\n* What are the default settings and allowed values for health check parameters?\n\nThe following default settings apply to network load balancer health check parameters:\n\n\n\n* Health check interval: Five seconds, and the range is 2 - 60 seconds.\n* Health check response timeout: Two seconds, and the range is 1 - 59 seconds.\n* Maximum retry attempts: Two retry attempts, and the range is 1-10 retries.\n\n\n\nThe health check response timeout value must be less than the health check interval value.\n* Is the network load balancer IP address fixed?\n\nThe IP address is fixed for both public and private network load balancers. However, route mode NLBs toggle between primary and standby appliance IPs throughput their lifetime.\n* Does IBM complete quarterly ASV scans of data-plane LBaaS appliances?\n\nApproved Scanning Vendor (ASV) quarterly scanning is a requirement of the Payment Card Industry (PCI) Security Standards Council. ASV scanning of LBaaS data-plane appliances is solely a customer responsibility. IBM does not use ASVs to scan data-plane appliances because these scans can negatively impact customer workload functions and performance.\n* What is a snapshot?\n\nSnapshots are a point-in-time copy of your Block Storage for VPC boot or data volume that you manually create. To create a snapshot, the original volume must be attached to a running virtual server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02395-4989-6827","score":23.61475,"text":"\nHow do I access and query data that has been archived for long term storage in COS? \n\nTo access data, you can download the archived file locally.\n\nTo query the data, you can also use a service like SQL Query to query your COS archives and get information based on queries that you define. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery).\n\n\n\n\n\n How do I configure archiving for my instance? \n\nTo configure archiving see [Archiving events to IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving).\n\n\n\n\n\n I get an error when I try to provision an Activity Tracker instance \n\nYou can only have 1 instance of the IBM Cloud Activity Tracker service per region and an instance already exists in the region.\n\nWhen an auditing instance already exists in a region, you get a message when you try to provision an auditing instance a second time.\n\nMost likely, your account administrator has already provisioned the auditing instances and has not given you permisisons to see or work with them.\n\nTo see auditing instances, you must have IAM platform permissions for the IBM Cloud Activity Tracker service.\n\nTherefore, if you cannot see any Auditing instances when you [launch the Activity Tracker observability dashboard](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-launch), check that you have permissions to at least view them. You need at least the viewer platform role to see the auditing instances. To learn more about IAM permissions, see [Managing access with IAM](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-iam).\n\n\n\n\n\n How do I create an API key? \n\nComplete the following steps:\n\n\n\n1. Log in to IBM Cloud with the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started).\n\nibmcloud login","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_faq"},{"document_id":"ibmcld_16727-735405-737229","score":23.61475,"text":"\n* How do I access and query data that has been archived for long term storage in COS?\n\nTo access data, you can download the archived file locally.\n\nTo query the data, you can also use a service like SQL Query to query your COS archives and get information based on queries that you define. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery).\n* How do I configure archiving for my instance?\n\nTo configure archiving see [Archiving events to IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving).\n* I get an error when I try to provision an Activity Tracker instance\n\nYou can only have 1 instance of the IBM Cloud Activity Tracker service per region and an instance already exists in the region.\n\nWhen an auditing instance already exists in a region, you get a message when you try to provision an auditing instance a second time.\n\nMost likely, your account administrator has already provisioned the auditing instances and has not given you permisisons to see or work with them.\n\nTo see auditing instances, you must have IAM platform permissions for the IBM Cloud Activity Tracker service.\n\nTherefore, if you cannot see any Auditing instances when you [launch the Activity Tracker observability dashboard](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-launch), check that you have permissions to at least view them. You need at least the viewer platform role to see the auditing instances. To learn more about IAM permissions, see [Managing access with IAM](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-iam).\n* How do I create an API key?\n\nComplete the following steps:\n\n\n\n1. Log in to IBM Cloud with the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started).\n\nibmcloud login","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_06518-4013-5586","score":22.45535,"text":"\nIncreasing memory decreases the amount that MongoDB reads or writes to disk, so additional memory might alleviate pressure on disk I\/O by supporting more caching.\n\nMore information about the WiredTiger cache is in the [MongoDB documentation](https:\/\/docs.mongodb.com\/manual\/faq\/storage\/to-what-size-should-i-set-the-wiredtiger-internal-cache).\n\n\n\n\n\n Query Performance \n\nThe MongoDB documentation has multiple resources on query performance, including a how-to on [analyzing query performance](https:\/\/docs.mongodb.com\/manual\/tutorial\/analyze-query-plan\/). Once you have a general idea on how your queries perform, they also have tips on [optimizing your queries](https:\/\/docs.mongodb.com\/manual\/core\/query-optimization\/).\n\nAs a more advanced topic, you can learn how MongoDB [manages query plans](https:\/\/docs.mongodb.com\/manual\/core\/query-plans\/).\n\n\n\n\n\n Other MongoDB Monitoring Tools \n\nYou can also take advantage of some of the native MongoDB monitoring functions. For example, you can use both [mongotop](https:\/\/docs.mongodb.com\/manual\/reference\/program\/mongotop\/bin.mongotop) and [mongostat](https:\/\/docs.mongodb.com\/manual\/reference\/program\/mongostat\/bin.mongostat).\n\nmongotop 30 --username admin --password $PASSWORD --ssl --sslCAFile $CERTFILE --authenticationDatabase admin --host host1.databases.appdomain.cloud:31712, host2.databases.appdomain.cloud:31712\n\nmongostat -n 20 1 --username admin --password $PASSWORD --ssl --sslCAFile $CERTFILE --authenticationDatabase admin --host host1.databases.appdomain.cloud:31712,host2.databases.appdomain.cloud:31712 --json","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-performance"},{"document_id":"ibmcld_03114-21092-22942","score":22.253555,"text":"\nfor (let i = 0; i < options.length; i++) {\nconsole.log((i+1).toString() + '. ' + options[i].label);\n}\nbreak;\n}\n}\n}\nShow more\n\nIf response_type=text, we just display the output, as before. But if response_type=option, we have to do a bit more work. First we display the value of the title property, which serves as lead-in text to introduce the list of options; then we list the options, using the value of the label property to identify each one. (A real-world application would show these labels in a drop-down list or as the labels on clickable buttons.)\n\nYou can see the result by triggering the menu intent:\n\nWelcome to the Watson Assistant example!\n>> what are the available actions?\nWhat do you want to do?\n1. Send greeting\n2. Display the local time\n3. Exit\n>> 2\nSorry, I have no idea what you're talking about.\n>>\n\nAs you can see, the application is now correctly handling the option response by listing the available choices. However, we aren't yet translating the user's choice into meaningful input.\n\n\n\n\n\n Selecting an option \n\nIn addition to the label, each option in the response also includes a value object, which contains the input data that should be sent back to the assistant if the user chooses the corresponding option. The value.input object is equivalent to the input property of the \/message API, which means that we can just send this object back to the assistant as-is.\n\nTo do this in our application, we will set a new promptOption flag when the client receives an option response. When this flag is true, we know that we want to take the next round of input from value.input rather than accepting natural language text input from the user. (Again, we don't have a real user interface, so we will just prompt the user to select a valid option from the list by number.)\n\n\/\/ Option example 2: sends back selected option value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses"},{"document_id":"ibmcld_02900-10747-12416","score":22.06567,"text":"\nIf you do not take action, the same text response is displayed a second time to let users know they have returned to the node they digressed away from. You can make it clearer to users that they have returned to the original conversation thread by specifying a unique message to be displayed when they return.\n\nFor example, if the original text response for the node is, What's the order number?, then you might want to display a message like, Now let's get back to where we were. What is the order number? when users return to the node.\n\nTo do so, use the following syntax to specify the node text response:\n\n<? (returning_from_digression)? \"post-digression message\" : \"first-time message\" ?>\n\nFor example:\n\n<? (returning_from_digression)? \"Now, let's get back to where we were.\nWhat is the order number?\" : \"What's the order number?\" ?>\n\nYou cannot include SpEL expressions or shorthand syntax in the text responses that you add. In fact, you cannot use shorthand syntax at all. Instead, you must build the message by concatenating the text strings and full SpEL expression syntax together to form the full response.\n\nFor example, use the following syntax to include a context variable in a text response that you would normally specify as, What can I do for you, $username?:\n\n<? (returning_from_digression)? \"Where were we, \" +\ncontext[\"username\"] + \"? Oh, I was asking what can I do\nfor you today.\" : \"What can I do for you today, \" +\ncontext[\"username\"] + \"?\" ?>\n\nFor full SpEL expression syntax details, see [Expression for accessing objects](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-languageexpression-language-shorthand-syntax).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_07578-187034-189096","score":21.773632,"text":"\n* What IBM catalog offerings work with Hyper Protect Virtual Servers?\n\nIn general, all offerings work with Hyper Protect Virtual Servers except for offerings that work explicitly only with classic infrastructure or VPC infrastructure. These offerings do not work with Hyper Protect Virtual Servers.\n* I cannot access my server after a restart because the boot disk is almost full. How can I recover the server?\n\nYou can't recover your server because the boot disk is not resizable. You need to create a new server and restore your backups to them. Consider monitoring your server resource usage to prevent the same problem in the future. Verify that your file system usage is according to the recommendations in [Hyper Protect Virtual Servers file system characteristics](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-protect_vshpvs_fs).\n\n\n\nIBM Cloud Hardware Security Modules\n\n\n\n* What is a Hardware Security Module (HSM)?\n\nAn HSM is a piece of hardware that processes cryptographic operations and does not allow encryption keys to leave the secure cryptographic environment. Data that is shared, stored, or in motion, is encrypted at its point of creation and you can run and maintain your own data protection policies in the cloud.\n* What HSM does IBM Cloud rely on?\n\nIBM\u00ae leverages Thales SafeNet Luna Network HSM technology for Cloud HSM 6.0 and 7.0 offerings. This solution gives use ease of access to 60 IBM Cloud\u00ae data centers around the world that you can use to solve their compliance and data sovereignty challenges.\n* Which version of IBM Cloud HSM should I order?\n\nIn most cases, you need to order the newest version of an HSM. With older versions, you might have compatibility issues with high availability if you have older HSMs. If you already have older versions, contact Support to determine which version is right for you.\n* Can I migrate my existing HSM to a new version?\n\nYour HSM can't be migrated. Instead, cancel your existing HSM from the Devices menu, and order a new version.\n* Is IBM Cloud HSM FIPS certified?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-187008-189070","score":21.773632,"text":"\n* What IBM catalog offerings work with Hyper Protect Virtual Servers?\n\nIn general, all offerings work with Hyper Protect Virtual Servers except for offerings that work explicitly only with classic infrastructure or VPC infrastructure. These offerings do not work with Hyper Protect Virtual Servers.\n* I cannot access my server after a restart because the boot disk is almost full. How can I recover the server?\n\nYou can't recover your server because the boot disk is not resizable. You need to create a new server and restore your backups to them. Consider monitoring your server resource usage to prevent the same problem in the future. Verify that your file system usage is according to the recommendations in [Hyper Protect Virtual Servers file system characteristics](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-protect_vshpvs_fs).\n\n\n\nIBM Cloud Hardware Security Modules\n\n\n\n* What is a Hardware Security Module (HSM)?\n\nAn HSM is a piece of hardware that processes cryptographic operations and does not allow encryption keys to leave the secure cryptographic environment. Data that is shared, stored, or in motion, is encrypted at its point of creation and you can run and maintain your own data protection policies in the cloud.\n* What HSM does IBM Cloud rely on?\n\nIBM\u00ae leverages Thales SafeNet Luna Network HSM technology for Cloud HSM 6.0 and 7.0 offerings. This solution gives use ease of access to 60 IBM Cloud\u00ae data centers around the world that you can use to solve their compliance and data sovereignty challenges.\n* Which version of IBM Cloud HSM should I order?\n\nIn most cases, you need to order the newest version of an HSM. With older versions, you might have compatibility issues with high availability if you have older HSMs. If you already have older versions, contact Support to determine which version is right for you.\n* Can I migrate my existing HSM to a new version?\n\nYour HSM can't be migrated. Instead, cancel your existing HSM from the Devices menu, and order a new version.\n* Is IBM Cloud HSM FIPS certified?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16358-16196-17845","score":21.427149,"text":"\nClick to open the NeuralSeek search action that you just added to the assistant.\n7. Add the following user example queries to the first step in the action:\n\nWhat Watson Discovery project types are available and what do they do?\n\nWhat external data sources are supported by Watson Discovery?\n\nCan I add a custom dictionary to Watson Discovery?\n\nHow do I use the Content Mining application?\n\nWhen should I add query expansions to my project?\n\nWhich file types support Smart Document Understanding models?\n\nCan I enable optical character recognition for all file types?\n\nDoes my data have to be written in English?\n\nWatson Assistant uses the sample questions to recognize the types of user questions it should route to this action.\n8. Click to open Step 3 for editing.\n\nIn the And then section, click Edit extension.\n\nChoose NeuralSeek, and then click Apply.\n\nZoom\n\n![Shows the extension setup page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-setup.png)\n\nFigure 14. Set up the NeuralSeek extension\n9. Click to open Step 6 for editing.\n\nThis step shows a link that users can click to get more information. We want this link to go directly to the product documentation on the IBM Cloud Docs site.\n\nChange the hypertext reference in the anchor HTML element to contain the following URL:\n\n<a href=\"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about\" target=\"_blank\">\n\n![Shows the extension setup page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-edit-url.png){: caption=\"Figure 15.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_03218-31027-32769","score":21.39043,"text":"\nIf you do not take action, the same text response is displayed a second time to let users know they have returned to the node they digressed away from. You can make it clearer to users that they have returned to the original conversation thread by specifying a unique message to be displayed when they return.\n\nFor example, if the original text response for the node is, What's the order number?, then you might want to display a message like, Now let's get back to where we left off. What is the order number? when users return to the node.\n\nTo do so, use the following syntax to specify the node text response:\n\n<? (returning_from_digression)? \"post-digression message\" : \"first-time message\" ?>\n\nFor example:\n\n<? (returning_from_digression)? \"Now, let's get back to where we left off.\nWhat is the order number?\" : \"What's the order number?\" ?>\n\nYou cannot include SpEL expressions or shorthand syntax in the text responses that you add. In fact, you cannot use shorthand syntax at all. Instead, you must build the message by concatenating the text strings and full SpEL expression syntax together to form the full response.\n\nFor example, use the following syntax to include a context variable in a text response that you would normally specify as, What can I do for you, $username?:\n\n<? (returning_from_digression)? \"Where were we, \" +\ncontext\"username\"] + \"? Oh right, I was asking what can I do\nfor you today.\" : \"What can I do for you today, \" +\ncontext\"username\"] + \"?\" ?>\n\nFor full SpEL expression syntax details, see Expression for accessing objects]] ! ! ! ! ! .\n* Preventing returns: In some cases, you might want to prevent a return to the interrupted conversation flow based on a choice the user makes in the current dialog flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_05713-115081-116576","score":21.229118,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapp_kinds)\n* [What about serverless apps?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapps_serverless-strategy)\n* [What skills should I have before I move my apps to a cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyknowledge)\n\n\n\n* [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_resources)\n* [What else besides my app might use resources in the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_other)\n* [What type of availability do I want my workload to have?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_availability)\n* [How many worker nodes do I need to handle my workload?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_workers)\n* [How do I monitor resource usage and capacity in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_manage)\n\n\n\n* [Structuring your Kubernetes environment](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-101780-103603","score":15.74504,"text":"\nFor more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.\n\nThe column and partition definitions are optional. If they are not provided, the table schema and partitioning is detected from the structure of the data at the indicated location. If you explicitly provide these definitions, ensure that they match the objects that are stored in Object Storage. See [data types](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencedataType) for details on the supported column types.\n\n-- create a definition for the table customer\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nlocation cos:\/\/us-geo\/sql\/customers.csv\nShow more\n\nBefore you can use a newly created partitioned table, you must call ALTER TABLE tablename RECOVER PARTITIONS. Otherwise, querying the table returns an empty result.\n\n-- create a definition for the table customers_partitioned\nCREATE TABLE customers_partitioned (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (COUNTRY)\nlocation cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\n-- attach table partitions by scanning the location of the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-37842-39831","score":14.67639,"text":"\nFROM cos:\/\/us-geo\/sql\/temperature_humidity.csv\nUSING TIME_SERIES_FORMAT(timetick=\"timestamp\", value=\"humidity\")\n\n\n\n\n\n tableTransformer \n\nA table transformer is a function that is applied to the input data set before it is sent to the actual SQL query compilation and execution.\n\nYou can wrap your external table definition optionally with the FLATTEN table transformation function. It preprocesses your input table before query compilation to a fully flat column schema. This table transformation function can be useful when you have hierarchical input data as it is often found in JSON documents. By using FLATTEN, you do not need to dereference all nested columns explicitly in your SQL statement.\n\nFor example, you can run a simple SELECT * FROM FLATTEN(cos:\/\/us-geo\/sql\/iotmessages STORED AS JSON) on a flattened JSON input and use CSV output to easily browse a sample of your JSON input data.\n\nThe FLATTEN table transformation function creates a flat list of columns by concatenating all nested column names with _. You can optionally also combine FLATTEN with CLEANCOLS.\n\nYou can wrap your external table definition optionally with the CLEANCOLS table transformation function. It preprocesses your input table before query compilation by renaming all columns that have characters that are NOT supported by certain target formats, such as Parquet. These characters are ,, ;, ,,,, =, (, ), {, and }. They are replaced by the corresponding URL-encoded representation, for example, %20 for space (). With this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos:\/\/us-geo\/sql\/iotmessages STORED AS JSON) INTO cos:\/\/us-geo\/mybucket\/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-39344-41146","score":14.467244,"text":"\nWith this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos:\/\/us-geo\/sql\/iotmessages STORED AS JSON) INTO cos:\/\/us-geo\/mybucket\/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.\n\nIf you wrap your external table definition with the DESCRIBE table transformer, the table does not show its actual content but the schema that is inferred from the objects in IBM Cloud\u00ae Object Storage instead. With this function, you can explore the schema before you author your actual SQL statements against it.\n\nWhen you use the DESCRIBE table transformer in your SQL statement, the default output format is JSON instead of CSV.\n\nYou can also wrap DESCRIBE around the other table transformers to explore the transformed table schema. However, you cannot wrap other table transformers around the DESCRIBE transformer.\n\n\n\n\n\n tableValuedFunction \n\nA table-valued function returns a relation, which is a set of rows. An example of a table-valued function is range(). For more information, see [SQL functions](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctionssqlfunctions).\n\n\n\n\n\n More topics - relation clause \n\nFor more information about the clauses that are used in relation clauses, see the following topics:\n\n\n\n* [booleanExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencebooleanExpression)\n* [COSURI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceCOSURI)\n* [expression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexpression)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_02628-4002-5694","score":13.193715,"text":"\nWith your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition\n\n Name Type \n\n zip string \n temperature integer \n humidity integer \n city string \n state string \n\n\n\n\n\n![definition-current-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/definition-current-1.png)\n\n\n\n5. Save your API.\n\n\n\n12. In the previous step, you defined the response object. Next you'll need to ensure the response object is associated with the get \/current path. In the navigation, scroll back up to the Paths panel. a. Open the GET \/current operation, and scroll to the Responses section. b. Change the schema of the 200OK response from \"object\" to \"Current\". c. Save your API.\n13. The GET \/current path and operation get the current weather data. Now you'll need to create a similar path and operation to get today's weather data. Similar to how you created the \/current path in step 11, create a new path: \/today.\n14. Add a Parameter to the GET \/today operation.\n\n\n\n* Parameter Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n\n\n\n15. Create a new definition: Today.\n16. Add new properties for the Today definition as shown in Table 2.\n\n\n\nTable 2. Properties for the Today definition\n\n Name Type \n\n zip string \n hi integer \n lowe integer \n nighthumidity integer \n dayhumidity integer \n city string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"},{"document_id":"ibmcld_00539-1510-2962","score":13.114606,"text":"\nFor the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byName\",\n\"type\": \"json\"\n}\n\nFor more information, see [Creating an Index](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querycreating-an-index).\n\n\n\n\n\n Can I sort my search results with IBM Cloudant Query? \n\nYes! The _find JSON syntax allows for a sort parameter to be provided listing the attribute or attributes to sort by. In this case, we are sorting by date:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_02610-7-1753","score":12.998845,"text":"\nImporting APIs \n\nYou can use a OpenAPI definition file to add a REST API in the Lite, Enterprise, and Hybrid plans.\n\n\n\n Prerequisites \n\nBefore you begin, ensure that your file conforms to version 2.0 of the OpenAPI specification. The format of the file can be JSON or YAML.\n\nTo add a REST API by loading a OpenAPI (Swagger) file, complete the following steps:\n\n\n\n1. In the API Manager UI navigation list, click Drafts, then click APIs. The APIs tab opens.\n2. Click + Add and then select Swagger 2.0 (Swagger) from the Import section. The Import Swagger API window opens.\n3. Optional: To upload a file from your local file system, click Select file and, in your file system, select the file that you want to use. .json, .yml, and .yaml files are supported if they contain a valid OpenAPI definition.\n4. Optional: To upload a file from a URL, click Or import from URL and then provide the correct URL in the URL field that is presented. If authentication is required to access the URL, provide a user name and password. .json, .yml, and .yaml files are supported if they contain a valid OpenAPI definition.\n5. Click Import. A new REST API definition is created, including Paths and HTTP operations.\n\n\n\nWhen the API definition has been imported, it is shown in the list of API definitions in the APIs tab of the Drafts page. Next, you can edit your API definition as you would any other REST API definition.\n\n\n\n\n\n Importing APIs from IBM Integration Bus \n\nImport REST APIs that you create with IBM Integration Bus into IBM\u00ae API Connect for IBM Cloud\u00ae, which makes it easier to manage and publish them.\n\nBefore you begin, ensure that your REST API file conforms to version 2.0 of the OpenAPI specification. The format of the file can be JSON or YAML.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-importing_apis"},{"document_id":"ibmcld_00512-12262-14029","score":12.892527,"text":"\nFor the queries described previously, you need two indexes:\n\n\n\n1. A global index-mapping device ID to infrastructure ID\n2. A partitioned index-mapping device ID to reading\n\n\n\n\n\n Creating a global view index \n\nA view index is the most efficient way to do the simple device ID to infrastructure ID mapping. To define it, upload a design document with options.partitioned set to false as this index is global. While in a real map function you'd want to be more defensive around field existence, this document would look something like this:\n\n{\n\"options\": {\n\"partitioned\": false\n},\n\"views\": {\n\"by-device\": {\n\"map\": \"function(doc) { emit(doc.deviceID, doc.infrastructureID) }\"\n}\n}\n}\n\nAssuming the previous document in .\/view.json, this document is uploaded to the database by using the following command:\n\ncurl -X PUT \"$SERVICE_URL\/readings\/_design\/infrastructure-mapping\" -H 'Content-Type: application\/json' --data @view.json\n\nFor more language examples that show creating a global view, see the [Storing the view definition](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreducestoring-the-view-definition) guide, or [the Create or modify a design document section in API Docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantputdesigndocument).\n\n\n\n\n\n Creating a partitioned IBM Cloudant Query index \n\nTo return the readings for a specific device from a partition, you can use an IBM Cloudant Query index. For this document, use POST to _index with an index definition that includes the partitioned field set to true.\n\nFor Query index definitions, the partitioned field isn't nested inside an options object.\n\nFor these queries, you need two partitioned indexes:\n\n\n\n1. By timestamp\n2. By device ID and timestamp\n\n\n\n\n\n Uploading partitioned index by timestamp","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_05519-16780-18182","score":12.693731,"text":"\n\"name\": \"rowguid\",\n\"datatype\": \"CHAR(36)\",\n\"nullable\": false,\n\"label\": \"Rowguid\",\n\"usage\": \"identifier\",\n\"regularAggregate\": \"countDistinct\"\n}, {\n\"name\": \"ModifiedDate\",\n\"datatype\": \"TIMESTAMP\",\n\"nullable\": false,\n\"label\": \"Modified Date\",\n\"usage\": \"identifier\",\n\"regularAggregate\": \"countDistinct\",\n\"taxonomyFamily\": \"cDate\"\n}\n]\n},\n\"label\": \"Module Name\",\n\"identifier\": \"moduleId\"\n}\n\nShow more\n\n\n\n\n\n\n\n\n\n CSV data sources \n\nAlternatively, you can use a CSV file as a data source for a dashboard. Instead of defining the JDBC connection information, a URL that contains the location, where the CSV file is stored is passed in, in the sourceUrl field below.\n\nDo not change the sourceUrl when it is defined. Make sure that the server that provides the file uses standard HTTP cache control response headers. IBM\u00ae Cognos Dashboard Embedded can now cache the response locally for better query performance.\n\nIf you need IBM\u00ae Cognos Dashboard Embedded to pass extra headers on the request for the CSV file, to for example, facilitate authentication, you can add headers to the module definition as shown.\n\nNotes:\n\n\n\n* The maximum supported size for CSV files is 1 GB.\n* The CSV file is accessed using a GET request to the sourceUrl provided. Provide a secure (https) URL.\n\n\n\n\n\n Sample CSV source specification: \n\n{\n\"xsd\": \"https:\/\/ibm.com\/daas\/module\/1.0\/module.xsd\",\n\"source\": {\n\"id\": \"StringID\",\n\"srcUrl\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-workingwithdatasources"},{"document_id":"ibmcld_13480-1642-3813","score":12.67574,"text":"\nSo, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names. Hence, SQL authors are able to compose queries without having to know the exact location and format of data on Object Storage. If the data location changes, only the table in the catalog must be updated, but the table name remains unchanged. Updates of the physical data structure are simplified and the robustness of SQL statements and applications is increased.\n\n\n\n\n\n Usage \n\nYou manage the database catalog in Data Engine with Database Definition Language (DDL) statements that you submit just like any other SQL query statement. The catalog is stored independently of Object Storage: No data is written to Object Storage when you create or change table definitions, and no data is deleted from Object Storage when you drop a table definition. To call the catalog management statements, you need the Manager user role assigned.\n\nTo register a new table in the catalog, use the CREATE TABLE statement, as in the following example:\n\nCREATE TABLE employees\nUSING PARQUET\nLOCATION cos:\/\/us-geo\/sql\/employees.parquet\n\nThe statement automatically detects the schema of the data at the location that is indicated. See the [SQL reference](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecreateTable) for options that can be set on the table.\n\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogpartitioned).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_03982-20766-22701","score":12.556078,"text":"\n* admins: Paste in the signing certificate of the organization admin in base64 format.\n* tls_root_certs: Paste in an array that contains one or more root certificates from the TLS CA in base64 format. You must provide either an external TLS CA root certificate or an external intermediate TLS CA certificate, you can also provide both.\n* ou_root_cert: Specify the trusted CA root certificate for each role. Typically this value would be the same as the root_certs.\n* host_url: Specify the URL of the blockchain console where this MSP will collect signatures.\n* fabric_node_OUs: Fabric-specific OUs that enable identity classification. NodeOUs contain information for how to distinguish clients, peers, and orderers based on their OU. If the check is enforced, by setting Enabled to true, the MSP considers an identity valid only if it is an identity of type client, a peer, an admin, or an orderer. An identity should have only one of these special OUs, which are assigned to an identity when it is registered with the CA. See this topic for an example of [how to specify the fabric_node_OU in an MSP](https:\/\/hyperledger-fabric.readthedocs.io\/en\/latest\/discovery-cli.htmlconfiguration-query) in the Fabric Service Discovery documentation. Or learn more about using [Node OUs](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/membership\/membership.htmlnode-ou-roles-and-msps) in Fabric.\n\n\n\nThe following additional fields are also available in your MSP definition but are not required:\n\n\n\n* intermediate_certs: (if an intermediate CA was used) Paste in an array that contains one or more certificates from the external intermediate CA in base64 format. You must provide either a CA root certificate or an intermediate CA certificate, you can also provide both.\n* tls_intermediate_certs: (if an intermediate TLS CA was used) Paste in an array that contains one or more certificates from the intermediate TLS CA in base64 format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-39565-41541","score":18.08704,"text":"\nFor more information about phrase sentiment, see [Detecting phrases that express sentiment](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-phrase-sentiment). You cannot detect the sentiment of entities or keywords in v2.\n* What is a nested field?\n\nWhen you ingest a file or crawl an external data source, the data that you add to Discovery is processed and added to the collection as a document. Fields from the original file are converted to document fields and are added to the collection's index. Some content is added to root-level index fields and some information is stored in nested fields. Where data gets stored differs by file type. Most of the fields from structured data sources are stored as root-level fields. For files with unstructured data, much of the body of the file is stored in the text field in the index. Other information, such as the file name, is stored in nested fields with names like extracted_metadata.filename. You can determine whether a field is a nested field by its name. If the field name includes a period, it is a nested field. For more information about how different file types are handled, see [How your data source is processed](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview).\n* Which type of query should I use in my custom app?\n\nWhen you submit a query, you can choose to submit a natural language query or use the Discovery Query Language to customize the search to target specific fields in the index, for example. For more information about the different types of queries and how to decide which one to use, see [Choosing the right query type](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-choose).\n\n\n\nKnowledge Studio\n\n\n\n* How do I set data collection options?\n\nFor Lite and Standard plans, by default, Knowledge Studio uses client data to improve the service. This data is used only in aggregate. Client data is not shared or made public.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-39555-41531","score":18.08704,"text":"\nFor more information about phrase sentiment, see [Detecting phrases that express sentiment](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-phrase-sentiment). You cannot detect the sentiment of entities or keywords in v2.\n* What is a nested field?\n\nWhen you ingest a file or crawl an external data source, the data that you add to Discovery is processed and added to the collection as a document. Fields from the original file are converted to document fields and are added to the collection's index. Some content is added to root-level index fields and some information is stored in nested fields. Where data gets stored differs by file type. Most of the fields from structured data sources are stored as root-level fields. For files with unstructured data, much of the body of the file is stored in the text field in the index. Other information, such as the file name, is stored in nested fields with names like extracted_metadata.filename. You can determine whether a field is a nested field by its name. If the field name includes a period, it is a nested field. For more information about how different file types are handled, see [How your data source is processed](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview).\n* Which type of query should I use in my custom app?\n\nWhen you submit a query, you can choose to submit a natural language query or use the Discovery Query Language to customize the search to target specific fields in the index, for example. For more information about the different types of queries and how to decide which one to use, see [Choosing the right query type](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-choose).\n\n\n\nKnowledge Studio\n\n\n\n* How do I set data collection options?\n\nFor Lite and Standard plans, by default, Knowledge Studio uses client data to improve the service. This data is used only in aggregate. Client data is not shared or made public.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07115-11488-13386","score":18.052704,"text":"\nIf you prefer to use the Discovery API to train Discovery, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalisttrainingqueries).\n\nYou also can use the API to add curations. Curations is a beta feature that you can use to teach Discovery to return a specific document every time a certain query is submitted. For more information, see [Curations](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-curations).\n\nAdding a custom stopwords list can also improve the relevance of results for natural language queries. For more information, see [Identifying words to ignore](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-stopwords).\n\n\n\n\n\n Understanding relevancy training \n\nAnswers to common questions about training a project.\n\n\n\n How do I know whether my system is trained? \n\nRun a natural language query and check the document_retrieval_strategy. See [confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-trainconfidence).\n\nIf you are using the API, see [List training queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalisttrainingqueries).\n\n\n\n\n\n How long does it take to train a model? \n\nIt can take between 45 minutes to an hour for the training to finish. The duration of the training differs depending on the amount and variety of the data that is used to train the relevancy model. Also, the training occurs asynchronously. It can be delayed if other data that it needs is unavailable because it is being searched or processed in some other way.\n\n\n\n\n\n How do I stop relevancy training from being applied to my project? \n\nUse the API to delete the relevancy model that is associated with your project. To delete the model, you delete that training data that is associated with the ranker model. For more information, see [Deleting training queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datadeletetrainingqueries).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_06310-0-1139","score":17.378237,"text":"\n\n\n\n\n\n\n  FAQs - General \n\nThis is a collection of frequently asked questions (FAQ) about the Watson Query service.\n\n\n\n  How do I generate credentials for my instance? \n\n\n\n1.  Log in to [IBM Cloud](https:\/\/cloud.ibm.com).\n2.  Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3.  Under Databases, locate your Watson Query instance and click the service name. This list includes all instances that were created under a resource group or that were migrated into a resource group.\n4.  Click Service credentials > New credentials > Add to generate your Watson Query Manager credentials.\n5.  Expand View credentials, which displays your service connectivity information including your credentials (username and password).\n6.  The Manager credentials can be used to connect to both Watson Query and the web console.\n\n\n\n\n\n\n\n  Now that I generated credentials, how do I access my Watson Query instance? \n\nYou can access your Watson Query instance by using a dedicated Data virtualization workspace in IBM Cloud Pak for Data as a Service or the [Watson Query Rest APIs](https:\/\/cloud.ibm.com\/apidocs\/data-virtualization-on-cloud).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-faq_dv"},{"document_id":"ibmcld_07578-41078-43150","score":17.262571,"text":"\nFor more information about the different types of queries and how to decide which one to use, see [Choosing the right query type](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-choose).\n\n\n\nKnowledge Studio\n\n\n\n* How do I set data collection options?\n\nFor Lite and Standard plans, by default, Knowledge Studio uses client data to improve the service. This data is used only in aggregate. Client data is not shared or made public.\n\nTo prevent Knowledge Studio from using client data, you must opt out by using at least one of two ways:\n\n\n\n* Clear the Data collection checkbox on the Service Details page in the Knowledge Studio application.\n* As the owner of the Knowledge Studio service instance, opt out of all data collection for Watson services at \/watson\/settings.\n\n\n\nFor Premium plans and Dedicated accounts, Knowledge Studio does not use client data to improve the service.\n\nFor more information, see the latest [Knowledge Studio service description](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/searchsaas\/?searchview&searchorder=4&searchmax=0&query=Knowledge+Studio).\n* Can I deploy custom models across regions?\n\nDeployment of models across regions is not supported. A custom model can only be deployed to the same region as your Knowledge Studio instance.\n* Can I access Knowledge Studio with an API?\n\nAt this time, there is no API to interact with Knowledge Studio. To launch the Knowledge Studio application, you click Launch tool from within the Manage page for the Knowledge Studio service instance in the IBM Cloud console. Or you can copy the tool URL and use it to launch the application directly. For details, see [Launching the Knowledge Studio application](https:\/\/cloud.ibm.com\/docs\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrolaunching-the-knowledge-studio-application).\n* Can I change from a Standard to Lite plan?\n\nDowngrading your plan for Knowledge Studio is not supported. You can, however, manage users, storage, billing, and usage with options such as setting limits or notifications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-41068-43135","score":17.262571,"text":"\nFor more information about the different types of queries and how to decide which one to use, see [Choosing the right query type](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-choose).\n\n\n\nKnowledge Studio\n\n\n\n* How do I set data collection options?\n\nFor Lite and Standard plans, by default, Knowledge Studio uses client data to improve the service. This data is used only in aggregate. Client data is not shared or made public.\n\nTo prevent Knowledge Studio from using client data, you must opt out by using at least one of two ways:\n\n\n\n* Clear the Data collection checkbox on the Service Details page in the Knowledge Studio application.\n* As the owner of the Knowledge Studio service instance, opt out of all data collection for Watson services at \/watson\/settings.\n\n\n\nFor Premium plans and Dedicated accounts, Knowledge Studio does not use client data to improve the service.\n\nFor more information, see the latest [Knowledge Studio service description](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/searchsaas\/?searchview&searchorder=4&searchmax=0&query=Knowledge+Studio).\n* Can I deploy custom models across regions?\n\nDeployment of models across regions is not supported. A custom model can only be deployed to the same region as your Knowledge Studio instance.\n* Can I access Knowledge Studio with an API?\n\nAt this time, there is no API to interact with Knowledge Studio. To launch the Knowledge Studio application, you click Launch tool from within the Manage page for the Knowledge Studio service instance in the IBM Cloud console. Or you can copy the tool URL and use it to launch the application directly. For details, see [Launching the Knowledge Studio application](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrolaunching-the-knowledge-studio-application).\n* Can I change from a Standard to Lite plan?\n\nDowngrading your plan for Knowledge Studio is not supported. You can, however, manage users, storage, billing, and usage with options such as setting limits or notifications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07035-9024-9915","score":15.873493,"text":"\nOther information, such as the file name, is stored in nested fields with names like extracted_metadata.filename. You can determine whether a field is a nested field by its name. If the field name includes a period, it is a nested field. For more information about how different file types are handled, see [How your data source is processed](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview).\n\n\n\n\n\n Which type of query should I use in my custom app? \n\nWhen you submit a query, you can choose to submit a natural language query or use the Discovery Query Language to customize the search to target specific fields in the index, for example. For more information about the different types of queries and how to decide which one to use, see [Choosing the right query type](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-faqs"},{"document_id":"ibmcld_07237-1522-3387","score":15.858122,"text":"\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n\n\n\n\n\n Is there size limitation on the length of Natural Language Queries (NLQ)? \n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n\n\n How do you improve query results? \n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n How do you know that relevancy training is complete? \n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Where can I learn more about uploading documents to Watson Discovery? \n\nYou can upload documents using the API or the Discovery tooling. You can also connect to several different data sources (including Box, Salesforce, SharePoint Online, SharePoint 2016, and IBM Cloud Object Storage), or do a web crawl. For details, see [Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent).\n\n\n\n\n\n What document types are supported for ingestion?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-troubleshoot"},{"document_id":"ibmcld_07578-499040-500999","score":15.524639,"text":"\nOpen your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Databases, locate your Watson Query instance and click the service name. This list includes all instances that were created under a resource group or that were migrated into a resource group.\n4. Click Service credentials > New credentials > Add to generate your Watson Query Manager credentials.\n5. Expand View credentials, which displays your service connectivity information including your credentials (username and password).\n6. The Manager credentials can be used to connect to both Watson Query and the web console.\n\n\n\n* Now that I generated credentials, how do I access my Watson Query instance?\n\nYou can access your Watson Query instance by using a dedicated Data virtualization workspace in IBM Cloud Pak for Data as a Service or the [Watson Query Rest APIs](https:\/\/%7BDomainName%7D\/apidocs\/data-virtualization-on-cloud).\n\n\n\nIBM watsonx.data\n\n\n\n* What is watsonx.data?\n\nwatsonx.data is an open, hybrid, and governed fit-for-purpose data store optimized to scale all data, analytics and AI workloads to get greater value from your analytics ecosystem.\n* What can I do with watsonx.data?\n\nYou can connect to data in multiple locations and get started in minutes with built-in governance, security and automation. You can leverage multiple query engines to run analytics and AI workloads, reducing your data warehouse costs by up to 50%.\n* What are the key features of watsonx.data?\n\nKey features of watsonx.data are:\n\n\n\n* The architecture fully separates compute, metadata, and storage to provide ultimate flexibility.\n* Fit for purpose query engines designed to handle modern data formats that are highly elastic and scalable.\n* Data sharing between watsonx.data, Db2\u00ae Warehouse on Cloud, and Netezza or any other data management solution through common Iceberg table format support, connectors, and a shareable metadata store.\n\n\n\n* How can I create a watsonx.data service instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-499022-500981","score":15.524639,"text":"\nOpen your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Databases, locate your Watson Query instance and click the service name. This list includes all instances that were created under a resource group or that were migrated into a resource group.\n4. Click Service credentials > New credentials > Add to generate your Watson Query Manager credentials.\n5. Expand View credentials, which displays your service connectivity information including your credentials (username and password).\n6. The Manager credentials can be used to connect to both Watson Query and the web console.\n\n\n\n* Now that I generated credentials, how do I access my Watson Query instance?\n\nYou can access your Watson Query instance by using a dedicated Data virtualization workspace in IBM Cloud Pak for Data as a Service or the [Watson Query Rest APIs](https:\/\/%7BDomainName%7D\/apidocs\/data-virtualization-on-cloud).\n\n\n\nIBM watsonx.data\n\n\n\n* What is watsonx.data?\n\nwatsonx.data is an open, hybrid, and governed fit-for-purpose data store optimized to scale all data, analytics and AI workloads to get greater value from your analytics ecosystem.\n* What can I do with watsonx.data?\n\nYou can connect to data in multiple locations and get started in minutes with built-in governance, security and automation. You can leverage multiple query engines to run analytics and AI workloads, reducing your data warehouse costs by up to 50%.\n* What are the key features of watsonx.data?\n\nKey features of watsonx.data are:\n\n\n\n* The architecture fully separates compute, metadata, and storage to provide ultimate flexibility.\n* Fit for purpose query engines designed to handle modern data formats that are highly elastic and scalable.\n* Data sharing between watsonx.data, Db2\u00ae Warehouse on Cloud, and Netezza or any other data management solution through common Iceberg table format support, connectors, and a shareable metadata store.\n\n\n\n* How can I create a watsonx.data service instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07115-5269-7471","score":17.706493,"text":"\nYour documents might not have a text field if you uploaded a CSV file that doesn't have a column named text, or uploaded a JSON file that doesn't have an object named text, or if you used the Smart Document Understanding tool to define fields with other names in which the bulk of the content of your documents now are stored.\n\nWhen you train a project from the API, results are taken from all of the root-level fields and they are all considered to have equal significance. Unlike Discovery Query Language queries, with natural language queries you cannot specify which fields from the document you care about or how much significance to give to each one. When you teach Discovery with examples, the service figures out for you how much weight to give to each field.\n\nDiscovery builds a model that assigns different weights to term, bigram, and skip-gram matches for each of the root-level fields and balances them against matches from all of the other document fields. With enough examples, Discovery can return better answers because it knows where the best answers are typically stored.\n\nRelevancy training cannot be used to give more weight to nested fields. Nested fields are grouped and assigned one overall score. No matter how much you train, Discovery never gives a nested field more weight than it gives to a root-level field. For more information about nested fields, see the [FAQ](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-faqsfaq-nested-fields).\n\n\n\n\n\n Training a project \n\nThe training data that is used to train the relevancy model includes these parts:\n\n\n\n* A natural language query that is representative of a query that your users might submit\n* Results of the query which are returned by the service\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_03369-85005-86957","score":16.419296,"text":"\nIf your German-language dialog skill has the root verb haben as an entity value, it recognizes conjugated forms of the verb (hast) in user input as mentions of the entity.\n\n\n\n\n\n 2 April 2020 \n\nNew and improved access control\n: Now, when you give other people access to your Watson Assistant resources, you have more control over the level of access they have to individual skills and assistants. You can give one person read-only access to a production skill and manager-level access to a development skill, for example. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n\nCan't see Analytics anymore? If you cannot do things that you could do before, you might not have appropriate access. Ask the service instance owner to change your service access role. For more information, see [How to keep your access](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-controlaccess-control-prep).\n\nIf you can't access the API Details for a skill or assistant anymore, you might not have the access role that is required to use the instance-level API credentials. You can use a personal API key instead. For more information, see [Getting API information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settingsassistant-settings-api-details).\n\n\n\n\n\n 1 April 2020 \n\nPlus plan changes\n: The Plus plan is now available starting at $120\/month for 1,000 users on pay-as-you-go or subscription IBM Cloud accounts. And you can subscribe without contacting Sales.\n\nFrench language beta support added for contextual entities\n: You can add contextual entities to French-language dialog skills. For more information about contextual entities, see [Creating entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nNew API version\n: The current API version is now 2020-04-01. The following change was made with this version:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_07163-7-1995","score":16.000826,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_12432-1399-3158","score":15.711051,"text":"\n[Catalog management](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog) Arbitrary secrets Centrally manage the credentials for software in your private catalogs. [Learn more about this integration](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog). \n [Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager) Arbitrary secrets <br>IAM credentials Centrally manage the credentials for your Continuous Delivery toolchain. Create an authorization between Toolchain and Secrets Manager to give a toolchain access to your secrets. [Learn more about this integration](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager). \n [Data Engine](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting-started) Arbitrary secrets <br>IAM credentials Store API keys for transferring messages between Event Streams, Data Engine and Cloud Object Storage. [Learn more](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-event-streams-landingpermissions-event-streams). \n [Event Notifications](https:\/\/cloud.ibm.com\/docs\/event-notifications) Arbitrary secrets <br>Certificates <br>IAM credentials <br>User credentials Send notifications of events in Secrets Manager to other users, or human destinations, by using email, SMS, or other supported delivery channels. [Learn more about this integration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-event-notifications). \n [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers) Arbitrary secrets <br>Certificates <br>IAM credentials <br>Key-value secrets <br>User credentials Centrally manage Ingress subdomain certificates and other secrets for your Kubernetes clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-integrations"},{"document_id":"ibmcld_16653-0-871","score":15.542448,"text":"\n\n\n\n\n\n\n  Query history \n\nA query history audits all the current and past queries across the existing engines in IBM\u00ae watsonx.data.\n\nThe query history page in watsonx.data provides the following details that are related to the queries that are run:\n\n\n\n*  Query ID\n*  Query\n*  State\n*  Engine\n*  User\n*  Created\n\n\n\nIn the Query history page, you can search, refresh, filter, and customize the queries. You can select a Query from the page, view or copy the details of query statement, logical execution plan, and distributed execution plan. You can open the queries directly in a workspace, and also get the explain details of a query from the overflow menu of each query listed.\n\nFor more information about exporting and importing query history, see [Exporting and importing the query history](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-eximp-q-hist).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-query_history"},{"document_id":"ibmcld_15456-10582-12184","score":15.124506,"text":"\n\"bytes_from_initiator\": 12000,\n\"packets_from_initiator\": 2212,\n\"bytes_from_target\": 323232,\n\"packets_from_target\": 3232\n\"cumulative_packets_from_initiator\": 2212,\n\"cumulative_packets_from_target\": 3232,\n\"cumulative_bytes_from_target\": 323232,\n\"cumulative_bytes_from_initiator\": 12000,\n}\n],\n}\n\n\n\n\n\n Analyzing flow logs by using IBM Cloud SQL Query \n\nYou can analyze flow logs with SQL that uses IBM Cloud\u00ae Data Engine by using the path to the objects on Object Storage in the FROM clause of your SQL query. (For an example, see Step 3 in [Viewing flow log objects](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-fl-analyze). However, for a more convenient way of querying, it is recommended that you create table and view definitions that give you a flattened view on your flows. For more information about table catalog functions and benefits, see [Getting started with the catalog](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\nThe view flattens the flow log data structure; thus, making it easier to analyze your flows.\n\nFor more elaborate and repeatable analysis, such as when you want to collaborate and share your log analysis, it is recommended that you use IBM Cloud\u00ae Data Engine through Jupyter Notebooks (for example, through IBM Watson Studio). For a generic starter and demo notebook for IBM Cloud\u00ae Data Engine that you can use as basis for your work, see [Using IBM Cloud SQL Query](https:\/\/dataplatform.cloud.ibm.com\/analytics\/notebooks\/v2\/656c7d43-7ccd-4e50-a3c0-bbc37c001132\/view?access_token=baaa77ad715e17a8f823615d45431329fde0fe92fecb85abb9fc55a877939fe8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-fl-analyze"},{"document_id":"ibmcld_07237-1522-3387","score":15.058326,"text":"\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n\n\n\n\n\n Is there size limitation on the length of Natural Language Queries (NLQ)? \n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n\n\n How do you improve query results? \n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n How do you know that relevancy training is complete? \n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Where can I learn more about uploading documents to Watson Discovery? \n\nYou can upload documents using the API or the Discovery tooling. You can also connect to several different data sources (including Box, Salesforce, SharePoint Online, SharePoint 2016, and IBM Cloud Object Storage), or do a web crawl. For details, see [Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent).\n\n\n\n\n\n What document types are supported for ingestion?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-troubleshoot"},{"document_id":"ibmcld_07163-14976-16332","score":15.037086,"text":"\nFor additional training guidance, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Performing other training-data query operations \n\nYou can administer and maintain training-data queries by using other API methods as described in the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery):\n\n\n\n* [List the training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n* [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data)\n* [Display the contents of a specified training-data query](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-details-about-a-query)\n* [Delete a training-data query from the collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-example-for-training-data-query)\n* [Change a training-data query example's relevance label or cross reference](https:\/\/cloud.ibm.com\/apidocs\/discoverychange-label-or-cross-reference-for-example)\n* [Delete an example document from a training-data query](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n\nError monitoring: Training-data errors appear in the notices, which you can monitor using the [query notices API](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-system-notices) ( GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/notices).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07045-4959-6113","score":14.955201,"text":"\nFor example, you might want to show facets based on keywords or dictionary categories. For more information, see [Facets](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets).\n\n\n\n\n\n Explore other search features \n\nWhen you test your project from the Discovery user interface, you submit a natural language query. Search features are available that you can enable to influence how the natural language query search is done. And Discovery Query Language search is another type of search that you can leverage by using the API. If the initial results don't meet your needs, experiment with another search method.\n\n\n\n* Discovery Query Language (DQL) search: A search mechanism that accepts more complex queries. You must use the query API to submit DQL queries.\n\nFor example, you can search for specific values in fields that are generated by enrichments that are applied to a collection.\n* Natural language query is the type of search that is triggered from the Improve and customize page.\n\n\n\nFor more information about the Query API, see [Query API overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_07098-4987-7173","score":14.89732,"text":"\nUp to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.\n\nFor example, if you set the query to return 100 documents (count=100) and ask for 2 passages from each document (passages.max_per_document=2), then 2 passages are chosen from each of the 30 top-ranked documents (2 x 30 = 60 passages) only. No passages are chosen from the remaining 70 documents.\n\n\n\nIf your goal is to get the best 10 short answers, a good approach is to give the answer-finding feature various passages from more documents than just the top 10. To do so, set passages.per_document to true, and then request 20 documents and up to 3 passages from each document with the answer-finding feature enabled. The answer-finding feature searches for answers in up to 20*3 = 60 passages.\n\nAnswer finding does not use the transformed query string that is generated by query analysis. Instead, it uses a copy of the user's original input that is stored at query time to find the best short answer. If the answer-finding module is confident that it found an answer in one of the passages, the answer confidence score is combined with the document and passage scores to produce a final ranking, which can promote a document or passage that might otherwise be missed.\n\n\n\n\n\n Answer-finding API details \n\nThe answer-finding API adds the following parameters to the passage section of the query API:\n\n\n\n* find_answers is optional and defaults to false. If it is set to true (and the natural_language_query parameter is set to a query string), the answer-finding feature is enabled.\n* max_answers_per_passage is optional and defaults to 1. In this case, the answer-finding feature finds the number of answers that are specified at most from any one passage.\n\n\n\nA section is also added to the return value within each passage object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-886144-887942","score":28.40789,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n* How many volumes can I provision on my account?\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n* Can I set up shared storage in a multizone cluster?\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n* I have volumes on the Classic infrastructure. Can I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-886021-887819","score":28.40789,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n* How many volumes can I provision on my account?\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n* Can I set up shared storage in a multizone cluster?\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n* I have volumes on the Classic infrastructure. Can I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16551-0-1579","score":27.70023,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_07578-1340295-1342245","score":26.347649,"text":"\nYou can get the encryption details using IBM Cloud UI\/CLI. For details, see [Cloud Storage Encryption](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption).\n* How can I list all permissions of a bucket?\n\nThe IAM feature creates a report at the instance level which may extend to their buckets. It does not specifically report at the bucket level. For details, see [Account Access Report](https:\/\/cloud.ibm.com\/docs\/account?topic=account-access-report).\n* How can I monitor bucket changes in the public cloud without using the cloud functions?\n\nYou must use cloud functions to get notifications for object changes.\n* How can I monitor Object Storage resources?\n\nUse the Activity Tracker service to capture and record Object Storage activities and monitor the activity of your IBM Cloud account. Activity Tracker is used to track how users and applications interact with Object Storage.\n* Does an object in a bucket get overwritten if the same object name is used again in the same bucket?\n\nYes, the object is overwritten.\n* How do I get bucket information without using the web console?\n\nUse the Object Storage Resource Configuration API to get bucket information. For details, see [COS configuration](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) and [COS Integration](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration).\n* How can I manage service credentials for Object Storage instances?\n\nWhen a service credential is created, the underlying Service ID is granted a role on the entire instance of Object Storage. For details, see [Managing Service credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-credentials).\n* Why are parts of my credentials hidden or not viewable?\n\nThere may be an issue where the viewer does not have sufficient roles to view the credential information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1342960-1344910","score":26.347649,"text":"\nYou can get the encryption details using IBM Cloud UI\/CLI. For details, see [Cloud Storage Encryption](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption).\n* How can I list all permissions of a bucket?\n\nThe IAM feature creates a report at the instance level which may extend to their buckets. It does not specifically report at the bucket level. For details, see [Account Access Report](https:\/\/cloud.ibm.com\/docs\/account?topic=account-access-report).\n* How can I monitor bucket changes in the public cloud without using the cloud functions?\n\nYou must use cloud functions to get notifications for object changes.\n* How can I monitor Object Storage resources?\n\nUse the Activity Tracker service to capture and record Object Storage activities and monitor the activity of your IBM Cloud account. Activity Tracker is used to track how users and applications interact with Object Storage.\n* Does an object in a bucket get overwritten if the same object name is used again in the same bucket?\n\nYes, the object is overwritten.\n* How do I get bucket information without using the web console?\n\nUse the Object Storage Resource Configuration API to get bucket information. For details, see [COS configuration](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) and [COS Integration](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration).\n* How can I manage service credentials for Object Storage instances?\n\nWhen a service credential is created, the underlying Service ID is granted a role on the entire instance of Object Storage. For details, see [Managing Service credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-credentials).\n* Why are parts of my credentials hidden or not viewable?\n\nThere may be an issue where the viewer does not have sufficient roles to view the credential information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00208-7298-9073","score":26.23522,"text":"\n* Windows\u00ae: you have two options.\n\nfsutil volume diskfree C:\n\ndir C:\n\nThe last line of the output shows how much space is unused.\n\nYou can also view the free disk space in the File Explorer by clicking This PC.\n\n\n\n\n\n\n\n Does the volume need to be pre-warmed to achieve expected throughput? \n\nPre-warming is not needed. You can observe specified throughput immediately upon provisioning the volume.\n\n\n\n\n\n Can more throughput be achieved by using a faster Ethernet connection? \n\nThroughput limits are set at the LUN level and a faster Ethernet connection doesn't increase that limit. However, with a slower Ethernet connection, your bandwidth can be a potential bottleneck.\n\n\n\n\n\n Do firewalls and security groups impact performance? \n\nIt's best to run storage traffic on a VLAN, which bypasses the firewall. Running storage traffic through software firewalls increases latency and adversely affects storage performance.\n\n\n\n\n\n How do I route Block Storage for Classic traffic to its own VLAN interface and bypass a firewall? \n\nTo enact this best practice, complete the following steps.\n\n\n\n1. Provision a VLAN in the same data center as the host and the Block Storage for Classic device. For more information, see [Getting started with VLANs](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-started).\n2. Provision a secondary private subnet to the new VLAN.3\n3. Trunk the new VLAN to the private interface of the host. For more information, see [How do I trunk my VLANs to my servers](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-vlans-faqstrunk-vlans-to-servers).\n\nThis action momentarily disrupts the network traffic on the host while the VLAN is being trunked to the host.\n4. Create a network interface on the host.\n\n\n\n* In Linux\u00ae or Windows\u00ae, create an 802.11q interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-block-storage-faqs"},{"document_id":"ibmcld_15111-4420-6168","score":26.146217,"text":"\nYou can also use the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=cliexpand-existing-boot-vol-cli) or the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes&interface=apiexpand-existing-boot-vol-api).\n\n\n\n\n\n How many volumes can I provision on my account? \n\nYou can provision up to 300 Block Storage for VPC volumes per account in a region. You can request your quota to be increased by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and specifying the region where you need more volumes. For more information about preparing a support case when you're ordering Block Storage for VPC volumes or requesting an increase to your volume or capacity limits, see [Managing volume count and capacity limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit).\n\n\n\n\n\n Can I set up shared storage in a multizone cluster? \n\nIn the IBM Cloud\u00ae, storage options are limited to an availability zone. Do not try to manage shared storage across multiple zones.\n\nInstead, use an IBM Cloud\u00ae classic service option outside a VPC such as IBM Cloud\u00ae Object Storage or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae if you must share your data across multiple zones and regions.\n\n\n\n\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n\n\n\n\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_07578-179678-181232","score":25.03206,"text":"\nSo, if your app needs a persistent connection, create a new connection before the timeout value is reached.\n* How can I review the Code Engine service terms?\n\nFor the latest service level agreement terms, see the [terms of service](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms).\n* How can I give feedback?\n\nYour feedback on Code Engine is important to us and helps us improve. You can provide feedback in multiple ways:\n\n\n\n* Click Feedback from any page on the [Code Engine console](https:\/\/cloud.ibm.com\/codeengine\/overview) or in the product documentation to provide your comments.\n* Share feedback through Slack. You can [register](https:\/\/cloud.ibm.com\/kubernetes\/slack) and join the discussion in the\n\n[#code-engine channel](https:\/\/ibm-cloud-success.slack.com).\n\n\n\n\n\nFunctions\n\n\n\n* What language runtimes are supported in Cloud Functions?\n\nCloud Functions supports many different language runtimes, including Node.js, Python, and PHP. Languages without specific support in Cloud Functions are supported by using Docker actions. For a complete list of supported language runtimes, see [Runtimes](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimes).\n* What's the maximum time or maximum memory that my function can run?\n\nThe maximum timeout is 10 minutes and you can use up to 2048 MB of memory for each function. Find more details about these limits and others in [System details and limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limits).\n* What's the difference between an action and a web action?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-179652-181206","score":25.03206,"text":"\nSo, if your app needs a persistent connection, create a new connection before the timeout value is reached.\n* How can I review the Code Engine service terms?\n\nFor the latest service level agreement terms, see the [terms of service](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms).\n* How can I give feedback?\n\nYour feedback on Code Engine is important to us and helps us improve. You can provide feedback in multiple ways:\n\n\n\n* Click Feedback from any page on the [Code Engine console](https:\/\/cloud.ibm.com\/codeengine\/overview) or in the product documentation to provide your comments.\n* Share feedback through Slack. You can [register](https:\/\/cloud.ibm.com\/kubernetes\/slack) and join the discussion in the\n\n[#code-engine channel](https:\/\/ibm-cloud-success.slack.com).\n\n\n\n\n\nFunctions\n\n\n\n* What language runtimes are supported in Cloud Functions?\n\nCloud Functions supports many different language runtimes, including Node.js, Python, and PHP. Languages without specific support in Cloud Functions are supported by using Docker actions. For a complete list of supported language runtimes, see [Runtimes](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimes).\n* What's the maximum time or maximum memory that my function can run?\n\nThe maximum timeout is 10 minutes and you can use up to 2048 MB of memory for each function. Find more details about these limits and others in [System details and limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limits).\n* What's the difference between an action and a web action?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05444-178874-180170","score":24.76982,"text":"\n(https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsfind-code-samples)\n* [!I need more memory Can I increase my limits?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsincrease-ce-limits)\n* [Do I need a Docker Hub account to use Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsdockerhub-options)\n* [What is the difference between a Docker build on my system and a build in Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsdockerbld-cebuild)\n* [Why do images that are built by using a Code Engine buildpacks build show up in my container registry as being more than 15,000 days old?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsbuildpacksbld-image-size)\n* [Why do images that are built with non-Intel processors not work with Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsbuildimage-nonintel)\n* [Do Code Engine apps support WebSockets?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsapp-websockets)\n* [How can I review the Code Engine service terms?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsreview-service-terms)\n* [How can I give feedback?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsgive-feedback)\n\n\n\n\n\n\n\n Learning paths for Code Engine","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13466-0-409","score":17.879725,"text":"\n\n\n\n\n\n\n  Data transport automation to Db2 on Cloud \n\nIBM Cloud\u00ae Data Engine supports automating the transport and transformation of data from IBM Cloud\u00ae Object Storage to IBM\u00ae Db2\u00ae on Cloud. Read how you can [automate serverless data pipelines for your data warehouse or data lakes](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/automate-serverless-data-pipelines-for-your-data-warehouse-or-data-lakes).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-db2"},{"document_id":"ibmcld_09978-4314-6065","score":16.846237,"text":"\n* Automatic pause and resume is enabled in the web console.\n\n\n\n\n\n\n\n Components \n\n\n\n* Netezza Performance Server 11.2.2.5\n* Web console 4.0.11\n\n\n\n\n\n\n\n Known issues \n\nIf a common table expression or derived table query contains column names or column aliases, which begin with an underscore, Netezza Performance Server deletes these columns in the query result set.\nIf there are no columns to display, Netezza Performance Server returns the following error.\n\nERROR: No columns are selected due to column alias begin with underscore\n\nExample:\n\ncreate table t1 ( c1 int , c2 int);\nCREATE TABLE\nwith tab1 as ( select c1 as _c1 , c2 as _c2 from t1 ) select tab1.* from tab1; ERROR: No columns are selected due to column alias begin with underscore\nselect tab1.* from ( select c1 as _c1 , c2 as _c2 from t1 ) as tab1; ERROR: No columns are selected due to column alias begin with underscore\n\n\n\n\n\n\n\n July 2022 \n\nAs of July 28, 2022, you can access data from data lakes and move data between applications with Kafka.\n\n\n\n New features \n\n\n\n* Use the technology preview of the Netezza Performance Server external tables to access and query parquet files that are stored outside of your database in data lakes (on AWS S3). For more information, see [Querying data from data lakes](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity).\n* Use Netezza Performance Server as a data source or data sink. For more information, see [Using Netezza Performance Server as a data source](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-netezzakafkadatasourcekafka) and [Using Netezza Performance Server as a data sink](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-netezzakafkadatasinkkafka).\n\n\n\n\n\n\n\n Known issues \n\ndatasource is a reserved keyword now.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-my-service-relnotes"},{"document_id":"ibmcld_09984-0-1283","score":16.7103,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_11164-6586-7646","score":16.039574,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_16628-0-1541","score":15.928073,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_02718-7-2113","score":15.395333,"text":"\nVideos \n\nYou can watch the videos to learn more about App Configuration service.\n\n\n\n* Video transcript\n\nWhat are Feature Flags?\n\nBefore you begin playing the video: In this video, the narrator draws representational images on the display board to explain the concept. [Draw] is used to represent when the narrator draws the representational image. [Writing] is used to represent when the narrator writes some text.\n\nWhat if you could release a feature to different groups of users without deployment? Is there a way to effectively test features in production, and immediately roll them back if needed?\n\nHi, my name is Dilan Orrino with IBM Cloud. I'll be answering those questions by discussing feature flags, or sometimes referred to as feature toggle, or switches.\n\nFeature flags are conditions that encompass feature code that allow you to flip them on and off at will. Okay, let's use an example. [Draw] Let's say we've got an ice cream shop franchise that's looking to expand to a new city and we've got a [Draw] banner that we want to display on our website. We'll call this open banner. We only want to display this banner to users that are [Draw] nearby our new ice cream shop we can do this by using feature flags.\n\nThere's a couple benefits to using feature flags. [Writing] Number one is we can actually turn these on or off without deployment. [Writing] Number two is we can actually test directly in production. [Writing] And number three we can segment our users based on different attributes.\n\nOkay, there's a couple ways you can do this one way is by using properties in JSON files or config maps. There's a better way however by using a feature flag service.\n\n[Writing] There's a couple benefits to using a feature flag service. Number one is you can have essentially managed place for your features, or excuse me your feature flags. [Writing] Number two is you can turn these on and off without modifying your properties in your future, in your apps or web pages. [Writing] And number three is you get audit and usage data. It's harder to get the audit and usage data by using JSON files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_09864-5103-6606","score":14.871977,"text":"\n\"moreInformation\": \"https:\/\/example.com\",\n\"queueManagerLocation\": \"qm.us-south.mq.appdomain.cloud\",\n\"queueManagers\": [{\n\"hostname\": \"qm1-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM1\"\n}, {\n\"hostname\": \"qm2-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM2\"\n}],\n\"region\": \"us-south\",\n\"serviceInstance\": \"crn:v1:staging:public:mqcloud:region:a\/ab90cde12f345:ab5c678d-e90a-b5678c9::\"\n}\nShow more\n\nThe notification will contain the following keys:\n\n\n\n* datestamp: the date and time the notification was sent\n* description: an explanation of the problem and what action was taken\n* moreInformation: this may contain an external link to further explain the cause behind the DR\n* queueManagerLocation: the location of the cluster on which the queue manager is deployed\n* queueManagers: a list of hostnames and names of all affected queue managers\n* region: the physical location of your service instance\n* serviceInstance: the unique CRN of the containing service instance\n\n\n\n\n\n\n\n How to implement the endpoint handler \n\nThe instructions below demonstrate some sample code to implement an endpoint handler to send notifications via PagerDuty in an IBM Cloud Function, but you could also adapt this code to run in a location of your choice\n\nNote: the below function is written in Node.js\n\nconst https = require('https');\n\nfunction main(params) {\n\nreturn new Promise((resolve, reject) => {\n\n\/\/ Replace the string \"R4nd0m5tr1ng0fCh4r4ct3r5\" with your own value to secure access to your own specific endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_dr_notifications"},{"document_id":"ibmcld_09988-1469-3494","score":14.006811,"text":"\nGo to Queries > Stored queries.\n2. Select a query.\n3. From the overflow menu, click Remove.\n4. Confirm your choice by clicking Remove again.\n\n\n\n\n\n\n\n\n\n Query history \n\nTo access the page, go to Queries > Query history or select Query history from the home page.\n\nWhen you are on the Query history page, you can do the following:\n\n\n\n* View your data in a table or card view.\n* Export data to export your query history to a data file.\n* Sort any column by placing the cursor on the column header.\n* Find specific queries by using various filtering criteria.\n\nFor example, you can use it to find queries that are submitted by a particular user or group, or queries that run on a particular database.\n* Search the query history but clicking Search. You can use a predefined search criteria, or create a new search option.\n* Select the columns to display in the table.\n\nClick the settings icon next to the Find query history field to edit columns.\n* View metrics, access the explain graph, explain summary, explain verbose, explain distribution pages, and view the plan file and statistics status.\n\n\n\n\n\n Query history columns \n\n\n\n* Start time Specifies the time when the query started.\n* End time Specifies the time when the query finished.\n* Elapsed time Specifies the time that it took the query to run.\n* Query text Specifies the SQL command of the query.\n* Database Specifies the name of the database on which the query ran.\n* Schema Specifies the schema that was used for the query.\n* User name Species the name of the user that ran the query.\n* Group Specifies the group of users from which the query originates.\n* Result rows Specifies the number of result rows that were returned by the query.\n* Prep time Specifies the preparation time that was needed for the query.\n* Status Specifies the completion status of the query.\n* Plan ID Specifies the ID of the system-generated plan for the query.\n* Client IP Specifies the IP of the client that ran the SQL query.\n* GRA time Specifies the time that the query spent at the GRA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queries"},{"document_id":"ibmcld_13497-1510-3518","score":13.876869,"text":"\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https:\/\/www.ibm.com\/cloud\/blog\/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https:\/\/www.ibm.com\/cloud\/blog\/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-query-relnotes"},{"document_id":"ibmcld_01083-16619-18066","score":13.534567,"text":"\n[Datastore Properties - Target](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/68e10678b2f8b8694884ecb5442c326c9b60a3fb\/Db2whc\/connecting\/images\/IIDR_target_datastore.jpg)\n\nFigure 5. View of target datastore properties\n\nc. If the user (for example, admin) that connects to the Access Server does not exist, create that user:\n\nZoom\n\n![New User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/68e10678b2f8b8694884ecb5442c326c9b60a3fb\/Db2whc\/connecting\/images\/IIDR_management_user.jpg)\n\nFigure 6. View of New User creation tool\n\nd. Click the Access Manager tab.\n\ne. On the Datastore Management tab, assign the user to both the source and target datastores by right-clicking each datastore and then clicking Assign User. Ensure that the credentials for accessing each instance are correct.\n\nZoom\n\n![IIDR Management Console - Access Manager](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/68e10678b2f8b8694884ecb5442c326c9b60a3fb\/Db2whc\/connecting\/images\/IIDR_management_assign_user.jpg)\n\nFigure 7. IIDR Management Console - Access Manager\n\n\n\n\n\n\n\n What to do next \n\nDefine a subscription and perform data replication. For information, see:\n\n\n\n* [Loading data from InfoSphere Data Replication](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.doc\/learn_how\/loaddata_iidr.html)\n\n\n\n\n\n\n\n\n\n Data Studio \n\nThese instructions explain how to create a connection from IBM\u00ae Data Studio to a Db2 Warehouse on Cloud database.\n\n\n\n Prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-connect_ibm"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-108109-110305","score":21.142048,"text":"\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-106506-108540","score":20.312538,"text":"\nIf the partition location is not specified, it is inferred from the location of the table and the value(s) of the partitioning column(s). ADD PARTITION does not validate the specified or inferred location.\n\n-- alter the table partitions by adding a partition\nALTER TABLE customers_partitioned ADD IF NOT EXISTS PARTITION ( COUNTRY = 'Spain') LOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\/COUNTRY=Spain\n-- alter the table partitions by dropping a partition\nALTER TABLE customers_partitioned DROP IF EXISTS PARTITION ( COUNTRY = 'Nowhere')\n\nThe SET LOCATION option can be used to change the location of an existing partition.\n\n-- modify the location of an existing partition\nALTER TABLE customers_partitioned PARTITION (country = 'Spain') SET LOCATION cos:\/\/eu-de\/sql\/customers_partitioned.csv\/COUNTRY=Spain\n\nUse the EXISTS option to avoid getting errors during ADD or DROP.\n\n\n\n\n\n\n\n Alter table columns \n\n\n\n alterTableColumns \n\nUse alter table to add new columns to the schema of a catalog table.\n\nAdding columns to the schema has no effect on the objects in Object Storage for the table. If some or all of these objects do not contain a column, values for the corresponding rows are treated as NULL. You can add new objects to the table location (for nonpartitioned tables) or new partitions (for partitioned tables) that contain the new columns to evolve the table schema.\n\n-- create a partitioned sample table in PARQUET format\nCREATE TABLE customers_addcol USING PARQUET LOCATION cos:\/\/us-geo\/sql\/customers_partitioned.parquet\n-- add a new column that does not yet occur in existing partitions. new partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_16627-0-1141","score":20.026587,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"},{"document_id":"ibmcld_09958-5588-7326","score":18.828066,"text":"\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Create a temporal table as described in [Creating tables](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-tablescreating-tables).\n\n\n\nYou must set retention time interval to a nonzero value.\n\nDatabases, schemas, and table names containing a dot character (\".\") do not show in the time travel statistics and graphs when you set the retention time interval to a nonzero value. When you do not set the retention time interval, all special characters are supported.\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the web console \n\nTo create a temporal schema, set retention time interval to a nonzero value.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Create a temporal schema as described in [Creating schemas](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemas).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_16638-0-764","score":18.228025,"text":"\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-import_data"},{"document_id":"ibmcld_00054-3422-4901","score":17.964817,"text":"\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql:\/\/<CHANGEME>.databases.appdomain.CHANGEME\/ibmclouddb?sslmode=verify-ca&sslrootcert=\/home\/spark\/shared\/user-libs\/certificate_library_set\/custom\/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them. After running the following Spark application called postgres-create-schema.py, you will see the Hive metadata tables created against the \"public\" schema of the instance.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-schema\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef create_schema(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 time.sleep(30)\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 create_schema(spark,sc)\nif __name__ == '__main__':\n\u00a0 main()\n6. Now run the following script called postgres-parquet-table-create.py to create a Parquet table with metadata from IBM Cloud Object Storage in the Databases for PostgreSQL database.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-parquet-table-test\").getOrCreate()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_12006-1477-3303","score":17.725243,"text":"\nSimilar to Terraform, a DAG (Directed Acyclic Graph) is generated from the dependencies and relationships to determine execution order. Dependencies are created using '$module' references.\n\n\n\n\n\n How do I edit and validate blueprint templates? \n\nBlueprint templates can be edited in any editor or IDE. Follow the instructions on how to use and configure VSCode to [edit templates and input files](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-edit-blueprints). The [Red Hat YAML VSCode extension](https:\/\/marketplace.visualstudio.com\/items?itemName=redhat.vscode-yaml) provides a framework for editing blueprint YAML files, using a [blueprint schema](https:\/\/github.com\/Cloud-Schematics\/vscode-blueprint-schema) defined using [JSON-Schema](https:\/\/json-schema.org) .\n\n\n\n\n\n Why do blueprints get the error 'Length for variable variable name greater than the given length'? \n\nThe default size of values that can be passed to Blueprints as inputs is set to 1KB. If the expected size is greater than 1KB, the [max_length inputs meta-data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-template-schema-yamlbp-inputs-max-len) can be defined to set the length that Blueprints should accept.\n\nA value larger than 1KB or the specified length will result in the error Length for variable <variable name> greater than the given length\n\n\n\n\n\n Why do blueprint operations require a blueprint ID? \n\nIn Schematics Blueprints, the displayed name is not a unique identifier. Only the blueprint ID that is generated at create time is unique. This unique blueprint ID is needed by the command line to identify the specific environment to be worked on. Blueprint IDs are unique globally and generated from the user supplied name at create time.\n\n\n\n\n\n What URL format is used for referencing blueprint templates and input files?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faq"},{"document_id":"ibmcld_07578-612452-614297","score":17.723671,"text":"\nFunctions and variable operators are not supported in this release.\n\nA future release intends to implement functions and operators.\n* How are blueprint module dependencies and execution order determined?\n\nDependencies between blueprint modules are created using the value references between module inputs and outputs. Similar to Terraform, a DAG (Directed Acyclic Graph) is generated from the dependencies and relationships to determine execution order. Dependencies are created using '$module' references.\n* How do I edit and validate blueprint templates?\n\nBlueprint templates can be edited in any editor or IDE. Follow the instructions on how to use and configure VSCode to [edit templates and input files](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-edit-blueprints). The [Red Hat YAML VSCode extension](https:\/\/marketplace.visualstudio.com\/items?itemName=redhat.vscode-yaml) provides a framework for editing blueprint YAML files, using a [blueprint schema](https:\/\/github.com\/Cloud-Schematics\/vscode-blueprint-schema) defined using [JSON-Schema](https:\/\/json-schema.org) .\n* Why do blueprints get the error 'Length for variable variable name greater than the given length'?\n\nThe default size of values that can be passed to Blueprints as inputs is set to 1KB. If the expected size is greater than 1KB, the [max_length inputs meta-data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-template-schema-yamlbp-inputs-max-len) can be defined to set the length that Blueprints should accept.\n\nA value larger than 1KB or the specified length will result in the error Length for variable <variable name> greater than the given length\n* Why do blueprint operations require a blueprint ID?\n\nIn Schematics Blueprints, the displayed name is not a unique identifier. Only the blueprint ID that is generated at create time is unique.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-612410-614255","score":17.723671,"text":"\nFunctions and variable operators are not supported in this release.\n\nA future release intends to implement functions and operators.\n* How are blueprint module dependencies and execution order determined?\n\nDependencies between blueprint modules are created using the value references between module inputs and outputs. Similar to Terraform, a DAG (Directed Acyclic Graph) is generated from the dependencies and relationships to determine execution order. Dependencies are created using '$module' references.\n* How do I edit and validate blueprint templates?\n\nBlueprint templates can be edited in any editor or IDE. Follow the instructions on how to use and configure VSCode to [edit templates and input files](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-edit-blueprints). The [Red Hat YAML VSCode extension](https:\/\/marketplace.visualstudio.com\/items?itemName=redhat.vscode-yaml) provides a framework for editing blueprint YAML files, using a [blueprint schema](https:\/\/github.com\/Cloud-Schematics\/vscode-blueprint-schema) defined using [JSON-Schema](https:\/\/json-schema.org) .\n* Why do blueprints get the error 'Length for variable variable name greater than the given length'?\n\nThe default size of values that can be passed to Blueprints as inputs is set to 1KB. If the expected size is greater than 1KB, the [max_length inputs meta-data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-template-schema-yamlbp-inputs-max-len) can be defined to set the length that Blueprints should accept.\n\nA value larger than 1KB or the specified length will result in the error Length for variable <variable name> greater than the given length\n* Why do blueprint operations require a blueprint ID?\n\nIn Schematics Blueprints, the displayed name is not a unique identifier. Only the blueprint ID that is generated at create time is unique.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04326-7254-8865","score":17.638594,"text":"\nibmcloud watson-query virtualized-table-role-revoke --role ROLE --table-name TABLE-NAME --table-schema TABLE-SCHEMA\n\n\n\n Command options \n\n--role (string)\n: The watson query role type. Values can be DV_ADMIN, DV_ENGINEER, DV_STEWARD, or DV_WORKER, which correspond to MANAGER, ENGINEER, STEWARD, and USER roles in the user interface. Required.\n\n--table-name (string)\n: The virtualized table's name. Required.\n\n--table-schema (string)\n: The virtualized table's schema name. Required.\n\n\n\n\n\n Examples \n\nRevoke roles access to a virtualized table\n\nibmcloud watson-query virtualized-table-role-revoke --table-name TABLE1 --table-schema DV_IBMID_270001PD8Q --role DV_ENGINEER\n\n\n\n\n\n\n\n ibmcloud watson-query tables-for-role \n\nRetrieves the list of virtualized tables that have a specific role.\n\nibmcloud watson-query tables-for-role --role ROLE\n\n\n\n Command options \n\n--role (string)\n: Watson Query has four roles: MANAGER, STEWARD, ENGINEER and USER The value of rolename should be one of them. Required.\n\n\n\n\n\n Examples \n\nGet virtualized tables by role\n\nibmcloud watson-query tables-for-role --role DV_ENGINEER\n\n\n\n\n\n Example output \n\n{\n\"objects\" : [ {\n\"table_name\" : \"TEST_TABLE\",\n\"table_schema\" : \"ADMIN\"\n} ]\n}\n\n\n\n\n\n\n\n\n\n Securities \n\nManage Wason Knowledge Catalog(WKC) policy enforcement status.\n\n\n\n ibmcloud watson-query policy-status-update \n\nTurn on WKC policy enforcement status.\n\nibmcloud watson-query policy-status-update --status STATUS\n\n\n\n Command options \n\n--status (string)\n: Set the status of WKC policy - can be 'enable' or 'disable'. Required.\n\n\n\n\n\n Examples \n\nTurn on or off WKC policy enforcement status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00553-6057-7460","score":16.94949,"text":"\n* [Design document management](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-document-management)\n* [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant)\n* [How to use attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n\n\n\n* Monitoring your instance\n\n\n\n* [Monitoring an IBM Cloudant cluster](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster)\n* [Capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-capacity)\n* [Active tasks](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks)\n* [Managing tasks](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-tasks)\n\n\n\n* Querying the database\n\n\n\n* [Working with IBM Cloudant Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* [IBM Cloudant Query Parameters](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-query-parameters)\n* [Working with indexes](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-indexes)\n* [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-selector-expressions)\n* [Selector syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax)\n* [IBM Cloudant Operators](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-operators)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-http-works-with-cloudant"},{"document_id":"ibmcld_00620-25943-27384","score":16.552708,"text":"\n* IBM Cloudant provides an array of 10 IBM Cloudant documents and a bookmark, an opaque key that represents a pointer to the next documents in the result set. * When the next set of results is required, the search is repeated. However, the query is sent, with the bookmark from the first response, to IBM Cloudant in the request. * IBM Cloudant replies with the second set of documents and another bookmark, which can be used to get a third page of results. * Repeat<-- <\/ul> -->Now you can see how to do that with code.<-- <\/section \"id=\"section-how-do-cloudant-bookmarks-work\" \"> --><-- <section \"id=\"section-use-cloudant-query-search\" \"> --> How can I use IBM Cloudant Query to search? First, you search for all the cities in the US. You're using IBM Cloudant Query]IBM Cloudant Query 1] , so the operation is specified as a block of JSON: {\n\"selector\": {\n\"$eq\": {\n\"country\": \"US\"\n}\n},\n\"limit\": 5\n}\nBy using the \/db\/_find]IBM Cloudant Query] ! ! API endpoint, the results are passed to IBM Cloudant.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -X POST -H \"Authorization: Bearer $API_BEARER_TOKEN\" -H 'Content-type: application\/json' -d '{\"selector\":{\"country\":{\"$eq\": \"US\"}},\"limit\":5}' \"$SERVICE_URL\/cities\/_find\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.FindResult;\nimport com.ibm.cloud.cloudant.v1.model.PostFindOptions;\n\nimport java.util.Collections;\nimport java.util.Map;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00539-7-1755","score":16.250982,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00616-3461-5143","score":16.160065,"text":"\n2. Copy the following sample JSON and replace the existing text in the new query window:\n\n{\n\"selector\": {\n\"lastname\" : \"Greene\",\n\"firstname\" : \"Anna\"\n}\n}\n3. Click Run Query.\n\nThe query displays the results. You can see them from the Table view in the following screen capture:\n\nZoom\n\n![Query results](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/dashboard_query1_results.png)\n\nFigure 2. Query results\n\n\n\nFor more information, see the [IBM Cloudant Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query) tutorial or the API reference on [IBM Cloudant Query](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetindexesinformation).\n\n\n\n\n\n\n\n Step 4: Replicating a database \n\nWhen you replicate a database, it synchronizes the state of two databases: source and target. A replication copies all the changes that happened in the source database to the target database. When a document is deleted from the source database, the document is also deleted from the target database.\n\nFor more information, see [Replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apireplication-operation).\n\n\n\n1. Click Replication.\n2. Click New Replication.\n\nThe Job configuration page opens.\n\nAdditionally, you can create a replication from the databases page by clicking Replicate in the Actions column.\n3. Enter the following information for your replication job. Use the following information in the Source section:\n\n\n\n* Type - Select Remote database.\n* Name - Enter the database URL: $SERVICE_URL\/query-movies.\n* Authentication - Leave as None.\n\n\n\nUse the following information in the Target section:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-navigate-the-dashboard"},{"document_id":"ibmcld_00491-1283-3050","score":16.04084,"text":"\n(Optional) [Create an acurl alias](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"},{"document_id":"ibmcld_00460-22680-24587","score":15.74145,"text":"\nSee [COUCHDB-1612](https:\/\/issues.apache.org\/jira\/browse\/COUCHDB-1612).\n\nIBM Cloudant Query and invalid reduce functions\n: Fix invalid reduce functions in IBM Cloudant Query indexes that prevent indexing. See [COUCHDB-1666](https:\/\/issues.apache.org\/jira\/browse\/COUCHDB-1666).\n\n\n\n\n\n\n\n October 2018 \n\n\n\n 11 October 2018 \n\nThe following changes were made in build 7304:\n\nImprovements\n: This build is identical to build 7302 except that the build is on Erlang 17.5 instead of Erlang 20.\n\n\n\n\n\n\n\n September 2018 \n\n\n\n 25 September 2018 \n\nThe following changes were made in build 7302:\n\nMango Query\n: Improve Mango Query so that mixed clusters return correct results during upgrades.\n\nDowngrade function\n: Add a downgrade function to support future cluster purge releases.\n\nSearch blocklist\n: Improve search blocklist.\n\n\n\n\n\n 18 September 2018 \n\nThe following changes were made in build 7276:\n\nImprovements\n: Add a filter for databases that are being opened asynchronously to prevent exceptions when couch_server terminates.\n\nConcurrency error\n: Fix couch_server concurrency error.\n\nConfiguration option\n: Add a configuration option to disable off-heap messages.\n\n\n\n\n\n 13 September 2018 \n\nTLS 1.3 connection support\n: From today, IBM Cloudant supports TLS 1.3 connections to IBM Cloudant.\n: IBM Cloudant recommends that you use TLS 1.2 or 1.3 for all access to IBM Cloudant. (In June 2019, IBM Cloudant retired the use of older versions (TLS 1.0 and 1.1) at which point only TLS 1.2+ is supported.) Find more information on the [Security page](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-securitysecurity).\n\n\n\n\n\n 7 September 2018 \n\nThe following changes were made in build 7205:\n\nRefactor Mango Query selectors\n: Refactor Mango Query selectors to reduce the amount of traffic sent between nodes in the cluster.\n\nDocument update errors\n: Expose document update errors on concurrent document updates to client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-classic-release-notes"},{"document_id":"ibmcld_00491-7-1604","score":15.739869,"text":"\nUsing IBM Cloudant Query \n\nIn this tutorial, we demonstrate how to create an index and use the index to query the database. You also learn to create different types of queries to more easily find data.\n\nHere you run the commands from the command line, but you can also complete these tasks with the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard, which gives you a visual example of each task. For more information about the dashboard, see [Using the IBM Cloudant Dashboard](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query) tutorial.\n\n\n\n Before you begin \n\nBefore you begin, follow these tutorials to create an instance, and then create and populate a database.\n\n\n\n1. [Create an IBM Cloudant instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-an-ibm-cloudant-instance-on-ibm-cloud).\n2. [Create a database](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudcreating-a-database-within-the-service-instance).\n3. [Populate the database](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudstoring-a-small-collection-of-data-as-documents-within-the-database).\n4. (Optional) [Create an acurl alias](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\/databasedemo\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"},{"document_id":"ibmcld_16729-108576-110297","score":15.71091,"text":"\n[Using a Dedicated Hardware plan instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud)Using a Dedicated Hardware plan instance\n\nThis tutorial shows you how to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dedicated Hardware plan instance that uses the IBM Cloud\u00ae Dashboard.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Using IBM Cloudant Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query)Using IBM Cloudant Query\n\nIn this tutorial, we demonstrate how to create an index and use the index to query the database. You also learn to create different types of queries to more easily find data.\n\nCloudant\n\n\n\n* 10 minutes\n* 2023-04-11\n\n\n\n[Creating an instance with CLI](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-instance-on-ibm-cloud-by-using-the-ibm-cloud-cli)Creating an instance with CLI\n\nThis tutorial shows you how to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae service instance on IBM Cloud\u00ae by using the IBM Cloud CLI.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Locating your Db2 Warehouse on Cloud credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-db2-warehouse-credentials)Locating your Db2 Warehouse on Cloud credentials\n\nTo find alternatives to IBM Cloudant's IBM\u00ae Db2\u00ae Warehouse on Cloud feature, see the data-flow-examples repository for tutorials on extracting IBM Cloudant documents and writing the data to a Db2 Warehouse on Cloud table.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Locating your service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentials)Locating your service credentials","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_00539-9878-11388","score":15.680901,"text":"\nBy default, an IBM Cloudant Query index is global (for example, not partitioned) but on a partitioned database, a partitioned index can be created by adding partitioned: true when the index is created: e To create a partitioned index on firstname and surname, the POST \/<dbname>\/_index is used:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byName\",\n\"type\": \"json\",\n\"partitioned\": true\n}\n\nPartitioned indexes can be used when you run only a partitioned query, for example, by using the [GET \/<dbname>\/_partition\/<partition key>\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostpartitionfind-partitioned-databases) API endpoint.\n\nFor more information, see [Creating a partitioned index](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n Can I use regular expressions in my queries? \n\nYes! IBM Cloudant Query has a [$regex operator](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querythe-regex-operator) that allows regular expression terms within a query.\n\nProceed with caution: if a query contains only a $regex operator, then a secondary index cannot help you - the query results in a document-by-document scan of the database.\n\nA $regex operator can be tagged onto the end of an already performant query. For example, if we already have a type=json index on firstname and surname, we can use the following example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\",\n\"title\": {\n\"$regex\": \"^Oliv\"\n}\n},\n\"limit\": 10\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00539-4998-6652","score":15.672509,"text":"\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...\n\"execution_stats\": {\n\"total_keys_examined\": 0,\n\"total_docs_examined\": 1000000,\n\"total_quorum_docs_examined\": 0,\n\"results_returned\": 2,\n\"execution_time_ms\": 4400.699\n}\n}\n\nThe ratio between total_docs_examined and results_returned is key here: a high value indicates that too many documents are being scanned per document that is returned.\n\nFor more information, see [Blog post on Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html).\n\n\n\n\n\n Which IBM Cloudant Query operators defeat the use of an index? \n\nAny of the [combination operators](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryoperators) other than $and can make a query do a full database scan without the help of a secondary index. For example, if an $or operator is used, then no secondary index can be used to assist the query. If in doubt, use the [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.3462096432,"ndcg_cut_10":0.3462096432}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-85554-87392","score":18.824163,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-85529-87367","score":18.824163,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03313-10911-12959","score":18.724047,"text":"\nTo regain access to the service instance, ask the service instance owner to review your access permissions. Ask to be given at least a service access role of Writer.\n\nAfter your access roles are fixed, be sure to use the correct web address, the URL of the migrated service instance, to open it.\n\n\n\n\n\n I don\u2019t see the Analytics page \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n\n\n\n\n\n I am unable to view the API details, API key, or service credentials \n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager service access to the instance can use the service credentials. For more information, see [Getting API information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settingsassistant-settings-api-details).\n\n\n\n\n\n I can't edit intents, entities, or dialog nodes \n\nTo edit skills, you must have Writer service access to the service instance and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n\n\n\n\n\n Where can I find an example for creating my first assistant? \n\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_07578-74047-75977","score":17.788332,"text":"\nYou can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* Why don't I see the Analytics page?\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n* Why am I unable to view the API details, API key, or service credentials?\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-74022-75952","score":17.788332,"text":"\nYou can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* Why don't I see the Analytics page?\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n* Why am I unable to view the API details, API key, or service credentials?\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16362-4518-6470","score":17.708805,"text":"\nLite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n\n\n\n\n\n Why am I unable to view the API details, API key, or service credentials? \n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I change my plan to a Lite plan? \n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n\n\n\n\n\n How many Lite plan instances of Watson Assistant can I create? \n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n\n\n\n\n\n How do I create a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_16258-7-1952","score":17.61185,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_07578-10559-12643","score":17.505522,"text":"\nAfter the migration, the service instance owner must update the user permissions to ensure that anyone who needs access to the instance is assigned to the appropriate Platform and Service access roles.\n\nTo regain access to the service instance, ask the service instance owner to review your access permissions. Ask to be given at least a service access role of Writer.\n\nAfter your access roles are fixed, be sure to use the correct web address, the URL of the migrated service instance, to open it.\n* I don\u2019t see the Analytics page\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n* I am unable to view the API details, API key, or service credentials\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager service access to the instance can use the service credentials. For more information, see [Getting API information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settingsassistant-settings-api-details).\n* I can't edit intents, entities, or dialog nodes\n\nTo edit skills, you must have Writer service access to the service instance and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-10559-12643","score":17.505522,"text":"\nAfter the migration, the service instance owner must update the user permissions to ensure that anyone who needs access to the instance is assigned to the appropriate Platform and Service access roles.\n\nTo regain access to the service instance, ask the service instance owner to review your access permissions. Ask to be given at least a service access role of Writer.\n\nAfter your access roles are fixed, be sure to use the correct web address, the URL of the migrated service instance, to open it.\n* I don\u2019t see the Analytics page\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n* I am unable to view the API details, API key, or service credentials\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager service access to the instance can use the service credentials. For more information, see [Getting API information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settingsassistant-settings-api-details).\n* I can't edit intents, entities, or dialog nodes\n\nTo edit skills, you must have Writer service access to the service instance and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-12038-13856","score":17.307856,"text":"\nFor more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control).\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-filter-reference). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":20.331106,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":19.868752,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03037-1358-3485","score":17.126152,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03216-16161-17914","score":17.098238,"text":"\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"message_to_human_agent\": \"User asked to speak to an agent.\",\n\"agent_available\": {\n\"message\": \"Please wait while I connect you to an agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"I'm sorry, but no agents are online at the moment. Please try again later.\"\n}\n}\n]\n}\n}\nShow more\n\n\n\n\n\n\n\n channel_transfer \n\nRequests that the conversation be transferred to a different integration.\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string channel_transfer Y \n message_to_user string A message to display to the user before the link for initiating the transfer. Y \n transfer_info object Information used by an integration to transfer the conversation to a different channel. Y \n transfer_info.target.chat string The URL for the website hosting the web chat to which the conversation is to be transferred. Y \n\n\n\n\n\n\n\n Example \n\nThis example requests a transfer from Slack to web chat. In addition to the channel_transfer response, the output also includes a text response to be displayed by the web chat integration after the transfer. The use of the channels array ensures that the channel_transfer response is handled only by the Slack integration (before the transfer), and the connect_to_agent response only by the web chat integration (after the transfer). For more information about using channels to target specific integrations, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"channel_transfer\",\n\"channels\":\n{\n\"channel\": \"whatsapp\"\n}\n],\n\"message_to_user\": \"Click the link to connect with an agent using our website.\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"},{"document_id":"ibmcld_03364-6793-8946","score":16.985428,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_16259-1485-3642","score":16.211111,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_16312-3100-5015","score":15.981049,"text":"\nEscalation If your assistant is integrated with one of the supported service desk systems, you can build in logic that transfers, or escalates, the conversation to a human when necessary. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent). \n Incompletion Reasons why an action is not completed by a user, including escalated to agent, started a new action, stuck on a step, or abandoned or ongoing. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completionreasons-for-incompletion) \n Integrations Add-ons to the end experience that help solve specific user problems, for example, connecting to a human agent or searching existing help content. Integrations are not required for an assistant, but they are recommended. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant). \n Message A single turn within a conversation that includes a single call to the \/message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based). \n Preview Embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview, you can test how a conversation flows through your assistant, from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share). \n Recognition Measurement of how many requests are being recognized by the assistant and routed into starting an action. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overviewrecognition). \n Response To create your assistant's response in an action step, you use the Assistant says section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-glossary"},{"document_id":"ibmcld_16321-34213-35925","score":15.649164,"text":"\nFor more information, see [Integrating with SMS](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms).\n\nWhen you exchange a text with a customer during a conversation, the assistant initiates the SMS message exchange. It sends a text message to the user and asks for the user to respond to it.\n\nTo send a specific message from an action step, use the user_defined response type with the vgwActSendSMS command:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"values\":\n{\n\"text\": \"I will send you a text message now.\"\n}\n],\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"user_defined\",\n\"user_defined\": {\n\"vgwAction\": {\n\"command\": \"vgwActSendSMS\",\n\"parameters\": {\n\"message\": \"Hey, this is Watson Assistant. To send me your street address, respond to this text message with your address.\"\n}\n}\n}\n}\n]\n}\nShow more\n\nYou can specify any of the following parameters in the parameters object:\n\n\n\n Parameter Type Description \n\n message string The text of the SMS message to send. Required. \n mediaURL list A list of URLs for media files to be sent with the message as MMS attachments. Optional. \n tenantPhoneNumber string The phone number that is associated with the tenant. The format of the number must match the format that is required by the SMS provider. If no tenantPhoneNumber value is provided, the tenant ID from the phone integration configuration for the active call is used. Optional. \n userPhoneNumber string The phone number to send the SMS message to. The format of the number must match the format that is required by the SMS provider. If no userPhoneNumber value is provided, the voice caller's phone number from From header of the incoming SIP INVITE request is used. Optional.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16337-4251-6012","score":15.617823,"text":"\n* The indicated channel integrations support initiating a channel transfer (currently, the web chat integration is the only supported transfer target).\n* Initiating a channel transfer from the phone integration requires that the SMS integration also be configured.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string channel_transfer Y \n message_to_user string A message to display to the user before the link for initiating the transfer. Y \n transfer_info object Information used by an integration to transfer the conversation to a different channel. Y \n transfer_info.target.chat string The URL for the website hosting the web chat to which the conversation is to be transferred. Y \n\n\n\n\n\n\n\n Example \n\nThis example requests a transfer from WhatsApp to the web chat. In addition to the channel_transfer response, the output also includes a text response to be displayed by the web chat integration after the transfer. The use of the channels array ensures that the channel_transfer response is handled only by the WhatsApp integration (before the transfer), and the connect_to_agent response only by the web chat integration (after the transfer). For more information about using channels to target specific integrations, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-referenceassistant-responses-json-target-integrations).\n\n{\n\"generic\": [\n{\n\"response_type\": \"channel_transfer\",\n\"channels\":\n{\n\"channel\": \"whatsapp\"\n}\n],\n\"message_to_user\": \"Click the link to connect with an agent using our website.\",\n\"transfer_info\": {\n\"target\": {\n\"chat\": {\n\"url\": \"https:\/\/example.com\/webchat\"\n}\n}\n}\n},\n{\n\"response_type\": \"connect_to_agent\",\n\"channels\":\n{\n\"channel\": \"chat\"\n}\n],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_03216-14701-16393","score":15.426562,"text":"\nGo to Message > Response > output > MessageOutput > generic > RuntimeResponseTypeSearch in [Watson Assistant v2 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2message-response) to view how response_type search renders when search_skill response is processed..\n\n\n\n\n\n Example \n\nThis example uses the user input text to send a natural-language query to the search skill.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"search_skill\",\n\"query\": \"\",\n\"query_type\": \"natural_language\"\n}\n]\n}\n}\n\n\n\n\n\n\n\n connect_to_agent \n\nRequests that the conversation be transferred to a service desk agent for help.\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string connect_to_agent Y \n message_to_human_agent string A message to display to the live agent to whom the conversation is being transferred. Y \n agent_available string A message to display to the user when agents are available. Y \n agent_unavailable string A message to display to the user when no agents are available. Y \n transfer_info object Information used by the web chat service desk integrations for routing the transfer. N \n transfer_info.target.zendesk.department string A valid department from your Zendesk account. N \n transfer_info.target.salesforce.button_id string A valid button ID from your Salesforce deployment. N \n\n\n\n\n\n\n\n Example \n\nThis example requests a transfer to a live agent and specifies messages to be displayed both to the user and to the agent at the time of transfer.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"message_to_human_agent\": \"User asked to speak to an agent.\",\n\"agent_available\": {\n\"message\": \"Please wait while I connect you to an agent.\"\n},\n\"agent_unavailable\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02064-20902-22794","score":10.952886,"text":"\nCan trusted profiles create user API keys? \n\nIf you use a trusted profile, you can't create a user API key. You can still create and manage all other API keys. For example, service ID API keys.\n\nTo create a user API key, your IAM ID and the IAM ID of the user that's requesting the user API key must be the same. When you apply a trusted profile, you take on the IAM ID of that profile. To create a user API key for your identity, log out of IBM Cloud and log back in without applying a trusted profile.\n\n\n\n\n\n How can I check whether a user can apply a trusted profile? \n\nTo check whether a user qualifies to apply a trusted profile by using the IBMid identity provider (IdP), the user and the administrator must complete specific steps.\n\n\n\n1. The user must go to [IBM Cloud User Claims](https:\/\/iam.cloud.ibm.com\/identity\/claims).\n2. From here, the claims are displayed.\n3. The user must provide the claims to the administrator.\n4. As the administrator, compare the claims of the user with the conditions set for the trusted profile. To view the conditions for a trusted profile, go to Manage > Access (IAM) > Trusted profiles in the IBM Cloud console.\n5. Click the profile and view the Conditions column.\n6. If the user's claims satisfy all of the conditions, the user can apply the profile.\n\n\n\nIf you are using a different IdP, check the user's claims in your corporate directory. Then, compare the claims of the user with the conditions set for the trusted profile. If the claims and the rules match, the user can apply the profile.\n\n\n\n\n\n How do I establish trust with the Kubernetes service in a trusted profile? \n\nIn Kubernetes, a service account provides an identity for processes that run in a Pod, and namespaces provide a mechanism for isolating groups of resources within a single cluster. All Kubernetes clusters have a default namespace, and each namespace has a default account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamfaq"},{"document_id":"ibmcld_08423-5202-6869","score":10.90309,"text":"\nThe role ID must begin with a capital letter and use alphanumeric characters only; for example, KeystoreOperator\n5. Optional: Enter a succinct and helpful description that helps the users who are assigning access know what level of access this role assignment gives a user. This description also shows in the console when a user assigns access to the service.\n6. From the list of services, select Hyper Protect Crypto Services.\n7. Select Add for the following actions:\n\n\n\n* hs-crypto.keystore.createkeystore\n* hs-crypto.keystore.deletekeystore\n* hs-crypto.keystore.listkeystoresbyattributes\n* hs-crypto.keystore.listkeystoresbyids\n\n\n\n8. Click Create when you're done adding actions.\n\n\n\nFor more information about how to create custom roles, see [Creating custom roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-custom-roles).\n\n\n\n\n\n\n\n Step 2: Create service IDs and API keys for the SO user, normal user, and anonymous user \n\n\n\n 1. Create service IDs and API keys for the SO user \n\nTo create a service ID for the SO user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the SO user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name SO user and description for the SO user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the SO user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, SO user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"},{"document_id":"ibmcld_07578-1114311-1116276","score":10.666569,"text":"\nYou can still create and manage all other API keys. For example, service ID API keys.\n\nTo create a user API key, your IAM ID and the IAM ID of the user that's requesting the user API key must be the same. When you apply a trusted profile, you take on the IAM ID of that profile. To create a user API key for your identity, log out of IBM Cloud and log back in without applying a trusted profile.\n* How can I check whether a user can apply a trusted profile?\n\nTo check whether a user qualifies to apply a trusted profile by using the IBMid identity provider (IdP), the user and the administrator must complete specific steps.\n\n\n\n1. The user must go to [IBM Cloud User Claims](https:\/\/iam.cloud.ibm.com\/identity\/claims).\n2. From here, the claims are displayed.\n3. The user must provide the claims to the administrator.\n4. As the administrator, compare the claims of the user with the conditions set for the trusted profile. To view the conditions for a trusted profile, go to Manage > Access (IAM) > Trusted profiles in the IBM Cloud console.\n5. Click the profile and view the Conditions column.\n6. If the user's claims satisfy all of the conditions, the user can apply the profile.\n\n\n\nIf you are using a different IdP, check the user's claims in your corporate directory. Then, compare the claims of the user with the conditions set for the trusted profile. If the claims and the rules match, the user can apply the profile.\n* How do I establish trust with the Kubernetes service in a trusted profile?\n\nIn Kubernetes, a service account provides an identity for processes that run in a Pod, and namespaces provide a mechanism for isolating groups of resources within a single cluster. All Kubernetes clusters have a default namespace, and each namespace has a default account.\n\nWhen you establish trust with the Kubernetes service in a trusted profile, you are required to enter information in the namespace and service account fields. You can enter default for both.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1116792-1118757","score":10.666569,"text":"\nYou can still create and manage all other API keys. For example, service ID API keys.\n\nTo create a user API key, your IAM ID and the IAM ID of the user that's requesting the user API key must be the same. When you apply a trusted profile, you take on the IAM ID of that profile. To create a user API key for your identity, log out of IBM Cloud and log back in without applying a trusted profile.\n* How can I check whether a user can apply a trusted profile?\n\nTo check whether a user qualifies to apply a trusted profile by using the IBMid identity provider (IdP), the user and the administrator must complete specific steps.\n\n\n\n1. The user must go to [IBM Cloud User Claims](https:\/\/iam.cloud.ibm.com\/identity\/claims).\n2. From here, the claims are displayed.\n3. The user must provide the claims to the administrator.\n4. As the administrator, compare the claims of the user with the conditions set for the trusted profile. To view the conditions for a trusted profile, go to Manage > Access (IAM) > Trusted profiles in the IBM Cloud console.\n5. Click the profile and view the Conditions column.\n6. If the user's claims satisfy all of the conditions, the user can apply the profile.\n\n\n\nIf you are using a different IdP, check the user's claims in your corporate directory. Then, compare the claims of the user with the conditions set for the trusted profile. If the claims and the rules match, the user can apply the profile.\n* How do I establish trust with the Kubernetes service in a trusted profile?\n\nIn Kubernetes, a service account provides an identity for processes that run in a Pod, and namespaces provide a mechanism for isolating groups of resources within a single cluster. All Kubernetes clusters have a default namespace, and each namespace has a default account.\n\nWhen you establish trust with the Kubernetes service in a trusted profile, you are required to enter information in the namespace and service account fields. You can enter default for both.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02064-19360-21288","score":10.642712,"text":"\nHow do I reset a verification method? \n\nA verification method becomes inaccessible if a phone number or email address that's associated with your identity changes or you no longer have access to it. To reset a verification method, [open a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and add a verification method that you can use to access the Verification methods and authentication factors page.\n\n\n\n\n\n How can I get a new QR code for MFA setup? \n\nTo get a new QR code for MFA setup, go to the [Verification methods and authentication factors](https:\/\/iam.cloud.ibm.com\/mysecurity) page. From the Authentication factors section, click Show authentication factors > Add. Next, choose a type and select TOTP. Then, the new QR is available. After you scan the QR code, enter the TOTP that is generated by the authenticator app to confirm your choice. Now, each time you log in you provide the TOTP generated by the authenticator app that you just set up.\n\n\n\n\n\n How do I change the email address that is used for MFA? \n\nYou can update the email address that is used for MFA on the [Verification methods and authentication factors](https:\/\/iam.cloud.ibm.com\/mysecurity) page. From the Authentication factors section, click Show authentication factors > Add. Select Email-based and enter the email address where you want to receive OTPs as an authentication factor. Then, enter the OTP you receive to confirm your choice. Next, click Complete. After you add the new factor, select the old email address, and click Remove.\n\n\n\n\n\n Can trusted profiles create user API keys? \n\nIf you use a trusted profile, you can't create a user API key. You can still create and manage all other API keys. For example, service ID API keys.\n\nTo create a user API key, your IAM ID and the IAM ID of the user that's requesting the user API key must be the same. When you apply a trusted profile, you take on the IAM ID of that profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamfaq"},{"document_id":"ibmcld_09934-7-1768","score":10.63227,"text":"\nSetting Azure AD authentication \n\nSet your authentication method to AzureAD with the [REGISTER EXTERNAL AUTHENTICATION SYSTEM SQL statement](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=reference-register-external-authentication).\n\nTwo factor authentication is not supported with an external authentication system.\n\n\n\n Syntax \n\nREGISTER EXTERNAL AUTHENTICATION SYSTEM 'AzureAD' with clientid 'AZURE CLIENT ID' tenantid 'AZURE TENANT ID'\n\n\n\n* For clientid, see [How to: Get an Azure Application ID](https:\/\/learn.microsoft.com\/en-us\/previous-versions\/windows\/desktop\/msipcthin2\/application-id?).\n* For tenantid, see [How to find your Azure Active Directory tenant ID](https:\/\/learn.microsoft.com\/en-us\/azure\/active-directory\/fundamentals\/active-directory-how-to-find-tenant).\n\n\n\n\n\n\n\n Setting Azure AD authentication with the web console \n\n\n\n1. [Log in to the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console) as an admin user.\n2. Go to the Query editor.\n3. Register an Azure AD external authentication system. Specify the clientid and tenantid parameters.\n\nREGISTER EXTERNAL AUTHENTICATION SYSTEM 'AzureAD' with clientid 'AZURE CLIENT ID' tenantid 'AZURE TENANT ID';\nSET VARIABLE\n4. Create a user or users with the external authentication method set to AzureAD as desribed in [Creating users](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-users-groupscreate-users).\n5. Verify whether the user was created successfully.\n\n\n\n1. Go to Users and groups > Users.\n2. Locate the user.\n3. Check the Authentication type section for the user.\n\n\n\n\n\n\n\n\n\n Setting Azure AD authentication with the command-line \n\n\n\n1. [Connect to Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-connecting-overview) as an admin user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-azureadauth"},{"document_id":"ibmcld_09294-7235-9274","score":10.615508,"text":"\nService role: Manager Allows the user to launch the web UI and configure archiving through the web UI or by using the API. \n\n\n\nFor more information on how to configure policies for a user, see [Granting user permissions to a user or service ID](https:\/\/cloud.ibm.com\/docs\/services\/log-analysis?topic=log-analysis-iam_view_logsiam_view_logs).\n\n\n\n\n\n IBM Cloud Object Storage service \n\nThe following table lists the roles that a user can have to complete the actions required to configure the IBM Cloud Object Storage service:\n\n\n\nTable 2. Roles and actions\n\n Service Roles Action \n\n Cloud Object Storage Platform role: Administrator Allows the user to assign policies to users in the account to work with the IBM Cloud Object Storage service. \n Cloud Object Storage Platform role: Administrator <br>or <br>Platform role:Editor Allows the user to provision an instance of the IBM Cloud Object Storage service. \n Cloud Object Storage Platform role: Administrator <br>or <br>Platform role:Editor <br>or <br>Platform role: Operator Allows the user to create a service ID. \n Cloud Object Storage Service role: writer Grants permissions to create, modify, and delete buckets. In addition, grants permissions to upload and download the objects in the bucket. \n\n\n\nFor more information on how to configure policies for a user, see [Grant IAM policies to a user to work with IBM Cloud Object StorageD](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-archivingarchiving_step1).\n\n\n\n\n\n Service ID \n\nThe service ID that you must create for an IBM Cloud Object Storage instance is used by IBM Log Analysis to authenticate and access the IBM Cloud Object Storage instance. This service ID must have the writer role. This role grants permissions to upload archive files in the bucket.\n\nWhen the service credential is rotated, make sure the [API Key is updated with the new API Key.](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-archivingarchiving_step8) Archiving will stop if the API Key is not updated.\n\n\n\n\n\n\n\n Activity Tracker logs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-archiving-ov"},{"document_id":"ibmcld_02377-7473-9555","score":10.562026,"text":"\nFor more information on how to configure policies for a user, see [Granting user permissions to a user or service ID](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-iam_view_eventsiam_view_events).\n\n\n\n\n\n IBM Cloud Object Storage service \n\nThe following table lists the roles that a user can have to complete the actions required to configure the IBM Cloud Object Storage service:\n\n\n\nTable 2. Roles and actions\n\n Service Roles Action \n\n Cloud Object Storage Platform role: Administrator Allows the user to assign policies to users in the account to work with the IBM Cloud Object Storage service. \n Cloud Object Storage Platform role: Administrator <br>or <br>Platform role:Editor Allows the user to provision an instance of the IBM Cloud Object Storage service. \n Cloud Object Storage Platform role: Administrator <br>or <br>Platform role:Editor <br>or <br>Platform role: Operator Allows the user to create a service ID. \n Cloud Object Storage Service role: writer Grants permissions to create, modify, and delete buckets. In addition, grants permissions to upload and download the objects in the bucket. \n\n\n\nFor more information on how to configure policies for a user, see [Grant IAM policies to a user to work with IBM Cloud Object StorageD](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archivingarchiving_step1).\n\n\n\n\n\n Service ID \n\nThe service ID that you must create for an IBM Cloud Object Storage instance is used by IBM Cloud Activity Tracker to authenticate and access the IBM Cloud Object Storage instance. This service ID must have the writer role. This role grants permissions to upload archive files in the bucket.\n\nWhen the service credential is rotated, make sure the [API Key is updated with the new API Key.](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archivingarchiving_step8) Archiving will stop if the API Key is not updated.\n\n\n\n\n\n\n\n Activity Tracker events \n\nThe following Activity Tracker events are generated when you configure archiving:\n\n\n\nTable 3. Archiving Activity Tracker events","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving-ov"},{"document_id":"ibmcld_13878-14307-15983","score":10.519625,"text":"\n* [Service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids): Similar to how a user ID identifies a user, a service ID can identify a specific service or application, even a task. The service ID could be considered a \"technical user\". You can assign privileges to a service ID. Moreover, a service ID has its own IAM API keys to authenticate. Thus, a service ID can be used instead of a regular user ID, thereby simplifying resource management and increasing security. [To avoid deleting a service ID by mistake, you can lock them](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids&interface=uilock_serviceid).\n* [Access groups with access policies](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups): To simplify management of privileges (authorization), you can group user IDs and service IDs into access groups. You create an access group for a purpose, e.g., to administrate the application or a component. Then, you create access policies for that group to assign privileges and add the related user IDs and service IDs.\n* [Trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile): Using a trusted profile, you can automatically grant access to your account in a defined context and with a set of defined privileges. You can define such a context for either federated users based on properties in the enterprise directory, e.g., for users labeled as administrators or project members. Or you can allow access for [compute identities](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profilecreate-profile-compute-ui), i.e., specific computing resources like a virtual server instance (VSI).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_02152-7-1996","score":10.504199,"text":"\nWhat's in an account? \n\nYour IBM Cloud\u00ae account includes many interacting components and systems for resource, user, and access management. Concepts like how certain components are connected or how access works help you in understanding how to set up your account.\n\nThe following diagram contains two main concepts for the components in the account hierarchy that are important to understand. The use of the solid lines and the dotted lines help illustrate that some components are contained within others, for example, users are added to access groups. However, some components interact with others for providing access instead of membership. For example, users are given access to resource groups but are not members of a resource group the same way they are for access groups.\n\nZoom\n\n![A diagram that shows the components in an account, including services, users, and the subcomponents of each.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account_diagram.svg)\n\nFigure 1. A diagram that shows the components in an account, including services, users, and the subcomponents of each.\n\nUsers\n: Users are invited to the account and given access to the resources in the account.\n\nService IDs\n: A service ID identifies a service or application similar to how a user ID identifies a user. You can use a service ID that you create to enable an application outside of IBM Cloud access to your services. You can assign specific access policies to the service ID that restrict permissions for using specific services, or even combine permissions for accessing different services. Since service IDs are not tied to a specific user, if a user happens to leave an organization and is deleted from the account, the service ID remains, ensuring that your application or service stays up and running. For more information, see [Creating and working with service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids).\n\nTrusted profiles","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07765-0-1628","score":17.804256,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_07787-0-1608","score":14.253385,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"},{"document_id":"ibmcld_02746-7-1681","score":13.089179,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_00708-54925-56282","score":13.004954,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-54925-56282","score":13.004954,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-54906-56263","score":13.004954,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00708-32460-34303","score":12.801088,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-32460-34303","score":12.801088,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-32441-34284","score":12.801088,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_07761-1647-3208","score":12.443963,"text":"\n* [Handling and securing secrets](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-secrets)\n\n\n\n\n\n\n\n IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\nRules for IA-5 in IBM Cloud for Financial Services v1.2.0 profile\n\n Requirement ID Rules \n\n IA-5 (b) <br><br> * IBM Cloud IAM establishes initial authenticator content for authenticators that are defined by the organization (for example, API keys)<br><br><br> \n IA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":16.960352,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_03036-5624-7724","score":15.48942,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4413-6535","score":15.001211,"text":"\nFor more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":14.974057,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":14.85601,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16258-7-1952","score":14.67724,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03363-3084-5067","score":14.57659,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node. For more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":14.537144,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16258-1324-3123","score":14.530057,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03036-7103-8947","score":14.500909,"text":"\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter. See [Enabling user metrics](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resourceslogs-resources-user-id) for more information.\n\n\n\n\n\n\n\n Top Intents and Top Entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. For each entity you can select from the Values column to see a list of the most common values that were identified for this entity during the time period. You can also select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.1695801026,"ndcg_cut_10":0.1695801026}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":33.943874,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":33.943874,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_07096-5734-7445","score":23.13683,"text":"\nFor example, the following syntax searches for documents in which Google is identified as an entity or the string IBM is present:\n\n{\n\"query\":\"enriched_text.entities.text:Google|IBM\"\n}\n\nIt is treated as follows:\n\n(enriched_text.entities.text:Google) OR IBM\n\n\n\n\n\n , (and) \n\nBoolean operator for \"and\".\n\nIn the following example, documents in which Google and IBM both are identified as entities are returned:\n\n{\n\"query\":\"enriched_text.entities.text:Google,enriched_text.entities.text:IBM\"\n}\n\nThe includes (:,:!) and match (::, ::!) operators have precedence over the AND operator.\n\nFor example, the following syntax searches for documents in which Google is identified as an entity and the string IBM is present:\n\n{\n\"query\":\"enriched_text.entities.text:Google,IBM\"\n}\n\nIt is treated as follows:\n\n(enriched_text.entities.text:Google) AND IBM\n\n\n\n\n\n <=, >=, >, < (Numerical comparisons) \n\nCreates numerical comparisons of less than or equal to, greater than or equal to, greater than, and less than.\n\nOnly use numerical comparison operators when the value is a number or date.\n\nAny value that is surrounded by quotations is a String. Therefore, score>=0.5 is a valid query and score>=\"0.5\" is not.\n\nFor example:\n\n{\n\"query\":\"invoice.total>100.50\"\n}\n\n\n\n\n\n ^x (Score multiplier) \n\nIncreases the score value of a search term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:IBM^3\"\n}\n\n\n\n\n\n * (Wildcard) \n\nMatches unknown characters in a search expression. Do not use capital letters with wildcards.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:ib\"\n}\n\n\n\n\n\n n (String variation) \n\nThe number of character differences that are allowed when matching a string. The maximum variation number that can be used is 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"},{"document_id":"ibmcld_03282-7502-9528","score":22.113068,"text":"\nFor example, to check if an entity or context variable contains the name O'Reilly, you must surround the name with parentheses.\n\n@person:(O'Reilly) and $person:(O'Reilly)\n\nYour assistant converts these shorthand references into these full SpEL expressions:\n\nentities['person']?.contains('O''Reilly') and context['person'] == 'O''Reilly'\n\nSpEL uses a second apostrophe to escape the single apostrophe in the name.\n* Checking for multiple values: If you want to check for more than one value, you can create a condition that uses OR operators (||) to list multiple values in the condition. For example, to define a condition that is true if the context variable $state contains the abbreviations for Massachusetts, Maine, or New Hampshire, you can use this expression:\n\n$state:MA || $state:ME || $state:NH\n* Checking for number values: When comparing numbers, first make sure the entity or variable you are checking has a value. If the entity or variable does not have a number value, it is treated as having a null value (0) in a numeric comparison.\n\nFor example, you want to check whether a dollar value that a user specified in user input is less than 100. If you use the condition @price < 100, and the @price entity is null, then the condition is evaluated as true because 0 is less than 100, even though the price was never set. To prevent this type of inaccurate result, use a condition such as @price AND @price < 100. If @price has no value, then this condition correctly returns false.\n* Checking for intents with a specific intent name pattern: You can use a condition that looks for intents that match a pattern. For example, to find any detected intents with intent names that start with 'User_', you can use a syntax like this in the condition:\n\nintents[0].intent.startsWith(\"User_\")\n\nHowever, when you do so, all of the detected intents are considered, even those with a confidence lower than 0.2. Also check that intents which are considered irrelevant by Watson based on their confidence score are not returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_02961-7089-9230","score":21.91041,"text":"\n* Checking for number values: When comparing numbers, first make sure the entity or variable you are checking has a value. If the entity or variable does not have a number value, it is treated as having a null value (0) in a numeric comparison.\n\nFor example, you want to check whether a dollar value that a user specified in user input is less than 100. If you use the condition @price < 100, and the @price entity is null, then the condition is evaluated as true because 0 is less than 100, even though the price was never set. To prevent this type of inaccurate result, use a condition such as @price AND @price < 100. If @price has no value, then this condition correctly returns false.\n* Checking for intents with a specific intent name pattern: You can use a condition that looks for intents that match a pattern. For example, to find any detected intents with intent names that start with 'User_', you can use a syntax like this in the condition:\n\nintents[0].intent.startsWith(\"User_\")\n\nHowever, when you do so, all of the detected intents are considered, even those with a confidence lower than 0.2. Also check that intents which are considered irrelevant by Watson based on their confidence score are not returned. To do so, change the condition as follows:\n\n!irrelevant && intents[0].intent.startsWith(\"User_\")\n* How fuzzy matching impacts entity recognition: If you use an entity as the condition and fuzzy matching is enabled, then @entity_name evaluates to true only if the confidence of the match is greater than 30%. That is, only if @entity_name.confidence > .3.\n\n\n\n\n\n\n\n Storing and recognizing entity pattern groups in input \n\nTo store the value of a pattern entity in a context variable, append .literal to the entity name. Using this syntax ensures that the exact span of text from user input that matched the specified pattern is stored in the variable.\n\n\n\n Variable Value \n\n email \n\n\n\nTo store the text from a single group in a pattern entity with groups defined, specify the array number of the group that you want to store. For example, assume that the entity pattern is defined as follows for the @phone_number entity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_04179-3022-5112","score":21.872292,"text":"\nCreate a Page Rule with the URL pattern of your API (for example, www.example.com\/api\/).\n2. Identify the Security Level setting.\n3. Turn Security Level to Low or Essentially off.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n What do security level settings mean? \n\nOur security level settings are aligned with threat scores that certain IP addresses acquire from malicious behavior on our network. A threat score above 10 is considered high.\n\n\n\n* High: Threat scores greater than 0 are challenged.\n* Medium: Threat scores greater than 14 are challenged.\n* Low: Threat scores greater than 24 are challenged.\n* Essentially off: Threat scores greater than 49 are challenged.\n* Off: Enterprise only\n* Defense mode: Should only be used when your website is under a DDoS attack. Visitors receive an interstitial page for about five seconds while CIS analyzes the traffic and behavior to make sure it is a legitimate visitor trying to access your website. Defense mode might affect some actions on your domain, such as using an API. You are able to set a custom security level for your API or any other part of your domain by creating a page rule for that section.\n\n\n\nIt is recommended that you review your security-level settings periodically. You can find instructions in [Best practices for CIS setup](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup).\n\n\n\n\n\n\n\n Best practice 3: Activate your Web Application Firewall (WAF) safely \n\nYour WAF is available in the Security section. Here, we walk through these settings in reverse order to ensure that your WAF is configured as safely as possible before turning it on for your entire domain. These initial settings can reduce false positives by populating Security Events for further tuning. Your WAF is updated automatically to handle new vulnerabilities as they are identified. For more information, see [Using Security events capability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-using-the-cis-security-events-capability).\n\nThe WAF protects you against the following types of attacks:\n\n\n\n* SQL injection attack\n* Cross-site scripting","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_07289-11173-13066","score":21.681614,"text":"\nFor speeds of 2-10 GB, IBM installs 10 GB optics. As a result, an upgrade of 1-5 GB would require new optics to be assigned or inserted. It would be a service affecting event. If you anticipate that type of growth, it's possible to request 10 GB optical fibers to be installed at the beginning of your Direct Link deployment, or to order 2 GB initially so that the 10 GB optics are in place.\n\n\n\n\n\n Is ECMP the way to go for redundant Direct Link connections? What alternatives exist? \n\nECMP isn\u2019t for redundant connections, but for balancing the load over the two links. With ECMP, both connections must terminate to the same IBM Cloud cross-connect router (XCR), which makes it a single point of failure. In other words, ECMP can be provisioned only as two sessions on the same IBM Cloud XCR.\n\nECMP is a feature of BGP. If you are looking for redundancy, you should get two Direct Link connections, one going into each XCR. If you want to use ECMP and have redundancy, you need two Direct Link connections on each XCR so that you can have 2 ECMP sessions running simultaneously.\n\nAlternatively, some customers set up two links into a different XCR in the same data center (for example, WDC02) and then failover as needed by using BGP configurations. This configuration is less redundant (less safe) than having Direct Link connections into two separate data centers, such as WDC02 and WDC05.\n\n\n\n\n\n Is there a Service Level Agreement (SLA) on the Direct Link XCR connections up to the account\u2019s BCR connection? \n\nThere is no SLA on Direct Link today. You can achieve 99.99% effectively with two or more direct links that are properly configured for failover by using BGP, but IBM cannot control that or provide an SLA on it.\n\n\n\n\n\n For Direct Link offerings, does IBM set a BGP password? \n\nBy default, BGP passwords for Direct Link aren't set up. Currently, BGP MD5 authentication is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-faqs"},{"document_id":"ibmcld_16425-14122-16407","score":21.073244,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":21.073244,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_09526-0-1954","score":21.022783,"text":"\n\n\n\n\n\n\n  Services \n\n\n\n  Scope of Services \n\nIBM Maximo Application Suite as a Service (MAS SaaS) is an offering supported by IBM's Site Reliability Engineering (SRE) team. IBM has been hosting Maximo systems for more than 20 years and has deep experience provisioning and supporting Maximo in Cloud environments. The SRE team is solely focused on Maximo Application Suite delivery, providing expert IT administration for both infrastructure and operations and support for customers through the IBM Support Community Portal. Customers interact with the IBM Product Support and SRE team members via case creation, interaction and followup. Team members are based in Canada, the United States, Brazil, Ireland, India, China and Australia.\n\nMAS SaaS is a subscription-based service offered on the Amazon Web Services (AWS) platform.\n\nZoom\n\n![Enter image alt text right here.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ce5408d6eecb7244ea40dac01f6d3acf7ff60148\/mas-saas\/images\/MAS-SaaS-Operational-View.png)\n\nFigure 1. MAS SaaS Scope of Services\n\n\n\n\n\n  Service Description \n\nSee the following link to the current Service Description for Maximo Application Suite as a Service. Please check this link regularly as the service description is updated periodically and the current version takes precedent.\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=i126-9424](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=i126-9424)\n\n\n\n\n\n  Service Level Agreement \n\nThe Service Level Agreement (SLA) for MAS SaaS is described in Section 3.1 of the service description document (above).\n\nSLA Summary for Maximo Application Suite as a SaaS (MAS SaaS):\n\n\n\n*  99.9 % Availability (Production Environment)\n*  SLA does not include planned or emergency maintenance windows. For details on the maintenance window schedule, see the Maintenance section\n*  SLA applies to production environments only\n*  Availability credits for availability of less than 99.9%\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-services"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":35.867847,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":35.867847,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-5155-7505","score":31.901423,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":31.901423,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":29.865505,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16436-9264-11446","score":29.80741,"text":"\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"},{"document_id":"ibmcld_16493-8964-11146","score":29.80741,"text":"\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"},{"document_id":"ibmcld_16425-14122-16407","score":29.805872,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":29.805872,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16417-1764-4158","score":29.664972,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1772392868}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-894428-896189","score":19.533947,"text":"\nFor more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes. A number of variables impact IOPS values, such as the balance of read\/write operations, queue depth, and data block sizes. In general, the higher the IOPS of your Block Storage for VPC volumes, the better the performance. For more information about expected IOPS for Block Storage for VPC profiles, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performancehow-block-size-affects-performance).\n* Is the allocated IOPS enforced by instance or by volume?\n\n Is the allocated IOPS enforced by instance or by volume? \n\nIOPS is enforced at the volume level.\n* What are IOPS profiles and how do they affect volume performance?\n\n What are IOPS profiles and how do they affect volume performance? \n\nIOPS profiles define IOPS\/GB performance for volumes of various capacities. You can select from three predefined [IOPS tiers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilestiers) that offer reliable IOPS performance for your workload requirements. You can also define [custom IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilescustom) and specify a range of IOPS for a volume size that you choose.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-894305-896066","score":19.533947,"text":"\nFor more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes. A number of variables impact IOPS values, such as the balance of read\/write operations, queue depth, and data block sizes. In general, the higher the IOPS of your Block Storage for VPC volumes, the better the performance. For more information about expected IOPS for Block Storage for VPC profiles, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performancehow-block-size-affects-performance).\n* Is the allocated IOPS enforced by instance or by volume?\n\n Is the allocated IOPS enforced by instance or by volume? \n\nIOPS is enforced at the volume level.\n* What are IOPS profiles and how do they affect volume performance?\n\n What are IOPS profiles and how do they affect volume performance? \n\nIOPS profiles define IOPS\/GB performance for volumes of various capacities. You can select from three predefined [IOPS tiers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilestiers) that offer reliable IOPS performance for your workload requirements. You can also define [custom IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilescustom) and specify a range of IOPS for a volume size that you choose.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16464-4463-6317","score":19.026554,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_01232-15963-18009","score":19.025064,"text":"\nYes, you can use this setup because NFS is a file-aware protocol.\n\n\n\n\n\n Can I increase inodes for my NFS volume? \n\nTypically, when volumes are provisioned, they are allotted the maximum inode count for the size that you ordered. Maximum inode count grows automatically as the volume grows. If the inodes count does not increase after you expanded a volume, submit a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\n\n\n\n\n I am unable to upgrade storage. What can affect the ability to upgrade or expand storage? \n\nThe following situations can affect the ability to upgrade or expand storage.\n\n\n\n* If the original volume is the Endurance 0.25 tier, then the IOPS tier can\u2019t be updated.\n* Older storage types can't be upgraded. Ensure that the storage was ordered in an upgraded Data Center that allows for [Expandable storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacity).\n* The permissions that you have in the Cloud console can be a factor. For more information, see the topics within [User roles and permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n\n\n Are File Storage for Classic volumes thin or thick provisioned? \n\nAll Block and File Storage for Classic services are thin-provisioned. This method is not modifiable.\n\n\n\n\n\n My billing ID changed, what does this mean? \n\nYou might notice that your Storage volumes are now billed as \"Endurance Storage Service\u201d or \"Performance Storage Service\" instead of \"Enterprise Storage\". You might also have new options in the console, such as the ability to adjust IOPS or increase capacity. IBM Cloud\u00ae strives to continuously improve storage capabilities. As hardware gets upgraded in the data centers, storage volumes that reside in those data centers are also upgraded to use all enhanced features. The price that you pay for your Storage volume does not change with this upgrade.\n\n\n\n\n\n How durable is File Storage for Classic? \n\nWhen you store your data in File Storage for Classic, it's durable, highly available, and encrypted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-file-storage-faqs"},{"document_id":"ibmcld_11408-8750-10521","score":18.514952,"text":"\nProcessors also have a different hourly rate depending on the system that they are on (Dedicated S922 vs Dedicated E980). For information on different processor type functions, see [What's the difference between capped and uncapped shared processor performance?How do they compare to dedicated processor performance?](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqsprocessor).\n\nAll prices mentioned on this page are illustrative and do not represent the actual amounts used for billing. To calculate the exact pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator).\n\nThe following tables show how different processor types affect the cost per system:\n\n\n\nTable 4. S922 processor type pricing\n\n Number of cores (S922) Hourly rate (Processor type) Monthly cost (730 hours) \n\n 1 $0.64 (dedicated) $353.028 \n 1 $0.28 (uncapped shared) $88.257 \n 1 $0.34 (capped shared) $132.422 \n\n\n\n\n\nTable 5. E980 processor type pricing\n\n Number of cores (E980) Hourly rate (Processor type) Monthly cost (730 hours) \n\n 1 $1.91 (dedicated) $1235.671 \n 1 $0.64 (uncapped shared) $308.936 \n 1 $0.85 (capped shared) $463.404 \n\n\n\n\n\n\n\n Storage types \n\nThe Power Systems Virtual Server charges based on three different storage types:\n\n\n\n* Data volumes: These are the simplest form of volume that you create. You are billed based on the current volume size at the metering time. The following table shows an example of how you are billed based on your volume creation:\n\n\n\nTable 7. Calculation of data volume\n\n Volume size you create You are billed \n\n 10 GB 10 GB \n 10+5 GB 15 GB \n\n\n\n* Image backing volumes:These volumes are part of a boot image in your cloud-instance boot image catalog. You are billed based on the total volume size(s) contained in the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_05633-4158-5796","score":17.63306,"text":"\n(https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.mdhow-does-scale-up-work) and [How does scale-down work?](https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.mdhow-does-scale-down-work).\n\nCan I change how scale-up and scale-down work?\n: You can customize settings or use other Kubernetes resources to affect how scaling up and down work.\n\nScale-up\n: [Customize the cluster autoscaler ConfigMap values](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-enablecluster-scaling-customize) such as scanInterval, expander, skipNodes, or maxNodeProvisionTime. Review ways to [overprovision worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-deploy-appsca_scaleup) so that you can scale up worker nodes before a worker pool runs out of resources. You can also [set up Kubernetes pod budget disruptions and pod priority cutoffs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-classic-vpcscalable-practices-apps) to affect how scaling up works.\n\nScale-down\n: [Customize the cluster autoscaler ConfigMap values](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-enablecluster-scaling-customize) such as scaleDownUnneededTime, scaleDownDelayAfterAdd, scaleDownDelayAfterDelete, or scaleDownUtilizationThreshold.\n\nCan I increase the minimum size per zone to trigger a scale up my cluster to that size?\n: No, setting a minSize does not automatically trigger a scale-up. The minSize is a threshold so that the cluster autoscaler does not scale to fewer than a certain number of worker nodes per zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-classic-vpc"},{"document_id":"ibmcld_05587-4158-5771","score":17.63306,"text":"\n(https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.mdhow-does-scale-up-work) and [How does scale-down work?](https:\/\/github.com\/kubernetes\/autoscaler\/blob\/master\/cluster-autoscaler\/FAQ.mdhow-does-scale-down-work).\n\nCan I change how scale-up and scale-down work?\n: You can customize settings or use other Kubernetes resources to affect how scaling up and down work.\n\nScale-up\n: [Customize the cluster autoscaler ConfigMap values](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-enablecluster-scaling-customize) such as scanInterval, expander, skipNodes, or maxNodeProvisionTime. Review ways to [overprovision worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-deploy-appsca_scaleup) so that you can scale up worker nodes before a worker pool runs out of resources. You can also [set up Kubernetes pod budget disruptions and pod priority cutoffs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cascalable-practices-apps) to affect how scaling up works.\n\nScale-down\n: [Customize the cluster autoscaler ConfigMap values](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-enablecluster-scaling-customize) such as scaleDownUnneededTime, scaleDownDelayAfterAdd, scaleDownDelayAfterDelete, or scaleDownUtilizationThreshold.\n\nCan I increase the minimum size per zone to trigger a scale up my cluster to that size?\n: No, setting a minSize does not automatically trigger a scale-up. The minSize is a threshold so that the cluster autoscaler does not scale to fewer than a certain number of worker nodes per zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ca"},{"document_id":"ibmcld_16425-14122-16407","score":17.609402,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":17.609402,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_07578-1281348-1283307","score":16.912573,"text":"\n* How do I disconnect my storage device from a host?\n\nComplete the following steps to disconnect a volume from a host.\n\n\n\n1. Unmount the device.\n2. Revoke access for the host from the storage device in the Cloud console.\n3. Remove auto mounts from NFS connections.\n\n\n\n* How do endurance and performance storage differ?\n\nEndurance and Performance are provisioning options that you can select for storage devices. In short, Endurance IOPS tiers offer predefined performance levels whereas you can fine-tune those levels with the Performance tier. The same devices are used but delivered with different options. For more information, see [File Storage Features](https:\/\/www.ibm.com\/products\/file-storage\/details).\n* Can I connect File Storage for Classic to Windows\u00ae?\n\nNo. You cannot connect IBM Cloud\u00ae File Storage for Classic on Microsoft\u00ae Windows\u00ae. NFS is not supported by IBM Cloud\u00ae in a Windows\u00ae environment.\n* Can I mount a single storage device to multiple hosts within IBM Cloud?\n\nYes, you can use this setup because NFS is a file-aware protocol.\n* Can I increase inodes for my NFS volume?\n\nTypically, when volumes are provisioned, they are allotted the maximum inode count for the size that you ordered. Maximum inode count grows automatically as the volume grows. If the inodes count does not increase after you expanded a volume, submit a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n* I am unable to upgrade storage. What can affect the ability to upgrade or expand storage?\n\nThe following situations can affect the ability to upgrade or expand storage.\n\n\n\n* If the original volume is the Endurance 0.25 tier, then the IOPS tier can\u2019t be updated.\n* Older storage types can't be upgraded. Ensure that the storage was ordered in an upgraded Data Center that allows for [Expandable storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacity).\n* The permissions that you have in the Cloud console can be a factor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-7-2064","score":33.293453,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":31.20316,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16410-11549-13658","score":31.08375,"text":"\nEnsure that the text color contrasts with the background color so the text will be visible after it is labeled.\n* Background color. This is the color of the label that is applied to the entity after you annotate it.\n\n\n\nWhen annotating documents, human annotators can use the keyboard shortcuts to quickly add annotations. And the annotation label and text colors help human annotators to instantly recognize types after they add annotations to a document.\n\n\n\n* If there are entity or relation types that you do not want human annotators to assign to mentions, you can hide them from the ground truth editor, which shortens and simplifies the list of type options that users see. To do so, deselect the Active check box for the type.\n\n\n\nAs you assign new shortcuts and colors, you can preview the changes.\n5. You can also change the default selection highlight color. The highlight color is the color of the border that is displayed around text after human annotators select it. The default color is a light blue, but you can change the color on the Selection Highlight tab to make it easier to identify the boundaries of the text that is selected.\n\n\n\n\n\n Related tasks \n\n[Modifying a type system without losing human annotations](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n\n\n Setting the IAA threshold \n\nTo help you decide whether to accept or reject an annotated document set, you can specify an inter-annotator agreement threshold. The threshold helps you compare how well or poorly inter-annotator agreement compares to the IAA score calculated by the system.\n\n\n\n About this task \n\nTo compare how different human annotators annotated the same documents, specify an evaluation threshold. If the annotations made by one human annotator differ from the annotations made by another human annotator to the point where the difference results in a low score, it means that the annotators do not agree. The disagreement needs to be investigated and resolved.\n\n\n\n\n\n Procedure \n\nTo set the inter-annotator agreement threshold:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16507-9193-11335","score":30.64415,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-4487-6387","score":30.256853,"text":"\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":29.903627,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16563-4292-6145","score":29.242434,"text":"\nSelect the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16507-7-2044","score":29.189623,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16463-4148-5042","score":28.807474,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16552-4166-4924","score":28.570253,"text":"\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6173196815}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16507-3099-4772","score":38.729935,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-1600-3658","score":36.925003,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-9193-11335","score":35.01841,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-7556-9640","score":33.76265,"text":"\nClick the overflow menu button in the Natural Language Understanding row, and then click Map entity types.\n\n\n\n* The drop-down list of the Natural Language Understanding entity types is pre-populated with entity types that are recognized by the Natural Language Understanding service.\n* You must map at least one entity type.\n* You cannot map an Natural Language Understanding entity type to a Knowledge Studio entity role, only Knowledge Studio entity types.\n* You can map more than one Natural Language Understanding entity type to a single Knowledge Studio entity type, or the other way around. For example, the following mappings are permitted:\n\n\n\nTable 1. Sample mapping of entity types\n\n\n\n Watson Knowledge Studio Entity Type Natural Language Understanding Entity Type \n\n ENGINEER <br> <br>SCIENTIST Person \n LOCATION CityTown <br> <br>Country \n\n\n\n4. After mapping all the entity types that you want to apply, go the Machine Learning Model > Pre-annotation page. Click Run Pre-annotators.\n5. Select Natural Language Understanding, and then click Next.\n\nThe Natural Language Understanding annotator is not available until you map at least one entity type.\n6. ore running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n7. Select the check box for each document set that you want to pre-annotate.\n\nIf you are running this pre-annotator for the first time, first validate that the pre-annotator can find mentions of the mapped entities as expected. Create one document set that contains a representative document or documents from each distinct data source.\n8. Click Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-5862-8152","score":33.437206,"text":"\nHuman annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case. Review the list of supported [Natural Language Understanding service entity types and subtypes](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-types) to determine if there is a natural overlap between them and the types in your type system. If so, continue with this procedure. If not, choose a different pre-annotator to use.\n\n\n\n\n\n About this task \n\nNatural Language Understanding is a service that offers text analysis through natural language processing. When you use the Natural Language Understanding pre-annotator, it calls the Natural Language Understanding service to find and annotate entities in your documents.\n\nYou must specify the entity types that you want the service to look for by mapping the Natural Language Understanding entity types to corresponding Knowledge Studio entity types that you have added to the Knowledge Studio type system. Only mentions of entity types that you map will be found and annotated.\n\n\n\n\n\n Procedure \n\nTo use the Natural Language Understanding service to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Natural Language Understanding row, and then click Map entity types.\n\n\n\n* The drop-down list of the Natural Language Understanding entity types is pre-populated with entity types that are recognized by the Natural Language Understanding service.\n* You must map at least one entity type.\n* You cannot map an Natural Language Understanding entity type to a Knowledge Studio entity role, only Knowledge Studio entity types.\n* You can map more than one Natural Language Understanding entity type to a single Knowledge Studio entity type, or the other way around.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16468-3297-5708","score":32.94767,"text":"\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16444-3168-4952","score":32.12773,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-15304-17168","score":30.710752,"text":"\nTo use the rule-based model to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Rule-based Model row in the page, then click Map entity types and classes to map entity types that you defined in the Knowledge Studio type system to one or more rule-based model classes.\n\nYou can also open the mapping page by selecting the Rule-based Model > Versions > Rule-based Model tab.\n4. Click Edit for each entity type you want to map.\n\n\n\n* The drop-down list of the Class Name column is pre-populated with classes that are associated with the rule-based model.\n* You must map at least one entity type to a class.\n\n\n\n5. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n\nThe Rule-based Model option is not available until you map at least one entity type to a class.\n6. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n7. Select the document sets or annotation sets that you want to pre-annotate.\n8. Click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document will appear pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Uploading pre-annotated documents \n\nYou can jump-start the training of your model by uploading documents that were pre-annotated through an Unstructured Information Management Architecture (UIMA) analysis engine.\n\nThe pre-annotated documents must be in the XMI serialization form of UIMA Common Analysis Structure (UIMA CAS XMI).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-10175-12144","score":30.599895,"text":"\nIf not already completed, open the overflow menu in the Rule-based Model row and click Map entity types and classes to map entity types that you defined in the Knowledge Studio type system to one or more rule-based model classes.\n5. Click Edit for each entity type you want to map.\n\n\n\n* The drop-down list of the Class Name column is pre-populated with classes that are associated with the rule-based model.\n* You must map at least one entity type to a class.\n\n\n\n6. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n\nThe Rule-based Model option is not available until you map at least one entity type to a class.\n7. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n8. Select the document sets or annotation sets that you want to pre-annotate.\n9. Click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document will appear pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Uploading pre-annotated documents \n\nYou can jump-start the training of your model by uploading documents that were pre-annotated through an Unstructured Information Management Architecture (UIMA) analysis engine.\n\nThe pre-annotated documents must be in the XMI serialization form of UIMA Common Analysis Structure (UIMA CAS XMI). The .zip file that you upload must include the UIMA TypeSystem descriptor file and a file that maps the UIMA types to entity types in your Knowledge Studio type system.\n\nUIMA CAS XMI is a standard format of Apache UIMA. Guidelines are provided for how to create files in the correct format from analyzed collections in IBM Watson Explorer. If you use another Apache UIMA implementation, adapt these guidelines for your purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16456-16406-18536","score":29.958626,"text":"\nIf you want to view the annotations in greater context, click the icons to preview the document content or open the document in a new window.\n10. Click Apply & Review to apply the selected entity types to mentions in the selected documents. You still have a chance to review the annotations that will be added. If an annotation is inaccurate in a particular context, you can remove that occurrence by clicking the Edit icon, and then removing the entity type assignment for the mention.\n11. When you are happy with the list of annotations, click Go Back to Ground Truth Editor .\n\n\n\n\n\n\n\n Results \n\nThe mentions are annotated in the document. There is no way to remove the set of mentions that you added through concordance at once. You must remove each mention, one at a time.\n\n\n\n\n\n\n\n Annotating mentions as coreferences \n\nTo annotate mentions as coreferences to the same entity, a human annotator selects every occurrence of a mention that refers to the same thing. Coreference helps a model recognize that entities that are referred to in different ways are to be associated with the same entity, such as the name of a U.S. state and its abbreviation, the name of a company and its acronym, or a person's name and a pronoun that refers back to that person.\n\n\n\n Before you begin \n\nYou must annotate mentions in the document before you can identify coreferences.\n\n\n\n\n\n About this task \n\nWhen you annotate mentions as coreferences, the system creates a coreference chain. The chain provides a way for you to view all of the mentions in context and verify that all of the occurrences belong together under the same entity. For example, \"Barack\", \"Michelle\", \"he\", and \"she\" are all of the same entity type, PERSON, but \"Barack\" and \"he\" are one entity, and \"Michelle\" and \"she\" are another entity. In this example, you create two coreference chains.\n\nWhen you create a coreference chain, you must select mentions that have been marked by the same entity type. In some cases, however, you might want to include mentions of different types in the same coreference chain. To do this, you must create multiple chains and then merge them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1301266833}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14508-7830-9886","score":15.3503685,"text":"\nIf the client installed the following, you can monitor them.\n\n\n\n* VMware Aria Automation\n* VMware Aria Orchestrator\n* VMware Aria Business for Cloud\n* VMware Site Recovery Manager\n\n\n\nThe VMware SDDC Health Management Pack provides the following dashboards:\n\n\n\n* SDDC Management Health Overview Dashboard - You can use SDDC Management Health overview dashboard to view and analyze the application-specific problems in the SDDC components.\n* SDDC Health Historic Trend Dashboard - The VMware SDDC Health Management Pack consists of SDDC health historic trend dashboard, which displays the health trend for each component in the SDDC stack.\n* SDDC VMware Aria Operations Manager Sizing Dashboard - The SDDC VMware Aria Operations Manager Sizing Dashboard provides VMware Aria Operations Manager cluster capacity to process object and metrics.\n\n\n\nThe plug-ins in the VMware SDDC Health Management Pack collect metrics for object types that are contained in the plug-ins. The Management Pack collects health metrics for the following components:\n\n\n\n* vCenter Server\n* Management Pack for NSX for vSphere\n* VMware Aria Automation\n* VMware Aria Operations Manager\n* VMware Aria Business\n* VMware Aria Operations for Logs\n* VMware Site Recovery Manager\n* vCenter HA\n* vMware vSAN Health\n* Services in vCenter Server Appliance\n* VMware Aria Operations Manager Sizing\n* VMware Aria Orchestrator\n\n\n\n\n\n\n\n Management Pack for NSX-T \n\nThe NSX-T management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks. The pack includes the following items.\n\n\n\n* Configuration assurance\n* Health\n* Performance\n* Capacity\n* Troubleshooting for NSX-T objects\n\n\n\n\n\n\n\n Management Pack for NSX for vSphere \n\nThe NSX for vSphere management pack offers operations management coverage for deployments of VMware's NSX virtual networking technologies. This management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_09628-4-1912","score":14.856183,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Defining routing rules \n\nTo define a routing rule, you must specify 1 or more targets as the destinations for metrics. You can also define 1 or more inclusion filters that define the conditions of how those metrics are routed to those destinations.\n\nFor each route that you define in the account, you can configure up to 4 rules. The rules specify what metrics are routed in a region and where to route them. For more information, see [Understanding how routes work in your account](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes&interface=cliroute_behaviour).\n\nA rule consists of 1 action, 1 or more targets, and 0 or more inclusion filters.\n\n\n\n Targets \n\nTargets define the list of target IDs where the metrics are routed.\n\n\n\n* You can specify up to three target IDs per rule.\n* You can define target IDs for resources that are available in the same region where you are configuring the route, in a different region, and in a different account.\n\n\n\nFor example, you can define a list of targets as follows:\n\n\"targets\": [{\"id\":\"11111111-1111-1111-1111-111111111111\"},{\"id\":\"22222222-2222-2222-2222-222222222222\"}]\n\nTargets must be IBM Cloud Monitoring instances.\n\n\n\n\n\n Action \n\nAction defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09778-0-1953","score":13.716591,"text":"\n\n\n\n\n\n\n  Configuring which metrics to monitor \n\nYou can customize a Monitoring agent and specify which metrics to include and which ones to filter out.\n\n\n\n\n\n  Filtering custom metrics in a Monitoring agent \n\nTo filter custom metrics, you must customize the metrics_filter section in the agent configuration file. You can specify which metrics to include and which ones to filter out by configuring the include and exclude filtering parameters.\n\nFor more information on how to configure the Monitoring agent, see:\n\n\n\n*  Linux Monitoring agent: [Including and excluding metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_linux_agentchange_linux_agent_inc_exc_metrics)\n*  Kubernetes Monitoring agent: [Including and excluding metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_kube_agentchange_kube_agent_inc_exc_metrics)\n*  Docker container Monitoring agent: [Including and excluding metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_agentparams)\n\n\n\n\n\n  Logging into a file what metrics are included or excluded \n\nYou can log the custom metrics that are collected by an agent. You must set the metrics_excess_log to true in the log section will enable logging of the custom metrics that are included or excluded.\n\nFor more information on how to configure the Monitoring agent to report which metrics are collected, see:\n\n\n\n*  Linux Monitoring agent: [Logging into a file what metrics are included or excluded](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_linux_agentchange_linux_agent_log_level)\n*  Kubernetes Monitoring agent: [Logging into a file what metrics are included or excluded](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_kube_agentchange_kube_agent_log_metrics)\n*  Docker container Monitoring agent: [Logging into a file what metrics are included or excluded](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_agentlog_level)\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-mng_metrics_filter"},{"document_id":"ibmcld_11801-12725-14858","score":13.470433,"text":"\n[Enable the instance for platform-level metrics collection](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_enabling). Note that within one region, only one Monitoring instance can be enabled for platform metrics collection.\n\n\n\n\n\n2. In the Monitoring dashboard, click Open Dashboard for your Monitoring instance.\n3. In the Monitoring dashboard, click Dashboards > IBM > Satellite Link - Overview. The pre-defined dashboard for Satellite Link metrics opens. Note that if you just created this Monitoring instance, it might take up to two hours for the **IBM ** dashboards to become available.\n\nYou can create a copy of this dashboard to customize the metrics that are shown. To add metrics that are enabled for IBM Cloud Satellite, search for the ibm_satellite_link prefix.\n4. Review the [available metrics](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-monitoravailable-metrics) and [attributes for segmentation](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-monitorattributes).\n5. Review more ways that you can [work with platform metrics](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working).\n\n\n\nAfter you set up Monitoring with the pre-defined dashboard for Satellite Link metrics, you can quickly access this dashboard from the Link endpoints tab of your Satellite location console by clicking Launch monitoring.\n\n\n\n Available metrics \n\nThe following metrics are available for your Satellite location control plane.\n\n\n\n Location tunnel numbers \n\nThe total number of Satellite Link tunnel servers present at the endpoint. Three tunnels are created between the tunnel server and the connector to support redundancy across the three availability zones of your location.\n\n\n\nMetadata for the location tunnel numbers metric\n\n Metadata Description \n\n Metric Name ibm_satellite_link_location_tunnel_count \n Metric Type gauge \n Value Type none \n Segment By Service instance, Service instance name, Location ID \n\n\n\n\n\n\n\n Location latency \n\nThe total round trip time of data in milliseconds for the location.\n\n\n\nMetadata for the location latency metric\n\n Metadata Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-monitor"},{"document_id":"ibmcld_09260-8590-10681","score":13.423446,"text":"\nThe first time that you access your IBM Cloud Monitoring instance, several windows display as part of the internal setup. Leave these selections with their default entries, and click through the pages until you reach the IBM Cloud Monitoring main page.\n3. Select Dashboards on the left sidebar to open the IBM Load Balancer Monitoring Metrics dashboard. Then, click Default Dashboards > IBM > Load Balancer Monitoring Metrics. The default dashboard is not editable.\n4. Three main metrics in the dashboard are shown: Throughput, Active Connections, and Connection Rate. To modify options and segment your metrics by load balancer ID or listener port, you must create a custom dashboard.\n\nYou can choose what time window that you'd like to see your metrics by using the time selection bar. You can also zoom in and out for more granularity and drag the mouse to create a selection of a specific time window.\n\n\n\n\n\n\n\n Creating a custom metrics dashboard \n\nYou can create your own dashboard to customize your monitoring metrics, such as viewing information about particular load balancers, or seeing only traffic that comes through HTTPS listeners.\n\nTo customize your dashboard, follow these steps:\n\n\n\n1. Navigate to the [metrics monitoring portal](https:\/\/cloud.ibm.com\/observe\/monitoring).\n2. Click View IBM Cloud Monitoring next to the service name of the IBM Cloud Monitoring instance you want to work with. The dashboard opens.\n3. On the left sidebar, select Dashboards. Then, click the green + sign in the pane.\n4. Select Blank dashboard, then select the type of visual representation you want.\n\nIBM Cloud Monitoring offers eight different visualizations for your dashboard. Read the description for each visualization, then choose the one that best meets your requirements.\n\nLine (\"View trends over time\") is the easiest and most basic option. It is also the most frequently selected option. The following examples show a Line-based visualization.\n5. Configure your custom dashboard.\n\n\n\n* In the Metrics field, enter ibm_cloud to display the IBM IBM Cloud Monitoring load balancer metrics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-monitoring-metrics"},{"document_id":"ibmcld_00324-12617-14618","score":12.987862,"text":"\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https:\/\/cloud.ibm.com\/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_13464-5732-7496","score":12.67234,"text":"\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform of a time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\nTS_SEG_FFT(DoubleSegmentTimeSeries, String)\n: Output: DoubleArrayTimeSeries\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform for each segment of the input time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\n: Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_AUTO_CORRELATION(DoubleTimeSeries)\n: Output: DoubleArray\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of a time series with a delayed copy of itself.\n\nTS_SEG_AUTO_CORRELATION(DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of each segment of the input time series with a delayed copy of itself. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_CROSS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: DoubleArray\n: Use a [cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation) algorithm to return a measure of the similarity of two time series.\n\nTS_SEG_CROSS_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_12742-4047-5865","score":12.269481,"text":"\nips_not_equals<br><br>[8] String The property value is not an exact match to the condition value. Yes \n num_equals<br><br>[9] Numeric The property value numerically matches to the condition value. Yes \n num_not_equals<br><br>[10] Numeric The property value does not numerically match the condition value. Yes \n num_less_than Numeric The property value is numerically less than the condition value. Yes \n num_less_than_equals Numeric The property value is numerically less than or equal to the condition value. Yes \n num_greater_than Numeric The property value is numerically greater than the condition value. Yes \n num_greater_than_equals Numeric The property value is numerically greater than or equal to the condition value. Yes \n days_less_than Numeric The property value is less than the condition value. Yes \n\n\n\n\n\n\n\n Formatting complex rules \n\nMost often, rules are more complex than a single property. To create more complex scenarios, you can include multiple conditions. To define multiple property conditions in a single rule, you can use the logical operators and and or to express the relationship between them. For example, the following scenarios would all evaluate as compliant.\n\n\n\n1. If all three - A, B, and C are true.\n2. If any of the three options are true.\n3. If A is true or if B and C are both true.\n\n\n\nZoom\n\n![The diagram shows the correlation between multiple conditions. The information is conveyed in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a6478671e8f845a84102d9cf49bf28ee7f4f3227\/security-compliance\/images\/config-rules-property.svg)\n\nFigure 1. The ways in which properties can relate to each other.\n\n\n\n\n\n\n\n Creating a rule \n\nYou can use the Security and Compliance Center UI to define the configuration rules that you want monitor for your IBM Cloud resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui"},{"document_id":"ibmcld_09794-7-2259","score":12.251917,"text":"\nWorking with platform metrics \n\nPlatform metrics are metrics that are exposed by enabled-monitoring services and the platform in IBM Cloud.\n\n\n\n* Platform metrics are regional.\n\nYou can monitor metrics from enabled-monitoring services on the IBM Cloud in the region where the service is available.\n* You can configure 1 instance only of the IBM Cloud Monitoring service per region to collect platform metrics in that location.\n\nTo configure a monitoring instance, you must set the platform metrics configuration setting.\n\nTo configure platform metrics, you must be assigned the IAM Editor role or higher for the IBM Cloud Monitoring with monitoring service.\n* If a monitoring instance in a region is already enabled to collect platform metrics, metrics from enabled-monitoring services are collected automatically and available for monitoring through this instance. For more information about enabled-monitoring services, see [Cloud services](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services).\n* To monitor platform metrics for a service instance, check that the IBM Cloud Monitoring instance is provisioned in the same region where the service instance that you want to monitor is provisioned.\n\n\n\n\n\n Controlling what data is visible \n\nYou can use attributes to segment metrics so that you can define what data is visible to users.\n\nThe following global attributes are available for segmenting metrics:\n\n\n\nTable 1. Global attributes\n\n Attribute Attribute Name Attribute Description \n\n Cloud Type ibm_ctype Type. <br>Valid values: public, dedicated, or local \n Location ibm_location Location of the monitored resource. <br>This field can be set to a region, a data center, or global. \n Scope ibm_scope Scope of the metric. <br>This field can be set to the account GUID, an organization GUID, or a space GUID. \n Service name ibm_service_name Name of the service generating this metric. \n Service instance ibm_service_instance Service instance GUID that identifies the instance the metric is associated with. \n Service instance name ibm_service_instance_name Service instance name. <br>This field provides the user-provided name of the service instance which isn't necessarily a unique value depending on the name provided by the user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_15712-8643-10836","score":12.236615,"text":"\nThe dashboard would contain different lines showing 10 users who are connected through HTTP on Port 80 in one color, and 6 users connected through TCP on port 8080 in another color.\n\n\n\n Global attributes \n\nThe following attributes are available for segmenting the three metrics.\n\n\n\nTable 12: Global attributes\n\n Attribute Attribute Name Attribute Description \n\n Resource ibm_resource A load balancer's unique ID \n Scope ibm_scope The account that is associated with a given load balancer \n Service name ibm_service_name ibm-is-load-balancer \n\n\n\n\n\n\n\n Additional attributes \n\nThe following attributes are available to segment one or more of the global attributes. See the individual metrics for any segmentation options.\n\n\n\nTable 13: Additional attributes\n\n Attribute Attribute Name Attribute Description \n\n Application load balancer appliance metrics ibm_is_load_balancer_appliance_ip The metrics coming from the load balancer back-end. Because the load balancer is highly available, multiple appliances support each load balancer for redundancy. \n Application load balancer listener metrics ibm_is_load_balancer_listener_port The metrics that are gathered from individual listeners and their ports. Configure the listeners in your load balancer settings. The monitoring metrics reflect the metrics coming from those listeners. \n Application load balancer pool metrics ibm_is_load_balancer_pool_name The metrics that are gathered from individual listener ports and the health check port (if a health check port is configured) or the back-end member ports (if a health check port is not configured). You must configure the listeners, back-end pool with members and, if needed, the health check port in your load balancer settings. The monitoring metrics reflect the metrics coming from those listeners and health check port, or the back-end member ports. \n\n\n\nThe following sample values are for the ibm_is_load_balancer_pool_name attribute in its different configurations. If the pool has no members, then this value will be in the format Pool_ListenerPort. If the pool has members and the health check port is configured, then this value will be in the format Pool_ListenerPort:HealthCheckPort.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-monitoring-metrics-alb"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08671-116647-117865","score":15.738729,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-store-backup)\n* [What happens if I delete my service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-instance)\n* [Can I back up the keys before I delete a service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-backup-keys)\n* [What happens when I delete a key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-a-key)\n* [What happens if I lose the signature key or the master key parts?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-lose-signature-key)\n\n\n\n[FAQs: Support and maintenance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-support-maintenance)\n\n\n\n* [How is routine maintenance performed on Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08472-1519-2873","score":15.262383,"text":"\nFor more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n\n\n\n\n\n What happens if I delete my service instances? \n\nIf you delete your service instance, your keys that are managed are not accessible.\n\n\n\n\n\n Can I back up the keys before I delete a service instance? \n\nBacking up the keys manually is not supported.\n\n\n\n\n\n What happens when I delete a key? \n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n\n\n\n\n\n What happens if I lose the signature key or the master key parts? \n\nIf your signature key or master key part is lost, you are not able to initialize your service instance, and your service instance is not accessible. Depending on how to store your keys, back up you key files on your workstation or back up your smart cards.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-dr"},{"document_id":"ibmcld_07578-1168185-1170133","score":14.735644,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1170818-1172766","score":14.735644,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1208134-1210204","score":14.577924,"text":"\n* As a ReaderPlus, you can browse a high-level view of keys, access key material for standard keys, and perform wrap and unwrap actions. The ReaderPlus role cannot modify key material.\n\n\n\n* How do I monitor API calls to Key Protect?\n\nYou can use the IBM Cloud Activity Tracker service to track how users and applications interact with your Key Protect instance. For example, when you create, import, delete, or read a key in Key Protect, an Activity Tracker event is generated. These events are automatically forwarded to the Activity Tracker service in the same region where the Key Protect service is provisioned.\n\nTo find out more, check out [IBM Cloud\u00ae Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events).\n* How can I check what data is encrypted by which root key?\n\nWhen you use a root key to protect at rest data with envelope encryption, the cloud services that use the key can create a registration between the key and the resource that it protects. Registrations are associations between keys and cloud resources that help you get a full view of which encryption keys protect what data on IBM Cloud.\n\nYou can [browse the registrations](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) that are available for your keys and cloud resources by using the Key Protect APIs.\n* What happens when I delete a key?\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1210767-1212837","score":14.577924,"text":"\n* As a ReaderPlus, you can browse a high-level view of keys, access key material for standard keys, and perform wrap and unwrap actions. The ReaderPlus role cannot modify key material.\n\n\n\n* How do I monitor API calls to Key Protect?\n\nYou can use the IBM Cloud Activity Tracker service to track how users and applications interact with your Key Protect instance. For example, when you create, import, delete, or read a key in Key Protect, an Activity Tracker event is generated. These events are automatically forwarded to the Activity Tracker service in the same region where the Key Protect service is provisioned.\n\nTo find out more, check out [IBM Cloud\u00ae Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events).\n* How can I check what data is encrypted by which root key?\n\nWhen you use a root key to protect at rest data with envelope encryption, the cloud services that use the key can create a registration between the key and the resource that it protects. Registrations are associations between keys and cloud resources that help you get a full view of which encryption keys protect what data on IBM Cloud.\n\nYou can [browse the registrations](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) that are available for your keys and cloud resources by using the Key Protect APIs.\n* What happens when I delete a key?\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1202060-1204107","score":14.351763,"text":"\nEach Key Protect instance gets a randomly-generated \"instance key-encrypted-key\" (IKEK) which is wrapped by the HSM master key, producing a wrapped instance key (WIKEK). No user has access to the WIKEK or the IKEK, and even IBM does not have access to the IKEK. There is no direct or explicit access to the WIKEK by IBM, and it is encrypted by the master key.\n* What is an active encryption key?\n\nWhen you import encryption keys into Key Protect, or when you use Key Protect to generate keys from its HSMs, those keys become Active keys. Pricing is based on all active keys within an IBM Cloud account.\n* How should I group and manage my keys?\n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to create a group of keys for a target group of users that require the same IAM access permissions by bundling your keys in your Key Protect service instance into groups called \"key rings\". A key ring is a collection of keys, within your service instance, that all require the same IAM access permissions. For example, if you have a group of team members who will need a particular type of access to a specific group of keys, you can create a key ring for those keys and assign the appropriate IAM access policy to the target user group. The users that are assigned access to the key ring can create and manage the resources that exist within the key ring.\n\nTo find out more about grouping keys, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n* I am trying to delete an instance am getting a 409 error. How can I delete my instance?\n\nThis error indicates that keys are still in this instance. Before you can delete an instance, you must delete every key in that instance.\n\nBecause the Keys table in the console shows only Enabled keys by default, use the filters to show keys in all states. This can reveal keys that must be deleted to delete the instance which are not being displayed in the table.\n\nAfter all keys have been deleted, you can proceed with deletion of the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1204693-1206740","score":14.351763,"text":"\nEach Key Protect instance gets a randomly-generated \"instance key-encrypted-key\" (IKEK) which is wrapped by the HSM master key, producing a wrapped instance key (WIKEK). No user has access to the WIKEK or the IKEK, and even IBM does not have access to the IKEK. There is no direct or explicit access to the WIKEK by IBM, and it is encrypted by the master key.\n* What is an active encryption key?\n\nWhen you import encryption keys into Key Protect, or when you use Key Protect to generate keys from its HSMs, those keys become Active keys. Pricing is based on all active keys within an IBM Cloud account.\n* How should I group and manage my keys?\n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to create a group of keys for a target group of users that require the same IAM access permissions by bundling your keys in your Key Protect service instance into groups called \"key rings\". A key ring is a collection of keys, within your service instance, that all require the same IAM access permissions. For example, if you have a group of team members who will need a particular type of access to a specific group of keys, you can create a key ring for those keys and assign the appropriate IAM access policy to the target user group. The users that are assigned access to the key ring can create and manage the resources that exist within the key ring.\n\nTo find out more about grouping keys, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n* I am trying to delete an instance am getting a 409 error. How can I delete my instance?\n\nThis error indicates that keys are still in this instance. Before you can delete an instance, you must delete every key in that instance.\n\nBecause the Keys table in the console shows only Enabled keys by default, use the filters to show keys in all states. This can reveal keys that must be deleted to delete the instance which are not being displayed in the table.\n\nAfter all keys have been deleted, you can proceed with deletion of the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09088-1516-3484","score":14.297259,"text":"\nNo user has access to the WIKEK or the IKEK, and even IBM does not have access to the IKEK. There is no direct or explicit access to the WIKEK by IBM, and it is encrypted by the master key.\n\n\n\n\n\n What is an active encryption key? \n\nWhen you import encryption keys into Key Protect, or when you use Key Protect to generate keys from its HSMs, those keys become Active keys. Pricing is based on all active keys within an IBM Cloud account.\n\n\n\n\n\n How should I group and manage my keys? \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to create a group of keys for a target group of users that require the same IAM access permissions by bundling your keys in your Key Protect service instance into groups called \"key rings\". A key ring is a collection of keys, within your service instance, that all require the same IAM access permissions. For example, if you have a group of team members who will need a particular type of access to a specific group of keys, you can create a key ring for those keys and assign the appropriate IAM access policy to the target user group. The users that are assigned access to the key ring can create and manage the resources that exist within the key ring.\n\nTo find out more about grouping keys, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n\n\n\n\n\n I am trying to delete an instance am getting a 409 error. How can I delete my instance? \n\nThis error indicates that keys are still in this instance. Before you can delete an instance, you must delete every key in that instance.\n\nBecause the Keys table in the console shows only Enabled keys by default, use the filters to show keys in all states. This can reveal keys that must be deleted to delete the instance which are not being displayed in the table.\n\nAfter all keys have been deleted, you can proceed with deletion of the instance.\n\n\n\n\n\n What is a root key? \n\nRoot keys are primary resources in Key Protect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_08671-117491-118751","score":14.182188,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-authenticate-apitroubleshoot-unable-to-authenticate-api)\n\n[Why am I receiving a CKR_IBM_WK_NOT_INITIALIZED error when I use CLI or API?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-error-CLI-APItroubleshoot-error-CLI-API)\n\n[Why can't I create a standard key after I load another master key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-standard-keystroubleshoot-unable-to-create-standard-keys)\n\n[Why can't I create or import keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09088-10880-12721","score":29.418892,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":28.805447,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":28.805447,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08472-1519-2873","score":25.763784,"text":"\nFor more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n\n\n\n\n\n What happens if I delete my service instances? \n\nIf you delete your service instance, your keys that are managed are not accessible.\n\n\n\n\n\n Can I back up the keys before I delete a service instance? \n\nBacking up the keys manually is not supported.\n\n\n\n\n\n What happens when I delete a key? \n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n\n\n\n\n\n What happens if I lose the signature key or the master key parts? \n\nIf your signature key or master key part is lost, you are not able to initialize your service instance, and your service instance is not accessible. Depending on how to store your keys, back up you key files on your workstation or back up your smart cards.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-dr"},{"document_id":"ibmcld_07578-1168185-1170133","score":24.86413,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1170818-1172766","score":24.86413,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09088-9397-11338","score":24.10246,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-889077-890886","score":23.709248,"text":"\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n* What happens to my data when I delete a Block Storage for VPC data volume?\n\n What happens to my data when I delete a Block Storage for VPC data volume? \n\nWhen you delete a Block Storage for VPC volume, your data immediately becomes inaccessible. All pointers to the data on that volume are removed. The inaccessible data is eventually overwritten as new data is written to the data block. IBM guarantees that data deleted cannot be accessed and that deleted data is eventually overwritten. For more information, see [Block Storage for VPC data eradication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageblock-storage-data-eradication).\n* I have compliance requirements for data deletion. What can I do to ensure that my data is inaccessible?\n\n I have compliance requirements for data deletion. What can I do to ensure that my data is inaccessible? \n\nIBM guarantees that your data is inaccessible on the physical disk and is eventually [eradicated](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageblock-storage-data-eradication). If you have extra compliance requirements such as NIST 800-88 Guidelines for Media Sanitization, you must perform data sanitation procedures before you delete your volumes. For more information, see the [NIST 800-88 Guidelines for Media Sanitation](https:\/\/csrc.nist.gov\/publications\/detail\/sp\/800-88\/rev-1\/final).\n* What rules apply to volume names and can I rename a volume later on?\n\n What rules apply to volume names and can I rename a volume later on?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-888954-890763","score":23.709248,"text":"\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n* What happens to my data when I delete a Block Storage for VPC data volume?\n\n What happens to my data when I delete a Block Storage for VPC data volume? \n\nWhen you delete a Block Storage for VPC volume, your data immediately becomes inaccessible. All pointers to the data on that volume are removed. The inaccessible data is eventually overwritten as new data is written to the data block. IBM guarantees that data deleted cannot be accessed and that deleted data is eventually overwritten. For more information, see [Block Storage for VPC data eradication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageblock-storage-data-eradication).\n* I have compliance requirements for data deletion. What can I do to ensure that my data is inaccessible?\n\n I have compliance requirements for data deletion. What can I do to ensure that my data is inaccessible? \n\nIBM guarantees that your data is inaccessible on the physical disk and is eventually [eradicated](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageblock-storage-data-eradication). If you have extra compliance requirements such as NIST 800-88 Guidelines for Media Sanitization, you must perform data sanitation procedures before you delete your volumes. For more information, see the [NIST 800-88 Guidelines for Media Sanitation](https:\/\/csrc.nist.gov\/publications\/detail\/sp\/800-88\/rev-1\/final).\n* What rules apply to volume names and can I rename a volume later on?\n\n What rules apply to volume names and can I rename a volume later on?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08671-116647-117865","score":22.042194,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-store-backup)\n* [What happens if I delete my service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-instance)\n* [Can I back up the keys before I delete a service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-backup-keys)\n* [What happens when I delete a key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-a-key)\n* [What happens if I lose the signature key or the master key parts?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-lose-signature-key)\n\n\n\n[FAQs: Support and maintenance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-support-maintenance)\n\n\n\n* [How is routine maintenance performed on Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-8253-9823","score":32.673676,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":32.56803,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":32.443672,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08211-1158-3123","score":29.452843,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08435-4752-6201","score":24.871794,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_11726-1653-3309","score":24.780748,"text":"\n: No, you don't need to re-create the Location. You can reconnect the existing Location and reauthenticate to continue working with your Location.\n\nHow do I reauthenticate?\n: Reconnect your Location first and then log in again with your credentials.\n\nDo I have to recover etcd backup?\n: No, you don't need to recover etcd backup. The Location recovers automatically after you reconnect it and reauthenticate.\n\nWhat happens if a location is disconnected for more than 7 days?\n: After restoring connection, you might need to replace all hosts across the location with new infrastructure.\n\nHow do I know when to reconnect a location?\n: You can make a note or set a reminder to reconnect the location before the 7-day window expires. The timer starts when you request the token.\n\n\n\n\n\n Setting the disconnected usage time \n\nSatellite Locations and Red Hat OpenShift on IBM Cloud can run disconnected from the parent managed-from region in IBM Cloud for up to 168 hours (7 days).\n\nYou can modify this setting by changing the accessTokenMaxAgeSeconds value for all your OAuth clients. The default value for accessTokenMaxAgeSeconds is 86400 seconds.\n\nThe accessTokenMaxAgeSeconds value starts counting when the user was last authenticated, not when the Location is disconnected. Note that a user must have access to IAM to authenticate.\n\n\n\n1. Get your OAuth clients by running oc get oauthclients.\n\nExample output\n\nNAME SECRET WWW-CHALLENGE TOKEN-MAX-AGE REDIRECT URIS\nconsole OBXIvSxQx2t5ANYe5-xAEylpsbdytupjyjJicScdFsE false default https:\/\/console-openshift-console.sl-disc2b-be7d0adc45c89a3b4c1f8e7bc127f800-0000.eu-de.containers.appdomain.cloud\/auth\/callback","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-use"},{"document_id":"ibmcld_02934-31538-33861","score":24.742342,"text":"\nFor Not found responses (that are displayed when the user does not provide a valid value), you can choose one of these actions to perform:\n\n\n\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_07392-2801-4817","score":24.37407,"text":"\nIf a network has been added to a zone, the zone cannot be deleted until the permitted network is deleted from the zone.\n\n\n\n\n\n What happens if I delete my VPC? \n\nIf the VPC is deleted, the corresponding permitted network will also be deleted from the DNS zones of your instance.\n\n\n\n\n\n Why can I still resolve my resource records after I deleted its associated zone or permitted network? \n\nTo maintain a level of performance while resolving DNS queries, DNS Services resolvers cache data related to permitted networks for a period of time. Changes made to a permitted network might not have propagated until the previously cached data expires. See [Known limitations](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-known-limitations) for more details.\n\n\n\n\n\n What do the different zone states mean? \n\nThe zone states definitions are as follows.\n\n\n\n* Pending: When a DNS zone is added to the instance it will be in Pending. In this state Resource Records can be added, deleted or updated. Since the zone does not have any permitted networks, the zone will not be served by the resolvers in any region.\n* Active: When a domain has one or more permitted networks added then the domain state changes to ACTIVE and the domain will be served by the resolver from all the regions.\n* Disabled: In this state the zone will not be served and all control path operations will be disabled except deleting the zone.\n\n\n\n\n\n\n\n Can I use any name for the zone? \n\nIn general, yes, you can use any name for the zone. Certain IBM-owned or IBM-specific DNS zone names are restricted, in other words, they can't be created in DNS Services. See [Restricted DNS zone names](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-zonesrestricted-dns-zone-names) for the complete list.\n\n\n\n\n\n Can I create two DNS zones with the same name? \n\nCreating two DNS Zones with the same name is allowed. Use label and description as described in the following steps to differentiate between the two.\n\n\n\n1. Create an instance of DNS Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-frequently-asked-questions"},{"document_id":"ibmcld_03249-32329-34629","score":24.27144,"text":"\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next. For example, if after capturing the one-way flight information, the slot prompt is, Are you buying round trip tickets?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_07578-568187-570089","score":24.070606,"text":"\nIf you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?\n\n What happens if I don\u2019t respond to the email from Hover? \n\nIf you don't respond to the email from Hover, your domains are moved to Tucows\u2019 Retail division, Hover. All emails from Hover are sent directly to the registrant\/owner email addresses on file. Failing to take action will require you to speak with the Hover support team.\n* Can I opt out of being migrated to OpenSRS?\n\n Can I opt out of being migrated to OpenSRS? \n\nYes, you can choose to be migrated to Tucows\u2019 retail domain platform, Hover. You must contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) before 1 October 2021.\n* Are all my brand settings carried over from the ResellOne reseller account?\n\n Are all my brand settings carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.7365896932,"ndcg_cut_10":0.7365896932}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":35.645977,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":31.502161,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08217-1687-3909","score":23.284286,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_12570-2467-4288","score":21.435097,"text":"\nibmcloud catalog entry-visibility ID [--global]\n\n\n\n Command options \n\n--global\n: Operate in global scope\n\n\n\n\n\n Examples \n\nGet visibility of resource j402-dnf1i in global scope:\n\nibmcloud catalog entry-visibility 'j402-dnf1i' --global\n\n\n\n\n\n\n\n ibmcloud catalog entry-visibility-set \n\nUpdate the visibility of an existing catalog entry(catalog admin of an account only):\n\nibmcloud catalog entry-visibility-set ID [--includes-add LIST] [--includes-remove LIST] [--excludes-add LIST] [--excludes-remove LIST] [--owner ID or Email] [--restrict] [--unrestrict] [-c PARAMETERS_AS_JSON] [--global]\n\n\n\n Command options \n\n--includes-add\n: Adding an account (or list of comma-separated accounts) to the includes list, granting visibility to the entry. Email or Account GUIDs are acceptable.\n\n--includes-remove\n: Removing an account (or list of comma-separated accounts) from the includes list, revoking visibility to the entry. Email or Account GUIDs are acceptable.\n\n--excludes-add\n: Adding an account (or list of comma-separated accounts) to the excludes list. Email or Account GUIDs are acceptable.\n\n--excludes-remove\n: Removing an account (or list of comma-separated accounts) from the excludes list, revoking visibility to the entry. If the account was set by global admins, the account admins can't remove the account. Email or Account GUIDs are acceptable.\n\n--owner\n: Changing the owner of an object. Email or Account GUIDs are acceptable.\n\n--restrict\n: Changing the restriction of the visibility object to 'Private'.\n\n--unrestrict\n: Changing the restriction of the visibility object to 'Public'.\n\n-c\n: Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration parameters, see documentation for the particular catalog entry.\n\n--global","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_catalog"},{"document_id":"ibmcld_04114-3937-5977","score":21.302364,"text":"\nCIS does cache a website's robots.txt. You can cache additional content by creating page rules.\n\n\n\n\n\n Understanding CIS cache responses \n\nThe output of the CF-Cache-Status header shows whether a resource is cached.\n\n\n\nTable 2. Cache response codes and definitions\n\n Response code Definition \n\n HIT The resource was found in the CIS cache. \n MISS The resource was not found in the CIS cache and was served from the origin web server. \n EXPIRED The resource was found in cache but has since expired and was served from the origin web server. \n STALE The resource was served from cache but is expired. CIS couldn\u2019t contact the origin to retrieve the updated resource. \n BYPASS The origin server instructed CIS to bypass cache via a cache-control header set to no-cache, private, or max-age=0. BYPASS is returned when enabling origin cache-control. CIS also sets BYPASS when your origin web server sends cookies in the response header. \n REVALIDATED The resource is served from cache but is stale. The resource was revalidated by either an If-Modified-Since header or an If-None-Match header. \n UPDATING The resource was served from cache but is expired. The resource is currently being updated by the origin web server. UPDATING is typically seen only for very popular cached resources. \n DYNAMIC The resource was not cached by default and your current CIS caching configuration doesn't instruct CIS to cache the resource. Instead, the resource was requested from the origin web server. Use page rules to implement custom caching options. \n\n\n\n\n\n\n\n Using query string sorting \n\nEnterprise Only CIS treats URLs that have query strings in different orders as separate files in the cache. This means that if one user requests:\n\n\/video\/123456?title=0&byline=0&portrait=0&color=987654\n\nAnd another user requests:\n\n\/video\/123456?byline=0&color=987654&portrait=0&title=0\n\nCIS goes back to the origin, even though we have the file in our cache.\n\nQuery String Sort sorts the query strings before they hit our cache, resulting in a higher cache hit rate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-caching-concepts"},{"document_id":"ibmcld_09087-31230-33194","score":19.94737,"text":"\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n this CLI request succeeds when using the --force option\n the registration between Key Protect and the cloud resource exists\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID --force --output json\n\n{\n\"id\": \"52a9d772-8982-4620-bfb4-b070dd812a0c\"\n}\nShow more\n\n\n\n\n\n\n\n 10 - Key metadata became corrupted... \n\n\n\n Message \n\nKey metadata became corrupted: Please delete this key\n\nReason code: INCOMPLETE_METADATA_ERR\n\n\n\n\n\n HTTP status code \n\n500 - Internal Server Error\n\nThe HTTP 500 Internal Server server error response code indicates that the server encountered an unexpected condition that prevented it from fulfilling the request.\n\nThis error response is a generic \"catch-all\" response. Usually, this indicates the server cannot find a better 5xx error code to response. Sometimes, server administrators log error responses like the 500 status code with more details about the request to prevent the error from happening again in the future.\n\n\n\n\n\n Context \n\nThis error is returned when there is an internal error.\n\nIf you get this error please contact [IBM support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter)\n\n\n\n\n\n\n\n 11 - Key restoration has expired \n\n\n\n Message \n\nKey restoration has expired\n\nReason code: KEY_RESTORE_EXPIRED\n\n\n\n\n\n HTTP status code \n\n400 - Bad Request\n\nThe HTTP 400 Bad Request response status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis error occurs when you try to restore a key that was deleted more than 30 days ago.\n\n\n\n\n\n\n\n 12 - KeyCreateImportAccess instance policy... \n\n\n\n Message \n\nKeyCreateImportAccess instance policy does not allow this action","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_00949-7-2157","score":19.868298,"text":"\nTroubleshooting for Continuous Delivery \n\nGeneral problems with using IBM Cloud\u00ae Continuous Delivery might include user access issues. In many cases, you can recover from these problems by following a few easy steps.\n\n\n\n I removed a user from the authorized user list. Why does this user keep getting added to the list again? \n\nUsers or their accesses were not removed from all locations.\n\n What\u2019s happening \n\nA user that you removed from the authorized user list was added to the list again.\n\n Why it\u2019s happening \n\nYou didn't remove the user or their access from all of the Continuous Delivery service instances, toolchains, or the Git Repos and Issue Tracking repos that are attached to all of the toolchains in the resource group.\n\n How to fix it \n\nTo remove authorized users from the Continuous Delivery service and prevent them from being added again:\n\n\n\n* Remove the user's access in IAM to all toolchains in the resource group.\n* Remove the user from the authorized user list in the Continuous Delivery service instance.\n* Remove Developer access from all Git Repos and Issue Tracking repos that are attached to all of the toolchains in the resource group.\n\n\n\nYou can maintain an activity log related to authorized users. For more information about viewing, managing, and auditing service-initiated and user-initiated activities in your IBM Cloud\u00ae Continuous Delivery instances, see [IBM Cloud Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-cd-at-events). For more information about managing authorized users, see [Authorized users](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-limitations_usageauthorized_users).\n\n\n\n\n\n I tried to run a pipeline, why am I getting an error about Lite plan limits? \n\nThe pipeline that you started failed with an error message.\n\n What\u2019s happening \n\nYou exceeded the 500-step and job run limit that includes both pipeline steps for Tekton pipelines and pipeline job runs for Classic pipelines. If your pipeline has many steps within a single run, such as with the DevSecOps pipelines, you might reach this limit quickly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-troubleshoot-cd"},{"document_id":"ibmcld_00324-14232-16229","score":19.732695,"text":"\nOptionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings \n\nYour IBM Cloud CDN service can be restricted to a particular directory path on the origin server by providing the path when you create the CDN. A user is allowed access only to those contents in that directory path. For example, if a CDN www.example.com is created with path \/videos, it is accessible only through www.example.com\/videos\/.\n\n\n\n\n\n Purge-cached content \n\nIBM Cloud CDN provides the capability to conveniently and quickly remove, or \"purge\", the cached content from the Edge servers. With the introduction of the [purge group](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cdn-api-referenceapi-for-multiple-file-purge) concept, paths can be classified into related groups, which can be purged at the same time. Purge groups can include 1000 paths, by default. A Purge operation with Akamai completes in about 5 seconds. You can also view your purge history, and save specific purge groups as favorites.\n\n\n\n\n\n Serve Stale content \n\nWhen the CDN Edge server receives a user request, and the requested content is not cached, the Edge server reaches out to the origin host to fetch the content. That content is then cached for the TTL duration specified for the content. If a user request is received after the TTL has expired, the Edge server reaches out to the origin host to fetch the content. If the origin server cannot be reached for some reason (for instance, the origin host is down, or there is a network issue), the Edge server serves the expired (stale) content to the request. This feature is supported by Akamai and cannot be turned off.\n\n\n\n\n\n Support for multiple origins with distinct paths","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_12297-147471-148800","score":19.119486,"text":"\n(https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqworkernode-kubernetes-faq)\n* [Where can I view the list of public and private allowed IP addresses of us-south, us-east, eu-gb, and eu-de regions?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqprivateip-workspace-faq)\n* [Can I manually add, or remove a resource from the service dashboard directly?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqadd-remove-resource-faq)\n* [What changes can I make to my resources?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqresource-faq)\n* [How can I compare the required state of my cloud resources against the actual state of my resources?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqrequired-resource-state-faq)\n* [What are the deviations that cannot be detected?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqedit-resource-faq)\n* [How must I remove resources with IBM Cloud Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqremove-resource-faq)\n* [What happens if I choose to delete my resource directly from the resource dashboard?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faqdelete-resource-directly-faq)\n* [Does Schematics supports ibmcloud terraform command?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_08700-0-1083","score":19.047813,"text":"\n\n\n\n\n\n\n  Why am I not authorized when I start the Trusted Key Entry application? \n\nYou receive an error message when you start the Trusted Key Entry application.\n\n  What\u2019s happening \n\nYou might receive the following error message:\n\nZoom\n\n![Unauthorized when you run TKE CLI plug-in commands](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/tke_401.gif)\n\nFigure 3. Unauthorized when you start the Trusted Key Entry application.\n\n  Why it\u2019s happening \n\nA valid authentication token is needed for the TKE application to send requests to IBM Cloud. You must log in to IBM Cloud with the IBM Cloud CLI to create a valid authentication token before you can run the TKE application, which might be the causes of this error:\n\n\n\n*  You do not log in to IBM Cloud to create an authentication token.\n*  Your authentication token is expired.\n\n\n\n  How to fix it \n\nFrom the command line, log in to the IBM Cloud with the ibmcloud login command. Click Refresh Panel on the Crypto units tab to retry the query of your service instance.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-token-tke-application"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08671-117491-118751","score":36.612106,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-authenticate-apitroubleshoot-unable-to-authenticate-api)\n\n[Why am I receiving a CKR_IBM_WK_NOT_INITIALIZED error when I use CLI or API?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-error-CLI-APItroubleshoot-error-CLI-API)\n\n[Why can't I create a standard key after I load another master key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-standard-keystroubleshoot-unable-to-create-standard-keys)\n\n[Why can't I create or import keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08671-118434-119667","score":30.89778,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keystroubleshoot-unable-to-delete-keys)\n\n[Why can't I perform any actions by using the IBM Cloud console?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-ui-session-timeouttroubleshoot-ui-session-timeout)\n\n[Why can't I rotate root keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-rotate-root-keystroubleshoot-unable-to-rotate-root-keys)\n\n[Why can't I view or list keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-keys-apitroubleshoot-unable-to-list-keys-api)\n\n[Why can't I view or list specific keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-specific-keystroubleshoot-unable-to-list-specific-keys)\n\n\n\n\n\n Troubleshooting master key rotation \n\n[Why can't I rotate master keys by using key part files?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08671-119258-120594","score":30.162992,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-keys-apitroubleshoot-unable-to-list-keys-api)\n\n[Why can't I view or list specific keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-specific-keystroubleshoot-unable-to-list-specific-keys)\n\n\n\n\n\n Troubleshooting master key rotation \n\n[Why can't I rotate master keys by using key part files?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-part-filestroubleshoot-master-key-rotation-key-part-files)\n\n[Why can't I rotate master keys by using recovery crypto units?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-recovery-crypto-unitstroubleshoot-master-key-rotation-recovery-crypto-units)\n\n[Why can't I rotate master keys by using smart cards?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-smart-cardstroubleshoot-master-key-rotation-key-smart-cards)\n\n[Why do I fail to load the new master key during the master key rotation process?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotationtroubleshoot-master-key-rotation)\n\n\n\n\n\n Troubleshooting smart cards and the Management Utilities \n\n[Why am I not authorized when I start the Trusted Key Entry application?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08671-120101-121577","score":26.869158,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotation-key-smart-cardstroubleshoot-master-key-rotation-key-smart-cards)\n\n[Why do I fail to load the new master key during the master key rotation process?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-master-key-rotationtroubleshoot-master-key-rotation)\n\n\n\n\n\n Troubleshooting smart cards and the Management Utilities \n\n[Why am I not authorized when I start the Trusted Key Entry application?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-token-tke-applicationtroubleshoot-unauthorized-token-tke-application)\n\n[Why am I receiving a blocked PIN on EP11 smart card error?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-block-smart-cardtroubleshoot-block-smart-card)\n\n[Why am I receiving a no smart card readers found error when I use the Management Utilities?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-no-smart-cardtroubleshoot-no-smart-card)\n\n\n\n\n\n Troubleshooting Trusted Key Entry \n\n[Why am I not authorized when running TKE CLI plug-in commands?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-tokentroubleshoot-unauthorized-token)\n\n[Why can't I change signature thresholds?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-change-signature-thresholdstroubleshoot-unable-to-change-signature-thresholds)\n\n[Why can't I list crypto units?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08671-121227-122562","score":26.121645,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unauthorized-tokentroubleshoot-unauthorized-token)\n\n[Why can't I change signature thresholds?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-change-signature-thresholdstroubleshoot-unable-to-change-signature-thresholds)\n\n[Why can't I list crypto units?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-list-crypto-unitstroubleshoot-list-crypto-units)\n\n\n\n\n\n Troubleshooting Unified Key Orchestrator \n\n[Why can't I assign keys to Azure Key Vault?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-import-azure-keytroubleshoot-import-azure-key)\n\n[Why can't I create internal keystores?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-create-internal-keystorestroubleshoot-create-internal-keystores)\n\n[Why can't I create vaults?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-create-vaulttroubleshoot-create-vault)\n\n[Why can't I delete vaults?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-vaulttroubleshoot-delete-vault)\n\n[Why can't I delete internal keystores?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-keystoretroubleshoot-delete-keystore)\n\n[Why do I fail to see the changes to my key in Azure Key Vault?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_04090-122783-124185","score":25.41248,"text":"\n(https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-browser-storage)\n* [Why am I getting the error Unable to authenticate with the enroll ID and secret you provided when I create a new organization MSP definition?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-create-msp)\n* [Why am I getting the error An error occurred when updating channel when I try to add an organization to my channel?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-update-channel)\n* [When I log in to my console, why am I getting a 401 Unauthorized error?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-console-401)\n* [Why am I getting a Cluster linking is taking too long error when I try to link my Kubernetes cluster in IBM Cloud to my IBM Blockchain Platform service instance?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-console-helm-reset)\n* [Why am I getting an error \u201call SubConns are in TransientFailure\u201d on the console?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-console-transientfailure)\n* [Why is my first invoke of a smart contract returns the following error: no suitable peers available to initialize from?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-sitemap"},{"document_id":"ibmcld_04083-2359-3762","score":24.555716,"text":"\n(https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-sc-install)\n* [Why is my Node.js smart contract fail to endorse?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-nodejs-endorsement)\n* [Why is the smart contract that I installed on the peer not listed in the UI?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-console-build-network-troubleshoot-missing-sc)\n* [My channel, smart contracts, and identities have disappeared from the console. How can I get them back?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-browser-storage)\n* [Why am I getting the error Unable to authenticate with the enroll ID and secret you provided when I create a new organization MSP definition?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-create-msp)\n* [Why am I getting the error An error occurred when updating channel when I try to add an organization to my channel?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-update-channel)\n* [When I log in to my console, why am I getting a 401 unauthorized error?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-console-401)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_01494-92029-93565","score":23.754498,"text":"\n(https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-unauthorized-cetroubleshoot-unauthorized-ce)\n\n[Why am I getting Access denied errors?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-access-deniedtroubleshoot-access-denied)\n\n[Why am I getting Access denied errors for a resource?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-resourcetroubleshoot-resource)\n\n[Why am I getting Access denied errors about insufficient scope?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-scopetroubleshoot-scope)\n\n[Why am I getting Access denied errors about my quota?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-quotatroubleshoot-quota)\n\n[Why am I getting Access denied errors over a private network?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-privatetroubleshoot-private)\n\n[Why am I getting a Forbidden error when I'm using Code Engine?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-forbidden-cetroubleshoot-forbidden-ce)\n\n[Why do images fail to pull from registry with ImagePullBackOff or authorization errors?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ts-app-image-pullts-app-image-pull)\n\n\n\n* [Troubleshooting image pull secrets that use API keys](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ts-app-image-pullimg-pull-api-key)\n\n\n\n\n\n\n\n Troubleshooting CLI commands \n\n[Why can't I add a namespace?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-add-namespacetroubleshoot-add-namespace)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_05010-22156-23485","score":23.351866,"text":"\nFor details on establishing a hard quota that prevents usage beyond a set bucket size, see [Using Bucket Quota](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-quota).\n\n\n\n\n\n Why am I unable to delete a Object Storage instance? \n\nIt isn't possible to delete an instance if the API key or Service ID being used is locked. You'll need to navigate in the console to Manage > Access (IAM) and unlock the API Key or Service ID. The error provided may seem ambiguous but is intended to increase security:\n\n> An error occurred during an attempt to complete the operation. Try fixing the issue or try the operation again later. Description: 400\n\nThis is intentionally vague to prevent any useful information from being conveyed to a possible attacker. For more information on locking API keys or Service IDs, [see the IAM documentation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids&interface=uilock_serviceid).\n\n\n\n\n\n How do I download the Root CA certificate for Object Storage? \n\nObject Storage root CA certificates can be downloaded from [https:\/\/www.digicert.com\/kb\/digicert-root-certificates.htm](https:\/\/www.digicert.com\/kb\/digicert-root-certificates.htm). Please download PEM or DER\/CRT format from \"DigiCert TLS RSA SHA256 2020 CA1\" that is located under \"Other intermediate certificates.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_07337-0-719","score":23.25846,"text":"\n\n\n\n\n\n\n  If my Direct Link is established, why can't I connect to my VPC virtual server instance? \n\nMy Direct Link is established, but I am still unable to connect to my VPC virtual server instance.\n\n  What\u2019s happening \n\nBecause Direct Link BGP is in an established state, on-prem and VPC routes are shown in the route report; however, on-prem customers cannot reach the VPC virtual server instance.\n\n  Why it\u2019s happening \n\nThe virtual server instance is powered off because the VPC is in suspended state.\n\n  How to fix it \n\nVerify that both your virtual server instance and VPC are not in suspended state. If they are in suspended state, you are unable to connect to them regardless of the BGP status and routes.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-troubleshoot-unable-connect-vsi"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09088-9397-11338","score":26.308058,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":26.21386,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":26.21386,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08671-116647-117865","score":25.785576,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-store-backup)\n* [What happens if I delete my service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-instance)\n* [Can I back up the keys before I delete a service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-backup-keys)\n* [What happens when I delete a key?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-delete-a-key)\n* [What happens if I lose the signature key or the master key parts?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-drfaq-lose-signature-key)\n\n\n\n[FAQs: Support and maintenance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-support-maintenance)\n\n\n\n* [How is routine maintenance performed on Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-routine-maintenance)\n* [How do I get support for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-support-maintenancefaq-hpcs-support)\n\n\n\n\n\n\n\n Troubleshooting key management service \n\n[Why am I not authorized to make key management service API request?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08472-1519-2873","score":25.579264,"text":"\nFor more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n\n\n\n\n\n What happens if I delete my service instances? \n\nIf you delete your service instance, your keys that are managed are not accessible.\n\n\n\n\n\n Can I back up the keys before I delete a service instance? \n\nBacking up the keys manually is not supported.\n\n\n\n\n\n What happens when I delete a key? \n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n\n\n\n\n\n What happens if I lose the signature key or the master key parts? \n\nIf your signature key or master key part is lost, you are not able to initialize your service instance, and your service instance is not accessible. Depending on how to store your keys, back up you key files on your workstation or back up your smart cards.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-ha-dr"},{"document_id":"ibmcld_07578-1168185-1170133","score":25.123106,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1170818-1172766","score":25.123106,"text":"\n* Can I back up my service instance manually?\n\nYou need to back up only your master key parts and signature keys for service initialization. Your data in Hyper Protect Crypto Services is backed up automatically by IBM Cloud daily.\n* What happens if my service instance fails?\n\nIBM Cloud has automatic in-region failover plan in place. Currently, your data is backed up daily by the service and you don't need to do anything to enable it. For [cross-region data restores](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr), you need to open an IBM support ticket so that IBM can restore the service instance for you.\n* How can I restore the content from backups?\n\nFor cross-region data restores of Standard Plan instances, you can restore your data by using failover crypto units or open an IBM support ticket so that IBM can restore the service instance for you. For more information, see [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data).\n\nFor the plan with Unified Key Orchestrator, currently you can only open an IBM support ticket so that IBM can restore the service instance.\n* What happens if I delete my service instances?\n\nIf you delete your service instance, your keys that are managed are not accessible.\n* Can I back up the keys before I delete a service instance?\n\nBacking up the keys manually is not supported.\n* What happens when I delete a key?\n\nWithin 30 days after you delete a key, you can still view the key and restore the key to reverse the deletion. After 90 days, the key is purged and permanently removed from your instance. The data that is associated with the key becomes inaccessible. Before you delete a key, make sure that the key is not actively protecting any resources. For more information, see [Restoring keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keys).\n* What happens if I lose the signature key or the master key parts?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":22.587692,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":22.587692,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09088-10880-12721","score":21.897015,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06341-2428-3641","score":14.1483555,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":14.1483555,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":14.1483555,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":14.1483555,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":14.1483555,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_01034-3831-4923","score":13.970213,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_01041-3464-4855","score":13.318511,"text":"\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"},{"document_id":"ibmcld_09551-1435-3087","score":13.275375,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06381-1376-2975","score":13.275375,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06564-1431-3083","score":13.275375,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.5,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.5147714449,"ndcg_cut_10":0.5670738206}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09551-1435-3087","score":26.680399,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06564-1431-3083","score":26.680399,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_06381-1376-2975","score":26.536884,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":25.592936,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":25.592936,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":25.592936,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":25.592936,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":25.592936,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":24.648891,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":24.648891,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-6973-8664","score":52.4145,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":52.274197,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":50.077084,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":44.145657,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":44.1198,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08211-1158-3123","score":36.609024,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_09061-7530-9143","score":34.4852,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09088-9397-11338","score":33.49649,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_08435-4-1684","score":33.466312,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":33.17732,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10075-20832-22434","score":22.807938,"text":"\n1.2.25 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 3.2.1 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 3.2.2 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set automountServiceAccountToken: false for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set automountServiceAccountToken: false.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-46"},{"document_id":"ibmcld_10076-21977-23502","score":22.66344,"text":"\n4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-47"},{"document_id":"ibmcld_10077-21979-23504","score":22.66344,"text":"\n4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48"},{"document_id":"ibmcld_10072-21806-23331","score":22.66344,"text":"\n4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410"},{"document_id":"ibmcld_10073-22000-23625","score":22.411179,"text":"\n3.2.2 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally configure [Red Hat OpenShift security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc) and [Kubernetes pod security admission](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-admission\/) which are similar to the deprecated [Kubernetes pod security policies](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411"},{"document_id":"ibmcld_10075-22054-23418","score":22.390991,"text":"\n5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set automountServiceAccountToken: false for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set automountServiceAccountToken: false. \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.2 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.3 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.4 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.5 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc). \n 5.2.6 Red Hat OpenShift on IBM Cloud can optionally [configure security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-46"},{"document_id":"ibmcld_10074-22114-23569","score":22.160473,"text":"\n4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted. \n 5.1.5 Red Hat OpenShift on IBM Cloud does not set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server) for each default service account. \n 5.1.6 Red Hat OpenShift on IBM Cloud deploys some system components that could set [automountServiceAccountToken: false](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/use-the-default-service-account-to-access-the-api-server). \n 5.2.1 Red Hat OpenShift on IBM Cloud can optionally configure [OpenShift security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc) and [Kubernetes pod security admission](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-admission\/) which are similar to the deprecated [Kubernetes pod security policies](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-policy\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412"},{"document_id":"ibmcld_10076-21122-22480","score":22.144196,"text":"\n1.2.25 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 3.2.1 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 3.2.2 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-47"},{"document_id":"ibmcld_10077-21124-22482","score":22.144196,"text":"\n1.2.25 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 3.2.1 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 3.2.2 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48"},{"document_id":"ibmcld_10074-21096-22617","score":22.089424,"text":"\n1.2.24 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 1.2.25 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally [enable a Kubernetes Key Management Service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionkms). \n 3.2.1 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 3.2.2 Red Hat OpenShift on IBM Cloud can optionally [enable Kubernetes API server auditing](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-audit). \n 4.2.6 Red Hat OpenShift on IBM Cloud does not protect kernel defaults to allow customers to tune kernel parameters. \n 4.2.8 Red Hat OpenShift on IBM Cloud ensures that the hostname matches the name issued by the infrastructure. \n 5.1.2 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes secret access further restricted. \n 5.1.3 Red Hat OpenShift on IBM Cloud deploys some system components that could have their Kubernetes resource access further restricted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-1033-2260","score":29.406874,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-394005-396150","score":26.413206,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":26.413206,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10214-1438-3413","score":24.580008,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10501-27569-29596","score":24.164516,"text":"\nFor more information, refer to the infrastructure provider documentation.\n\n\n\n\n\n\n\n\n\n Limitations for Red Hat OpenShift clusters in IBM Cloud Satellite \n\nSee [Satellite cluster limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationssatellite_limits).\n\n\n\n\n\n Pricing for clusters in Satellite \n\nReview the table for information on charges related to Red Hat OpenShift clusters in IBM Cloud Satellite. For information about Location pricing, see [Satellite pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n\nLooking for an estimate? Try the [Cost estimator](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost) or review the [Pricing model](https:\/\/www.ibm.com\/products\/satellite\/overview)\n\n\n\nRed Hat OpenShift cluster on Satellite charges.\n\n Type of charge Clusters created after 15 November 2022 Clusters created before 15 November 2022 What the charge covers \n\n Cluster management fee A flat monthly fee for the cluster, charged hourly. Per vCPU hour of the hosts that are assigned to the cluster as worker nodes The benefits of Red Hat OpenShift on IBM Cloud, such as installation and security patch updates of OpenShift Container Platform for your worker nodes; managing your cluster with a suite of API, CLI, and UI tools; integration with IBM Cloud platform tooling such as IAM; continuous monitoring by IBM Site Reliability Engineers; access to IBM Cloud support; and more. \n Worker node management fee Per vCPU hour of the hosts that are assigned to the cluster as worker nodes. Per vCPU hour of the hosts that are assigned to the cluster as worker nodes. The benefits of IBM Cloud Satellite, such as to create the cluster on any compatible infrastructure that you want; tooling to consistently deploy apps, storage drivers, and endpoints across the location; integration with IBM Cloud platform tooling such as IAM; continuous monitoring by IBM Site Reliability Engineers; access to IBM Cloud support; and more. \n OCP licensing fee Per vCPU hour.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusters"},{"document_id":"ibmcld_10116-3182-5089","score":23.70705,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Compute licenses \n\nIn Red Hat OpenShift on IBM Cloud, worker nodes require OpenShift Container Platform licenses to cover the use of Red Hat OpenShift Container Platform and Red Hat Enterprise Linux. OpenShift Container Platform licenses can be supplied by an [existing IBM Cloud Pak entitlement](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-cloud-pak) or [by Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand).\n\n\n\n OCP licenses from Red Hat OpenShift on IBM Cloud \n\nWhen you create worker nodes by adding a worker pool or cluster, Red Hat OpenShift on IBM Cloud helps you include the purchase of OpenShift Container Platform licenses for the worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10214-7-1980","score":23.665646,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10154-7-1896","score":23.458649,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_05713-1178-2700","score":23.237707,"text":"\nAbout \n\n[Understanding IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewoverview)\n\n\n\n* [What is IBM Cloud Kubernetes Service and how does it work?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-are-containers-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits)\n* [Comparison of offerings and their combinations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation)\n* [Comparison of free and standard clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10170-12206-14575","score":22.788942,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-17039-18368","score":28.856451,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10407-7-1954","score":26.523352,"text":"\nService limitations \n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and the Red Hat OpenShift open source project come with default service settings and limitations to ensure security, convenience, and basic functionality. Some limitations you might be able to change where noted.\n\nIf you anticipate reaching any of the following Red Hat OpenShift on IBM Cloud limitations, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) and provide the cluster ID, the new quota limit, and the region in your support ticket.\n\n\n\n Service and quota limitations \n\nRed Hat OpenShift on IBM Cloud comes with the following service limitations and quotas that apply to all clusters, independent of what infrastructure provider you plan to use. Keep in mind that the [classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsclassic_limits) and [VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits) cluster limitations also apply.\n\nTo view quota limits on cluster-related resources in your IBM Cloud account, use the ibmcloud oc quota ls command.\n\n\n\nRed Hat OpenShift on IBM Cloud limitations\n\n Category Description \n\n API rate limits 200 requests per 10 seconds to the Red Hat OpenShift on IBM Cloud API from each unique source IP address. \n App deployment The apps that you deploy to and services that you integrate with your cluster must be able to run on the operating system of the worker nodes. \n Container-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_11950-7-2002","score":26.480465,"text":"\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"},{"document_id":"ibmcld_11672-20476-21069","score":25.58086,"text":"\nFind the hosts to add to your Red Hat OpenShift cluster worker pool.\n\nibmcloud sat hosts --location <locationID>\n2. Assign the Bare Metal Server to the Red Hat OpenShift cluster worker pool\n\nibmcloud sat host assign --location <locationID> --cluster <clusterID> --host <hostID> --worker-pool default --zone <zone>\n\n\n\nRepeat this tutorial to attach more Bare Metal Servers to your location and cluster.\n\nNow that your Bare Metal Server is assigned to a worker pool, you can [set up Red Hat OpenShift virtualization](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assign-bare-metal"},{"document_id":"ibmcld_11950-1571-3276","score":24.709959,"text":"\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead. For more information, see [CPU overhead](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/install\/preparing-cluster-for-virt.htmlCPU-overhead_preparing-cluster-for-virt) in the Red Hat OpenShift docs.\n* Must include enough memory for your workload needs. For example: 360 MiB + (1.002 * requested memory) + 146 MiB + 8 MiB * (number of vCPUs) + 16 MiB * (number of graphics devices). For more information, see [Memory overhead](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/install\/preparing-cluster-for-virt.htmlmemory-overhead_preparing-cluster-for-virt) in the Red Hat OpenShift docs.\n* Must run Red Hat CoreOS operating system, which is installed during when you attach it to the location.\n\n\n\nIf your servers do not meet these requirements, follow the steps to [create a Bare Metal Server](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-ordering-baremetal-server). For a list of bare metal options, see [Available options for a bare metal server](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-about-bmoptions-for-bare-metal-servers).\n\n\n\n\n\n Step 1: Attaching bare metal servers to your location \n\nFollow these general steps to attach your bare metal servers to your location. These steps might vary, depending on your specific hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"},{"document_id":"ibmcld_16729-39924-41947","score":23.880375,"text":"\n[Setting up virtualization on a Satellite location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location)Setting up virtualization on a Satellite location\n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSatellite\n\n\n\n* 2023-06-19\n\n\n\n[AWS, Azure, GCP, and OCI workloads to IBM Cloud VPC migration with RMM](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-cloud-rackware)AWS, Azure, GCP, and OCI workloads to IBM Cloud VPC migration with RMM\n\nThe RackWare Management Module (RMM) migration solution provides a seamless virtual-to-virtual replatforming from other cloud service providers (AWS, Azure, GCP, and OCI (bare metal)) to IBM Cloud\u00ae virtual server instance migration, which allows the adoption of the existing capabilities of IBM Cloud. Its intuitive GUI allows you to move the OS, application, and data from other cloud service providers to IBM Cloud VPC instances.\n\nVirtual Private Cloud (VPC) Virtual Servers for Classic\n\n+1\n\nBuilding infrastructure\n\n\n\n* 45 minutes\n* 2022-11-23\n\n\n\n[Creating a resilient three-tier highly available infrastructure VPC in multiple regions with Terraform](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-create-three-tier-resilient-vpc-mzr)Creating a resilient three-tier highly available infrastructure VPC in multiple regions with Terraform\n\nTerraform on IBM Cloud\u00ae enables predictable and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly build complex, cloud environments. The IBM Cloud VPC infrastructure that is created uses Intel Xeon CPUs and additional Intel technologies. For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+2","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_11672-7-1946","score":23.642765,"text":"\nAttaching bare metal hosts to a location \n\nYou can attach bare metal hosts to your Satellite location. After your hosts are attached, you can [set up Red Hat OpenShift virtualization](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location) in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\nThe following steps use IBM Cloud\u00ae Bare Metal Servers for Classic. However, you can adapt these steps for your own bare metal servers.\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name. For this Bare Metal Server, this information is found in the Name field on the Overview page for your specific Bare Metal Servers.\n* Find your bare metal server network information. For this Bare Metal Server, this information is found in the Network details section on the Overview page. Record the CIDR and gateway information for the public and private interfaces for your system.\n* Create or identify an IBM Cloud Object Storage bucket to store your ignition file.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n\n\n\nIn addition, the Bare Metal Servers used in this example required the following prerequisites.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assign-bare-metal"},{"document_id":"ibmcld_11893-41606-43131","score":23.521254,"text":"\n* [Assigning a Bare Metal Server host to your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assign-bare-metalassign-bare-metal-to-cluster)\n\n\n\n\n\n\n\n Setting up virtualization on a Satellite location \n\n[Setting up virtualization on a Satellite location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirtualization-location)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-bare-metal-prereq)\n* [Bare Metal Server requirements for Satellite](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-setup-bare-metal)\n* [Attaching bare metal servers to your location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationassign-bm-loc-virt)\n* [Assigning a Bare Metal Server host to your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationassign-bare-metal-cluster-virt)\n* [Setting up storage for your cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-cluster-storage)\n* [Installing the virtualization operator](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-operator-install)\n* [Setting up the virtctl CLI](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-tools)\n* [Creating a data volume for your virtual machine](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-locationvirt-vm-storage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sitemap&interface=cli"},{"document_id":"ibmcld_02826-1915-3049","score":23.348938,"text":"\nExample taxomony \n\nThe following are examples of cloud deployments and cloud service providers.\n\nCloud deployment model\n: Public, Private, Hybrid, Multi-Cloud, Distributed Cloud\n\nCloud platform\n: IBM Cloud, AWS, Azure, GCP, other cloud\n\nThe following table illustrates component options for the Containers domain across various Public Cloud Service Providers. Note that this is just a sample and not a comprehensive list of available services on each cloud provider. How to make component architecture decisions for your solution is covered in [Designing a cloud solution by using the architecture framework](https:\/\/cloud.ibm.com\/docs\/architecture-framework?topic=architecture-framework-create-solution).\n\n\n\nTable 1. Component options for Containers domain across various Public Cloud Service Providers\n\n Aspect Domain IBM Cloud AWS Azure Google Cloud Platform \n\n Compute Containers IBM Kubernetes Service <br>Red Hat OpenShift on IBM Cloud Elastic Kubernetes Service <br>Elastic Container Service <br>Red Hat OpenShift on AWS Azure Kubernetes Service <br>Azure Red Hat OpenShift Google Kubernetes Engine <br>Red Hat OpenShift on GCP","title":"","source":"https:\/\/cloud.ibm.com\/docs\/architecture-framework?topic=architecture-framework-taxonomy"},{"document_id":"ibmcld_16729-38635-40379","score":23.34436,"text":"\n[Using IBM Cloud Kubernetes Service on classic to host the dl-reverse-proxy](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-dl-iks-classic)Using IBM Cloud Kubernetes Service on classic to host the dl-reverse-proxy\n\nFollow these steps to set up the dl-reverse-proxy for IBM Cloud\u00ae Direct Link by using IBM Cloud Kubernetes Service on classic.\n\nSatellite Kubernetes service\n\n+1\n\nDirect Link\n\n\n\n* 2 hours\n* 2023-01-30\n\n\n\n[Deploying OpenShift Data Foundation on Satellite clusters with Azure worker nodes](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-odf-tutorial)Deploying OpenShift Data Foundation on Satellite clusters with Azure worker nodes\n\nIn this tutorial, you complete the following tasks to set up OpenShift Data Foundation.\n\nSatellite Kubernetes service\n\n+1\n\nVirtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-06-02\n\n\n\n[Deploying apps to clusters with Continuous Delivery and Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat_toolchain_tutorial)Deploying apps to clusters with Continuous Delivery and Satellite Config\n\nDeploy Kubernetes resources, like deployments, from your GitHub or GitLab repository to multiple clusters with IBM Cloud\u00ae Continuous Delivery and Satellite Config.\n\nSatellite Continuous Delivery\n\n\n\n* 30 minutes\n* 2022-12-14\n\n\n\n[Setting up virtualization on a Satellite location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location)Setting up virtualization on a Satellite location\n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSatellite\n\n\n\n* 2023-06-19","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13878-13031-14791","score":17.201826,"text":"\nA similar flow is available for [Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-encryption) to encrypt VPC boot and data volumes.\n\n\n\n\n\n Example: Watson services \n\nMany solutions are based on services with artificial intelligence (AI). At IBM they are offered as [Watson services](https:\/\/cloud.ibm.com\/developer\/watson\/services). By default, all data is encrypted. In the Premium plans, you can enhance security by [taking control of the encryption keys (BYOK)](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice). After authorizing the service type, e.g., Watson Assistant, to access Key Protect, the following additional option is offered when creating an instance with Premium plan.\n\nZoom\n\n![Control encryption in Watson services](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution51-extended-app-security\/Sol51_WatsonBYOK.png)\n\nControl encryption in Watson services\n\n\n\n\n\n\n\n Organize and control access \n\nIBM Cloud includes many capabilities for fine-grained access control. Depending on your type of application, project, and account, the following features help you to organize who has access to the application resources and with what set of privileges.\n\n\n\n* [Service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids): Similar to how a user ID identifies a user, a service ID can identify a specific service or application, even a task. The service ID could be considered a \"technical user\". You can assign privileges to a service ID. Moreover, a service ID has its own IAM API keys to authenticate. Thus, a service ID can be used instead of a regular user ID, thereby simplifying resource management and increasing security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_14593-0-999","score":17.00601,"text":"\n\n\n\n\n\n\n  Contacting IBM Support \n\nIf you need help with IBM Cloud\u00ae for VMware Solutions, create a case from the IBM Cloud Support Center to get assistance.\n\n\n\n  Procedure to create a case for VMware Solutions \n\n\n\n1.  Go to the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n2.  Log in with your IBMid account.\n3.  Select All Products and type VMware Solutions where prompted for the product name, then click VMware Solutions.\n4.  Review the various solutions offered. If you do not see an answer to your problem, click Create a case.\n5.  On the New support case page, provide the following information:\n\n\n\n1.  Enter a subject for your issue.\n2.  Describe your issue in detail, such as the error messages, steps to re-create, and the URL that you are accessing.\n3.  Under Add attachments, upload screen captures of the issue.\n4.  If you want to be notified of updates on the issue, select the Email me updates about this case checkbox.\n\n\n\n6.  Click Submit.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-trbl_support"},{"document_id":"ibmcld_16729-64027-65605","score":16.316633,"text":"\n[Getting Started with IBM Cloud for VMware Solutions Shared](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-solutions-shared-getting-started)Getting Started with IBM Cloud for VMware Solutions Shared\n\nOn IBM Cloud there are a number of deployment offerings for VMware that you can choose from, with each providing a different level of abstraction. VMware Cloud Director (VCD) is offered under the banner of IBM Cloud for VMware Solutions Shared. It is a multi-tenant service with elasticity and two subscription types:\n\nVMware Solutions Schematics\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Provision Bare Metal Servers for VPC for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-bms)Provision Bare Metal Servers for VPC for VMware deployment\n\nThis tutorial will show how to provision Bare Metal Servers for VPC into IBM Cloud VPC, and how to provision network interfaces for vSphere VMkernel adapters (VMK) adapters.\n\nVMware Solutions Virtual Private Cloud (VPC)\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Provision IBM Cloud DNS Services for VMware deployment](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-dns)Provision IBM Cloud DNS Services for VMware deployment\n\nIn this tutorial, you will deploy IBM Cloud DNS Services for a VMware Deployment in IBM Cloud VPC. IBM Cloud DNS Services will be used and your IBM Cloud VPC will be configured to access and use the deployed DNS serrvice.\n\nVirtual Private Cloud (VPC) VMware Solutions\n\n+1\n\nDNS Services\n\n\n\n* 1 hour\n* 2023-05-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-62863-64631","score":16.315008,"text":"\n[Creating a virtual data center in a VMware as a Service using the VMware Cloud Director Console](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-as-a-service-vdc)Creating a virtual data center in a VMware as a Service using the VMware Cloud Director Console\n\nThis tutorial is to demonstrate the basic steps to operationalize an IBM Cloud\u00ae for VMware as a Service \u2013 single tenant instance after initial instance provisioning. This tutorial should take about 30-60 minutes to complete and assumes that IBM Cloud\u00ae for VMware as a Service \u2013 single tenant instance and a virtual data center (VDC) have already been provisioned.\n\nVMware as a Service\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Getting started with VMware as a Service](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-getting-started)Getting started with VMware as a Service\n\nIn this IBM Cloud\u00ae for VMware as a Service tutorial, we take you through the process of ordering a VMware as a Service instance by using the IBM Cloud for VMware Solutions user interface. Other operations that you can complete are also listed.\n\nVMware as a Service\n\n\n\n* 20 minutes\n* 2023-02-08\n\n\n\n[Getting Started with IBM Cloud for VMware Solutions Shared](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-solutions-shared-getting-started)Getting Started with IBM Cloud for VMware Solutions Shared\n\nOn IBM Cloud there are a number of deployment offerings for VMware that you can choose from, with each providing a different level of abstraction. VMware Cloud Director (VCD) is offered under the banner of IBM Cloud for VMware Solutions Shared. It is a multi-tenant service with elasticity and two subscription types:\n\nVMware Solutions Schematics\n\n\n\n* 2 hours\n* 2023-05-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-159864-161747","score":16.04476,"text":"\n[Getting Started with IBM Cloud for VMware Solutions Shared](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-solutions-shared-getting-started)Getting Started with IBM Cloud for VMware Solutions Shared\n\nOn IBM Cloud there are a number of deployment offerings for VMware that you can choose from, with each providing a different level of abstraction. VMware Cloud Director (VCD) is offered under the banner of IBM Cloud for VMware Solutions Shared. It is a multi-tenant service with elasticity and two subscription types:\n\nVMware Solutions Schematics\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Scale workloads in shared and dedicated VPC environments](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-scaling-dedicated-compute)Scale workloads in shared and dedicated VPC environments\n\nIsolate workloads by provisioning a dedicated host, attaching an encrypted data volume to a VSI, expanding the attached data volume, and resizing the VSI after the fact.\n\nVirtual Private Cloud (VPC) Databases For PostgreSQL\n\n+2\n\nSchematics,Object Storage\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Use a VPC\/VPN gateway for secure and private on-premises access to cloud resources](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-site2site-vpn)Use a VPC\/VPN gateway for secure and private on-premises access to cloud resources\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular strongSwan VPN Gateway is used to represent the on-premises VPN gateway.\n\nSchematics Virtual Private Cloud (VPC)\n\n+3\n\nObject Storage,Databases For PostgreSQL,DNS Services\n\n\n\n* 2 hours","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_11355-19042-21233","score":15.872663,"text":"\nIBM Cloud Connect is a software-defined network interconnect service that brings secure connectivity to client locations around the world. For more information, see [Connecting Power Systems Virtual Server instances and networks](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-connecting-networks).\n\nIBM Cloud Connect is only available to IBM clients within the US.\n\n\n\n\n\n How is network bandwidth billed? \n\nIBM Cloud Classic environment: Inbound bandwidth is unlimited and not charged. Outbound bandwidth is charged per GB tier with bandwidth offered as an allotment for each month. As an example, for your compute instances, 250 GB is included with each monthly virtual server and 20 TB is included with each monthly bare metal server. Extra bandwidth can also be purchased per packages. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\nIBM Power Systems Virtual Server environment: Inbound bandwidth is unlimited and not charged. Bandwidth is not charged when you use a public network. If you are using a private network with DirectLink Connect, you are charged IBM Cloud Classic environment rates.\n\n\n\n\n\n What monitoring services are available? \n\nIBM does not provide status and performance monitoring for the Power Systems Virtual Server. Clients must use their own on-premises tools.\n\n\n\n\n\n What performance and capacity planning services do you provide for IBM i? \n\nIBM uses the same tools that are on an on-premises system.\n\n\n\n\n\n IBM i and solution certification \n\nYou can find self-certification and listing information on the [IBM Global Solutions Directory](https:\/\/www.ibm.com\/partnerworld\/public\/find-partner-solution).\n\n\n\n\n\n How do I delete a workspace? \n\nTo delete a workspace (and all its resources), use the left navigation to navigate the workspace page. Find the workspace to be deleted and click on the overflow menu on the top right corner of the tile. Click Delete and confirm the request from the pull-down menu by typing Delete in the text field. Finally, click the red Delete button to initiate the request.\n\n\n\n\n\n How do I delete a single virtual server instance? \n\nThere are two methods to delete a virtual server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqs"},{"document_id":"ibmcld_13197-7-1816","score":15.861243,"text":"\nGetting Started with IBM Cloud for VMware Solutions Shared \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nOn IBM Cloud there are a number of [deployment offerings](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-getting-startedgetting-started-depl-offerings) for VMware that you can choose from, with each providing a different level of abstraction. VMware Cloud Director (VCD) is offered under the banner of IBM Cloud for VMware Solutions Shared. It is a multi-tenant service with elasticity and two subscription types:\n\n\n\n* On-demand where vCPU and RAM are allocated as needed and priced on an hourly basis.\n* Reserved where vCPU and RAM are pre-allocated and priced monthly.\n\n\n\nVMware changed the name of VMware vCloud Director to VMware Cloud Director, you may see references in the UI and\/or related documentation of one or the other, they are the same product.\n\n\n\n Objectives \n\n\n\n* Create and explore a IBM Cloud for VMware Solutions Shared instance in the IBM Cloud.\n* Create a Schematics workspace in the IBM Cloud to run Infrastructure as Code(IaC) based on Terraform.\n* Use Schematics to create a network, firewall, source network address translation (SNAT), destination network address translation (DNAT) rules, and deploy a virtual machine instance in VMware Virtual Data Center via a Terraform template.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution58-vmware-solutions-getting-started\/Architecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Create a IBM Cloud for VMware Solutions Shared virtual data center (VDC) instance using the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-solutions-shared-getting-started"},{"document_id":"ibmcld_07578-250403-252504","score":15.832167,"text":"\nIBM Cloud Connect is only available to IBM clients within the US.\n* How is network bandwidth billed?\n\nIBM Cloud Classic environment: Inbound bandwidth is unlimited and not charged. Outbound bandwidth is charged per GB tier with bandwidth offered as an allotment for each month. As an example, for your compute instances, 250 GB is included with each monthly virtual server and 20 TB is included with each monthly bare metal server. Extra bandwidth can also be purchased per packages. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\nIBM Power Systems Virtual Server environment: Inbound bandwidth is unlimited and not charged. Bandwidth is not charged when you use a public network. If you are using a private network with DirectLink Connect, you are charged IBM Cloud Classic environment rates.\n* What monitoring services are available?\n\nIBM does not provide status and performance monitoring for the Power Systems Virtual Server. Clients must use their own on-premises tools.\n* What performance and capacity planning services do you provide for IBM i?\n\nIBM uses the same tools that are on an on-premises system.\n* IBM i and solution certification\n\nYou can find self-certification and listing information on the [IBM Global Solutions Directory](https:\/\/www.ibm.com\/partnerworld\/public\/find-partner-solution).\n* How do I delete a workspace?\n\nTo delete a workspace (and all its resources), use the left navigation to navigate the workspace page. Find the workspace to be deleted and click on the overflow menu on the top right corner of the tile. Click Delete and confirm the request from the pull-down menu by typing Delete in the text field. Finally, click the red Delete button to initiate the request.\n* How do I delete a single virtual server instance?\n\nThere are two methods to delete a virtual server instance. Both deletion methods are manual processes. There is no way to delete all VSIs without deleting the workspace or deleting a subset of the virtual server instance.\n\n\n\n* Delete a single virtual server instance from the Virtual server instances page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-250377-252478","score":15.832167,"text":"\nIBM Cloud Connect is only available to IBM clients within the US.\n* How is network bandwidth billed?\n\nIBM Cloud Classic environment: Inbound bandwidth is unlimited and not charged. Outbound bandwidth is charged per GB tier with bandwidth offered as an allotment for each month. As an example, for your compute instances, 250 GB is included with each monthly virtual server and 20 TB is included with each monthly bare metal server. Extra bandwidth can also be purchased per packages. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\nIBM Power Systems Virtual Server environment: Inbound bandwidth is unlimited and not charged. Bandwidth is not charged when you use a public network. If you are using a private network with DirectLink Connect, you are charged IBM Cloud Classic environment rates.\n* What monitoring services are available?\n\nIBM does not provide status and performance monitoring for the Power Systems Virtual Server. Clients must use their own on-premises tools.\n* What performance and capacity planning services do you provide for IBM i?\n\nIBM uses the same tools that are on an on-premises system.\n* IBM i and solution certification\n\nYou can find self-certification and listing information on the [IBM Global Solutions Directory](https:\/\/www.ibm.com\/partnerworld\/public\/find-partner-solution).\n* How do I delete a workspace?\n\nTo delete a workspace (and all its resources), use the left navigation to navigate the workspace page. Find the workspace to be deleted and click on the overflow menu on the top right corner of the tile. Click Delete and confirm the request from the pull-down menu by typing Delete in the text field. Finally, click the red Delete button to initiate the request.\n* How do I delete a single virtual server instance?\n\nThere are two methods to delete a virtual server instance. Both deletion methods are manual processes. There is no way to delete all VSIs without deleting the workspace or deleting a subset of the virtual server instance.\n\n\n\n* Delete a single virtual server instance from the Virtual server instances page.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16728-19194-21114","score":15.548053,"text":"\nIt looks into enhanced data encryption, isolation of compute runtimes and network traffic, and by using activity logs to look for suspicious activities.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Enterprise account architecture](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture)Enterprise account architecture White paper\n\nA generalized recommendation for how large customers should configure and govern IBM Cloud at scale.\n\n![White paper icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/white-paper.svg) [Getting Started with IBM Cloud for VMware Solutions Shared](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-solutions-shared-getting-started)Getting Started with IBM Cloud for VMware Solutions Shared Solution tutorial\n\nOn IBM Cloud there are a number of deployment offerings for VMware that you can choose from, with each providing a different level of abstraction. VMware Cloud Director (VCD) is offered under the banner of IBM Cloud for VMware Solutions Shared. It is a multi-tenant service with elasticity and two subscription types:\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Hosting web applications from a secure private network](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-web-app-private-network)Hosting web applications from a secure private network Solution tutorial\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server. It combines three tutorials to illustrate how web applications can be securely deployed on the IBM Cloud IaaS platform using classic networking.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-1033-2260","score":23.92443,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10392-250715-251723","score":23.00801,"text":"\n: Updated the [CLI reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli) to reflect multiple changes for the release of version [0.3.34](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog) of the IBM Cloud Kubernetes Service CLI plug-in.\n\nNew! Red Hat OpenShift on IBM Cloud clusters\n: With the Red Hat OpenShift on IBM Cloud beta, you can create IBM Cloud Kubernetes Service clusters with worker nodes that come installed with the Red Hat OpenShift container orchestration platform software. You get all the advantages of managed IBM Cloud Kubernetes Service for your cluster infrastructure environment, along with the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/3.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments. To get started, see [Tutorial: Creating a Red Hat OpenShift on IBM Cloud cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_10534-528379-529617","score":22.716282,"text":"\n* [tor](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorstor)\n* [wdc](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorswdc)\n\n\n\n\n\n\n\n FAQs \n\n[FAQs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaqs)\n\n\n\n* [How does Red Hat OpenShift on IBM Cloud work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqskubernetes_service)\n* [Why should I use Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_benefits)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscontainer_platforms)\n* [Does the service come with a managed Red Hat OpenShift master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-7-1321","score":22.542929,"text":"\nSite map \n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\n[Getting started with Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedgetting-started)\n\n\n\n* [Creating a classic Red Hat OpenShift cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedclusters_gs)\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedvpc-gen2-gs)\n* [Creating classic clusters in the Red Hat OpenShift on IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedclusters_gs_classic_cli)\n* [Creating VPC clusters in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedclusters_gs_vpc_cli)\n* [Deploying an app with the Red Hat OpenShift service catalog](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-starteddeploy-app)\n* [What's next?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-startedwhats-next)\n\n\n\n\n\n\n\n About \n\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-147312-148742","score":22.096788,"text":"\n* [Using a reservation in a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservationsri-use)\n* [Reviewing reservation usage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservationsri-review)\n\n\n\n\n\n\n\n Enhancing security \n\n[Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity)\n\n\n\n* [Overview of security threats for your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitythreats)\n* [Red Hat OpenShift API server and etcd](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapiserver)\n\n\n\n* [How is access to my API server granted?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapi-server-access)\n* [What does Red Hat OpenShift on IBM Cloud do to secure my API server and etcd data store?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecure-api-server)\n* [What else can I do to secure my API server?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapi-server-what-else)\n* [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitycert-rotate)\n\n\n\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-owner)\n* [How does my worker node setup look?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10505-8927-11021","score":21.989765,"text":"\nCluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/), [CLI plug-in](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli), and [console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities \n\n Observability Provide the ability to integrate IBM Cloud Activity Tracker with your cluster to audit the actions that users take in the cluster. Set up IBM Cloud Activity Tracker or other capabilities to track user activity in the cluster. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nIBM is responsible for the security and compliance of Red Hat OpenShift on IBM Cloud. Compliance to industry standards varies depending on the infrastructure provider that you use for the cluster, such as classic or VPC. You are responsible for the security and compliance of any workloads that run in the cluster and your application data. For more information, see [What standards does the service comply to?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-responsibilities"},{"document_id":"ibmcld_10702-7-1940","score":21.7226,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10495-9135-10569","score":21.486513,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_13150-7-1859","score":21.125149,"text":"\nScalable web application on Red Hat OpenShift on IBM Cloud \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through how to deploy an application to a [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/openshiftcluster) cluster from a remote Git repository, expose the app on an Red Hat OpenShift on IBM Cloud route, monitor the health of the environment, and scale the application. Additionally, you will learn how to use a private container registry, deploy an application from a private Git repository and bind a custom domain to your application.\n\nWith Red Hat OpenShift on IBM Cloud, you can create IBM Cloud Kubernetes Service clusters with worker nodes that come installed with the Red Hat OpenShift on IBM Cloud Container Platform orchestration software. You get all the [advantages of managed IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for your cluster infrastructure environment, while using the [Red Hat OpenShift on IBM Cloud tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.12\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n\n\n\n Objectives \n\n\n\n* Deploy a web application to the Red Hat OpenShift on IBM Cloud cluster.\n* Bind a custom domain.\n* Monitor the logs and health of the cluster.\n* Scale Red Hat OpenShift on IBM Cloud pods.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution50-scalable-webapp-openshift\/Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The developer deploys a web application using the code from a remote Git repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-openshift"},{"document_id":"ibmcld_10534-152882-154317","score":21.062235,"text":"\n* [VPC version 4 master and worker node components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureservice-arch-vpc-4)\n\n\n\n* [Overview of personal and sensitive data storage and removal options](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureibm-data)\n\n\n\n* [What information is stored with IBM when using Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecturepi-info)\n* [How is my information stored and encrypted?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecturepi-storage)\n* [Where is my information stored?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecturepi-location)\n* [How can I remove my information?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecturepi-removal)\n* [Does Red Hat collect information about my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecturepi-rh-telemetry)\n\n\n\n\n\n[Protecting Red Hat OpenShift on IBM Cloud resources with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbrcbr)\n\n\n\n* [How Red Hat OpenShift on IBM Cloud integrates with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbrcbr-overview)\n\n\n\n* [Protecting Red Hat OpenShift on IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbrresources-types-cbr)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-282713-284024","score":28.996199,"text":"\n* [FAQs for Cloud Pak on Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_paksfaq_cloud_paks)\n\n\n\n* [How do I install a Cloud Pak in my Red Hat OpenShift on IBM Cloud cluster? How do I access it later?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_pakscloud_pak_manage)\n* [Can I use the Red Hat OpenShift entitlement that comes with my Cloud Pak for my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_pakscloud_pak_byo_entitlement)\n* [What is included in a Cloud Pak?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_pakscloud_pak_included)\n* [What else do I need to know to use Cloud Paks?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_pakscloud_paks_other)\n\n\n\n\n\n[Adding services by using Operators](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-operatorsoperators)\n\n\n\n* [Using Operators in version 4 clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-operatorsoperators_4)\n* [Disabling and mirroring OperatorHub catalog source images](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-operatorsmirror-operatorhub)\n\n\n\n[Setting up the Red Hat Marketplace](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rh-marketplacerh-marketplace)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_16729-86110-87974","score":28.357733,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Node.js Express application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Deploy a Java Spring app by using IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-spring-webapp)Deploy a Java Spring app by using IBM Cloud Schematics\n\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10534-107977-109345","score":27.66989,"text":"\n* [Uninstalling on Linux and macOS](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-uninstall-ibmcloud-cliuninstall-cli-linux-macos)\n\n\n\n\n\n\n\n Planning your cluster environment \n\n[Moving your environment to Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategystrategy)\n\n\n\n* [Moving your workloads to the IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategycloud_workloads)\n\n\n\n* [What can I move to the IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategymove_to_cloud)\n* [Can I automate my infrastructure deployments?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyinfra_packaging)\n* [What kind of apps can I run? Can I move existing apps, or do I need to develop new apps?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyapp_kinds)\n* [What about serverless apps?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyapps_serverless-strategy)\n* [What skills should I have before I move my apps to a cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyknowledge)\n\n\n\n* [Sizing your Red Hat OpenShift cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_resources)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_16729-139037-140928","score":27.365595,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-246841-248669","score":27.175467,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Reconciling usage for nonsubscription multi-year account invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice)Reconciling usage for nonsubscription multi-year account invoices\n\nAs an IBM Cloud\u00ae customer with a nonsubscription multi-year account, understanding the different invoices that are available to you can help you understand your monthly cost breakdown.\n\nManaging billing and usage\n\n\n\n* 15 minutes\n* 2022-08-30\n\n\n\n[Getting started with the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started)Getting started with the IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10404-74695-75915","score":26.44826,"text":"\nRed Hat OpenShift Control Plane Operator v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift 4.8.21 4.8.26 Changed the duration of worker node certificates from 3 years to 2 years. See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.8\/release_notes\/ocp-4-8-release-notes.htmlocp-4-8-26). \n Red Hat OpenShift on IBM Cloud toolkit 4.8.0+20211201 4.8.0+20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n OpenVPN client 2.4.6-r3-IKS-463 2.5.4-r0-IKS-556 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts. \n OpenVPN server 2.4.6-r3-IKS-462 2.5.4-r0-IKS-555 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_48"},{"document_id":"ibmcld_10534-528379-529617","score":25.676695,"text":"\n* [tor](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorstor)\n* [wdc](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorswdc)\n\n\n\n\n\n\n\n FAQs \n\n[FAQs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaqs)\n\n\n\n* [How does Red Hat OpenShift on IBM Cloud work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqskubernetes_service)\n* [Why should I use Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_benefits)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscontainer_platforms)\n* [Does the service come with a managed Red Hat OpenShift master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-147312-148742","score":25.608189,"text":"\n* [Using a reservation in a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservationsri-use)\n* [Reviewing reservation usage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservationsri-review)\n\n\n\n\n\n\n\n Enhancing security \n\n[Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity)\n\n\n\n* [Overview of security threats for your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitythreats)\n* [Red Hat OpenShift API server and etcd](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapiserver)\n\n\n\n* [How is access to my API server granted?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapi-server-access)\n* [What does Red Hat OpenShift on IBM Cloud do to secure my API server and etcd data store?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecure-api-server)\n* [What else can I do to secure my API server?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapi-server-what-else)\n* [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitycert-rotate)\n\n\n\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-owner)\n* [How does my worker node setup look?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-284670-286038","score":25.445122,"text":"\n[Adding services by using Helm charts](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmhelm)\n\n\n\n* [About Helm in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmabout-helm)\n\n\n\n* [What is Helm and how do I use it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmwhat-is-helm)\n* [What Helm charts are supported in Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmsupported-charts)\n\n\n\n* [Installing Helm v3 in your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helminstall_v3)\n\n\n\n[Adding services by using IBM Cloud service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingservice-binding)\n\n\n\n* [About service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-about)\n\n\n\n* [What types of services can I bind to my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-types)\n* [What is IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-what)\n* [I already have an IBM Cloud service. Can I still use IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-existing)\n* [What if I want to use service credentials that use the private cloud service endpoint?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_13144-1354-3173","score":25.39239,"text":"\n3. Users access the frontend application.\n4. The IBM Cloudant database instance is provisioned through an IBM Cloud Operator Service.\n5. The backend application is connected to the database with an IBM Cloud Operator Binding.\n6. Log Analysis is provisioned and agent deployed.\n7. Monitoring is provisioned and agent deployed.\n8. An Administrator monitors the app with Log Analysis and Monitoring.\n\n\n\nThere are [scripts](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend\/tree\/master\/scripts) that will perform some of the steps below. It is described in the [README.md](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend). If you run into trouble and want to start over just execute the destroy.sh script and sequentially go through the scripts that correspond to the steps to recover.\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* oc to interact with OpenShift.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\n\n\n\n\n Step 1: Create a Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-692271-694037","score":10.5563545,"text":"\nWebSphere Application Server\n\n\n\n* What products can I install with WebSphere Application Server?\n\nYou can install a WebSphere Application Server traditional environment on a virtual server instance (VSI) on IBM Cloud. For a description of the topologies that you can install with WebSphere Application Server, see [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies).\n* What permissions do I need to use this tile?\n\nYou need Manager role on the Schematics service in at least one resource group. You also need Administrator role for VPC Infrastructure Services in the resource group for the Schematics workspace, VPC, and VSIs.\n* Where can I see the installation logs?\n\nTo see the Installation logs, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* Where can I see my installation history?\n\nTo see the installation history, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* How do I uninstall?\n\nFollow the instructions in [Uninstalling your workspace or resources](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-uninstalling).\n* Do I get charged for using the tile?\n\nNo, but you get charged for the infrastructure. Refer to [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies) for infrastructure resources provisioned and to [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) for the associated cost.\n* Can I use the tile to upgrade WebSphere Application Server after initial installation?\n\nNo, you can use the tile only for one installation. After the initial installation, it is your responsibility to manage and upgrade the installation.\n\n\n\nIntegration Event Streams\n\n\n\n* How do I use Kafka APIs to create and delete topics?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-692229-693995","score":10.5563545,"text":"\nWebSphere Application Server\n\n\n\n* What products can I install with WebSphere Application Server?\n\nYou can install a WebSphere Application Server traditional environment on a virtual server instance (VSI) on IBM Cloud. For a description of the topologies that you can install with WebSphere Application Server, see [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies).\n* What permissions do I need to use this tile?\n\nYou need Manager role on the Schematics service in at least one resource group. You also need Administrator role for VPC Infrastructure Services in the resource group for the Schematics workspace, VPC, and VSIs.\n* Where can I see the installation logs?\n\nTo see the Installation logs, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* Where can I see my installation history?\n\nTo see the installation history, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* How do I uninstall?\n\nFollow the instructions in [Uninstalling your workspace or resources](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-uninstalling).\n* Do I get charged for using the tile?\n\nNo, but you get charged for the infrastructure. Refer to [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies) for infrastructure resources provisioned and to [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) for the associated cost.\n* Can I use the tile to upgrade WebSphere Application Server after initial installation?\n\nNo, you can use the tile only for one installation. After the initial installation, it is your responsibility to manage and upgrade the installation.\n\n\n\nIntegration Event Streams\n\n\n\n* How do I use Kafka APIs to create and delete topics?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16215-0-1888","score":10.439026,"text":"\n\n\n\n\n\n\n  FAQs \n\nReview frequently asked questions for IBM\u00ae WebSphere\u00ae Application Server in IBM Cloud\u00ae. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n  What products can I install with WebSphere Application Server? \n\nYou can install a WebSphere Application Server traditional environment on a virtual server instance (VSI) on IBM Cloud. For a description of the topologies that you can install with WebSphere Application Server, see [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies).\n\n\n\n\n\n  What permissions do I need to use this tile? \n\nYou need Manager role on the Schematics service in at least one resource group. You also need Administrator role for VPC Infrastructure Services in the resource group for the Schematics workspace, VPC, and VSIs.\n\n\n\n\n\n  Where can I see the installation logs? \n\nTo see the Installation logs, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n\n\n\n\n\n  Where can I see my installation history? \n\nTo see the installation history, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n\n\n\n\n\n  How do I uninstall? \n\nFollow the instructions in [Uninstalling your workspace or resources](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-uninstalling).\n\n\n\n\n\n  Do I get charged for using the tile? \n\nNo, but you get charged for the infrastructure. Refer to [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies) for infrastructure resources provisioned and to [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) for the associated cost.\n\n\n\n\n\n  Can I use the tile to upgrade WebSphere Application Server after initial installation? \n\nNo, you can use the tile only for one installation. After the initial installation, it is your responsibility to manage and upgrade the installation.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-faq"},{"document_id":"ibmcld_10183-7-2147","score":10.106054,"text":"\nDebugging your Portworx installation \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nThis troubleshooting topic applies to only Red Hat OpenShift clusters that run version 3.11.\n\n What\u2019s happening \n\nWhen you create a Portworx service instance from the IBM Cloud catalog, the Portworx installation in your cluster fails and the service instance shows a status of Provision failure.\n\n Why it\u2019s happening \n\nBefore Portworx is installed in your cluster, a number of checks are performed to verify the information that you provided on the Portworx service page of the IBM Cloud catalog.\n\nIf one of these checks fails, the status of the Portworx service is changed to Provision failure. You can't see the details of what check failed or what information is missing to complete the installation.\n\n How to fix it \n\nFollow this guide to start troubleshooting your Portworx installation and to verify the information that you entered in the IBM Cloud catalog.\n\nIf you find information that you entered incorrectly or you must change the setup of your cluster, correct the information or the cluster setup. Then, create a new Portworx service instance to restart the installation.\n\n\n\n Step 1: Verifying the IBM Cloud catalog information \n\nStart by verifying that the information that you entered in the IBM Cloud catalog is correct. If information was entered incorrectly, the installation does not pass the pre-installation checks and fails without starting the installation.\n\n\n\n1. Verify that the cluster where you want to install Portworx is located in the IBM Cloud region and resource group that you selected.\n\nibmcloud oc cluster get --cluster <cluster_name_or_ID>\n2. Verify that the IBM Cloud API key that you entered has sufficient permissions to work with your cluster. You must be assigned the Editor platform access role and the Manager service access role for Red Hat OpenShift on IBM Cloud. For more information, see [User access permissions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference).\n3. Verify that you entered the etcd API endpoint for your Databases for etcd service instance in the correct format.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-portworx"},{"document_id":"ibmcld_05748-7-2053","score":10.106054,"text":"\nDebugging your Portworx installation \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nWhen you create a Portworx service instance from the IBM Cloud catalog, the Portworx installation in your cluster fails and the service instance shows a status of Provision failure.\n\n Why it\u2019s happening \n\nBefore Portworx is installed in your cluster, a number of checks are performed to verify the information that you provided on the Portworx service page of the IBM Cloud catalog.\n\nIf one of these checks fails, the status of the Portworx service is changed to Provision failure. You can't see the details of what check failed or what information is missing to complete the installation.\n\n How to fix it \n\nFollow this guide to start troubleshooting your Portworx installation and to verify the information that you entered in the IBM Cloud catalog.\n\nIf you find information that you entered incorrectly or you must change the setup of your cluster, correct the information or the cluster setup. Then, create a new Portworx service instance to restart the installation.\n\n\n\n Step 1: Verifying the IBM Cloud catalog information \n\nStart by verifying that the information that you entered in the IBM Cloud catalog is correct. If information was entered incorrectly, the installation does not pass the pre-installation checks and fails without starting the installation.\n\n\n\n1. Verify that the cluster where you want to install Portworx is located in the IBM Cloud region and resource group that you selected.\n\nibmcloud ks cluster get --cluster <cluster_name_or_ID>\n2. Verify that the IBM Cloud API key that you entered has sufficient permissions to work with your cluster. You must be assigned the Editor platform access role and the Manager service access role for IBM Cloud Kubernetes Service. For more information, see [User access permissions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference).\n3. Verify that you entered the etcd API endpoint for your Databases for etcd service instance in the correct format.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-portworx"},{"document_id":"ibmcld_16651-7-2005","score":9.854032,"text":"\nPresto overview \n\n\n\n What is Presto? \n\nPresto is a distributed SQL query engine, with the capability to query vast data sets located in different data sources, thus solving data problems at scale.\n\nPresto provides the ANSI SQL interface, which can be used for all data analytics and IBM\u00ae watsonx.data use cases. With this feature, you do not need to manage multiple query languages and interfaces to different databases and storage. Presto is designed for storage abstraction, which allows connections to any data source through its connectors.\n\nwatsonx.data uses version 0.279 of Presto.\n\n\n\n\n\n Presto server types \n\nA Presto installation includes three server types - Coordinator, Worker, and Resource manager. Following is a brief explanation of the server types. For more information about the server types, see [Presto concepts](https:\/\/prestodb.io\/docs\/current\/overview\/concepts.html) in Presto documentation.\n\n\n\n* Coordinator - A coordinator is a server type in a Presto installation, which is responsible for parsing statements, planning queries, and managing Presto worker nodes. It is the brain of a Presto installation and is also the node to which a client connects to submit statements for execution. It is also responsible for fetching results from the workers and returning the results to the client.\n* Worker - A worker is a server type in a Presto installation, which is responsible for running tasks and processing data. Worker nodes fetch data from connectors and exchange intermediate data with each other.\n* Resource manager - The resource manager is a server type in presto, which aggregates data from all coordinator and workers and creates a global view of the Presto cluster.\n\n\n\nThe following connectors are supported in watsonx.data:\n\n\n\n* [Iceberg](https:\/\/prestodb.io\/docs\/current\/connector\/iceberg.html)\n* [Db2](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-db2_connector)\n* [Netezza](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-netezza_connector)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-presto_overview"},{"document_id":"ibmcld_06966-2415-4333","score":9.73733,"text":"\nThe crawler plug-in can apply more nuanced rules to what documents and what fields in the documents get added. For more information, see [Building a Cloud Pak for Data custom crawler plug-in](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-crawler-plugin-build).\n\n\n\n Data source requirements \n\nThe following requirements and limitations are specific to IBM Watson\u00ae Discovery:\n\n\n\n* The individual file size limit is 32 MB per file, which includes compressed archive files (ZIP, CZIP, TAR). When decompressed, the individual files within compressed files cannot exceed 32 MB per file. This limit is the same for collections in which you upload your own data.\n* Depending on the type of installation (starter or production mode), the number of collections you can ingest simultaneously varies. A starter installation includes one crawler pod, which allows three collections to be processed simultaneously. A production installation includes two crawler pods, which can process six collections simultaneously.\n\nIf you are running a starter installation and you want to process more than three collections simultaneously, you must increase the number of crawler pods by running the following commands:\n\noc patch wd wd --type=merge --patch='{\"spec\": {\"ingestion\": {\"crawler\": {\"replicas\": <number-of-replicas> } } } }'\n\nIn a starter installation, the maximum number of simultaneous collections that can crawl an external data source is 3. If you start a fourth, that collection does not start to process until the prior three crawls finish.\n\nEach number-of-replicas allows 3 simultaneous crawls, so number-of-replicas=2 increases the replicas to 6, and number-of -replicas=3 increases them to 9.\n\n\n\n\n\n\n\n Crawler plug-in settings \n\nWhen you deploy one or more crawler plug-ins, you can configure your collection to use one of the plug-ins.\n\nThese settings are only available when crawler plug-ins are deployed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-types"},{"document_id":"ibmcld_11790-1250-2755","score":9.677728,"text":"\n[Plan your environment](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-infrastructure-plan) for Satellite by choosing your infrastructure, thinking about the services that you want to use, and setting up the hosts that you want to use. Make sure your hosts meet the [minimum requirement](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-reqs) and that you consider the [size of your location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-sizing).\n\nZoom\n\n![Plan for your Satellite location.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c8335d66af691d19e837116fd633481c477061eb\/satellite\/\/images\/1-plan-location.svg)\n\nFigure 2. Planning for your Satellite location\n2. Create your location that runs on your host infrastructure. [Choose an installation method](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations) for your location, based on what is available for your infrastructure provider.\n\nZoom\n\n![Create your location.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c8335d66af691d19e837116fd633481c477061eb\/satellite\/\/images\/2-create-location.svg)\n\nFigure 3. Creating your Satellite location\n3. [Attach hosts to your location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationslocation-create-manual) by running the installation scripts (RHEL) or ingestion scripts (RHCOS). If you are using a Schematics template, this step is done for you. After your hosts are attached, they are in an unassigned state.\n\nZoom\n\n![Attach hosts to your location.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-host"},{"document_id":"ibmcld_11633-27418-28379","score":9.57904,"text":"\nAll security groups for VPC](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/\/images\/quickstudy-intel-vs-gen2-image5.png)\n\nFigure 14. All security groups for VPC\n\n\n\n\n\n Installing SAP software \n\nAfter you download the installation media, follow the standard SAP installation procedure that is documented in the [SAP installation guides](https:\/\/help.sap.com\/viewer\/index) for your SAP version and components. Also, review the corresponding SAP notes. See more detailed information about SAP NetWeaver installation that uses Db2 as the RDBMS in [Considerations about IBM Db2](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-anydb-ibm-db2).\n\n\n\n\n\n Relevant SAP Notes \n\n\n\n* [SAP Note 2002167 - Red Hat Enterprise Linux 7.x: Installation and Upgrade](https:\/\/launchpad.support.sap.com\/\/notes\/2002167).\n* [SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License](https:\/\/launchpad.support.sap.com\/\/notes\/2923773).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-quickstudy-vs-gen2-netweaver-rhel"},{"document_id":"ibmcld_00194-1364-2940","score":9.4377365,"text":"\n* If the BUAgent appears to be running, restart the service with the following command.\n\n\/etc\/init.d\/vvagent restart\n\n\n\n\n\n\n\n Agent needs to be reregistered to the Cloud Backup portal \n\n Why it\u2019s happening \n\nIf it still shows that the Agent is offline after a refresh of the Portal page, then the Agent needs to be registered again.\n\n How to fix it \n\nRegistering an Agent to the Portal retains all existing jobs, schedules, and configurations as-is. Go to the Agent installation directory, then run the register command.\n\ncd opt\/BUAgent\n.\/register\n\nAnswer the following prompts.\n\n\n\n* What is the web-based Agent Console address? cloudbackupregister.service.softlayer.com\n* What is the web-based Agent Console connection port [8086]? Press enter, 8086 is the correct port.\n* What is the web-based Agent Console username? This entry is the same username that is used to log in to Portal.\n* What is the web-based Agent Console password? This entry is the same password that is used to log in to Portal.\n\n\n\nFor more information about viewing or changing the backup password, see [Managing username and password for the Cloud Backup service](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-changePassword).\n\nIf the previous steps don't work, pull up and review the most recent BUAgent-X.XLOG.\n\n\n\n1. Go to opt\/BUAgent.\n\ncd \/opt\/BUAgent\n2. List the contents and sort them by date.\n\nls -lrth\n3. Find the name of the most recent BUAgent-x.XLOG and open it with \/opt\/BUAgent\/xlogcat. It can't be opened with cat or vim.\n\n.\/xlogcat BUAgent-1.XLOG\n4. Review the log and determine the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-troubleshoot-LinuxAgent"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11893-71354-72902","score":5.6412687,"text":"\n* [Key concepts for Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-cluster-configsatcon-terminology)\n\n\n\n\n\n Setting up clusters to use with Satellite Config \n\n[Granting Satellite Config access to your clusters](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigsetup-clusters-satconfig)\n\n\n\n* [Automatically granting Satellite Config access to your clusters](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigauto-setup-clusters-satconfig)\n* [Manually granting Satellite Config access to your clusters](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigmanual-setup-clusters-satconfig)\n\n\n\n* [Cluster admin access](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigcluster-admin-access)\n* [Custom access, cluster-wide](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigcustom-access-cluster-wide)\n* [Custom access, scoped to a project](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfigcustom-access-scoped-project)\n\n\n\n\n\n[Setting up cluster groups](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig-groupssetup-clusters-satconfig-groups)\n\n[Registering clusters with Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-register-openshift-clustersregister-openshift-clusters)\n\n[Verifying cluster status](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satconfig-verify-cluster-statussatconfig-verify-cluster-status)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sitemap&interface=cli"},{"document_id":"ibmcld_11793-3366-5550","score":5.5194836,"text":"\n(https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-sizingtypes-changes-sizing-increase).\n\n4 vCPU, 16 GB RAM\n\n16 vCPU, 64 GB RAM\n\n\n\nSizing guidance for the Satellite location control plane\n\n Number of control plane hosts Max clusters in location Example of max worker nodes in location Max cluster size \n\n 6 hosts Up to 5 clusters 20 workers across 5 clusters, or 80 workers across 2 clusters 60 workers per cluster \n 9 hosts Up to 8 clusters 40 workers across 8 clusters, or 140 workers across 3 clusters 60 workers per cluster \n 12 hosts Up to 11 clusters 60 workers across 11 clusters, or 200 workers across 4 clusters 60 workers per cluster \n\n\n\n\n\n\n\n Location size for Red Hat CoreOS (RHCOS) enabled location \n\nThe following tables show sizing guidance for the number of hosts that the Satellite location control plane requires to run the master components for various combinations of clusters and worker nodes in a Red Hat CoreOS enabled location. These sizings are for reference only. Your sizing requirements can increase depending on the amount of workload running in a cluster. For more information, see [What types of changes can increase my location sizing requirements?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-sizingtypes-changes-sizing-increase).\n\n4 vCPU, 16 GB RAM\n\n16 vCPU, 64 GB RAM\n\n\n\nSizing guidance for the Satellite location control plane\n\n Number of control plane hosts Max clusters in location Example of max worker nodes in location Max cluster size \n\n 6 hosts Up to 3 clusters 20 workers across 3 clusters, or 80 workers across 2 clusters 60 workers per cluster \n 9 hosts Up to 5 clusters 40 workers across 5 clusters, or 140 workers across 3 clusters 60 workers per cluster \n 12 hosts Up to 8 clusters 60 workers across 8 clusters, or 200 workers across 4 clusters 60 workers per cluster \n\n\n\n\n\n\n\n Location size for testing \n\nThe following table shows sizing guidance for the number of hosts that the Satellite location control plane requires to run a Satellite location demonstration. This configuration is not intended for production use.\n\nFor a non-RHCOS enabled location, your hosts must have at least 4 vCPU and 16 GB RAM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-sizing"},{"document_id":"ibmcld_10041-5131-6632","score":5.486975,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-5113-6614","score":5.486975,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05713-132600-134017","score":5.3711576,"text":"\n* [Creating a VPC cluster in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n\n\n\n\n Accessing clusters \n\n[Accessing clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_cluster)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusterprereqs)\n* [Accessing clusters through the public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_public_se)\n* [Accessing clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_private_se)\n\n\n\n* [Accessing VPC clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clustervpc_private_se)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05869-5175-6602","score":5.3676767,"text":"\npublic-crbmnj1b1d09lpvv3oof0g-alb1 true enabled public 169.XX.XXX.XX dal10 ingress:1.1.2_2507_iks 2234945 2.0\n\n\n\n* If a public ALB is listed and is assigned an IP address (classic clusters) or hostname (VPC clusters), continue to the next step.\n* If a public ALB is listed and but is not assigned an IP address (classic clusters) or hostname (VPC clusters), try to disable and re-enable the ALBs.\n\n\n\n* Classic clusters:\n\nibmcloud ks ingress alb disable --alb <ALB_ID> -c <cluster_name_or_ID>\n\nibmcloud ks ingress alb enable classic --alb <ALB_ID> -c <cluster_name_or_ID>\n* VPC clusters:\n\nibmcloud ks ingress alb disable --alb <ALB_ID> -c <cluster_name_or_ID>\n\nibmcloud ks ingress alb enable vpc-gen2 --alb <ALB_ID> -c <cluster_name_or_ID>\n\n\n\n* If no ALBs are created after several minutes, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n4. Check whether the LoadBalancer service that exposes the ALB exists and is assigned the same IP address (classic clusters) or hostname (VPC clusters) as the public ALB.\n\n\n\n* If a LoadBalancer service is listed and is assigned an IP address (classic clusters) or hostname (VPC clusters), continue to the next step.\n* If no LoadBalancer services are created after several minutes, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\nkubectl get svc -n kube-system | grep LoadBalancer\n\nExample output","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ingress_subdomain"},{"document_id":"ibmcld_10534-129593-131048","score":5.351368,"text":"\n* [Accessing Red Hat OpenShift clusters on Satellite](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_cluster_sat)\n\n\n\n* [Accessing clusters through the cluster service URL](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_cluster_sat_se)\n* [Accessing clusters from within the IBM Cloud private network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_cluster_sat_link)\n* [Accessing clusters from the public network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clustersat_public_access)\n\n\n\n* [Accessing VPC clusters through the Virtual Private Endpoint Gateway](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clustervpc_vpe)\n* [Accessing clusters from automation tools by using an API key](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_automation)\n\n\n\n* [Using an API key to log in to clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_api_key)\n* [Using a service ID to log in to clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_service_id)\n\n\n\n\n\n[Accessing the cluster master with admission controllers and webhooks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks)\n\n\n\n* [Can I create my own admission controllers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks_create_controllers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05825-11096-13078","score":5.3221297,"text":"\nTo balance your workload across multiple clusters, you must set up a global load balancer and add the public IP addresses of your ALBs or load balancer services to your domain. By adding these IP addresses, you can route incoming traffic between your clusters. For the global load balancer to detect if one of your clusters is unavailable, consider adding a ping-based health check to every IP address. When you set up this check, your DNS provider regularly pings the IP addresses that you added to your domain. If one IP address becomes unavailable, then traffic is not sent to this IP address anymore. However, Kubernetes does not automatically restart pods from the unavailable cluster on worker nodes in available clusters. If you want Kubernetes to automatically restart pods in available clusters, consider setting up a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters).\n\n\n\n Why do I need 3 clusters in three zones? \n\nSimilar to using [3 zones in multizone clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters), you can provide more availability to your app by setting up three clusters across zones. You can also reduce costs by purchasing smaller machines to handle your workload.\n\n\n\n\n\n What if I want to set up multiple clusters across regions? \n\nYou can set up multiple clusters in different regions of one geolocation (such as US South and US East) or across geolocations (such as US South and EU Central). Both setups offer the same level of availability for your app, but also add complexity when it comes to data sharing and data replication. For most cases, staying within the same geolocation is sufficient. But if you have users across the world, it might be better to set up a cluster where your users are so that your users don't experience long waiting times when they send a request to your app.\n\n\n\n\n\n What options do I have to load balance workloads across multiple clusters?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clusters"},{"document_id":"ibmcld_14619-7-2038","score":5.3221297,"text":"\nDeleting clusters from vCenter Server instances \n\nYou can delete clusters from VMware vCenter Server\u00ae instances when you do not need them.\n\nDeleting clusters from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n\n\n\n Before you delete clusters from vCenter Server instances \n\n\n\n* Whenever possible, delete clusters by using the IBM Cloud\u00ae for VMware Solutions console and not the VMware vSphere\u00ae Web Client. Changes that you make on the vSphere Web Client are not synchronized with the VMware Solutions console. If you want to delete clusters from vCenter Server instances by using the vSphere Web Client, do so only for on-premises clusters or clusters that you don't manage in the VMware Solutions console.\n* You can delete any cluster except for the first cluster (the one that is created during initial deployment).\n* You can delete multiple clusters at a time. You can also delete a cluster while another cluster is being created or deleted.\n* Ensure that all nodes in a cluster are powered on and operational before you delete the cluster.\n* When you delete a cluster, all VMs from the cluster are also deleted and they can't be recovered. If you want to keep the VMs, migrate them to other clusters.\n* When you delete a cluster, all storage and subnets that are associated with the cluster are deleted as well. To view the storage and subnets that are associated with a cluster, see the cluster details page.\n* You do not have to delete any services that are installed on the cluster, including services on a gateway cluster. The services are automatically deleted when you delete the cluster.\n\n\n\n\n\n\n\n Procedure to delete clusters from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance that you want to delete clusters from.\n\nEnsure that the instance status is Available. Otherwise, you can't delete clusters from the instance.\n3. Click the Infrastructure tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingclusters"},{"document_id":"ibmcld_14358-7-1967","score":5.3221297,"text":"\nDeleting clusters from Cyber Recovery instances \n\nYou can delete clusters from Cyber Recovery instances when you do not need them.\n\n\n\n Before you delete clusters from Cyber Recovery instances \n\n\n\n* Whenever possible, delete clusters by using the IBM Cloud\u00ae for VMware Solutions console and not the VMware vSphere\u00ae Web Client. Changes that you make on the vSphere Web Client are not synchronized with the VMware Solutions console. If you want to delete clusters from Cyber Recovery instances by using the vSphere Web Client, do so only for on-premises clusters or clusters that you don't manage in the VMware Solutions console.\n* You can delete any cluster except for the first cluster (the one that is created during initial deployment).\n* You can delete multiple clusters at a time. You can also delete a cluster while another cluster is being created or deleted.\n* Ensure that all nodes in a cluster are powered on and operational before you delete the cluster.\n* When you delete a cluster, all virtual machines (VMs) from the cluster are also deleted, and they can't be recovered. If you want to keep the VMs, migrate them to other clusters.\n* You don't have to delete any services that are installed on a cluster. The services are automatically deleted when you delete the cluster.\n\n\n\n\n\n\n\n Procedure to delete clusters from Cyber Recovery instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > Cyber Recovery from the left navigation pane.\n2. In the Cyber Recovery table, click the instance that you want to delete clusters from.\n\nEnsure that the instance status is Available. Otherwise, you can't delete clusters from the instance.\n3. Click Infrastructure on the left navigation pane. In the Clusters table, locate the cluster that you want to delete and click the Delete icon ![Delete icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/icons\/delete.svg) next to the Status column.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-cr_deletingclusters"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-755905-757955","score":18.77137,"text":"\nYou can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04145-7-2180","score":18.632933,"text":"\nFAQs for IBM Cloud Internet Services \n\nHave a question about IBM Cloud\u00ae Internet Services? Review these frequently asked questions, which provide answers to provisioning concerns, application access, and other common inquiries.\n\n\n\n What do I get with a Free Trial Plan? \n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n\n\n\n\n\n How many Free Trial instances can I have? \n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n\n\n\n\n\n Can I downgrade from Standard to the Free Trial? \n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n\n\n\n\n\n My Free Trial has expired. What are my options? \n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n\n\n\n\n\n What happened to Enterprise Package plans? \n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04183-0-2205","score":18.124624,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_16727-754871-756890","score":17.968153,"text":"\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-756469-758485","score":17.274426,"text":"\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13139-17831-19468","score":16.81458,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-199697-200931","score":16.498583,"text":"\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- <\/section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- <\/section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-110743-112003","score":16.381977,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-glb-monitor-options\" \"> --><-- <section \"id=\"section-delete-glb-monitor-examples\" \"> --> Examples Delete GLB monitor f1aba936b94213e5b8dca0c0dbf1f9cc. ibmcloud cis glb-monitor-delete f1aba936b94213e5b8dca0c0dbf1f9cc -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-glb-monitor-examples\" \"> --><-- <\/section \"id=\"section-delete-glb-monitor\" \"> --><-- <section \"id=\"section-update-glb-monitor\" \"> --> ibmcloud cis glb-monitor-update Update the GLB monitor for a given service instance. ibmcloud cis glb-monitor-update GLB_MON_ID (--json @JSON_FILE | JSON_STRING) -i, --instance INSTANCE] --output FORMAT]\nDeprecated] ibmcloud cis glb-monitor-update GLB_MON_ID (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) -i, --instance INSTANCE] --output FORMAT] ! !!!!!!!!!!\n<-- <section \"id=\"section-update-glb-monitor-options\" \"> --> Command options GLB_MON_ID: The ID of global load balancer monitor. Required.--json: The JSON file or JSON string used to describe a GLB monitor. Required.\n<-- <ul> -->\n\n* The required fields in JSON data are type.\n\n<-- <ul> -->\n\n* type: The protocol to use for the healthcheck. Valid values: HTTP, HTTPS, TCP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-3588-5028","score":16.25718,"text":"\n: The domain and path that Access will block. Required.\n\n--session-duration value\n: Defines the amount of time that the tokens issued for this application are valid. Valid values: 30m, 6h, 12h, 24h, 168h, 730h.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nUpdate access application a5836c2a7ea72d2e225890caea70ae32.\n\nibmcloud cis access-app-update 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 --name exampleUpdate --domain example.com --session-duration 24h -i cis-demo\n\n\n\n\n\n\n\n ibmcloud cis access-app-delete \n\nDelete an access application (Enterprise plan only).\n\nibmcloud cis access-app-delete DNS_DOMAIN_ID ACCESS_APPLICATION_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nACCESS_APPLICATION_ID\n: The ID of access application. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete access application a5836c2a7ea72d2e225890caea70ae32.\n\nibmcloud cis access-app-delete 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 -i cis-demo\n\n\n\n\n\n\n\n\n\n Access certificate \n\n\n\n ibmcloud cis access-certificate-create \n\nCreate an access certificate for a given DNS domain (Enterprise plan only).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-198873-200152","score":16.116417,"text":"\n<-- <\/section \"id=\"section-set-context-cis-service-examples\" \"> --><-- <\/section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":43.21286,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-33215-34565","score":39.562595,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16727-756469-758485","score":35.317516,"text":"\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04334-32129-33511","score":34.851448,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04145-1739-3868","score":34.82307,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04334-31256-32402","score":34.70876,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_07578-796137-798029","score":33.629387,"text":"\nCreate a VPC instance.\n2. Create a DNS Services instance.\n3. Add a DNS zone to the DNS Services instance.\n4. Designate the VPC instance as a permitted network for the DNS zone.\n5. Add a DNS Resource Record to the DNS zone.\n6. Verify name resolution of the DNS Resource Record works from within the VPC.\n\n\n\n* How is DNS Services different from public DNS?\n\nDNS Services permits name resolution only from permitted VPCs within your IBM Cloud\u00ae account. The DNS zone is not resolvable from the internet.\n* Can I manage publicly available DNS records with this service?\n\nNo, DNS Services only offers private DNS at the moment. Use [CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedgetting-started) for public DNS.\n* Is DNSSec supported with zones managed by DNS Services?\n\nDNSSec allows resolvers to cryptographically verify the data received from authoritative servers. DNS Services resolvers support DNSSec for public domains, for which requests are forwarded to public resolvers that support DNSSec. For private zones, since the authority is within IBM Cloud, records are fetched using secure protocols, and are guaranteed to have the same level of privacy and security that DNSSec provides for public zones.\n* Is DNS Services regional or global?\n\nDNS Services is a global service and can be used from permitted networks in any IBM Cloud region.\n* When creating a DNS zone, what is the purpose of the Label field?\n\nA given instance can have multiple DNS zones with the same name. The label helps to differentiate zones with name collisions.\n* How many private zones are supported?\n\nDNS Services supports 10 private zones per service instance.\n* How many permitted networks are supported?\n\nDNS Services supports 10 permitted networks per DNS zone.\n* How many DNS records are supported?\n\nDNS Services supports 3500 DNS records per DNS zone.\n* How do I delete my DNS Services instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-796010-797902","score":33.629387,"text":"\nCreate a VPC instance.\n2. Create a DNS Services instance.\n3. Add a DNS zone to the DNS Services instance.\n4. Designate the VPC instance as a permitted network for the DNS zone.\n5. Add a DNS Resource Record to the DNS zone.\n6. Verify name resolution of the DNS Resource Record works from within the VPC.\n\n\n\n* How is DNS Services different from public DNS?\n\nDNS Services permits name resolution only from permitted VPCs within your IBM Cloud\u00ae account. The DNS zone is not resolvable from the internet.\n* Can I manage publicly available DNS records with this service?\n\nNo, DNS Services only offers private DNS at the moment. Use [CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedgetting-started) for public DNS.\n* Is DNSSec supported with zones managed by DNS Services?\n\nDNSSec allows resolvers to cryptographically verify the data received from authoritative servers. DNS Services resolvers support DNSSec for public domains, for which requests are forwarded to public resolvers that support DNSSec. For private zones, since the authority is within IBM Cloud, records are fetched using secure protocols, and are guaranteed to have the same level of privacy and security that DNSSec provides for public zones.\n* Is DNS Services regional or global?\n\nDNS Services is a global service and can be used from permitted networks in any IBM Cloud region.\n* When creating a DNS zone, what is the purpose of the Label field?\n\nA given instance can have multiple DNS zones with the same name. The label helps to differentiate zones with name collisions.\n* How many private zones are supported?\n\nDNS Services supports 10 private zones per service instance.\n* How many permitted networks are supported?\n\nDNS Services supports 10 permitted networks per DNS zone.\n* How many DNS records are supported?\n\nDNS Services supports 3500 DNS records per DNS zone.\n* How do I delete my DNS Services instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-797627-799450","score":33.41531,"text":"\nThe label helps to differentiate zones with name collisions.\n* How many private zones are supported?\n\nDNS Services supports 10 private zones per service instance.\n* How many permitted networks are supported?\n\nDNS Services supports 10 permitted networks per DNS zone.\n* How many DNS records are supported?\n\nDNS Services supports 3500 DNS records per DNS zone.\n* How do I delete my DNS Services instance?\n\nTo delete a DNS Services instance,\n\n\n\n* Navigate to the Resource List in the [IBM Cloud console](https:\/\/%7BDomainName%7D\/).\n* Click the \"overflow\" menu ![overflow menu icon](https:\/\/cloud.ibm.com\/icons\/actions-icon-vertical.svg) in the final column and select \"Delete\".\n\n\n\n* Why can't I delete a DNS Services instance?\n\nIf a DNS zone has been added to the DNS Services instance, the instance cannot be deleted.\n* Why can't I delete a DNS zone?\n\nIf a network has been added to a zone, the zone cannot be deleted until the permitted network is deleted from the zone.\n* What happens if I delete my VPC?\n\nIf the VPC is deleted, the corresponding permitted network will also be deleted from the DNS zones of your instance.\n* Why can I still resolve my resource records after I deleted its associated zone or permitted network?\n\nTo maintain a level of performance while resolving DNS queries, DNS Services resolvers cache data related to permitted networks for a period of time. Changes made to a permitted network might not have propagated until the previously cached data expires. See [Known limitations](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-known-limitations) for more details.\n* What do the different zone states mean?\n\nThe zone states definitions are as follows.\n\n\n\n* Pending: When a DNS zone is added to the instance it will be in Pending. In this state Resource Records can be added, deleted or updated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-797500-799323","score":33.41531,"text":"\nThe label helps to differentiate zones with name collisions.\n* How many private zones are supported?\n\nDNS Services supports 10 private zones per service instance.\n* How many permitted networks are supported?\n\nDNS Services supports 10 permitted networks per DNS zone.\n* How many DNS records are supported?\n\nDNS Services supports 3500 DNS records per DNS zone.\n* How do I delete my DNS Services instance?\n\nTo delete a DNS Services instance,\n\n\n\n* Navigate to the Resource List in the [IBM Cloud console](https:\/\/%7BDomainName%7D\/).\n* Click the \"overflow\" menu ![overflow menu icon](https:\/\/cloud.ibm.com\/icons\/actions-icon-vertical.svg) in the final column and select \"Delete\".\n\n\n\n* Why can't I delete a DNS Services instance?\n\nIf a DNS zone has been added to the DNS Services instance, the instance cannot be deleted.\n* Why can't I delete a DNS zone?\n\nIf a network has been added to a zone, the zone cannot be deleted until the permitted network is deleted from the zone.\n* What happens if I delete my VPC?\n\nIf the VPC is deleted, the corresponding permitted network will also be deleted from the DNS zones of your instance.\n* Why can I still resolve my resource records after I deleted its associated zone or permitted network?\n\nTo maintain a level of performance while resolving DNS queries, DNS Services resolvers cache data related to permitted networks for a period of time. Changes made to a permitted network might not have propagated until the previously cached data expires. See [Known limitations](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-known-limitations) for more details.\n* What do the different zone states mean?\n\nThe zone states definitions are as follows.\n\n\n\n* Pending: When a DNS zone is added to the instance it will be in Pending. In this state Resource Records can be added, deleted or updated.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":45.15477,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-33215-34565","score":41.78566,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16727-758098-760027","score":38.210392,"text":"\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n* Who is the registrar for my domain?\n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n* I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS?\n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04334-34286-35758","score":38.011166,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_05353-20027-21778","score":37.928524,"text":"\nIf you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS\/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2. [Create the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscustom-domain) in Code Engine with the certificate chain and the private key.\n3. [Obtain the CNAME record for the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-cname).\n4. In CIS, update the DNS records to point to your Code Engine project. In CIS, go to the DNS records page (Reliability>DNS) and Add the CNAME record.\n5. Change the CIS mode. Go to the TLS security page (Security>TLS). Select End-to-end CA signed as the TLS mode.\n\n\n\nIf you need to register multiple domains and subdomains, such as example.com and www.example.com, you must repeat the previous steps 2 and 3 for each subdomain. You can consider creating a single certificate that covers more than one domain. However, you can use that single certificate only one time in a region. If you plan to use your custom domains in more than one project in a single region, keep them separate.\n\n\n\n\n\n\n\n Testing your custom domain \n\nAfter the CNAME record updates are published, you can test the application with the custom domain mapping.\n\nWith a browser, call the application by targeting the custom domain by using curl.\n\ncurl -v -X GET https:\/\/www.example.com\n\nExample output\n\nHello World from:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_04145-3314-5349","score":37.6788,"text":"\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n\n\n\n\n\n Who is the registrar for my domain? \n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n\n\n\n\n\n I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS? \n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_07578-765387-767230","score":36.383595,"text":"\nProxied records are records that proxy their traffic through IBM CIS. Only proxied records receive CIS benefits, such as IP masking, where a CIS IP is substituted for your origin IP to protect it:\n\n$ whois 104.28.22.57 | grep OrgName\nOrgName: IBM\n\nIf you would rather bypass CIS on a domain (we still resolve DNS), then non-proxying the record is a possible solution.\n* I got a DNS Validation error: 1004; now what can I do?\n\nFor page rules to work, DNS needs to resolve for your zone. As a result, you must have a proxied DNS record for your zone.\n* Can I add a CNAME for a root record?\n\nYes. IBM CIS supports a feature called \"CNAME Flattening\" which allows our users to add a CNAME as a root record. Our authoritative DNS servers enumerate the CNAME target's records and respond with those records instead of the CNAME itself, effectively hiding the fact that the user configured a CNAME at the root of the domain.\n* What is the default health check timeout?\n\nThe default health check timeout for the Free Trial and Standard plans is 60 seconds.\n* Can health checks be configured for non-HTTP\/HTTPS traffic?\n\nNo, health checks can only be configured with HTTP\/HTTPS.\n* Can global load balancers be configured for non-HTTP\/HTTPS traffic?\n\nNo, global load balancers can only be configured with HTTP\/HTTPS.\n* Does disabling all of my origins in an origin pool disable the entire pool itself?\n\nYes, if the origin pool is being used in a load balancer, the traffic is routed to the next highest priority pool or the fallback pool.\n* I have an error in my Kubernetes Ingress, what do I do?\n\nThe hostname in a Kubernetes ingress must consist of lower case alphanumeric characters, - or ., and must start and end with an alphanumeric character. Using _ in the load balancer name, though permitted, can cause an ingress error in Kubernetes clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-758976-760934","score":36.34658,"text":"\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n* I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS?\n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.\n* What is TLS?\n\nTLS is a standard security protocol for establishing encrypted links between a web server and a browser in an online communication. A TLS certificate is necessary to create a TLS connection with a website and comprises the domain name, the name of the company, and additional data, such as company address, city, state, and country. The certificate also shows the expiration date and details of the issuing Certificate Authority (CA).\n* How Does TLS Work?\n\nWhen a browser initiates a connection with a TLS secured website, it first retrieves the site's TLS Certificate to check whether the certificate is still valid.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-756469-758485","score":34.878452,"text":"\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04145-1739-3868","score":34.593792,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16242-7-2224","score":21.290277,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16242-1610-3614","score":18.86106,"text":"\nFor example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support. If the customer picks this choice, the assistant uses your Fallback action.\n\nStep validation attempts before offering support: If a customer provides invalid answers for a step in an action, the assistant can offer to connect to other support in the Fallback action. The step validation count measures how many invalid answers can occur before the assistant provides this choice.\n\nThis table shows the default settings for each mode.\n\n\n\nDefault settings\n\n Clarifying Confident \n\n Clarify when one action matches More often Sometimes \n Clarify when more than one action matches More often Sometimes \n Offer support option when asking a clarifying question More often Sometimes \n Step validation attempts before offering support 1 time 3 times \n\n\n\n\n\n\n\n Choosing a mode for individual actions \n\nWhen you edit an action, you can see the mode that it uses and change it if you need to.\n\n\n\n1. Click the Action response mode icon ![Action response mode icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-icon.svg). The mode in use is checked.\n\nZoom\n\n![Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_14192-1597-3529","score":17.71264,"text":"\nHowever, when a hardware firewall is associated with a VLAN, the type of firewall might impose restrictions on the number of devices that reside on the VLAN.\n\n\n\n\n\n What kinds of devices are assigned to a VLAN? \n\nAny device that has a network connection is associated with a VLAN. Dedicated servers have both a public and private network connection, so you see those devices associated with both public and private VLANs.\n\n\n\n\n\n How do I trunk my VLANs to my servers? \n\nFor more information about managing VLANs as trunks, see [Configuring VLAN trunks](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-configuring-vlan-trunks&interface=ui).\n\n\n\n\n\n As I order a VLAN, what does it mean when I'm told that no VLANs are available? \n\nIf you are told that no VLANs are available, see [A note about capacity](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-startednote-about-capacity).\n\n\n\n\n\n How long can empty Premium VLANs remain unused on my account? \n\nStarting February 13, 2023, Premium VLANs which are not participating in Layer 2 or Layer 3 networks for 90 days or more are subject to automatic cancellation of billing and reclaim of the VLAN in order to maintain sufficient VLAN capacity for all customers. Any secondary subnets present on the VLAN will be unrouted as part of VLAN reclaim. For more information regarding the automatic reclaim policy of unrouted secondary subnets, see the [Subnets FAQs](https:\/\/cloud.ibm.com\/docs\/subnets?topic=subnets-faqfaq-unrouted-subnets-automatic-reclaim).\n\n\n\n\n\n Why can't my devices communicate with one another on the same private VLAN? \n\nIf each server is on a different subnet, then by default, they are not able to communicate via IP addresses. Technically, your servers can communicate by using OSI Model Layer 2 methods because they are on the same VLAN (a Layer 2 construct). For Internet Protocol (IP) (also called Layer 3) communication to work, you can do either of the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-vlans-faqs"},{"document_id":"ibmcld_07024-2933-4407","score":17.626432,"text":"\n[Transportation dictionary in the product ui](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/dict-transportation.png)\n\nFigure 1. Transportation dictionary\n\nThe resulting facet that is created for the dictionary is displayed in the search page.\n\nZoom\n\n![Search page with Transportation facet](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/dict-facet.png)\n\nFigure 2. Transportation facet\n\nThe document where the enrichment is applied contains the following sentence:\n\nSome car fluids can be acidic, such as battery fluid.\n\nThe following JSON snippet illustrates how a Transportation dictionary enrichment mention is stored when the term car, which is a synonym for the vehicle dictionary entry, is found in the document. In this collection, the dictionary enrichment is applied to the text field, so the mention is listed in the entities array that is in the enriched_text array.\n\n{\n\"enriched_text\": [\n{\n\"entities\":\n{\n\"model_name\": \"Dictionary:.Transportation\",\n\"mentions\":\n{\n\"confidence\": 1,\n\"location\": {\n\"end\": 91122,\n\"begin\": 91119\n},\n\"text\": \"car\"\n}\n],\n\"text\": \"vehicle\",\n\"type\": \"Transportation\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n Uploading dictionary terms \n\nTo add dictionary from a CSV file, complete the following steps:\n\n\n\n1. Create a CSV file that contains the dictionary terms that you want to add.\n\nUse UTF-8 encoding. Specify one entry per line.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-dictionary"},{"document_id":"ibmcld_16359-6868-8948","score":17.343557,"text":"\nAs part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.\n* Enable response modes to modify the assistant's behavior when it asks questions. For more information, see [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\nTo change settings, complete the following steps:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, you can edit the Ask clarifying questions section:\n\n\n\nAsk clarifying question settings\n\n Field Default text Description \n\n Assistant says Did you mean: The text that is displayed before the list of clarification choices. You can change it to something else, such as What do you want to do? or Pick what to do next. \n No action matches None of the above The choice that customers can click when none of the other choices are right. If the customer picks this choice, the assistant uses your No action matches action. You can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_16516-17782-19845","score":16.000702,"text":"\nAdded Performance page\n: Added a Performance page for model quality evaluation and guidance about how to improve quality.\n\n\n\n\n\n\n\n November 2017 \n\n\n\n Changes \n\nBug fixes\n: Fixed an issue where some relation annotations were missing in the downloaded corpus.\n: Fixed an issue where a model could not be withdrawn from deployment if its status was None.\n: Fixed an issue where the model could not be evaluated for Korean.\n\n\n\n\n\n\n\n October 2017 \n\n\n\n Changes \n\nExport issue fixed\n: Fixed the issue with the Export button not being enabled until you refreshed the browser window in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release.\n\nButton label issue fixed\n: Fixed the button labels and tooltips to match the changes for the terms upload and download in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release. These terms are used instead of import and export when referring to type systems, documents, and dictionaries.\n\nDescription delay issue fixed\n: Fixed the delay in updating the descriptions on the Knowledge Studio User Account Management page in the IBM Cloud [experimental](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks-faqsexperimental) release.\n\nUI changes to pre-annotation interface\n: In the pre-annotation section of the interface, made a couple GUI changes to clarify the functionality of the machine learning model, the rule-based model, the dictionary, and IBM\u00ae AlchemyLanguage. Changed the button label from Run to Pre-annotate, changed the title of the window from Run Annotator to Run Pre-annotation, and changed the error message to clarify that you can't add automated annotations after humans annotated the documents.\n\nDictionary-based tokenizer fix\n: For projects or workspaces that use dictionary-based tokenizers, fixed an issue that showed empty sentences if you imported documents without ground truth.\n\n\n\n\n\n\n\n September 2017","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_07578-863555-865379","score":15.906693,"text":"\n* How many devices can be assigned to a single VLAN?\n\nCurrently, no limit exists for the number of devices that are associated with a single VLAN at any time. However, when a hardware firewall is associated with a VLAN, the type of firewall might impose restrictions on the number of devices that reside on the VLAN.\n* What kinds of devices are assigned to a VLAN?\n\nAny device that has a network connection is associated with a VLAN. Dedicated servers have both a public and private network connection, so you see those devices associated with both public and private VLANs.\n* How do I trunk my VLANs to my servers?\n\nFor more information about managing VLANs as trunks, see [Configuring VLAN trunks](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-configuring-vlan-trunks&interface=ui).\n* As I order a VLAN, what does it mean when I'm told that no VLANs are available?\n\nIf you are told that no VLANs are available, see [A note about capacity](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-startednote-about-capacity).\n* How long can empty Premium VLANs remain unused on my account?\n\nStarting February 13, 2023, Premium VLANs which are not participating in Layer 2 or Layer 3 networks for 90 days or more are subject to automatic cancellation of billing and reclaim of the VLAN in order to maintain sufficient VLAN capacity for all customers. Any secondary subnets present on the VLAN will be unrouted as part of VLAN reclaim. For more information regarding the automatic reclaim policy of unrouted secondary subnets, see the [Subnets FAQs](https:\/\/cloud.ibm.com\/docs\/subnets?topic=subnets-faqfaq-unrouted-subnets-automatic-reclaim).\n* Why can't my devices communicate with one another on the same private VLAN?\n\nIf each server is on a different subnet, then by default, they are not able to communicate via IP addresses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-863432-865256","score":15.906693,"text":"\n* How many devices can be assigned to a single VLAN?\n\nCurrently, no limit exists for the number of devices that are associated with a single VLAN at any time. However, when a hardware firewall is associated with a VLAN, the type of firewall might impose restrictions on the number of devices that reside on the VLAN.\n* What kinds of devices are assigned to a VLAN?\n\nAny device that has a network connection is associated with a VLAN. Dedicated servers have both a public and private network connection, so you see those devices associated with both public and private VLANs.\n* How do I trunk my VLANs to my servers?\n\nFor more information about managing VLANs as trunks, see [Configuring VLAN trunks](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-configuring-vlan-trunks&interface=ui).\n* As I order a VLAN, what does it mean when I'm told that no VLANs are available?\n\nIf you are told that no VLANs are available, see [A note about capacity](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-startednote-about-capacity).\n* How long can empty Premium VLANs remain unused on my account?\n\nStarting February 13, 2023, Premium VLANs which are not participating in Layer 2 or Layer 3 networks for 90 days or more are subject to automatic cancellation of billing and reclaim of the VLAN in order to maintain sufficient VLAN capacity for all customers. Any secondary subnets present on the VLAN will be unrouted as part of VLAN reclaim. For more information regarding the automatic reclaim policy of unrouted secondary subnets, see the [Subnets FAQs](https:\/\/cloud.ibm.com\/docs\/subnets?topic=subnets-faqfaq-unrouted-subnets-automatic-reclaim).\n* Why can't my devices communicate with one another on the same private VLAN?\n\nIf each server is on a different subnet, then by default, they are not able to communicate via IP addresses.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13878-1596-3665","score":15.022647,"text":"\nThis can be part of the regular activities of (agile) development and the next steps towards a fully secure app or by increasing requirements for an app already in production.\n\nIf you tried the tutorial on how to [apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security), you already know how to rotate service credentials. But there is far more to app security than regular changes of passwords and access keys. You may want to assess the application, its deployment and usage characteristics to better understand what needs to, could be and should be addressed. It helps you to move towards a [zero trust security model](https:\/\/en.wikipedia.org\/wiki\/Zero_trust_security_model). Moreover, depending on your industry, country and region, etc. there exist different [security and resiliency requirements](https:\/\/www.ibm.com\/cloud\/compliance). It could mean\n\n\n\n* to isolate the application, its services, the network traffic and stored data from those of other applications,\n* to encrypt data and have control over the management of encryption keys,\n* to log all kind of events, regularly analyze logs and keep them for audits or incident forensics,\n* to organize DevOps activities and the related teams with more fine-grained privileges,\n* and much more.\n\n\n\nTo assess your application and its resources, consider the [IBM Cloud\u00ae Security and Compliance Center](https:\/\/www.ibm.com\/cloud\/security-and-compliance-center). It allows to govern resource configurations. You can set up and manage security and compliance controls. Checks can be automated. Results are directly compared against defined controls, can be exported and integrated into a customized dashboard. Read how to [get started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started) for the first steps.\n\n\n\n\n\n Isolate runtime environments, networks traffic and data \n\nOne of the fundamental principles of Cloud Computing is the sharing of resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_04131-4-2061","score":14.7901125,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Configuring alert policies \n\nIBM Cloud\u00ae Internet Services has alerts that you can configure through the API to warn you when events occur.\n\nSee [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks) for detailed instructions on using webhooks.\n\nAlerts are available only to Enterprise plans.\n\n\n\n Types of alerts \n\nCIS offers the following alert types:\n\n\n\n* DDoS attack layer 7 alerts are intended for WAF and CDN customers who want to receive a notification when an attack is mitigated.\n\nNo action is necessary if you receive a DDoS attack layer 7 alert. Each alert includes a short description, the time the attack was detected and mitigated, the attack type, its maximum rate of attack, and the target.\n* Pool toggle alerts notify when the pool is enabled or disabled manually.\n\nNo action is necessary if you receive a pool toggle alert. Each alert includes the state that the pool was toggled to, the time it occurred, and which user made the change.\n* Security alerts include WAF alerts and Advanced WAF alerts.\n\n\n\n* WAF alerts look for spikes across all services that generate log entries in firewall events. The mean time to detection is 2 hours.\n* Advanced WAF alerts. You can select the services to monitor, and each selected service is monitored separately. The mean time to detection is 5 minutes.\n\n\n\n* Certificate alerts include alerts that your Universal SSL and Dedicated\/Advanced certificates need to be renewed.\n\n\n\n* Universal SSL certificates are automatically refreshed and no user action is required.\n* Dedicated\/Advanced receive notification for validation, issuance renewal, and expiration of Dedicated\/Advanced certificates.\n\n\n\n* Load-balancing health check alerts are sent when a change occurs in the health status of a load-balancing health check.\n\n\n\n\n\n\n\n Configuring alert policies by using the console \n\nUse the console to create, update, and delete alerting policies.\n\nTo configure alert policies by using the console, navigate to your Account page and select the Alerts tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09852-23029-24933","score":15.069298,"text":"\n* Message Integrity: Enables authentication of inbound traffic on a per-message basis, as well as strict restrictions on which queues those messages can be sent to and which recipients can receive them.\n* Message Privacy: Based on the protection policy set on the target queue, AMS encrypts the message even before it is placed on the queue, thus ensuring that its contents are never exposed.\n\n\n\nDemonstration of end to end message security involves demonstrating message integrity and message privacy. We start by demonstrating message integrity, where we can see that non-authorized users are not allowed to access the protected queue. We then check if the authorized users, from our example, alice and bob can send and receive messages on protected queue. We conclude by demonstrating that messages while at rest in the protected queue are encrypted and not readable.\n\n\n\n Message Integrity Check \n\nTo demonstrate that message integrity is protected, any attempt to access the protected queue without complying to the signing or encryption policy shall fail. To test this, we run the sender program without setting the environment variable MQS_KEYSTORE_CONF. By doing so, AMS will fail to find the keystore and certificate to use for signing.\nYou can observe that alice is able to establish connection with the queue manager, but an attempt to open the protected queue will fail as this is the point where the AMS interceptor would check the identity for user alice.\n\n\n\n1. Create the following environment variables in alice's command shell.\n\nOn Mac:\nexport MQSAMP_USER_ID=alice\nexport MQSERVER=\"CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\"\n\nOn Linux:\nexport MQSAMP_USER_ID=alice\nexport MQSERVER=\"CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\"\n\nOn Windows:\nset MQSAMP_USER_ID=alice\nset MQSERVER=CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\n\n\n\n* <HOSTNAME> - this is 'hostname' in the file connection_info.txt","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_09852-27859-29335","score":13.101226,"text":"\n[Image showing alice sending message to protected queue](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_app_ams_st_putpq.png)\n4. From bob's command shell, run the sample program to receive the messages.\n\namqsgetc DEV.QUEUE.1 <your Queue manager name>\n\n4.1 Enter the application API key of bob when prompted for a password(This is your '\"apiKey' value in the file \"applicationApiKeybob.json)\n4.2. You can see that received message message <Hello> confirms that bob is able to read the message data.\n![Image showing bob receiving message from protected ueue](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_app_ams_st_getpq.png)\n\n\n\n\n\n\n\n Message Privacy Check - Data stored as encrypted. \n\nTo demonstrate that the messages are encrypted, we test using an alias queue. Retrieving messages via the alias queue will not trigger the interceptors on the target queue, so the message will be retrieved as it is, without decryption, and so will give an accurate view on whether the message is plain text or encrypted. As part of this demonstration, we run the sender program (amqsputc) using the alice's userid to send a message to protected queue. We then run receiver program (amqsgetc) using the bob's userid to receive the message from an alias queue.\n\n\n\n1. Create the following environment variables in alice's command shell.\n\nOn Mac:\nexport MQSAMP_USER_ID=alice","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_09852-22031-23666","score":11.646403,"text":"\nThis section guides you in creating the keystore.conf file for alice and bob.\n\n\n\n1. Create a new file keystore.conf in the .mqs directory for user alice and copy following contents into it.\n\nOn Mac:\n\ncms.keystore=\/alice\/.mqs\/alicekey\ncms.certificate=Alice_Cert\n\nOn Linux:\n\ncms.keystore=\/home\/alice\/.mqs\/alicekey\ncms.certificate=Alice_Cert\n\nOn Windows:\n\ncms.keystore=%HOMEDRIVE%Usersalice.mqsalicekey\ncms.certificate=Alice_Cert\n\n\n\n* Replace %HOMEDRIVE% with the value of it on your computer (for ex: C:)\n\n\n\n2. Create a new file keystore.conf in the .mqs directory of user bob and copy following contents into it.\nOn Mac:\n\ncms.keystore=\/bob\/.mqs\/bobkey\ncms.certificate=Bob_Cert\n\nOn Linux:\n\ncms.keystore=\/home\/bob\/.mqs\/bobkey\ncms.certificate=Bob_Cert\n\nOn Windows:\n\ncms.keystore=%HOMEDRIVE%Usersbob.mqsbobkey\ncms.certificate=Bob_Cert\n\n\n\n* Replace %HOMEDRIVE% with the value of it on your computer (for ex: C:)\n\n\n\n\n\n\n\n\n\n Testing End to End Message Protection \n\nMQ Advanced Message Security provides:\n\n\n\n* Message Integrity: Enables authentication of inbound traffic on a per-message basis, as well as strict restrictions on which queues those messages can be sent to and which recipients can receive them.\n* Message Privacy: Based on the protection policy set on the target queue, AMS encrypts the message even before it is placed on the queue, thus ensuring that its contents are never exposed.\n\n\n\nDemonstration of end to end message security involves demonstrating message integrity and message privacy. We start by demonstrating message integrity, where we can see that non-authorized users are not allowed to access the protected queue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_00478-7-2275","score":11.336583,"text":"\nCompliance \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae provides a trustworthy and secure cloud database system. The service is built on best-in-industry standards, including ISO 27001:2013.\n\n\n\n Tier-1 physical systems \n\nIBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by these providers.\n\n\n\n\n\n General Data Protection Regulation (GDPR) \n\nThe GDPR seeks to create a harmonized data protection law framework across the EU. It also aims to give citizens back the control of their personal data, while it imposes strict rules on those entities who host and \"process\" this data, anywhere in the world. The Regulation also introduces rules that relate to the free movement of personal data within and outside the EU. For more information, see the [IBM privacy statement](https:\/\/www.ibm.com\/privacy\/).\n\n\n\n\n\n HIPAA \n\nIBM Cloudant, when deployed on dedicated hardware on IBM Cloud, meets the required IBM controls that are commensurate with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Security and Privacy Rule requirements. These requirements include the appropriate administrative, physical, and technical safeguards required of Business Associates in 45 CFR Part 160 and Subparts A and C of Part 164. HIPAA must be requested at the time of provisioning and applies to the IBM Cloudant Enterprise plan, IBM Cloudant on IBM Cloud Dedicated plan, and IBM Cloudant Dedicated Hardware plan on IBM Cloud. Contact your sales representative to sign a Business Associate Addendum (BAA) agreement with IBM.\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nIBM Cloudant and IBM Cloudant Dedicated Cluster are audited by a third-party security firm and meet ISO 27001, ISO 27017, and ISO 27018 requirements. For more information, see the [IBM Cloudant Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the IBM Cloudant Compliance page cover the IBM Cloudant service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compliance"},{"document_id":"ibmcld_04689-5555-7946","score":11.132692,"text":"\nA certificate is issued by a certificate authority and is digitally signed by that authority. A certificate is generally issued and signed by a certificate authority. However, for testing and development purposes, you might use a self-signed certificate.\n* Private key: An algorithmic pattern that is used to encrypt messages that only the corresponding public key can decrypt. The private key is also used to decrypt messages that were encrypted by the corresponding public key. The private key is kept on the user system and is protected by a password.\n* Intermediate certificate (optional): A subordinate certificate that is issued by the trusted root certificate authority (CA) specifically to issue end-entity server certificates. The result is a certificate chain that begins at the trusted root CA, passes through the intermediate certificate, and ends with the SSL certificate issued to the organization. Use an intermediate certificate to verify the authenticity of the main certificate. Intermediate certificates are typically obtained from a trusted third party. You might not require an intermediate certificate when you test your app before you deploy it to production.\n* Enable request of client certificate: When you enable this option, a user who tries to access an SSL protected domain is requested to provide a client-side certificate. For example, in a web browser, when a user tries to access an SSL protected domain, the web browser prompts the user to provide a client certificate for the domain.\n* Client certificate truststore (optional): Includes the client certificates for the users who you want to allow access to your app. Upload a client certificate truststore file to enable the option to request a client certificate.\n\n\n\nYou can set up mutual authentication by uploading a client certificate truststore that includes a public key in its metadata.\n\n\n\n\n\n\n\n Importing SSL certificates into IBM Cloud Secrets Manager \n\nYou can apply a security protocol to provide communication privacy for your app to prevent eavesdropping, tampering, and message forgery. If you have a Lite account, you must upgrade your account to upload a certificate.\n\nWhen an expired or expiring certificate must be renewed, and after the new certificate is ready, delete the existing certificate and then add the new one.\n\n\n\n Import your existing credentials into IBM Cloud Secrets Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-ssl_csr"},{"document_id":"ibmcld_14910-7-1976","score":10.970584,"text":"\nConfidential computing with LinuxONE \n\nConfidential computing is enabled on LinuxONE (s390x processor architecture) by using the [IBM Secure Execution for Linux](https:\/\/www.ibm.com\/docs\/en\/linux-on-systems?topic=virtualization-introducing-secure-execution-linux) technology. This technology is part of the hardware of IBM z15 (z15) and IBM LinuxONE III generation systems. With IBM Secure Execution for Linux, you can securely deploy workloads in the cloud. It ensures the integrity and confidentiality of boot images, and server authenticity. Applications are isolated from the operating system, thus providing more privacy and security for the workload.\n\nBy using IBM Secure Execution for Linux, you can create encrypted Linux images that can run on a public, private, or hybrid cloud with their in-use memory protected. The workload or data is protected from external and insider threats.\n\nA new operating system that leverages the IBM Secure Execution for Linux technology is now available as IBM Hyper Protect. The associated image that's used to create the instance is called the [IBM Hyper Protect Container Runtime (HPCR) image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsabout-imageshyper-protect-runtime). A virtual server instance that's provisioned by using this image is called as an IBM Cloud Hyper Protect Virtual Servers for VPC (Virtual Private Cloud) instance.\n\nFor a technical deep dive into the IBM Hyper Protect Platform, see the white paper [The Second Generation of IBM Hyper Protect Platform](https:\/\/www.ibm.com\/downloads\/cas\/GPVMWPM3).\n\nCheck out the [tutorial](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-financial-transaction-confidential-computing-on-hyper-protect-virtual-server-for-vpc) and the [video](https:\/\/mediacenter.ibm.com\/media\/Confidential+Computing+for+a+financial+transaction+using+Hyper+Protect+Virtual+Server+for+VPC\/1_vv3j2oo6) on Confidential Computing for a financial transaction using Hyper Protect Virtual Server for VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-se"},{"document_id":"ibmcld_09852-30990-32361","score":10.885889,"text":"\n[Image showing alice sending message to protectec queue](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_app_ams_st_putpq.png)\n4. From bob's command shell, run the sample program to receive the messages.\n\namqsgetc DEV.QUEUE.1.ALIAS <your Queue manager name>\n\n4.1 Enter the application API key for bob when prompted for a password(This is your '\"apiKey' value in the file \"applicationApiKeybob.json)\n4.2. You can see that the message is received as message <PDMQ> shows data encrypted, thus confirming that message is stored as encrypted and not readable by non-authorized users. ![Image showing bob receiving message from alias queue](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_app_ams_st_getpaq.png)\n\n\n\n\n\n\n\n\n\n\n\n Conclusion \n\nYou have now completed this tutorial. As a part of this guide, you have set up Application AMS for end to end security of messages. We have demonstrated that this ensures message integrity and message privacy are protected and that messages are readable only by authorized users.\n\n\n\n\n\n Appendix \n\n\n\n Appendix 1: connection_info.txt \n\nTo retrieve the connection_info.txt file containing queue manager connection details:\n\n\n\n1. Login to the IBM Cloud service instance by clicking on the relevant service shown in the table\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_09852-31877-33237","score":10.542697,"text":"\nAs a part of this guide, you have set up Application AMS for end to end security of messages. We have demonstrated that this ensures message integrity and message privacy are protected and that messages are readable only by authorized users.\n\n\n\n\n\n Appendix \n\n\n\n Appendix 1: connection_info.txt \n\nTo retrieve the connection_info.txt file containing queue manager connection details:\n\n\n\n1. Login to the IBM Cloud service instance by clicking on the relevant service shown in the table\n![Image showing service instance](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_ams_si.png)\n2. This will open the queue manager view. Select the queue manager you wish to retrieve the connection info from\n![Image showing list of queue managers](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_ams_qmview.png)\n3. Click Connection information\n![Image of queue manager connection information](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/3a120b16db5fdc3e70d071af8a63ce5515c1b096\/mqcloud\/images\/mqoc_ams_connection_info.png)\n4. Download this file in 'JSON text format'\n\n\n\n\n\n\n\n Appendix 2: platformApiKey.json \n\nTo create or reset your administrator api key:\n\n\n\n1. Login to the IBM Cloud service instance by clicking on the relevant service shown in the table\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_09492-15644-17291","score":10.454151,"text":"\nApplication administration, including the logging configuration, are the responsibility of the customer, and it is highly recommended that logging PII\/SPI not be configured unless absolutely required. The following document describes how to configure logs to exclude any data classified as PII or SPI:\n\n[https:\/\/www.ibm.com\/support\/pages\/node\/2801463](https:\/\/www.ibm.com\/support\/pages\/node\/2801463)\n\nIBM Data Security and Privacy Principles for IBM Cloud services can be found at the link below: [https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security)\n\nIBM Privacy Shield Privacy Policy for Certified IBM Cloud Services can be found below. This is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a MAS-Dedicated client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"},{"document_id":"ibmcld_13616-12161-13939","score":10.419266,"text":"\nAny vulnerabilities found by these scans must be resolved before product release or submitted through IBM's Product Security Incident Response Team (PSIRT) process for resolution via defect (IBM Authorized Program Analysis Report or APAR)\n* IBM TRIRIGA development uses Rational Team Concert for development (management of tasks, stories, epics, version control, test management, etc) Selenium and TestNG for test automation, Jenkins for deployment automation, and Rational Performance Tester (RPT) for performance load testing.\n\n\n\n\n\n\n\n Data Security & Privacy (DS&P) \n\n\n\n* IBM Data Security and Privacy Principles for IBM Cloud services can be found at the link below:\n\n\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=data-security)\n\n\n\n* IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services can be found below. This is applicable to EU-US and Swiss-US customers:\n\n\n\n[https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\n\n\n* Data Responsibility at IBM\n\n\n\n[https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\n\n\n* Data Processing Addendum (GDPR)\n\n\n\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10214-7502-9481","score":10.248299,"text":"\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference) or in the following table's links.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_07578-380995-382843","score":10.164977,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-380969-382817","score":10.164977,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01494-6857-8423","score":9.636188,"text":"\n* [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_vperegistry_notices_vpe_know)\n* [How you benefit from this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_vperegistry_notices_vpe_benefit)\n* [Understanding if you are impacted by this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_vperegistry_notices_vpe_impact)\n* [What actions you must take](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_vperegistry_notices_vpe_actions)\n\n\n\n[Changes to private IP addresses from 15 December 2022](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_ip_addressregistry_notices_ip_address)\n\n\n\n* [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_ip_addressregistry_notices_ip_address_know)\n* [What actions you need to take](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_ip_addressregistry_notices_ip_address_actions)\n\n\n\n[Container Registry CLI stops returning security status results in lists by default from version 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_listsregistry_notices_lists)\n\n\n\n* [Action required now](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_listsregistry_notices_lists_action)\n\n\n\n[Container Registry private IP addresses changed on 5 July 2022](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_iam_private_networkregistry_notices_iam_private_network)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_16366-2985-3766","score":9.529713,"text":"\nFor more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_06063-73255-73986","score":9.442528,"text":"\nKubernetes security bulletins that affect IBM Cloud Kubernetes Service users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https:\/\/cloud.ibm.com\/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a Kubernetes version that you can install as part of the regular [cluster update process](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) in IBM Cloud Kubernetes Service. Make sure to apply security patches in time to protect your cluster from malicious attacks. For more information about what is included in a security patch, refer to the [version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05777-10230-11885","score":9.43144,"text":"\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_11710-7-2152","score":9.416534,"text":"\nSecurity and compliance \n\nYou can use built-in security features in IBM Cloud Satellite\u00ae for risk analysis and security protection. These features help you to protect your Satellite workloads that run on your location infrastructure and network communication.\n\n\n\n Data security \n\nLearn more about options to secure the data that you use for workloads in IBM Cloud Satellite.\n\n\n\n What data is stored when I use Satellite? How can I use my own keys to encrypt my data? \n\nSee [Securing your data in IBM Cloud Satellite](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-data-security).\n\n\n\n\n\n How do I make my data secure over Satellite Link? \n\nYour Satellite location infrastructure is a part of your local network (on-prem hosts) or the network of your cloud provider, but is managed remotely by using secure Satellite Link access from IBM Cloud. All communication over Satellite Link is encrypted by IBM. When you create an endpoint, you can optionally specify an additional data encryption protocol for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify your own additional TLS encryption for the connection that goes over the internet.\n\nTo review information about how Satellite Link handles each type of connection protocol, see [Encryption protocols](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloudlink-protocols). To review other frequently asked questions about Satellite Link network security, see [External network requirements and security](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloudlink-security).\n\n\n\n\n\n What measures can I take to secure user access to data in my location? \n\nReview the following ways that you can secure access to your location.\n\n\n\n* Consider the types of [user access to resources that run in your Satellite location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-service-connectionuser-access)\n* [Manage access for Satellite by using IBM Cloud Identity and Access Management (IAM)](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-compliance"},{"document_id":"ibmcld_07597-0-1885","score":9.353534,"text":"\n\n\n\n\n\n\n  FAQs for FortiGate Security Appliance 10 Gbps \n\nThe following are some frequently asked questions you may have about working with the FortiGate Security Appliance 10 Gbps firewall.\n\n\n\n  What is the difference between FortiGate Security Appliance (FSA) 10 Gbps and FSA 1 Gbps? What about Virtual Router Appliance? \n\nFSA 10 Gbps provides faster throughput compared to FSA 1 Gbps. It allows the customer to protect multiple VLANs (both private and public). More add-ons such as Anti-Virus (AV), Intrusion Prevention (IPS), and web filtering can be enabled on demand.\n\nVirtual Router Appliance also protects multiple VLANs. However, Virtual Router Appliance does not provide next-generation firewall add-ons and purpose-built security processors.\n\n\n\n\n\n  Can FSA 10G and a network gateway be associated with the same VLAN? \n\nNo, it is not possible to have an FSA 10G and a network gateway device to be associated with the same customer VLAN.\n\n\n\n\n\n  Does this offering charge for private network connectivity? \n\nIBM offers private connectivity free of charge, which is one of the key differentiators in the marketplace.\n\n\n\n\n\n  Is FSA 1 Gbps also a multi-VLAN offering? \n\nNo, only FSA 10 Gbps supports multiple VLANs.\n\n\n\n\n\n  Is FSA 10 Gbps available in Federal data centers? \n\nFSA 10 Gbps is not currently available in Federal data centers.\n\n\n\n\n\n  Can an FSA 10 Gbps be used in place of a Virtual Router Appliance? \n\nYes.\n\n\n\n\n\n  Do you plan to upgrade FSA 1G with the same capability of the FSA 10G appliance? \n\nNot currently.\n\n\n\n\n\n  Can the FSA 10 Gbps span over multiple pods in a data center? \n\nNot currently. FSA 10 Gbps is only able to protect VLANs for the pod it is deployed in.\n\n\n\n\n\n  What are the default DNS servers of FortiGate 10 Gbps? \n\nBy default, FortiGate uses the following FortiGuard's DNS servers.\n\n\n\n*  Primary: 208.91.112.53\n*  Secondary: 208.91.112.52\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/fortigate-10g?topic=fortigate-10g-faqs-for-fortigate-security-appliance-10gbps"},{"document_id":"ibmcld_06027-1539-3662","score":9.346355,"text":"\nFor more information about pod security profiles, see [Profile details](https:\/\/kubernetes.io\/docs\/concepts\/security\/pod-security-standards\/) in the Kubernetes documentation.\n\nPod Security Admission contains three modes that define what action the control plane takes if a potential violation is detected.\n\nenforce\n: Policy violations cause the pod to be rejected.\n\naudit\n: Policy violations trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed.\n\nwarn\n: Policy violations trigger a user-facing warning, but are otherwise allowed.\n\nAs security standards or profiles implementations change to address new features, you can configure Pod Security Admission to use a specific version of the roles. The following versions are supported.\n\n\n\n* A Kubernetes major.minor version (for example, v1.25)\n* latest\n\n\n\n\n\n\n\n What if Pod Security Admission isn't the right choice for me? \n\nWhile Pod Security Admission is always enabled, it can be one of multiple admission controllers. You can configure third-party Kubernetes admission controllers to implement other security policy models that suit your use case.\n\nIf you configure Pod Security Admission to enforce, warn, and audit by using the privileged profile, then the control plane allows all pods to run. You can then configure other admission controllers to reject them.\n\nYou can install a third-party admission controller as long as it doesn't take either of the following actions.\n\n\n\n* It doesn't install its own pod security policies (PSPs).\n* It doesn't rely on PSPs to enforce parts of the policy.\n\n\n\n\n\n\n\n Configuring Pod Security admission namespace labels \n\nYou can define the admission control mode you want to use for pod security in each namespace. Kubernetes defines a set of labels that you can set to define which of the predefined Pod Security Standard profiles you want to use for a namespace. The label you select defines what action the control plane takes if a potential violation is detected.\n\nBy default, IBM Cloud Kubernetes Service adds the privileged Pod Security labels to the following namespaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13915-6476-8449","score":18.697546,"text":"\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_07578-842782-844922","score":17.062132,"text":"\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-842655-844795","score":17.062132,"text":"\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04226-1709-3348","score":16.741213,"text":"\nFor example, bypass the WAF for a specific URL and a specific IP address or user agent.\n* Disable WAF for traffic to a URL (not recommended). Disabling WAF using page rules lowers security on the particular URL endpoint.\n\n\n\nIf you contact IBM Support to verify whether a WAF rule triggers as expected, provide a HAR file captured while sending the specific request of concern.\n\nIf one specific rule causes false positives, set rule\u2019s Mode to Disable rather than turning Off the entire rule group. For false positives with the administrator content on your website, create a page rule to disable security for the admin section of your site resources, for example, yoursite.com\/admin.\n\n\n\n\n\n Troubleshooting WAF false negatives \n\n How to fix it \n\nTo identify false negatives, review the HTTP logs on your origin web server.\n\nTo reduce false negatives, use the following checklist:\n\n\n\n* Is Web Application Firewall On in the Firewall app under Managed Rules?\n* Is Web Application Firewall Off using page rules?\n* Not all WAF rules are enabled by default, so review individual WAF rule default actions. For example, CIS allows requests with empty user agents by default.\n\n\n\nTo block requests with an empty user agent, change the WAF rule Mode to Block.\n\n\n\n* Are DNS records that serve HTTP traffic proxied through CIS?\n* Does a firewall rule bypass CIS managed rules?\n* Does an allowed country, ASN, IP range, or IP in IP access rules or firewall rules match the attack traffic?\n* Is the malicious traffic directed at your origin IP addresses to bypass CIS protection? Block all traffic except from CIS's IP addresses at your origin web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-false-pos-neg"},{"document_id":"ibmcld_14705-2946-4892","score":16.692799,"text":"\n* A new T1 named Isolated-NW-T1 and links it to the workload T0. Isolated-NW-T1 is configured to advertise only all NAT IP addresses. This action stops the advertisement of connected segments and advertises only the NAT IP addresses of the segments.\n* The following distributed firewall groups.\n\n\n\n* Name Cyber-Tools-Segments, Category Segments, Members Cybertools\n* Name Cyber-Isolated-Segments, Criteria Segment Tag Equals Isolated-Segments, Scope Cyber\n\n\n\n* A distributed firewall policy that is named Cyber-Isolated, which contains the following rules to satisfy their isolation requirements:\n\n\n\n\n\nTable 1. NSX-T distributed firewall rules\n\n Rule Name Sources Destinations Services Action \n\n Allow access to Isolated Cyber-Tools-Segments Cyber-Isolated-Segments All Allow \n Allow access between Isolated Cyber-Isolated-Segments Cyber-Isolated-Segments All Allow \n Deny access to Isolated Any Cyber-Isolated-Segments All Deny \n Deny access from Isolated Any Cyber-Isolated-Segments All Deny \n\n\n\nWhen a sandbox is required, the customer uses their preferred scripting tool to automatically:\n\n\n\n* Create logical segments connected to Isolated-NW-T1 by using the IP address of the default gateway of that network on the T1. In the following diagram, you can see two Isolated-NW2 and Isolated-NW3 segments with subnets that match NW2 and NW3. These segments are created with Tags and Scopes, such as Scope Cyber and Tag Isolated-Segments. These tags and scope are used in the distributed firewall groups and rules that are listed in the previous table.\n* Create destination NAT rules that map destination subnets to translated subnets for IP packets with a source address from the cybertools segment. For example, Src=172.16.67.2->Dst=172.16.68.2 => Src=172.16.67.2->Dst=172.16.253.2.\n\n\n\nThe required traffic flow is shown in the following diagram where:\n\n\n\n* Green designates allowed traffic flow.\n* Red designates denied traffic flow.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib-nw"},{"document_id":"ibmcld_08152-3492-5681","score":16.575909,"text":"\nWill the Hardware Firewall protect the Virtual Machines running on my hypervisor? \n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n\n\n\n\n\n What are the grayed out ports in my Windows Firewall? \n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n\n\n\n\n\n What Hardware Firewall options are available for 10Gbps servers? \n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n\n\n\n\n\n What IP ranges do I allow through the firewall? \n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n\n\n\n\n\n What VPN options are included with each firewall product? \n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:\n\n\n\n* Each customer receives unlimited SSL VPN connections to our private network. These connections can be established by clicking the VPN link at the top of the page while logged into the IBM Cloud console.\n* IBM Cloud also offers a basic multi-tenant IPsecVPN service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-faqs-for-hardware-firewall-shared-"},{"document_id":"ibmcld_05149-1374-3479","score":16.573595,"text":"\nYou can learn more about how context-based restrictions work in the [detailed documentation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-create&interface=ui), or you can follow a [quick tutorial](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cos-tutorial-cbr).\n\nAny Activity Tracker or audit log events generated will come from the context-based restrictions service, and not Object Storage.\n\nIf no rules are applicable to a particular resource, access is determined by IAM policies and the presence of a legacy bucket firewall.\n\nAn account is limited in the [number of rules and network zones that can be supported](https:\/\/cloud.ibm.com\/docs\/account?topic=account-known-issuescontext-based-restrictions-limits).\n\n\n\n\n\n Bucket firewalls versus context-based restrictions \n\nPrior to the availability of context-based restrictions, Object Storage itself would enforce access restrictions based on IP addresses. While this method is still supported, it is recommended to [use the newer context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-create&interface=ui) instead of the legacy bucket firewall.\n\nBucket firewalls and context-based restrictions operate independently of one another, which means it's possible to have a request permitted by one and denied by the other.\n\n\n\n* Bucket creation requests must be permitted by any context-based restrictions.\n* For all other bucket or object requests, both the context-based restrictions and the bucket firewall must allow the request.\n\n\n\nAn IP address that is allowed by context-based restrictions can still be denied by the bucket firewall.\n\n\n\n About legacy bucket firewalls \n\nThere are some rules around setting a firewall:\n\n\n\n* A user that sets or views a firewall must have the Manager role on the bucket.\n* A user with the Manager role on the bucket can view and edit the list of allowed IP addresses from any IP address to prevent accidental lockouts.\n* The Object Storage Console can still access the bucket, provided the user's IP address is authorized.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"},{"document_id":"ibmcld_15726-1497-3465","score":16.179396,"text":"\nNo. The network load balancer does not support layer 7 switching.\n\n\n\n\n\n What's the maximum number of front-end listeners I can define with my load balancer? \n\nYou can define a maximum of ten front-end listeners for an NLB.\n\n\n\n\n\n What's the maximum number of virtual server instances I can attach to my back-end pool? \n\nYou can attach a maximum of 50 virtual server instances to your back-end pool for a network load balancer.\n\n\n\n\n\n Is an NLB horizontally scalable? \n\nNo. A network load balancer is not horizontally scalable.\n\n\n\n\n\n What should I do if I'm using ACLs on the subnets that are used to deploy an NLB? \n\nMake sure that the proper ACL rules are in place to allow incoming traffic for configured listener ports and traffic between a network load balancer and back-end instances should also be allowed.\n\n\n\n\n\n What are the default settings and allowed values for health check parameters? \n\nThe following default settings apply to network load balancer health check parameters:\n\n\n\n* Health check interval: Five seconds, and the range is 2 - 60 seconds.\n* Health check response timeout: Two seconds, and the range is 1 - 59 seconds.\n* Maximum retry attempts: Two retry attempts, and the range is 1-10 retries.\n\n\n\nThe health check response timeout value must be less than the health check interval value.\n\n\n\n\n\n Is the network load balancer IP address fixed? \n\nThe IP address is fixed for both public and private network load balancers. However, route mode NLBs toggle between primary and standby appliance IPs throughput their lifetime.\n\n\n\n\n\n Does IBM complete quarterly ASV scans of data-plane LBaaS appliances? \n\nApproved Scanning Vendor (ASV) quarterly scanning is a requirement of the Payment Card Industry (PCI) Security Standards Council. ASV scanning of LBaaS data-plane appliances is solely a customer responsibility. IBM does not use ASVs to scan data-plane appliances because these scans can negatively impact customer workload functions and performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb-faqs"},{"document_id":"ibmcld_04334-72037-73413","score":16.168947,"text":"\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet firewall rule details.\n\nibmcloud cis firewall dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_15851-1530-3633","score":16.066832,"text":"\nEach ACL consists of rules, based on a source IP, source port, destination IP, destination port, and protocol.\n\nEvery VPC has a default ACL that allows all inbound and outbound traffic. You can edit the default ACL rules, or create a custom ACL and attach it to your subnets. A subnet can only have one ACL attached to it at any time, but one ACL can be attached to multiple subnets. For more information about how to use ACLs, see [Setting up network ACLs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls).\n\n\n\n\n\n Security groups \n\nA security group acts as a virtual firewall that controls the traffic for one or more virtual server instances. A security group is a collection of rules that specify whether to allow or deny traffic for an associated instance. You can associate an instance with one or more security groups and edit the security group rules. For more information, see [Using security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups).\n\n\n\n\n\n Comparing security groups and access control lists \n\nTable 1 summarizes some key differences between security groups and ACLs.\n\n\n\nTable 1. Differences between security groups and ACLs\n\n Security Groups ACLs \n\n Control level Virtual server instance Subnet \n State Stateful - When an inbound connection is permitted, it is allowed to reply Stateless - Both inbound and outbound connections must be explicitly allowed \n Supported rules Uses allow rules only Uses allow and deny rules \n How rules are applied All rules are considered Rules are processed in sequence \n Relationship to the associated resource An instance can be associated with multiple security groups Multiple subnets can be associated with the same ACL \n\n\n\n\n\n\n\n End-to-end encryption \n\nAlthough IBM Cloud VPC doesn't provide end-to-end encryption, it allows for it. For example, if you have a secure endpoint on a virtual server instance (such as an HTTPS server on port 443), you can attach a floating IP to that instance, and then your connection is end-to-end encrypted from the client to the server on port 443. Nothing in the path forces a decryption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12330-7-2140","score":26.379637,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10817-4371-5701","score":25.715979,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":22.741846,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-7-1802","score":22.502121,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":21.614279,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_12330-1723-4013","score":21.13858,"text":"\nAsynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service. In particular, the SDK should supply the SDK name and version in the User-Agent header of each API request, along with supporting information such as language version, OS name and version, etc. whenever such information is readily available.\n\n\n\n\n\n Parameter validation \n\nThe SDK MUST perform basic validation of method parameters and return errors\/exceptions before invoking the underlying API. For example, the SDK should ensure all required parameters have been supplied before invoking the API.\n\nHowever, validation of specific enum values SHOULD NOT be performed in the SDK, since this would preclude the SDK from being used with a later version of the service that supports new enum values for a parameter.\n\n\n\n\n\n Default values \n\nThe SDK SHOULD NOT supply default values for any parameter not supplied by the caller, even if a default value is clearly specified in the API documentation. Rather, the assignment of the default should be delegated to the service, so that the service can alter the default value when appropriate without impacting the SDK.\n\n\n\n\n\n Serialization and deserialization \n\nThe SDK MUST silently ignore additional properties in response payloads, to allow the SDK to work with newer versions of the service.\n\nThe SDK SHOULD silently ignore additional properties in dictionary- or map-type parameters. This is to allow values that may have been returned from a newer version of the service to be supplied on subsequent method invocations.\n\n\n\n\n\n Retry \n\nThe SDK MAY provide an automated retry mechanism provided that the user can specify:\n\n\n\n* The maximum number of retry attempts, including zero.\n* The minimum and maximum time interval between retry attempts.\n* The HTTP status codes or error classes that should be retried.\n\n\n\nThe retry mechanism should respect a \"retry-after\" response header if one is returned from the service.\n\n\n\n\n\n Logging","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_02698-7-1759","score":21.086628,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_10852-44214-45420","score":21.070156,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12335-0-917","score":20.589218,"text":"\n\n\n\n\n\n\n  Errors \n\n\n\n  Error delivery \n\nSDK methods MUST surface errors to the caller in the manner that is idiomatic for the particular language. For example, a Go SDK should return an error value from the method, but a Java SDK should raise an Exception.\n\n\n\n\n\n  Error content \n\nWhen an SDK method encounters an error, it MUST capture all relevant information about the error and return it in the error structure that is returned to the caller. Relevant information includes the entire contents of the error response and all response headers. The SDK documentation MUST clearly describe how this information is returned and how it can be accessed by the calling program.\n\nErrors that are generated within the SDK MUST give a clear and specific description of the problem. For example, if a method parameter failed a validation, the message should state which parameter is invalid and the reason it is invalid.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-errors"},{"document_id":"ibmcld_10817-5370-6915","score":20.412188,"text":"\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {\ntry whisk.fireTrigger(name: \"locationChanged\", package: \"mypackage\", namespace: \"mynamespace\", parameters: locationParams, callback: {(reply, error) -> Void in\nif let error = error {\nprint(\"Error firing trigger (error.localizedDescription)\")\n} else {\nprint(\"Trigger fired!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nIn the previous example, you are firing a trigger that is called locationChanged.\n\n\n\n\n\n Use mobile SDK actions that return a result \n\nIf the action returns a result, set hasResult to true in the invokeAction call. The result of the action is returned in the reply dictionary, for example:\n\ndo {\ntry whisk.invokeAction(name: \"actionWithResult\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: true, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":38.56181,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":34.397476,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":32.027603,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":29.145374,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":27.03316,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_05088-31320-33239","score":21.35421,"text":"\nDirectory download in progress: 5632 bytes transferred\nDirectory download in progress: 1047552 bytes transferred\n...\nDirectory download in progress: 53295130 bytes transferred\nDirectory download in progress: 62106855 bytes transferred\nDownload complete!\n\n\n\n\n\n Pause\/Resume\/Cancel \n\nThe SDK provides the ability to manage the progress of file\/directory transfers through the following methods of the AsperaTransferFuture object:\n\n\n\n* pause()\n* resume()\n* cancel()\n\n\n\nThere are no side-effects from calling either of the methods outlined above. Proper clean up and housekeeping is handled by the SDK.\n\n Create Transfer manager\nbucket_name = \"<bucket-name>\"\nlocal_download_directory = \"<absolute-path-to-directory>\"\nremote_directory = \"<object prefix>\"\n\nwith AsperaTransferManager(client) as transfer_manager:\n\n download a directory with Aspera\nfuture = transfer_manager.download_directory(bucket_name, remote_directory, local_download_directory, None, None)\n\n pause the transfer\nfuture.pause()\n\n resume the transfer\nfuture.resume()\n\n cancel the transfer\nfuture.cancel()\nShow more\n\n\n\n\n\n Troubleshooting Aspera Issues \n\nIssue: Developers using any version of Python besides 3.6 may experience failures when installing or using Aspera SDK.\n\nCause: If there are different versions of Python installed on your environment, then you might encounter installation failures when you try to install the Aspera SDK. This can be caused by a missing DLL files or wrong DLL in path.\n\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_10852-44214-45420","score":21.038727,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-45155-46272","score":19.797781,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":19.541277,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07578-504795-506943","score":19.453768,"text":"\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID. This task is most easily accomplished by programming your app or microservice to send the Entity ID by using the App Configuration SDK.\n\nAPI Call - An API call is the invocation of the App Configuration through a programmable interface.\n\nExactly what constitutes an API call varies depending on the entity type (for example, a microservice or a mobile app). For server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.8529278651,"ndcg_cut_10":0.8529278651}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":43.0139,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":34.865192,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":33.399017,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":33.312973,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":27.346514,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-45155-46272","score":22.161926,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":22.037504,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_05088-31320-33239","score":21.104452,"text":"\nDirectory download in progress: 5632 bytes transferred\nDirectory download in progress: 1047552 bytes transferred\n...\nDirectory download in progress: 53295130 bytes transferred\nDirectory download in progress: 62106855 bytes transferred\nDownload complete!\n\n\n\n\n\n Pause\/Resume\/Cancel \n\nThe SDK provides the ability to manage the progress of file\/directory transfers through the following methods of the AsperaTransferFuture object:\n\n\n\n* pause()\n* resume()\n* cancel()\n\n\n\nThere are no side-effects from calling either of the methods outlined above. Proper clean up and housekeeping is handled by the SDK.\n\n Create Transfer manager\nbucket_name = \"<bucket-name>\"\nlocal_download_directory = \"<absolute-path-to-directory>\"\nremote_directory = \"<object prefix>\"\n\nwith AsperaTransferManager(client) as transfer_manager:\n\n download a directory with Aspera\nfuture = transfer_manager.download_directory(bucket_name, remote_directory, local_download_directory, None, None)\n\n pause the transfer\nfuture.pause()\n\n resume the transfer\nfuture.resume()\n\n cancel the transfer\nfuture.cancel()\nShow more\n\n\n\n\n\n Troubleshooting Aspera Issues \n\nIssue: Developers using any version of Python besides 3.6 may experience failures when installing or using Aspera SDK.\n\nCause: If there are different versions of Python installed on your environment, then you might encounter installation failures when you try to install the Aspera SDK. This can be caused by a missing DLL files or wrong DLL in path.\n\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_10817-2884-4620","score":20.782145,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":20.309668,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.8854598816,"ndcg_cut_10":0.8854598816}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":20.33454,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":17.58172,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":15.221954,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":15.050215,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":14.256535,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":14.173355,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":10.301189,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":8.919115,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07578-969419-971359","score":8.781678,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n* Can I map IBM Cloud services to a VPE from the service catalog?\n\nIBM Cloud services cannot be mapped to a VPE from the service catalog during the time of purchase.\n* Can I map an IBM Cloud service to a Public endpoint?\n\nPublic endpoints of IBM Cloud services are not eligible for VPE. VPE can be mapped only to a private endpoint of IBM Cloud services.\n* Is a VPE created in high-availability mode?\n\nA VPE is not created in high-availability (HA) mode, by default. HA comes primarily from the IBM Cloud service.\n* Can I access an IBM Cloud service by using a private service endpoint IP address?\n\nWhen an IBM Cloud service is created, IBM Cloud DNS Services are automatically set up to resolve the IBM Cloud service FQDN to the IBM Cloud private service address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-969295-971235","score":8.781678,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n* Can I map IBM Cloud services to a VPE from the service catalog?\n\nIBM Cloud services cannot be mapped to a VPE from the service catalog during the time of purchase.\n* Can I map an IBM Cloud service to a Public endpoint?\n\nPublic endpoints of IBM Cloud services are not eligible for VPE. VPE can be mapped only to a private endpoint of IBM Cloud services.\n* Is a VPE created in high-availability mode?\n\nA VPE is not created in high-availability (HA) mode, by default. HA comes primarily from the IBM Cloud service.\n* Can I access an IBM Cloud service by using a private service endpoint IP address?\n\nWhen an IBM Cloud service is created, IBM Cloud DNS Services are automatically set up to resolve the IBM Cloud service FQDN to the IBM Cloud private service address.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.8385465275}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-43319-44485","score":34.679707,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":34.188095,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":34.04941,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":31.62755,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":28.984007,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":28.268375,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":24.99646,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-15747-17355","score":24.509182,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-14062-16080","score":22.705145,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_02772-2964-4516","score":19.877337,"text":"\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https:\/\/jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.618288502,"ndcg_cut_10":0.618288502}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11192-0-1195","score":20.601452,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_07578-1335909-1337781","score":19.04981,"text":"\n* How can I archive and restore objects in Object Storage?\n\nArchived objects must be restored before you can access them. While restoring, specify the time limit the objects should remain available before being re-archived. For details, see [archive-restore data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive).\n* Can I enable Object Storage replication between two different regions for DR purposes?\n\nYes, it is possible to configure buckets for automated [replication of objects to a destination bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-replication-overview).\n* How can I track events in Object Storage?\n\nThe Object Storage Activity Tracker service records user-initiated activities that change the state of a service in Object Storage. For details, see [IBM Cloud Activity Tracker](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-at-events).\n* How can I setup notifications when objects are updated or written to a bucket?\n\nUse [Cloud Functions for object storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-functions) to setup an Event Source (notification).\n* Does Object Storage have rate limits when writing to or reading from buckets?\n\nYes, Object Storage has rate limiting. For details, see [COS support](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n* Is Object Storage HIPAA compliant to host PHI data?\n\nYes, Object Storage is HIPAA compliant.\n* Is there any option in Object Storage to enable accelerate data transfer?\n\nObject Storage offers [Aspera](https:\/\/www.ibm.com\/cloud\/object-storage\/aspera) service for high speed data transfer.\n* How can I compare various attributes of an object in two different buckets?\n\nUse [Rclone](https:\/\/rclone.org\/commands\/rclone_check). It enables you to compare various attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1338574-1340446","score":19.04981,"text":"\n* How can I archive and restore objects in Object Storage?\n\nArchived objects must be restored before you can access them. While restoring, specify the time limit the objects should remain available before being re-archived. For details, see [archive-restore data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive).\n* Can I enable Object Storage replication between two different regions for DR purposes?\n\nYes, it is possible to configure buckets for automated [replication of objects to a destination bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-replication-overview).\n* How can I track events in Object Storage?\n\nThe Object Storage Activity Tracker service records user-initiated activities that change the state of a service in Object Storage. For details, see [IBM Cloud Activity Tracker](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-at-events).\n* How can I setup notifications when objects are updated or written to a bucket?\n\nUse [Cloud Functions for object storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-functions) to setup an Event Source (notification).\n* Does Object Storage have rate limits when writing to or reading from buckets?\n\nYes, Object Storage has rate limiting. For details, see [COS support](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n* Is Object Storage HIPAA compliant to host PHI data?\n\nYes, Object Storage is HIPAA compliant.\n* Is there any option in Object Storage to enable accelerate data transfer?\n\nObject Storage offers [Aspera](https:\/\/www.ibm.com\/cloud\/object-storage\/aspera) service for high speed data transfer.\n* How can I compare various attributes of an object in two different buckets?\n\nUse [Rclone](https:\/\/rclone.org\/commands\/rclone_check). It enables you to compare various attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10510-47356-49157","score":18.41682,"text":"\nTo access the logs of your cluster components, set up [IBM Log Analysis](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-healthopenshift_logging). IBM Log Analysis provides access to all your logs and you can aggregate logs and build your own customized views across multiple clusters.\n\nHow can I monitor the health and performance of my cluster?\n: You can verify the health, capacity, and performance of your apps, services, and worker nodes by monitoring your cluster components and compute resources from the Red Hat OpenShift on IBM Cloud console or CLI, such as the CPU and memory usage. To view more in-depth metrics for your cluster, you can use the built-in monitoring capabilities that are based on open source technologies, such as [Prometheus and Grafana](http:\/\/docs.openshift.com\/container-platform\/4.11\/monitoring\/monitoring-overview.html). Prometheus is automatically installed when you create the cluster and you can use the tool to access real-time cluster and app metrics. Prometheus metrics are not stored persistently. To access historic metrics and to compare metrics across multiple clusters, use [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor) instead.\n\nTo set up a host-based intrusion detection system (HIDS) and security event log monitoring (SELM), install third-party tools that are designed to monitor your cluster and containerized apps to detect intrusion or misuse, such as [Twistlock](https:\/\/www.paloaltonetworks.com\/prisma\/cloud) or the [Sysdig Falco project](https:\/\/sysdig.com\/opensource\/falco\/).\n\nHow can I audit events that happen in my cluster?\n: You can [set up IBM Cloud\u00ae Activity Tracker in your Red Hat OpenShift on IBM Cloud cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-at_eventsat_events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_09557-3599-4590","score":17.609892,"text":"\nOpen a [support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add) with details if you have time periods longer than a minute with no connectivity so we can investigate.\n\nIf you have deployments in more than one region, you must provision IBM Cloud\u00ae Monitoring and enable platform metrics in each region. For more information, see IBM Cloud Monitoringyour Cloud Databases deployment's IBM Cloud Monitoring page\n\n\n\n\n\n SLAs \n\nSee [How do I ensure zero downtime?](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimezero-downtime) to learn more about the high availability and disaster recovery standards in IBM Cloud.\n\nAll IBM Cloud\u00ae Databases general availability (GA) offerings conform to the IBM Cloud\u00ae [Service Level Agreement](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) (SLA) terms.\n\nFor more information, see the [Responsibilities for Cloud Databases](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-responsibilities-cloud-databases) page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-ha-dr"},{"document_id":"ibmcld_05010-11625-13519","score":17.397799,"text":"\nYes, it is possible to configure buckets for automated [replication of objects to a destination bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-replication-overview).\n\n\n\n\n\n How can I track events in Object Storage? \n\nThe Object Storage Activity Tracker service records user-initiated activities that change the state of a service in Object Storage. For details, see [IBM Cloud Activity Tracker](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-at-events).\n\n\n\n\n\n How can I setup notifications when objects are updated or written to a bucket? \n\nUse [Cloud Functions for object storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-functions) to setup an Event Source (notification).\n\n\n\n\n\n Does Object Storage have rate limits when writing to or reading from buckets? \n\nYes, Object Storage has rate limiting. For details, see [COS support](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n\n\n\n\n\n Is Object Storage HIPAA compliant to host PHI data? \n\nYes, Object Storage is HIPAA compliant.\n\n\n\n\n\n Is there any option in Object Storage to enable accelerate data transfer? \n\nObject Storage offers [Aspera](https:\/\/www.ibm.com\/cloud\/object-storage\/aspera) service for high speed data transfer.\n\n\n\n\n\n How can I compare various attributes of an object in two different buckets? \n\nUse [Rclone](https:\/\/rclone.org\/commands\/rclone_check). It enables you to compare various attributes.\n\n\n\n\n\n What is the default retention period for buckets? \n\nThere is no default retention period applied. You can set it while creating the bucket.\n\n\n\n\n\n Can we add a retention policy to an existing bucket? \n\nYes, [Retention policies](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-sdk-add-policy) can be added to an existing bucket; however, the retention period can only be extended.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_05444-96814-98116","score":17.087305,"text":"\n* [How Functions compare to apps and jobs](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-compare-app-job)\n* [Migrating IBM Cloud Functions Actions to Code Engine Functions FAQ](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faqs)\n\n\n\n* [How can I process a bulk-load of computations?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq1)\n* [I used Cloud Function to include dynamic elements for my web application. Can I move to Code Engine Functions?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq2)\n* [Can I trigger my function code?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq3)\n* [Can my function be accessed through a public URL?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq4)\n* [How can I secure my functions?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq5)\n* [Can I include dynamic elements?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq6)\n* [Can I use sequences to chain my functions together?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-migratefun-migrate-faq7)\n* [Can I use whisk.system actions?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-sitemap"},{"document_id":"ibmcld_05881-1520-2832","score":16.711699,"text":"\nTo verify that the ibm-cloud-provider-ip and istio-ingressgateway pods don't exist in the same zone:\n\n\n\n1. Identify the NODE that your istio-ingressgateway pod is deployed to.\n\nkubectl get pod -n istio-system -o wide\n2. Get the EXTERNAL-IP address for the gateway's load balancer service.\n\nkubectl get service -n istio-system\n3. Identify the NODE that the ibm-cloud-provider-ip pod for the load balancer is deployed to. Replace <IP-with-hyphens> with the IP address that you found in the previous step. In the IP address, use hyphens (-) instead of periods (.). For example, 169.12.345.67 becomes 169-12-345-67.\n\nkubectl get pod -n ibm-system -o wide -l ibm-cloud-provider-ip=<IP-with-hyphens>\n4. List the zones that the worker nodes are in. Compare the worker nodes that you found in step 1 and 3 to determine whether the pods are deployed to worker nodes in different zones.\n\nkubectl get node --no-headers -L ibm-cloud.kubernetes.io\/zone\n\nExample output\n\n10.176.48.106 Ready <none> 529d v1.26+IKS dal10\n10.176.48.107 Ready <none> 196d v1.26+IKS dal10\n10.184.58.23 Ready <none> 2y38d v1.26+IKS dal12\n10.184.58.42 Ready <none> 529d v1.26+IKS dal12\n\n\n\n How to fix it \n\nTo resolve this issue, you can either move the istio-ingressgateway pod to the zone that the ibm-cloud-provider-ip pod exists in, or vice versa.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio_gateway_affinity"},{"document_id":"ibmcld_07578-1337406-1339258","score":16.55966,"text":"\n* Is there any option in Object Storage to enable accelerate data transfer?\n\nObject Storage offers [Aspera](https:\/\/www.ibm.com\/cloud\/object-storage\/aspera) service for high speed data transfer.\n* How can I compare various attributes of an object in two different buckets?\n\nUse [Rclone](https:\/\/rclone.org\/commands\/rclone_check). It enables you to compare various attributes.\n* What is the default retention period for buckets?\n\nThere is no default retention period applied. You can set it while creating the bucket.\n* Can we add a retention policy to an existing bucket?\n\nYes, [Retention policies](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-sdk-add-policy) can be added to an existing bucket; however, the retention period can only be extended. It cannot be decreased from the currently configured value.\n* Why is there a \"legal hold\" concept on top of the \"retention period\"?\n\nA legal hold prevents an object from being overwritten or deleted. However, a legal hold does not have to be associated with a retention period and remains in effect until the legal hold is removed. For details, see [Legal hold and retention period](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-hold).\n* How can I access a private COS endpoint in a data center from another date center?\n\nUse Object Storage [Direct Link Connection](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storage) to create a global direct link.\n* How does frequency of data access impact the pricing of Object Storage?\n\nStorage cost for Object Storage is determined by the total volume of data stored, the amount of public outbound bandwidth used, and the total number of operational requests processed by the system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1340071-1341923","score":16.55966,"text":"\n* Is there any option in Object Storage to enable accelerate data transfer?\n\nObject Storage offers [Aspera](https:\/\/www.ibm.com\/cloud\/object-storage\/aspera) service for high speed data transfer.\n* How can I compare various attributes of an object in two different buckets?\n\nUse [Rclone](https:\/\/rclone.org\/commands\/rclone_check). It enables you to compare various attributes.\n* What is the default retention period for buckets?\n\nThere is no default retention period applied. You can set it while creating the bucket.\n* Can we add a retention policy to an existing bucket?\n\nYes, [Retention policies](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-sdk-add-policy) can be added to an existing bucket; however, the retention period can only be extended. It cannot be decreased from the currently configured value.\n* Why is there a \"legal hold\" concept on top of the \"retention period\"?\n\nA legal hold prevents an object from being overwritten or deleted. However, a legal hold does not have to be associated with a retention period and remains in effect until the legal hold is removed. For details, see [Legal hold and retention period](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-hold).\n* How can I access a private COS endpoint in a data center from another date center?\n\nUse Object Storage [Direct Link Connection](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storage) to create a global direct link.\n* How does frequency of data access impact the pricing of Object Storage?\n\nStorage cost for Object Storage is determined by the total volume of data stored, the amount of public outbound bandwidth used, and the total number of operational requests processed by the system.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09585-8248-9899","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-tutorial-k8s-app"},{"document_id":"ibmcld_06394-8247-9898","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-tutorial-k8s-app"},{"document_id":"ibmcld_06474-8242-9893","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-tutorial-k8s-app"},{"document_id":"ibmcld_06367-8260-9911","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-tutorial-k8s-app"},{"document_id":"ibmcld_06669-8254-9905","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-tutorial-k8s-app"},{"document_id":"ibmcld_06728-8244-9895","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-tutorial-k8s-app"},{"document_id":"ibmcld_06602-8244-9895","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-tutorial-k8s-app"},{"document_id":"ibmcld_06534-8248-9899","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-tutorial-k8s-app"},{"document_id":"ibmcld_04581-8236-9887","score":15.183068,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-tutorial-k8s-app"},{"document_id":"ibmcld_13878-7395-9242","score":14.825415,"text":"\nBy setting up notifications you can make sure that certifications do not expire. Note that Secrets Manager allows you to order certificates.\n\nConsider implementing more stringent access rules to resources. [Context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis) allow defining access restrictions based on network zones and endpoint types. Thus, it is possible to isolate teams, users and resources by location.\n\n\n\n\n\n\n\n Evaluate and monitor app security \n\nEvents related to IBM Cloud account activities, such as logging in or provisioning a service, are logged to Activity Tracker. It does not, however, directly integrate any application-related events. But some services have options to enable tracking of security events. Examples are [Object Storage which allows both read and write events to be tracked](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-at) and [App ID which can track sign-in, sign-up and other runtime events](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-eventsat-monitor-runtime-activity) when enabled. Applications can ingest security and diagnostic events into [Log Analysis](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-getting-started). Moreover, most [services support sending usage logs directly to Log Analysis](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-cloud_services).\n\nBy sending both application logs, such as general diagnostics and security-related information like failed logins to a single logging facility, you can aggregate the logs and perform security analysis in application context, across the full stack. You can use the queries as foundation for [defining alerts](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts). Alerts help you to monitor your app and related services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":25.05095,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16242-7-2224","score":22.418911,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_03036-2789-4951","score":21.640394,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":21.328726,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":20.88604,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16242-1610-3614","score":19.99245,"text":"\nFor example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support. If the customer picks this choice, the assistant uses your Fallback action.\n\nStep validation attempts before offering support: If a customer provides invalid answers for a step in an action, the assistant can offer to connect to other support in the Fallback action. The step validation count measures how many invalid answers can occur before the assistant provides this choice.\n\nThis table shows the default settings for each mode.\n\n\n\nDefault settings\n\n Clarifying Confident \n\n Clarify when one action matches More often Sometimes \n Clarify when more than one action matches More often Sometimes \n Offer support option when asking a clarifying question More often Sometimes \n Step validation attempts before offering support 1 time 3 times \n\n\n\n\n\n\n\n Choosing a mode for individual actions \n\nWhen you edit an action, you can see the mode that it uses and change it if you need to.\n\n\n\n1. Click the Action response mode icon ![Action response mode icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-icon.svg). The mode in use is checked.\n\nZoom\n\n![Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_13129-5800-7679","score":19.20038,"text":"\nOn the left pane, click +New.\n2. Set the name to iris_model.\n3. Under Watson Machine Learning service instance, select the service previously associated.\n\n\n\n3. Click Create.\n\n\n\nOnce the model is created,\n\n\n\n1. Add training data by clicking Select data from project.\n\n\n\n1. Choose the iris_initial.csv file under Data asset.\n2. Click Select asset.\n\n\n\n2. If prompted, answer No to Create a time series forecast?.\n3. Select Species as your What do you want to predict?.\n4. Click Experiment settings.\n5. Select Data source.\n6. Under Training data split, set Holdout data split to 15% by moving the slider.\n7. On the left menu, Click on Prediction:\n\n\n\n1. Set Prediction type to Multiclass classification.\n2. Set Optimized metric as Accuracy.\n3. Click on Save settings.\n\n\n\n8. Click on Run experiment.\n9. The AutoAI experiment may take up to 5 minutes to select the right Algorithm for your model. Click on Swap view to see the Relationship map.\n\nEach model pipeline is scored for a variety of metrics and then ranked. The default ranking metric for binary classification models is the area under the ROC curve, for multi-class classification models is accuracy, and for for regression models is the root mean-squared error (RMSE). The highest-ranked pipelines are displayed in a leaderboard, so you can view more information about them. The leaderboard also provides the option to save select model pipelines after reviewing them.\n\n\n\nOnce the experiment completes running,\n\n\n\n1. Click on Pipeline comparison to view how the top pipelines compare.\n2. Sort the leaderboard by a different metric by clicking on the various column headers.\n3. Click a pipeline to view more detail about the metrics and performance.\n\nSorting by different metrics may not change the leaderboard rankings as the dataset used in this tutorial is very simple and used only for your understanding of the concepts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_16359-6868-8948","score":18.538446,"text":"\nAs part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.\n* Enable response modes to modify the assistant's behavior when it asks questions. For more information, see [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\nTo change settings, complete the following steps:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, you can edit the Ask clarifying questions section:\n\n\n\nAsk clarifying question settings\n\n Field Default text Description \n\n Assistant says Did you mean: The text that is displayed before the list of clarification choices. You can change it to something else, such as What do you want to do? or Pick what to do next. \n No action matches None of the above The choice that customers can click when none of the other choices are right. If the customer picks this choice, the assistant uses your No action matches action. You can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_09629-4-1985","score":16.778708,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n About routes \n\nYou can manage routes in your account by using the IBM Cloud\u00ae Metrics Routing CLI, IBM Cloud Metrics Routing REST API, and Terraform scripts. A route defines the rules that indicate what metrics are routed in a region and where to route them.\n\n\n\n Understanding how routes work in your account \n\nNote the following information about routes:\n\n\n\n* Routes are global under an account and are evaluated in all regions where IBM Cloud\u00ae Metrics Routing is deployed.\n* You can define a route from any of the supported locations where IBM Cloud Metrics Routing is available. For more information, see [Locations](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions).\n* Routes may be accessed from any regional IBM Cloud Metrics Routing API endpoint.\n* You can define up to 4 routes for an account.\n* By default, the account has 0 routes configured.\n* You can configure up to 4 rules for each route.\n* You can configure up to 8 locations for each rule.\n* You can configure up to 3 targets ({\"targets\":[{\"id\":ID1},{\"id\":ID2},{\"id\":ID3}]) for each rule.\n* Routes are processed independently. If you have multiple routes with rules that match the same metric data, that data will be sent to multiple targets.\n* Rules in 1 route definition are processed in order. The first matching rule (for example, location) that matches metrics data is used to process that data. When metrics are processed, they will not be processed by a subsequent rule within that route's definition. If you want to specify a default rule for all metrics that are not processed by other rules, you would specify the rule (\"locations\" : [\"\"]) as the final rule in your rules definition for the route.\n* If metrics data doesn't match any rule and no default target is configured, the metrics are dropped and not routed to any target.\n* Any update to 1 or more rules in a route definition discards the existing rule set and replaces it with the specified configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes"},{"document_id":"ibmcld_06357-1183-2746","score":16.251753,"text":"\n[Cloud databases dashboard in monitoring](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6da1ae87b1f476791c38688e7a0b7f7c7a7d71b9\/databases-for-elasticsearch\/images\/monitoring-ibm-list.png)\n\nFigure 2. Cloud databases dashboard\n\n\n\n Monitoring Availability \n\nIBM Cloud Monitoring is available for deployments in every region. Deployments in Multi-zone Regions (MZRs) - eu-gb, eu-de, us-east, us-south, jp-tok, au-syd - have their metrics in the corresponding region.\n\nIf you have deployments that are in Single-zone Region (SZR) che01 then your logs are forwarded to an IBM Cloud Monitoring instance in another region. You need to provision monitoring instances in the region where your metrics are forwarded to. Metrics for deployments in che01 go to jp-tok.\n\n\n\n\n\n Available Metrics \n\n\n\nTable 1. Available Metrics Reference Table\n\n Metric Name \n\n [Cluster status](https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-monitoringibm_databases_for_elasticsearch_cluster_status) \n [Disk read latency mean](https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-monitoringibm_databases_for_elasticsearch_disk_read_latency_mean) \n [Disk write latency mean](https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-monitoringibm_databases_for_elasticsearch_disk_write_latency_mean) \n [GC Percentage](https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-monitoringibm_databases_for_elasticsearch_garbage_collection_percent_average_15m)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-monitoring"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03109-8981-10943","score":16.295778,"text":"\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nAn empty JSON object {} is returned.\n\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2deleteuserdata).\n\nNote: Delete requests are processed in batches and may take up to 24 hours to complete.\n\n\n\n\n\n\n\n Web chat usage data \n\nThe Watson Assistant web chat sends limited usage data to the [Amplitude service](https:\/\/amplitude.com\/). When the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03036-2789-4951","score":13.96118,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_16081-1672-3396","score":13.916179,"text":"\nMetric Name ibm_is_resource_quota_limit \n Metric Type gauge \n Value Type none \n Segment By IBM IS Generation, Name of resource type for quota, Associated Resource \n\n\n\n\n\n\n\n\n\n Attributes for segmentation \n\n\n\n Global attributes \n\nThe following attributes are available for segmenting all previously mentioned metrics.\n\n\n\nTable 4: Global attributes\n\n Attribute name Attribute Attribute description \n\n Cloud Type ibm_ctype The cloud type is a value of public, dedicated or local \n Location ibm_location The location of the monitored resource - this may be a region, data center or global \n Resource ibm_resource The resource being measured by the service - typically a indentifying name or GUID \n Resource Type ibm_resource_type The type of the resource being measured by the service \n Resource group ibm_resource_group_name The resource group where the service instance was created \n Scope ibm_scope The scope is the account, organization or space GUID associated with this metric \n Service name ibm_service_name Name of the service generating this metric \n\n\n\n\n\n\n\n Additional attributes \n\nThe following attributes are available for segmenting one or more attributes as described in the Global attributes reference. See the individual metrics for segmentation options.\n\n\n\nTable 5: Additional attributes\n\n Attribute name Attribute Attribute description \n\n Associated Resource ibm_secondary_resource_id The ID of a linked or associated resource \n IBM IS Generation ibm_is_generation IBM IS Generation \n Name of resource type for quota ibm_resource_quota_name The name of the resource type being monitored for quota usage\/limit \n\n\n\n\n\n\n\n\n\n Next steps \n\n\n\n* [Quotas and service limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotas)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-quota-metrics"},{"document_id":"ibmcld_12716-0-1031","score":13.622926,"text":"\n\n\n\n\n\n\n  FAQs \n\nFrequently asked questions for IBM Cloud\u00ae Security and Compliance Center might include questions about managing profiles, defining custom rules, attaching scopes, and evaluating resources for compliance. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n  How do I start monitoring a rule? \n\nSecurity and Compliance Center supports two types of rules - predefined and custom. Predefined rules are associated with specifications by default and are automatically monitored when you create an attachment to a profile. Custom rules can be monitored after they are associated with a specification by customizing a control library. Then, you select those controls when you create an attachment.\n\n\n\n\n\n  Can I create a rule for a service that I didn't provision? \n\nYes, you can create rules for services or resources that are not already provisioned in your accounts. When the service or resource is created, it is automatically evaluated according to your rule definition.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-faqs"},{"document_id":"ibmcld_14513-5183-7508","score":13.512265,"text":"\n* Alarms - VMware vSphere\u00ae includes an events and alarms subsystem, which tracks events that occur in the vSphere environment and makes this information available in vCenter. This section describes this subsystem and how to enable and use the alarms in your enterprise.\n* Proactive daily checks - These checks enable system administrators to keep the environment healthy. When carried out daily, it prevents many common issues that are related to capacity and performance from impacting your workloads.\n* Troubleshooting - Even when you carry out proactive daily checks, issues occur that impact your workloads. Therefore, you need to fix the underlying issue as quickly as possible. These troubleshooting guides and some common troubleshooting scenarios assist system administrators with identifying and fixing these issues quickly.\n* Compliance - The compliance guide provides some insights on maintaining compliance of the environment against a regulatory compliance regime or industry best practice. The focus of this guide is on the VMware hardening guide, which is a number of documented lists of best practice for a VMware environment.\n\n\n\nMany of the previous tasks are automated in Operations Management on IBM Cloud, and for those tasks that are not, these tools make the manual processes easier for your systems administrators. It is imperative that you have the core components of the VMware environment monitored, in Operations Management on IBM Cloud, this is achieved as follows:\n\n\n\n\n\n Operations management on IBM Cloud \n\nYou can have enterprise tools in place that you can use to monitor and manage your vCenter Server instance. Table 1 describes the core components of the vCenter Server environment, why they need to be monitored and how they are monitored by using Operations Management on IBM Cloud. For more information, see the reference architecture documentation.\n\n\n\nTable 1. vCenter Server environment core components\n\n Component Why Monitored by \n\n vCenter vCenter is the infrastructure management component that manages the vSphere hosts and manages virtualized constructs such as clusters. vSAN\u2122 is monitored through vCenter. vSphere networking such as distributed switches and port groups are monitored through vCenter. VMware Aria\u00ae Operations\u2122 Manager and the VMware SDDC Health Management Pack.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-intro-overview"},{"document_id":"ibmcld_09410-17162-18713","score":13.261196,"text":"\nLOGDNA_INGESTION_KEY Reference to the logging ingestion key. secretKeyRef \n LOGDNA_HOST IBM Log Analysis ingestion endpoint. logs.us-south.logging.cloud.ibm.com \n LOGDNA_API_HOST IBM Log Analysis API ingestion endpoint. api.us-south.logging.cloud.ibm.com \n LOGDNA_ENDPOINT Ingestion log path. \/logs\/agent\/ \n LOGDNA_HOSTNAME Log Source name. MyCluster \n LOGDNA_LOG_DIRS Defines custom paths that you want the agent to monitor. <br>Separate multiple paths by using commas. <br>You can use glob patterns. Use double quotation marks to add a globe pattern. \/var\/log\/ \/output\/,\/mylogs\/myapplogs\/ \n LOGDNA_INCLUSION_RULES Custom rules that you can define to configure what log files to monitor. <br>These files can be located in any of the paths that are defined through the logdir parameter. <br>You can use glob patterns. For more information, see [Glober rules](https:\/\/github.com\/CJP10\/globber) .json,.test \n LOGDNA_INCLUSION_REGEX_RULES Regex custom rules that you can define to configure what log files to monitor. For more information, see [regex syntax](https:\/\/docs.rs\/regex\/1.2.1\/regex\/syntax) <br>These files can be located in any of the paths that are defined through the logdir parameter. \n LOGDNA_EXCLUSION_RULES Custom rules that you can define to configure what log files to exclude from being monitored. <br>You can use glob patterns. For more information, see [Glober rules](https:\/\/github.com\/CJP10\/globber) \n LOGDNA_EXCLUSION_REGEX_RULES Regex custom rules that you can define to configure what log files to exclude from being monitored.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_09410-14536-16139","score":13.014485,"text":"\nLOGDNA_INCLUSION_RULES Custom rules that you can define to configure what log files to monitor. <br>These files can be located in any of the paths that are defined through the logdir parameter. <br>You can use glob patterns. For more information, see [Glober rules](https:\/\/github.com\/CJP10\/globber) .json,.test \n LOGDNA_LINE_EXCLUSION_REGEX Regex custom rules that you can define to configure what log files to exclude from monitoring. For more information, see [regex syntax](https:\/\/docs.rs\/regex\/1.2.1\/regex\/syntax) <br>These files can be located in any of the paths that are defined through the logdir parameter. \n LOGDNA_EXCLUSION_RULES Custom rules that you can define to configure what log files to exclude from being monitored. <br>You can use glob patterns. For more information, see [Glober rules](https:\/\/github.com\/CJP10\/globber) \n LOGDNA_EXCLUSION_REGEX_RULES Regex custom rules that you can define to configure what log files to exclude from being monitored. \/var\/log\/containers\/,\/var\/log\/pods\/ \n LOGDNA_USE_SSL Boolean that defines whether TLS 1.2 should be used when the agent sends logs to the logging instance. <br>The default value is set to true. true Valid values are true and false. \n LOGDNA_USE_COMPRESSION Boolean that defines whether compression is enabled when the agent sends logs to the logging instance. <br>The default value is set to true. true true \n LOGDNA_GZIP_LEVEL Compression level for gzip. <br>Valid values are: 1, 2, 3, 4, 5, 6, 7, 8, 9 <br>When you set this variable to 1, you are configuring the agent to use the fastest compression speed but at a lower ratio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_09410-18360-20069","score":12.9565,"text":"\nLOGDNA_EXCLUSION_RULES Custom rules that you can define to configure what log files to exclude from being monitored. <br>You can use glob patterns. For more information, see [Glober rules](https:\/\/github.com\/CJP10\/globber) \n LOGDNA_EXCLUSION_REGEX_RULES Regex custom rules that you can define to configure what log files to exclude from being monitored. \/var\/log\/containers\/,\/var\/log\/pods\/ \n LOGDNA_USE_SSL Boolean that defines whether TLS 1.2 should be used when the agent sends logs to the logging instance. <br>The default value is set to true. true true \n LOGDNA_USE_COMPRESSION Boolean that defines whether compression is enabled when the agent sends logs to the logging instance. <br>The default value is set to true. true true \n LOGDNA_GZIP_LEVEL Compression level for gzip. <br>Valid values are: 1, 2, 3, 4, 5, 6, 7, 8, 9 <br>When you set this variable to 1, you are configuring the agent to use the fastest compression speed but at a lower ratio. When you set this variable to 9, you are configuring the agent to use the highest compression ratio but at a lower speed. 2 6 \n LOGDNA_TAGS Define tags to group hosts automatically into dynamic groups. production,serviceA \n\n\n\n\n\n\n\n Standard Kubernetes clusters: environment variables for logging agent V1 \n\n\n\nTable 6. Tags that are available for the logging agent V2\n\n Environment variable Description Default value Sample value \n\n DEFAULT_CONF_FILE Default configuration file. \/etc\/logdna\/config.yaml \n LOGDNA_PLATFORM Log source type. k8s \n LOGDNA_INGESTION_KEY Reference to the logging ingestion key. secretKeyRef \n LDLOGHOST IBM Log Analysis ingestion endpoint. logs.us-south.logging.cloud.ibm.com \n LDAPIHOST IBM Log Analysis API ingestion endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_09410-20834-22645","score":12.539157,"text":"\nFor more information, see [regex syntax](https:\/\/docs.rs\/regex\/1.2.1\/regex\/syntax) <br>These files can be located in any of the paths that are defined through the logdir parameter. \n LOGDNA_EXCLUDE Custom rules that you can define to configure what log files to exclude from being monitored. <br>These files can be located in any of the paths that are defined through the logdir parameter. <br>Separate multiple files by using commas. You can use glob patterns. You can configure specific files. \n LOGDNA_EXCLUDE_REGEX Regex custom rules that you can define to configure what log files to exclude from being monitored. \/var\/log\/containers\/,\/var\/log\/pods\/ \n LDLOGSSL Boolean that defines whether TLS 1.2 should be used when the agent sends logs to the logging instance. <br>The default value is set to true. true true \n COMPRESS Boolean that defines whether compression is enabled when the agent sends logs to the logging instance. <br>The default value is set to true. true true \n GZIP_COMPRESS_LEVEL Compression level for gzip. <br>Valid values are: 1, 2, 3, 4, 5, 6, 7, 8, 9 <br>When you set this variable to 1, you are configuring the agent to use the fastest compression speed but at a lower ratio. When you set this variable to 9, you are configuring the agent to use the highest compression ratio but at a lower speed. 2 6 \n LOGDNA_TAGS Define tags to group hosts automatically into dynamic groups. production,serviceA \n\n\n\n\n\n\n\n Linux: configuration parameters for logging agent V1 \n\n\n\nTable 7. Configuration options for the logging agent V1\n\n Parameter Description \n\n tags Define tags to group hosts automatically into dynamic groups. \n logdir Define custom paths that you want the agent to monitor. <br>Separate multiple paths by using commas. You can use glob patterns. You can configure specific files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_16259-1485-3642","score":12.371922,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-7-1952","score":26.66766,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16300-0-2464","score":26.56139,"text":"\n\n\n\n\n\n\n  Analyzing dialog and actions \n\nThe Analyze page provides a summary of the interactions between users and your assistant. If the dialog feature is enabled, the Analyze page remains the same, but some slight differences in functionality exist.\n\n\n\n  Overview tab \n\nWhen you view the Overview page, you can see action completion information in the Action completion diagram if a dialog node triggers an action. The Action completion diagram is empty if you are using only a dialog in your assistant. The three cards that display information about the most frequent actions, least frequent actions, and least completed actions are not available if your assistant uses only a dialog.\n\nFor more information about the Analyze page and how to use analytics with actions, see [Use analytics to review your entire assistant at a glance](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview).\n\n\n\n\n\n  Action completion tab \n\nThe Action completion page of Watson Assistant provides an overview of how all your assistant's actions are doing. If the dialog feature is enabled, the Action completion tab is relevant only if a dialog node triggers an action. If your assistant uses only a dialog, then this tab will be empty.\n\nFor more information about understanding action completion with actions, see [Understand your most and least successful actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completion).\n\n\n\n\n\n  Conversations tab \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nFrom the Conversations page, an intent that directly calls an action is displayed in the Topics column. For example, you might set up an intent called buy_takeout in the dialog, and that intent calls the order pizza action. This conversation topic is listed as buy_takeout > order pizza in the Topics column.\n\nYou might also see Dialog called action listed in the Requests column next to a conversation. In this case, customer input triggered an intent. Then, the customer engaged with the assistant before an action was eventually called.\n\nFor more information about analyzing conversations with actions, see [Review customer conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-analyze"},{"document_id":"ibmcld_03354-4-1897","score":25.420801,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_03363-4-2165","score":25.331108,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16258-2570-3569","score":24.58425,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_07578-75544-77185","score":24.303505,"text":"\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n* Can I change my plan to a Lite plan?\n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n* How many Lite plan instances of Watson Assistant can I create?\n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n* How do I create a webhook?\n\nTo define a webhook and add its details, go to the Live environment page and open the Environment settings page. From the Environment settings page, click Webhooks > Pre-message webhook. You can add details about your webhook. For more information, see [Making a call before processing a message](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-pre).\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-75519-77160","score":24.303505,"text":"\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n* Can I change my plan to a Lite plan?\n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n* How many Lite plan instances of Watson Assistant can I create?\n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n* How do I create a webhook?\n\nTo define a webhook and add its details, go to the Live environment page and open the Environment settings page. From the Environment settings page, click Webhooks > Pre-message webhook. You can add details about your webhook. For more information, see [Making a call before processing a message](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-pre).\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16362-4518-6470","score":24.117573,"text":"\nLite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n\n\n\n\n\n Why am I unable to view the API details, API key, or service credentials? \n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I change my plan to a Lite plan? \n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n\n\n\n\n\n How many Lite plan instances of Watson Assistant can I create? \n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n\n\n\n\n\n How do I create a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_16364-36153-38148","score":23.612316,"text":"\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-32797-34928","score":23.553755,"text":"\n: On the Preview page, you can now upload an image of your organization's website as a background. For more information, see [Previewing and sharing your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share).\n\n\n\n\n\n 16 September 2022 \n\nSession ID information on Analyze page\n: Session ID information for conversations is now displayed on the Conversations tab of the Analyze page. You can also filter customer conversation data by the session ID. From the Conversations tab of the Analyze page, use the Keyword filter to search by session ID. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nThe ability to filter on session ID has limited support for conversations that occurred before this feature release. For all conversations that occurred before 16 September 2022, you can filter only by a single session ID at a time.\n\n\n\n\n\n 9 September 2022 \n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The options response type now has the is any of and is none of operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nCopy actions to other assistants\n: You can copy an action from one assistant to another. When you copy an action, references to other actions, variables, and saved responses are also copied. For more information, see [Copying an action to another assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-copy-action).\n\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-85554-87392","score":15.103569,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-85529-87367","score":15.103569,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02990-7468-9182","score":14.970851,"text":"\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n How long are log files kept for a workspace? \n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n\n\n\n\n\n How do I create a webhook? \n\nTo define a webhook and add its details, open the skill where you want to add the webhook. Open the Options page, and then click Webhooks to add details about your webhook. To invoke the webhook, call it from one or more of your dialog nodes. For more information, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\n\n\n\n\n Can I have more than one entry in the URL field for a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-faqs"},{"document_id":"ibmcld_02796-0-1599","score":14.65456,"text":"\n\n\n\n\n\n\n  How can I debug my SAML connection? \n\nYou encounter bugs in your SAML connection. Check out some following helpful tips for debugging your SAML connection.\n\n\n\n  How do I capture my SAML authentication request and response? \n\nThere are several options for browser plug-ins such as [Firefox](https:\/\/addons.mozilla.org\/en-US\/firefox\/addon\/saml-tracer\/) and [Chrome](https:\/\/chrome.google.com\/webstore\/detail\/saml-tracer\/mpdajninpobndbfcldcmbpnnbhibjmch?hl=en) that can be used to capture your SAML requests and responses. Don't want to use a plug-in? No problem. Atlassian provides instructions for a more [manual extraction approach](https:\/\/confluence.atlassian.com\/jirakb\/how-to-view-a-saml-responses-in-your-browser-for-troubleshooting-872129244.html).\n\n\n\n\n\n  I don't understand the messages! How can I decode them? \n\nIf you're still having trouble after using your SAML debug tool, try using the [SAML developer tools](https:\/\/www.samltool.com\/online_tools.php) for more help decoding your messages. Don't forget! Depending on where you intercept your SAML messages, your request might be [URL encoded](https:\/\/www.samltool.com\/online_tools.php), [base 64 encoded and deflated](https:\/\/www.samltool.com\/decode.php), or [encrypted](https:\/\/www.samltool.com\/decrypt.php).\n\nDo not use online tools for decrypting SAML messages like your SAML response. The tools need access to the encryption private key to decrypt the information. The key should be kept private and access controlled. The decryption tool that is mentioned in this section must be used for debugging purposes only.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-ts-saml-debug-connection"},{"document_id":"ibmcld_11754-1788-3814","score":14.169273,"text":"\nNote that within one region, only one Log Analysis instance can be enabled for platform logs collection.\n\n\n\n\n\n\n\n Viewing logs for your Satellite location \n\nBecause the IBM Log Analysis instance is enabled for platform-level log collection, logs for all Log Analysis-integrated services are shown in the Log Analysis dashboard. You can apply filters to view only logs for your Satellite location.\n\n\n\n1. In the [Logging dashboard](https:\/\/cloud.ibm.com\/observe\/logging), click Open Dashboard for your Log Analysis instance.\n2. In the Filters toolbar, click Sources, select satellite, and click Apply. The logs for all your Satellite locations in the region are shown.\n3. To filter for a specific Satellite location, click Apps in the Filters toolbar, select the CRN for your Satellite location, and click Apply. To identify the CRN for your location, get your location ID by running ibmcloud sat location ls, look for this location's ID at the end of the listed CRNs.\n\n\n\nFor more tips on identifying logs in the dashboard, review how you can [search and filter logs](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-view_logs).\n\n\n\n\n\n Analyzing logs for your Satellite location \n\nUse logs that are automatically generated for your Satellite location to monitor and maintain its health.\n\n\n\n How often are logs posted? \n\nLogs are collected for your location and posted every 60 seconds.\n\n\n\n\n\n What kinds of logs are collected? \n\nBy default, three types of logs are automatically generated for your Satellite location: [R00XX-level error messages](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-healthlogs-error), [the status of whether resource deployment to the location is enabled](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-healthlogs-deploy), and [the status of Satellite Link](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-healthlogs-link). Review the following sections for an example of each log type and descriptions of each log field.\n\n\n\n\n\n How can I set up alerts for location error logs?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-health"},{"document_id":"ibmcld_03156-14203-14765","score":14.142607,"text":"\nThe workspace must have an associated user interface client. If it does not, see [How do I create an app?](https:\/\/www.intercom.com\/help\/en\/articles\/1827298-how-do-i-create-an-app) for help with setting one up.\n\nSubmit test user queries through a client application that is associated with your Intercom workspace to see how the messages are handled by Intercom. Verify that messages that are meant to be answered by the assistant are generating the appropriate responses, and that the assistant is not responding to messages that it is not configured to answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-intercom"},{"document_id":"ibmcld_07578-571119-573175","score":13.661577,"text":"\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.\n* When can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n When can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username followed by _srs (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n\n\n\nEvent Notifications\n\n\n\n* Why are messages reported as delivered but not received by the user?\n\nSometimes messages are reported as delivered but are not received by the user for the following reasons:\n\n\n\n* They are rejected by the telecom operator. If the same message is repeated over a span of time, messages are classified as SPAM message by the operator.\n\n\n\nA resolution is to add any TransactionID or ReferenceID to the message body. These IDs classify the SMS as transactional, and is not blocked by the operator.\n\n\n\n* The user opts out. If the user opts out from messaging by sending opt-out text like Opt Out, Stop, or Exit, then messages do not reach that user and the status report states that. The user can send an Opt in message to the same source to restart receiving messages.\n\n\n\n* Why do some devices are marked invalid and deleted from database?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-571073-573129","score":13.661577,"text":"\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.\n* When can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n When can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username followed by _srs (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n\n\n\nEvent Notifications\n\n\n\n* Why are messages reported as delivered but not received by the user?\n\nSometimes messages are reported as delivered but are not received by the user for the following reasons:\n\n\n\n* They are rejected by the telecom operator. If the same message is repeated over a span of time, messages are classified as SPAM message by the operator.\n\n\n\nA resolution is to add any TransactionID or ReferenceID to the message body. These IDs classify the SMS as transactional, and is not blocked by the operator.\n\n\n\n* The user opts out. If the user opts out from messaging by sending opt-out text like Opt Out, Stop, or Exit, then messages do not reach that user and the status report states that. The user can send an Opt in message to the same source to restart receiving messages.\n\n\n\n* Why do some devices are marked invalid and deleted from database?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09566-2410-3876","score":13.526302,"text":"\n[IO utilization in percent 60-minute average](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_disk_io_utilization_percent_average_60m) \n [IOPS read and write total count for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_disk_iops_read_write_total) \n [Max allowed memory for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_memory_limit_bytes) \n [Total disk space for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_disk_total_bytes) \n [Used CPU for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_cpu_used_percent) \n [Used disk space for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_disk_used_bytes) \n [Used memory for an instance.](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoringibm_messages_for_rabbitmq_memory_used_bytes) \n\n\n\n\n\n IO utilization in percent 5-minute average \n\nHow much disk I\/O has been used over 5 minutes as a percentage of total disk I\/O available.\n\n\n\nTable 2. IO utilization in percent 5 minute average metric metadata\n\n Metadata Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-monitoring"},{"document_id":"ibmcld_07578-431778-433665","score":13.512585,"text":"\n\/orders\/_design\/query\/_view\/by_last_edit?startkey=\"2022-01-13T00:00:00\"\n\nThis technique produces a time-ordered set of results with no repeated values in a performant and repeatable fashion. The consumer of this data does not need to manage the data idempotently, making for a simpler development process.\n\n\n\n\n\nThe IBM Cloudant changes feed is good for the following tasks:\n\n\n\n* Powering IBM Cloudant replication, optionally with a selector to filter some changes.\n* Clients consuming the changes feed in batches but dealing with each change idempotently while not being concerned with sort order and expecting to see some changes more than one time.\n\n\n\nThe IBM Cloudant changes feed is not good for the following components:\n\n\n\n* A message queue. For more information, see [IBM Messages for RabbitMQ](https:\/\/www.ibm.com\/cloud\/messages-for-rabbitmq) for managing queues.\n* A message broker. For more information, see [IBM Event Streams](https:\/\/www.ibm.com\/cloud\/event-streams) for handling scalable, time-ordered streams of events.\n* A real-time publish and subscribe system. For more information, see [IBM Databases for Redis](https:\/\/www.ibm.com\/uk-en\/cloud\/databases-for-redis) for handling publish and subscribe topics.\n* A transaction log. Some databases store each change in a transaction log, but the distributed and eventually consistent nature of IBM Cloudant means that no definitive time-ordered transaction log exists.\n* A querying mechanism. For more information, see [MapReduce Views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce) for creating views of your data that is ordered by a key of your choice.\n\n\n\n\n\n* How do I consume the changes feed?\n\nGiven a single database orders, I can ask the database for a list of changes, in this case, limiting the result set to five changes with ?limit=5:\n\nGET \/orders\/_changes?limit=5\n{\n\"results\": [\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02998-1325-2715","score":37.6229,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03329-1102-2607","score":36.338676,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03049-1355-3132","score":34.632576,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03381-1467-3226","score":33.163914,"text":"\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill upload issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n* If you have created a dialog skill already, the Add existing skill tab is displayed, and you can click to add an existing skill.\n\n\n\n3. Specify the details for the skill:\n\n\n\n* Name: A name no more than 64 characters in length. A name is required.\n* Description: An optional description no more than 128 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n4. For Skill type, choose Dialog.\n5. Click Create skill.\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03139-2715-4132","score":32.737858,"text":"\n[Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.\n4. Select the JSON file you want to import.\n\nThe imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON file cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1createworkspace).\n5. Click Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n6. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the skill, it appears as a tile on the Skills page.\n\n\n\n\n\n Re-creating your assistant \n\nYou can now re-create your assistant. You can then link your uploaded skills to the assistant, and configure integrations for it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_07578-18457-20516","score":31.390564,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":31.390564,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03049-2703-4536","score":31.301308,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03353-4-2000","score":30.49337,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03027-7-1946","score":30.310501,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-52142-53973","score":24.623579,"text":"\n* [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud)\n* [Authenticating to IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cpd)\n\n\n\n* What languages does the service support?\n\nThe Speech to Text service supports both previous-generation and next-generation languages and models. Most languages support both broadband\/multimedia and narrowband\/telephony models, which have minimum sampling rates of 16 kHz and 8 kHz, respectively. For more information about the available models and the features they support for all languages, see the following topics:\n\n\n\n* [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models)\n* [Next-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng)\n\n\n\n* What are the input audio formats?\n\nThe service supports many audio formats (MIME types). Different formats support different sampling rates and other characteristics. By using a format that supports compression, you can maximize the amount of audio data that you can send with a request. For more information about the supported audio formats, see the following topics:\n\n\n\n* [Audio terminology and characteristics](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-terminology)\n* [Supported audio formats](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formats)\n\n\n\n* How much audio data can I submit to the service?\n\nThe amount of audio that you can submit with a single speech recognition request depends on the interface that you are using:\n\n\n\n* The WebSocket and synchronous HTTP interfaces accept a maximum of 100 MB of audio data.\n* The asynchronous HTTP interface accepts a maximum of 1 GB of audio data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-52127-53958","score":24.623579,"text":"\n* [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud)\n* [Authenticating to IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cpd)\n\n\n\n* What languages does the service support?\n\nThe Speech to Text service supports both previous-generation and next-generation languages and models. Most languages support both broadband\/multimedia and narrowband\/telephony models, which have minimum sampling rates of 16 kHz and 8 kHz, respectively. For more information about the available models and the features they support for all languages, see the following topics:\n\n\n\n* [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models)\n* [Next-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng)\n\n\n\n* What are the input audio formats?\n\nThe service supports many audio formats (MIME types). Different formats support different sampling rates and other characteristics. By using a format that supports compression, you can maximize the amount of audio data that you can send with a request. For more information about the supported audio formats, see the following topics:\n\n\n\n* [Audio terminology and characteristics](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-terminology)\n* [Supported audio formats](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formats)\n\n\n\n* How much audio data can I submit to the service?\n\nThe amount of audio that you can submit with a single speech recognition request depends on the interface that you are using:\n\n\n\n* The WebSocket and synchronous HTTP interfaces accept a maximum of 100 MB of audio data.\n* The asynchronous HTTP interface accepts a maximum of 1 GB of audio data.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-101992-104197","score":22.93739,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_13337-7-1836","score":22.831966,"text":"\nUsage FAQs \n\nFAQs for IBM Watson\u00ae Speech to Text include questions about speech recognition, audio transmission, customization, and other topics. To find all FAQs for IBM Cloud\u00ae, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n How do I access my service credentials? \n\nHow you access your service credentials depends on whether you are using Speech to Text with IBM Cloud\u00ae or IBM Cloud Pak\u00ae for Data. For more information about obtaining your credentials for both versions, see [Before you begin](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-gettingStartedgetting-started-before-you-begin) in the getting started tutorial.\n\nOnce you have your service credentials, see the following topics for information about authenticating to the service:\n\n\n\n* [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud)\n* [Authenticating to IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cpd)\n\n\n\n\n\n\n\n What languages does the service support? \n\nThe Speech to Text service supports both previous-generation and next-generation languages and models. Most languages support both broadband\/multimedia and narrowband\/telephony models, which have minimum sampling rates of 16 kHz and 8 kHz, respectively. For more information about the available models and the features they support for all languages, see the following topics:\n\n\n\n* [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models)\n* [Next-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ng)\n\n\n\n\n\n\n\n What are the input audio formats? \n\nThe service supports many audio formats (MIME types). Different formats support different sampling rates and other characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-usage"},{"document_id":"ibmcld_03369-66296-68553","score":22.174961,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-147609-149563","score":22.016758,"text":"\nAll workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German. The revised system entities offer better date and time understanding. They can recognize date and number spans, national holiday references, and classify mentions with more precision.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_00510-7-1689","score":21.846043,"text":"\nData modeling \n\nThe Data modeling document is the first best practice document in the series. It shows you the following best practices:\n\n\n\n* What you need to know about your APIs.\n* How to model your data.\n* What size documents you must use.\n* What to avoid.\n* How to configure your databases.\n\n\n\nFor more information, see [Indexing and querying](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the API that you are targeting \n\nYou can use [Java\u2122](https:\/\/github.com\/IBM\/cloudant-java-sdk), [Python](https:\/\/github.com\/IBM\/cloudant-python-sdk), [Go](https:\/\/github.com\/IBM\/cloudant-go-sdk), or [Node.js](https:\/\/github.com\/IBM\/cloudant-node-sdk) or some other use-case-specific language or platform. One of these languages most likely comes with convenient client-side libraries that integrate IBM Cloudant access nicely, following the conventions that you expect for your tools. These languages are great for programmer efficiency, but they also hide the API from view.\n\nThis abstraction is what you want, the whole reason for using a client library is to save yourself repeated, tedious boiler-plating. However, you must understand the underlying API is vital when you troubleshoot and report problems. When you report a suspected problem to IBM Cloudant, it helps us help you if you can provide a way for us to reproduce the problem.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_11510-7-2157","score":21.768076,"text":"\nFAQs for IBM Cloud Qiskit Runtime \n\nTo find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is Qiskit Runtime service? \n\nQiskit Runtime service is a runtime environment through the IBM Cloud that provides access to the IBM Quantum processors and simulators. They allow users to run quantum programs, which require specialized quantum hardware that is coupled closely with traditional \u201cclassical\u201d, computer hardware.\n\n\n\n\n\n Why is IBM launching Qiskit Runtime service? \n\nIBM made quantum computers available through the cloud in 2016. In 2022, IBM integrates with IBM Cloud\u00ae accounts to offer Qiskit Runtime API access. This access creates a smoother customer experience and the ability to combine Qiskit Runtime with other kinds of cloud compute resources for their particular workflow or application.\n\n\n\n\n\n What can Qiskit Runtime service not do? \n\nQiskit Runtime service provides access to IBM Quantum systems. Today\u2019s quantum systems are somewhat constrained in the size of problems that they can address due to available scale and quantum volume. Nonetheless, these systems can already be used to solve small problems and to explore this new and exciting field.\n\n\n\n\n\n What skills are required to use the Qiskit Runtime service? \n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.\n\n\n\n\n\n What are the benefits of using Qiskit Runtime? \n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n\n\n\n\n\n What are Qiskit Runtime primitives? \n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_14610-1490-3561","score":21.528389,"text":"\nThe following factors govern the complexity of migration:\n\n\n\n* Project-based factors - such as how is the project that is being staffed.\n* Architecture factors - such as changes to the existing NSX-V environment since deployment.\n* Micro-segmentation factors - such as the use of distributed firewall rules and the use of tagging in these rules.\n* Integration factors - what systems are integrating with NSX-V Manager and vCenter as both these components are replaced in the migration. Integrated systems can include VMware Aria Automation, VMware Aria Operations, VMware Aria Orchestrator, SEIM or security tools, backup and recovery, replication, F5, vSRX, FortiGate, or other third-party network applications.\n\n\n\nFor more information, see [Assess migration complexity](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-complexity).\n\nClassifying or assessing migration complexity is just an informative step to provide you guidance. So that you can estimate the migration timescales, required tools, skills and knowledge, and you can prepare in the best possible way.\n\n\n\n\n\n Required skills \n\nWhen you assess the complexity, you must focus on skills and resource availability. You must assess:\n\n\n\n* If existing resources have time to participate in migration activities while they are delivering their existing duties.\n* If existing resources have the skills, knowledge and experience that are needed to successfully deliver the required tasks.\n\n\n\nIf it is deemed that in-house skills need to be supplemented, then it is advised to engage a migration services provider as soon as possible.\n\nIn addition, to ensure successful Day 2 operations, improve the core VMware NSX-T\u2122 skills by using the available [VMware Learning for NSX-T education](https:\/\/www.vmware.com\/learning.html).\n\n\n\n\n\n Engage a migration services provider \n\nYou can engage PrimaryIO\u2019s experienced Professional Services team through the IBM Catalog. For more information, see [HDM Cloud Connect NSX-V to NSX-T](https:\/\/cloud.ibm.com\/catalog\/services\/hdm-cloud-connect-nsx-v-to-nsx-t).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-planning"},{"document_id":"ibmcld_03369-64600-66787","score":21.445179,"text":"\n: Want a quick way to see how your dialog is doing at responding to customer queries? Enable the new coverage metric to find out. The coverage metric measures the rate at which your dialog is confident that it can address a customer's request per message. For conversations that are not covered, you can review the logs to learn more about what the customer wanted. For the metric to work, you must design your dialog to include an Anything else node that is processed when no other dialog node intents are matched. For more information, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n\nTry out the enhanced intent detection model\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time.\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05713-115081-116576","score":18.461418,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapp_kinds)\n* [What about serverless apps?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapps_serverless-strategy)\n* [What skills should I have before I move my apps to a cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyknowledge)\n\n\n\n* [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_resources)\n* [What else besides my app might use resources in the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_other)\n* [What type of availability do I want my workload to have?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_availability)\n* [How many worker nodes do I need to handle my workload?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_workers)\n* [How do I monitor resource usage and capacity in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_manage)\n\n\n\n* [Structuring your Kubernetes environment](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-107977-109345","score":17.274696,"text":"\n* [Uninstalling on Linux and macOS](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-uninstall-ibmcloud-cliuninstall-cli-linux-macos)\n\n\n\n\n\n\n\n Planning your cluster environment \n\n[Moving your environment to Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategystrategy)\n\n\n\n* [Moving your workloads to the IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategycloud_workloads)\n\n\n\n* [What can I move to the IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategymove_to_cloud)\n* [Can I automate my infrastructure deployments?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyinfra_packaging)\n* [What kind of apps can I run? Can I move existing apps, or do I need to develop new apps?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyapp_kinds)\n* [What about serverless apps?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyapps_serverless-strategy)\n* [What skills should I have before I move my apps to a cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyknowledge)\n\n\n\n* [Sizing your Red Hat OpenShift cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_resources)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-882118-884014","score":15.457922,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-881995-883891","score":15.457922,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16425-20985-23039","score":15.178229,"text":"\nA precision score reaches its best value at 1 and worst value at 0. A low precision score indicates that the machine learning model generated incorrect annotations.\n\n\n\n\n\n Causes \n\nLow precision scores can occur for many different reasons that depend on the domain, type system complexity, appropriateness of training documents, human annotator skills, and other factors.\n\n\n\n\n\n Resolving the problem \n\nTune the performance of your machine learning model by performing one or more of following steps then retrain your model:\n\n\n\n1. Identify commonly occurring types with low precision.\n2. Identify commonly confused types. This information can be found by looking at the numbers that are off the diagonal in the confusion matrix.\n3. Review errors where the machine learning model has high confidence.\n4. Find patterns in the false negatives in the confusion matrix.\n5. If certain types have low precision scores, review the clarity of the annotation guidelines that apply to those types.\n\n\n\n![How to resolve low precision scores.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_lowprec.svg)\n\nFigure 2. How to resolve low precision scores\n\n\n\n\n\n\n\n Analyzing low recall scores \n\nTune the performance of your machine learning model to address low recall scores. At a high level, low recall indicates a need to add more training data.\n\n\n\n Symptoms \n\nA recall score reaches its best value at 1 and worst value at 0. A low recall score indicates that the machine learning model failed to create annotations that it should have created.\n\n\n\n\n\n Causes \n\nLow recall scores can occur for many different reasons that depend on the domain, type system complexity, appropriateness of training documents, human annotator skills, and other factors.\n\n\n\n\n\n Resolving the problem \n\nTune the performance of your machine learning model by performing one or more of following steps then retrain your model:\n\n\n\n1. Identify commonly occurring types with low recall.\n2. Identify commonly confused types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_07578-873193-875161","score":14.988987,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-873070-875038","score":14.988987,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-363349-365063","score":14.774799,"text":"\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-363323-365037","score":14.774799,"text":"\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-362072-363770","score":14.750808,"text":"\nibmcloud cr image-digests\n* Run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command:\n\nibmcloud cr image-list --no-trunc\n\nIf you run the ibmcloud cr image-list command without the --no-trunc option, you see the truncated format of the digest.\n\n\n\n* How do I use digests to work with images?\n\n How do I use digests to work with images? \n\nThe [digest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_digest) identifies an image by using the sha256 hash of the [image manifest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_manifest).\n\nTo find the digests for your images, run the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. You can refer to an image by using a combination of the content of the Repository column (repository) and the Digest column (digest) separated by an at (@) symbol to create the image name in the format repository@digest.\n* How do you use access control?\n\n How do you use access control? \n\nYou can create IBM Cloud Identity and Access Management (IAM) policies to control access to your namespaces in IBM Cloud Container Registry. For more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09226-18248-20249","score":12.592601,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_09229-16048-18016","score":12.131038,"text":"\nen-th English (en) Thai (th) general \n en-tr English (en) Turkish (tr) general \n en-uk English (en) Ukrainian (uk) general \n en-ur English (en) Urdu (ur) general \n en-vi English (en) Vietnamese (vi) general \n en-zh English (en) Simplified Chinese (zh) general \n en-zh-TW English (en) Traditional Chinese (zh-TW) general \n\n\n\n\n\n\n\n Estonian \n\nThe following Estonian translation model can be customized.\n\n\n\nTable 15. Estonian translation model\n\n Model ID Source Target Domain \n\n et-en Estonian (et) English (en) general \n\n\n\n\n\n\n\n Finnish \n\nThe following Finnish translation model can be customized.\n\n\n\nTable 16. Finnish translation model\n\n Model ID Source Target Domain \n\n fi-en Finnish (fi) English (en) general \n\n\n\n\n\n\n\n French \n\nThe following French translation model can be customized.\n\n\n\nTable 17. French translation model\n\n Model ID Source Target Domain \n\n fr-en French (fr) English (en) general \n\n\n\n\n\n\n\n French (Canadian) \n\nThe following French (Canadian) translation model can be customized.\n\n\n\nTable 18. Canadian French translation model\n\n Model ID Source Target Domain \n\n fr-CA-en Canadian French (fr-CA) English (en) general \n\n\n\n\n\n\n\n German \n\nThe following German translation models can be customized.\n\n\n\nTable 19. German translation models\n\n Model ID Source Target Domain \n\n de-en German (de) English (en) general \n de-fr German (de) French (fr) general \n de-it German (de) Italian (it) general \n\n\n\n\n\n\n\n Greek \n\nThe following Greek translation model can be customized.\n\n\n\nTable 20. Greek translation model\n\n Model ID Source Target Domain \n\n el-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09229-17595-19748","score":12.131038,"text":"\nel-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general \n\n\n\n\n\n\n\n Hindi \n\nThe following Hindi translation model can be customized.\n\n\n\nTable 23. Hindi translation model\n\n Model ID Source Target Domain \n\n hi-en Hindi (hi) English (en) general \n\n\n\n\n\n\n\n Hungarian \n\nThe following Hungarian translation model can be customized.\n\n\n\nTable 24. Hungarian translation model\n\n Model ID Source Target Domain \n\n hu-en Hungarian (hu) English (en) general \n\n\n\n\n\n\n\n Indonesian \n\nThe following Indonesian translation model can be customized.\n\n\n\nTable 25. Indonesian translation model\n\n Model ID Source Target Domain \n\n id-en Indonesian (id) English (en) general \n\n\n\n\n\n\n\n Irish \n\nThe following Irish translation model can be customized.\n\n\n\nTable 26. Irish translation model\n\n Model ID Source Target Domain \n\n ga-en Irish (ga) English (en) general \n\n\n\n\n\n\n\n Italian \n\nThe following Italian translation models can be customized.\n\n\n\nTable 27. Italian translation models\n\n Model ID Source Target Domain \n\n it-de Italian (it) German (de) general \n it-en Italian (it) English (en) general \n\n\n\n\n\n\n\n Japanese \n\nThe following Japanese translation model can be customized.\n\n\n\nTable 28. Japanese translation model\n\n Model ID Source Target Domain \n\n ja-en Japanese (ja) English (en) general \n\n\n\n\n\n\n\n Kannada \n\nThe following Kannada translation model can be customized.\n\n\n\nTable 29. Kannada translation model\n\n Model ID Source Target Domain \n\n kn-en Kannada (kn) English (en) general \n\n\n\n\n\n\n\n Korean \n\nThe following Korean translation model can be customized.\n\n\n\nTable 30. Korean translation model\n\n Model ID Source Target Domain \n\n ko-en Korean (ko) English (en) general \n\n\n\n\n\n\n\n Latvian \n\nThe following Latvian translation model can be customized.\n\n\n\nTable 31. Latvian translation model\n\n Model ID Source Target Domain","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_16460-9978-11758","score":9.960489,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-9963-11743","score":9.960489,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_07104-32103-34057","score":9.580844,"text":"\nFor more information, see [Monitoring usage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapiapi-usage).\n\n\n\n\n\n 30 August 2020 \n\nUpdate to API version\n: The current API version (v2) is now 2020-08-30. The following change was made with this version:\n\nChange to 'options' object\n: The List enrichments method no longer returns the options object per enrichment. Use the Get enrichment method to return the options object for a single enrichment.\n\n\n\n\n\n 2.1.3 release, 19 June 2020 \n\nNew release now available\n: IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data version 2.1.3 is available.\n: Discovery for Cloud Pak for Data now works with IBM Cloud Pak\u00ae for Data 3.0.1.\n\nNew Finnish and Hebrew language support\n: Added basic support for Finnish and Hebrew. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nChange to Analyze endpoint\n: The Analyze endpoint, which supports stateless document ingestion workflows. For details, see the [Analyze API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapi). The Analyze API supports JSON documents only. Use of the Analyze API affects license usage.\n\nNew options for Content Miner\n: The content mining application includes two new options: Cyclic time scale on the Time series dashboard, and the Contextual view tab.\n\nNew shortcut for Content Mining projects\n: For Content Mining projects only, the Improve and customize page includes a shortcut: the Launch application button. Previously, you were required to open the Integrate and deploy page, select the Launch application tab, and click the Launch button.\n\nImproved segment limit\n: The segment limit when splitting documents has been increased to 1,000. For details, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\nImproved Filenet connector","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes-data"},{"document_id":"ibmcld_09903-9624-10554","score":9.390844,"text":"\nHebrew [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"},{"document_id":"ibmcld_02839-3583-5403","score":9.269004,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_16460-10316-12439","score":9.229076,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-10301-12424","score":9.229076,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-14024-16089","score":19.617144,"text":"\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https:\/\/en.wikipedia.org\/wiki\/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_03069-6360-8216","score":17.527094,"text":"\n[Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/ask_watson.png) icon to open the Try it out pane.\n2. Enter, I want to learn more about your restaurant.\n\nYour assistant indicates that the about_restaurant intent is recognized, and returns a response with the image and text that you specified for the dialog node.\n\n![Shows the Try it out pane recognizing the #about_restaurant intent and showing the image and text response.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ass-test-about-restaurant.png)\n\n\n\nCongratulations! You have added a custom intent, and a dialog node that knows how to handle it.\n\nThe about_restaurant intent is designed to recognize a variety of general questions about the restaurant. You added a single node to capture such questions. The response is long, but it is a single statement that can potentially answer questions about all of the following topics:\n\n\n\n* The restaurant owners\n* The restaurant history\n* The philosophy\n* The number of sites\n* The days of operation\n* The meals served\n* The fact that the restaurant bakes cakes to order\n\n\n\nFor general, low-hanging fruit types of questions, a single, general answer is suitable.\n\n\n\n\n\n\n\n Step 4: Manage cake orders \n\nCustomers place orders in person, over the phone, or by using the order form on the website. After the order is placed, users can cancel the order through the virtual assistant. First, define an entity that can recognize order numbers. Then, add an intent that recognizes when users want to cancel a cake order.\n\n\n\n Adding an order number pattern entity \n\nYou want the assistant to recognize order numbers, so you will create a pattern entity to recognize the unique format that the restaurant uses to identify its orders.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_03403-6208-8025","score":17.322166,"text":"\nTest the intent by checking whether user utterances that are similar to, but not exactly the same as, the examples you added to the training data have successfully trained your assistant to recognize input with an about_restaurant intent.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/ask_watson.png) icon to open the \"Try it out\" pane.\n2. Enter, I want to learn more about your restaurant.\n\nYour assistant indicates that the about_restaurant intent is recognized, and returns a response with the image and text that you specified for the dialog node.\n\n![Shows the Try it out pane recognizing the #about_restaurant intent and showing the image and text response.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-test-about-restaurant.png)\n\n\n\nCongratulations! You have added a custom intent, and a dialog node that knows how to handle it.\n\nThe about_restaurant intent is designed to recognize a variety of general questions about the restaurant. You added a single node to capture such questions. The response is long, but it is a single statement that can potentially answer questions about all of the following topics:\n\n\n\n* The restaurant owners\n* The restaurant history\n* The philosophy\n* The number of sites\n* The days of operation\n* The meals served\n* The fact that the restaurant bakes cakes to order\n\n\n\nFor general, low-hanging fruit types of questions, a single, general answer is suitable.\n\n\n\n\n\n\n\n Step 4: Manage cake orders \n\nCustomers place orders in person, over the phone, or by using the order form on the website. After the order is placed, users can cancel the order through the virtual assistant. First, define an entity that can recognize order numbers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03285-34490-35530","score":15.786817,"text":"\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the output.generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Goodbye.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"end_session\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_02114-4183-5917","score":15.703242,"text":"\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only alternative options are json and csv.\n\n--kind KIND (optional)\n: Flag is only valid for services search. Provide a comma-separated list of types of products.\n\n--region REGION (optional)\n: Flag is only valid for services search. Provide a comma-separated list of regions. Run ibmcloud cs regions to return a valid list.\n\n--price PRICE (optional)\n: Flag is only valid for services search. Provide a comma-separated list of pricing types.\n\n--tag TAG (optional)\n: Flag is only valid for services search. Provide a comma-separated list of tags.\n\n--global (optional)\n: Flag is only valid for services search. Use it to operate in global scope.\n\n--sort-by TYPE (optional)\n: Flag is only valid for services search and used to order the search result. Available options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-4183-5917","score":15.703242,"text":"\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only alternative options are json and csv.\n\n--kind KIND (optional)\n: Flag is only valid for services search. Provide a comma-separated list of types of products.\n\n--region REGION (optional)\n: Flag is only valid for services search. Provide a comma-separated list of regions. Run ibmcloud cs regions to return a valid list.\n\n--price PRICE (optional)\n: Flag is only valid for services search. Provide a comma-separated list of pricing types.\n\n--tag TAG (optional)\n: Flag is only valid for services search. Provide a comma-separated list of tags.\n\n--global (optional)\n: Flag is only valid for services search. Use it to operate in global scope.\n\n--sort-by TYPE (optional)\n: Flag is only valid for services search and used to order the search result. Available options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-4183-5917","score":15.703242,"text":"\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only alternative options are json and csv.\n\n--kind KIND (optional)\n: Flag is only valid for services search. Provide a comma-separated list of types of products.\n\n--region REGION (optional)\n: Flag is only valid for services search. Provide a comma-separated list of regions. Run ibmcloud cs regions to return a valid list.\n\n--price PRICE (optional)\n: Flag is only valid for services search. Provide a comma-separated list of pricing types.\n\n--tag TAG (optional)\n: Flag is only valid for services search. Provide a comma-separated list of tags.\n\n--global (optional)\n: Flag is only valid for services search. Use it to operate in global scope.\n\n--sort-by TYPE (optional)\n: Flag is only valid for services search and used to order the search result. Available options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_04179-3022-5112","score":14.901456,"text":"\nCreate a Page Rule with the URL pattern of your API (for example, www.example.com\/api\/).\n2. Identify the Security Level setting.\n3. Turn Security Level to Low or Essentially off.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n What do security level settings mean? \n\nOur security level settings are aligned with threat scores that certain IP addresses acquire from malicious behavior on our network. A threat score above 10 is considered high.\n\n\n\n* High: Threat scores greater than 0 are challenged.\n* Medium: Threat scores greater than 14 are challenged.\n* Low: Threat scores greater than 24 are challenged.\n* Essentially off: Threat scores greater than 49 are challenged.\n* Off: Enterprise only\n* Defense mode: Should only be used when your website is under a DDoS attack. Visitors receive an interstitial page for about five seconds while CIS analyzes the traffic and behavior to make sure it is a legitimate visitor trying to access your website. Defense mode might affect some actions on your domain, such as using an API. You are able to set a custom security level for your API or any other part of your domain by creating a page rule for that section.\n\n\n\nIt is recommended that you review your security-level settings periodically. You can find instructions in [Best practices for CIS setup](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup).\n\n\n\n\n\n\n\n Best practice 3: Activate your Web Application Firewall (WAF) safely \n\nYour WAF is available in the Security section. Here, we walk through these settings in reverse order to ensure that your WAF is configured as safely as possible before turning it on for your entire domain. These initial settings can reduce false positives by populating Security Events for further tuning. Your WAF is updated automatically to handle new vulnerabilities as they are identified. For more information, see [Using Security events capability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-using-the-cis-security-events-capability).\n\nThe WAF protects you against the following types of attacks:\n\n\n\n* SQL injection attack\n* Cross-site scripting","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_03184-7285-9367","score":14.417015,"text":"\nIf multiple actions in a single JSON action array add the result of their programmatic call to the same context variable, then the order in which the context is updated matters. Per action type, the order in which the actions are defined in the array determines the order in which the context variable's value is set. The context variable value returned by the last action in the array overwrites the values calculated by any other actions.\n\nThe result_variable property is required. If the client action does not return any result, specify null as the value.\n\n\n\n\n\n\n\n\n\n Client action example \n\nThe following example shows what a request for a call to an external weather service might look like. It is added to the JSON editor that is associated with the node response. By the time the node-level response is triggered, slots have collected and stored the date and location information from the user. This example assumes that the client action is named weather_forecast, that it takes a location parameter, and that the results are to be stored in the weather_forecast context variable.\n\n{\n\"actions\": [\n{\n\"name\": \"get_weather\",\n\"type\": \"client\",\n\"parameters\": {\n\"location\": \"$location\"\n},\n\"result_variable\": \"weather_forecast\"\n}\n]\n}\n\nThe client application must check for the presence of any client actions in the responses to messages it sends to the assistant. When it recognizes a request for the get_weather action, it executes the action (calling the external weather service), and it stores the result in the specified context variable (weather_forecast). It then sends a message to the service, including the updated context.\n\nTo handle this message in your dialog, create a child node following the node that requested the action. You can condition this child node on the special condition true to ensure that it is always triggered by the message that the client sends after completing the requested action. In this child node, add the response to show the user, reading the stored action result from the $my_forecast context variable:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_04126-7-1694","score":14.30613,"text":"\nCompression and optimization concepts \n\nIBM Cloud\u00ae Internet Services applies gzip and brotli compression to some types of content. CIS also compresses items based on the browser's UserAgent to speed up page loading time.\n\nIf you're already using gzip, CIS honors your gzip settings as long as you're passing the details in a header from your web server for the files.\n\nCIS only supports the content type gzip towards your origin server and can also only deliver content either gzip-compressed, brotli-compressed, or not compressed.\n\nCIS's reverse proxy is also able to convert between compressed formats and uncompressed formats, meaning that it can pull content from a customer's origin server through gzip and serve it to clients uncompressed (or reversed). This is done independently of caching.\n\nThe Accept-Encoding header is not respected and is removed.\n\n\n\n What gets compressed \n\nIn addition to CIS's serving stale content and minification of CSS, JS, and HTML to speed up your site, CIS also provides gzip and brotli compression to help site owners.\n\nCIS returns gzip or brotli encoded responses to compatible clients and browsers for the following content-types:\n\ntext\/html\ntext\/richtext\ntext\/plain\ntext\/css\ntext\/x-script\ntext\/x-component\ntext\/x-java-source\ntext\/x-markdown\napplication\/javascript\napplication\/x-javascript\ntext\/javascript\ntext\/js\nimage\/x-icon\nimage\/vnd.microsoft.icon\napplication\/x-perl\napplication\/x-httpd-cgi\ntext\/xml\napplication\/xml\napplication\/xml+rss\napplication\/vnd.api+json\napplication\/x-protobuf\napplication\/json\nmultipart\/bag\nmultipart\/mixed\napplication\/xhtml+xml\nfont\/ttf\nfont\/otf\nfont\/x-woff\nimage\/svg+xml\napplication\/vnd.ms-fontobject\napplication\/ttf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compression-concepts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12297-152596-153844","score":14.254549,"text":"\n* [How do I delete a workspace when the delete fails](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqclusterdeletion-warn-faq)\n* [What is the best way to deploy a Helm chart using credentials or secrets?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqgherepo-warn-faq)\n* [How do I address job failures caused by maintenance activities?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqimpact-downtime-workspace)\n* [How do you set the Git release tag?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqreleasetag-warn-faq)\n* [Why do I get a 403 error instead of 404 error when using an invalid workspace ID?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqinvalidwspid-warn-faq)\n* [How can I enable Terraform debug logging](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqterraform-debug-ibmcli)\n* [How can I import Cloud resources into a workspace?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqworkspace-import-ibmcli)\n* [How can I download Job files?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqdownload-jobfile)\n* [How do I set the TF_CLI_ARGS environment variable?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_13933-3021-3901","score":13.801248,"text":"\nHow do I protect the VRA itself with a zone-based firewall? \n\nThe VRA does not have a local zone. You can use the Control Plane Policing (CPP) functionality instead as it is applied as a local firewall on loopback.\n\nThis is a stateless firewall and you must explicitly allow the returning traffic of outbound sessions that originate on the VRA itself.\n\n\n\n\n\n How do I restrict SSH and block connections that come from the internet? \n\nIt is considered a best practice to not allow SSH connections from the internet, and to use another means of accessing the private address, such as SSL VPN.\n\nBy default, the VRA accepts SSH on all interfaces. To listen only for SSH connections on the private interface, you must set the following configuration:\n\nset service ssh listen-address '10.1.2.3'\n\nKeep in mind that you must replace the IP address with the address that belongs to the VRA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-technical-faqs-for-ibm-virtual-router-appliance"},{"document_id":"ibmcld_05713-152846-154383","score":13.55359,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-network-traffic-default)\n* [What is network segmentation and how can I set it up for a VPC cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork-segment-what-is)\n* [What else can I do to reduce the surface for external attacks for VPC clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-external-what-else)\n* [Securely expose apps with LoadBalancer and Ingress services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_lb_ingress)\n* [Can I use security groups to manage my cluster's network traffic?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycan-i-use-security-groups)\n* [How can I secure the source IP within the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecure-source-ip-cluster)\n* [How can I do TLS termination with LoadBalancer and Ingress services?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitytls-termination-lb)\n\n\n\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitystorage)\n* [Monitoring and logging](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitymonitoring_logging)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05248-1488-3339","score":13.451027,"text":"\n* Log out of IBM Cloud\u00ae. Clear your browser cache and cookies to remove your preferences and then log in again and open Cloud Shell.\n* Check whether [Concurrent sessions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-work-sessions&interface=uisessions-concurrent) is set. If so, ensure that the number of logged in sessions for the account does not exceed the Limit sessions value.\n\n\n\n\n\n\n\n Why can't I work with my Kubernetes clusters from my session? \n\n What\u2019s happening \n\nYou want to work with your IBM Cloud\u00ae Kubernetes Service clusters, but when you run a command such as kubectl get pods, the following error is displayed:\n\n$ kubectl get pods\nThe connection to the server localhost:8080 was refused - did you specify the correct host or port?\n\n Why it\u2019s happening \n\nThe cluster isn't currently set as the context. As with your local development environment, the cluster context must be set for each individual session.\n\n How to fix it \n\nSet the cluster as the context in your session as described in [Configuring the CLI to run kubectl](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_installcs_cli_configure).\n\n\n\n\n\n What do I do if I changed my .bashrc file and my sessions don't work? \n\n What\u2019s happening \n\nYou customized your Cloud Shell sessions by editing the .bashrc file, and now your sessions don't open. As a result, you can't work in Cloud Shell.\n\n Why it\u2019s happening \n\nSome code in your .bashrc file isn't working correctly, and it's interfering with your sessions' ability to initialize.\n\n How to fix it \n\nIf you're able to run commands from an existing open session, [download any files](https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-files) that you want to keep. Then, restart Cloud Shell by going to the Cloud Shell menu and clicking Restart.\n\n\n\n\n\n Why do I keep losing my connection to Cloud Shell?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-troubleshooting"},{"document_id":"ibmcld_12297-153574-154815","score":13.349741,"text":"\n(https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqworkspace-import-ibmcli)\n* [How can I download Job files?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqdownload-jobfile)\n* [How do I set the TF_CLI_ARGS environment variable?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqterraformcli-arguments-faq)\n* [Can I use private Git repositories?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqdownload-module-netrc-faq)\n* [Can I edit all the variables in a workspace?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqedit-variables-faq)\n* [How do I import keys when importing KMS resources?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqkmskey-value-faq)\n* [Can you enable the TRACE to help DEBUG Schematics API while running workspace list command?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqtraces-api-faq)\n* [How do I resolve errors listing workspaces](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqbadstatus-workspace-faq)\n* [How can I use (IBM) GitLab repositories?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faqgitlab-workspace-faq)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_10534-149622-151010","score":13.342821,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityvpc-network-traffic-default)\n* [What is network segmentation and how can I set it up for a VPC cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork-segment-what-is)\n* [What else can I do to reduce the surface for external attacks for VPC clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityvpc-external-what-else)\n* [Securely expose apps with routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityexpose-apps-with-routes)\n* [Securely expose apps with LoadBalancer and Ingress services](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_lb_ingress)\n* [Can I use security groups to manage my cluster's network traffic?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitycan-i-use-security-groups)\n* [How can I do TLS termination with LoadBalancer and Ingress services?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitytls-termination-lb)\n\n\n\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitystorage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10852-36156-37516","score":13.330594,"text":"\n* [How do I set IAM policies so that others can work with my namespace?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_policies)\n* [How do I set IAM policies so that others can create namespaces in my account?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_create)\n* [How do I know which access policies have set for me?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_set_policies_me)\n* [Platform management roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_platform_roles)\n* [Service-specific roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice_specific_roles)\n* [Setting access policies for a service ID](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-policy)\n\n\n\n* [Setting access policies for a service ID in the console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-ui)\n* [Setting an access policy for your Cloud Functions service ID through the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamcli-set)\n\n\n\n\n\n\n\n\n\n Integrating serverless apps \n\n[Binding IBM Cloud services to Cloud Functions entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices)\n\n\n\n* [Binding a service to an action or package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices_bind)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_11726-7-2061","score":13.291737,"text":"\nDisconnected use for Satellite components \n\nCertain features of IBM Cloud Satellite\u00ae can be used while disconnected temporarily. See the following table to understand the disconnected use for these components.\n\n\n\n Understanding disconnected usage \n\nWhat does disconnected usage mean?\n: When Satellite Locations and Red Hat OpenShift on IBM Cloud are disconnected from the parent managed-from region in IBM Cloud, they can still run with some limitations for a certain amount of time. The limitations of disconnected usage include no security fixes and no alerts. For more information, see [Disconnected usage by component](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-usedisconnect-usage-component).\n\nAre there additional requirements for disconnected usage?\n: Your location should still maintain network connection.\n\nHow do I set how long my access token is valid for?\n: Edit the value of the accessTokenMaxAgeSeconds parameter to set the token validity in seconds. For more information, see [Setting the disconnected usage time](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-usedisconnect-time).\n\nWhat happens when my token expires?\n: After your token expires, you will lose the ability to work with the Location. When you run a command, you will get error messages such as error: You must be logged in to the server (Unauthorized). To recover, you must reconnect the Location and log in again to retrieve a new token. Do not reload nodes before the Location is reconnected. Reloading nodes while the Location is disconnected prevents the Location from recovering.\n\nDo I need to re-create the Location?\n: No, you don't need to re-create the Location. You can reconnect the existing Location and reauthenticate to continue working with your Location.\n\nHow do I reauthenticate?\n: Reconnect your Location first and then log in again with your credentials.\n\nDo I have to recover etcd backup?\n: No, you don't need to recover etcd backup. The Location recovers automatically after you reconnect it and reauthenticate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-use"},{"document_id":"ibmcld_10534-109008-110371","score":13.153882,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyknowledge)\n\n\n\n* [Sizing your Red Hat OpenShift cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_resources)\n* [What else besides my app might use resources in the cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_other)\n* [What type of availability do I want my workload to have?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_availability)\n* [How many worker nodes do I need to handle my workload?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_workers)\n* [How do I monitor resource usage and capacity in my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_manage)\n\n\n\n* [Structuring your Red Hat OpenShift environment](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_multicluster)\n* [How can I set up my resources within the cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-1007575-1009533","score":13.076731,"text":"\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'\n\nThe combination of Source NAT and firewall achieves the required design goal.\n\nEnsure that the rules are appropriate for your design, and that no other rules allow traffic that should be blocked.\n* How do I protect the VRA itself with a zone-based firewall?\n\nThe VRA does not have a local zone. You can use the Control Plane Policing (CPP) functionality instead as it is applied as a local firewall on loopback.\n\nThis is a stateless firewall and you must explicitly allow the returning traffic of outbound sessions that originate on the VRA itself.\n* How do I restrict SSH and block connections that come from the internet?\n\nIt is considered a best practice to not allow SSH connections from the internet, and to use another means of accessing the private address, such as SSL VPN.\n\nBy default, the VRA accepts SSH on all interfaces. To listen only for SSH connections on the private interface, you must set the following configuration:\n\nset service ssh listen-address '10.1.2.3'\n\nKeep in mind that you must replace the IP address with the address that belongs to the VRA.\n\n\n\nPlatform Building infrastructure\n\n\n\n* What is the RMM server?\n\nRackWare Management Module (RMM) server is a software appliance that is offered by RackWare that replatforms your server from a VMware (on-premises or classic) to an IBM Cloud VPC virtual server instance.\n* Where can I find more information about the RMM server?\n\nFor RMM server overview information, see [RackWare's Cloud Migration](https:\/\/www.rackwareinc.com\/cloud-migration) documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-891912-893651","score":44.74481,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":44.74481,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-893091-894874","score":43.071587,"text":"\nIf you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n* Can I add tags to a volume?\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-892968-894751","score":43.071587,"text":"\nIf you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n* Can I add tags to a volume?\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n* What is IOPS and how do it relate to my Block Storage for VPC volume performance?\n\n What is IOPS and how do it relate to my Block Storage for VPC volume performance? \n\nInput\/output operations per second (IOPS) is used to measure the performance of your Block Storage for VPC volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15111-10169-12034","score":40.023964,"text":"\nBy using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n\n\n\n\n\n\n\n Performance questions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_07578-969419-971359","score":37.384567,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n* Can I map IBM Cloud services to a VPE from the service catalog?\n\nIBM Cloud services cannot be mapped to a VPE from the service catalog during the time of purchase.\n* Can I map an IBM Cloud service to a Public endpoint?\n\nPublic endpoints of IBM Cloud services are not eligible for VPE. VPE can be mapped only to a private endpoint of IBM Cloud services.\n* Is a VPE created in high-availability mode?\n\nA VPE is not created in high-availability (HA) mode, by default. HA comes primarily from the IBM Cloud service.\n* Can I access an IBM Cloud service by using a private service endpoint IP address?\n\nWhen an IBM Cloud service is created, IBM Cloud DNS Services are automatically set up to resolve the IBM Cloud service FQDN to the IBM Cloud private service address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-969295-971235","score":37.384567,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n* Can I map IBM Cloud services to a VPE from the service catalog?\n\nIBM Cloud services cannot be mapped to a VPE from the service catalog during the time of purchase.\n* Can I map an IBM Cloud service to a Public endpoint?\n\nPublic endpoints of IBM Cloud services are not eligible for VPE. VPE can be mapped only to a private endpoint of IBM Cloud services.\n* Is a VPE created in high-availability mode?\n\nA VPE is not created in high-availability (HA) mode, by default. HA comes primarily from the IBM Cloud service.\n* Can I access an IBM Cloud service by using a private service endpoint IP address?\n\nWhen an IBM Cloud service is created, IBM Cloud DNS Services are automatically set up to resolve the IBM Cloud service FQDN to the IBM Cloud private service address.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-967938-969769","score":37.285007,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n\n\n\n* Can I add tags to a Block Storage for VPC snapshot?\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-967814-969645","score":37.285007,"text":"\nFor more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there. However, the snapshot and ackup services do not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the snapshot can exist in each region. You can't create a copy of the snapshot in the source (local) region.\n\n\n\n* Can I add tags to a Block Storage for VPC snapshot?\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n* Can I use volume snapshot for disaster recovery?\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15007-5092-6710","score":37.008324,"text":"\nThe [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. When you opt for fast restore, your existing regional plan is adjusted, including billing. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Comparison of backups and snapshots \n\nBackups are in effect, backup snapshots. In the console, backups appear in the list of Block Storage for VPC snapshots. Backups are identified by how they were created, in this case, by backup policy. These terms are used interchangeably in the Documentation, depending on the context.\n\nThe snapshots service is used to create backups, similarities and differences exist between backups and snapshots. Table 1 compares backups to snapshots.\n\n\n\nTable 1. Comparison of backups and snapshots\n\n Feature Backup Snapshot \n\n Backs up Block Storage for VPC boot and data volumes. ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/checkmark-icon.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13108-7-2001","score":15.738252,"text":"\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/key-protect?topic=key-protect-about"},{"document_id":"ibmcld_16628-0-1541","score":15.729687,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_11164-6586-7646","score":15.658396,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_09864-5103-6606","score":15.4739685,"text":"\n\"moreInformation\": \"https:\/\/example.com\",\n\"queueManagerLocation\": \"qm.us-south.mq.appdomain.cloud\",\n\"queueManagers\": [{\n\"hostname\": \"qm1-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM1\"\n}, {\n\"hostname\": \"qm2-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM2\"\n}],\n\"region\": \"us-south\",\n\"serviceInstance\": \"crn:v1:staging:public:mqcloud:region:a\/ab90cde12f345:ab5c678d-e90a-b5678c9::\"\n}\nShow more\n\nThe notification will contain the following keys:\n\n\n\n* datestamp: the date and time the notification was sent\n* description: an explanation of the problem and what action was taken\n* moreInformation: this may contain an external link to further explain the cause behind the DR\n* queueManagerLocation: the location of the cluster on which the queue manager is deployed\n* queueManagers: a list of hostnames and names of all affected queue managers\n* region: the physical location of your service instance\n* serviceInstance: the unique CRN of the containing service instance\n\n\n\n\n\n\n\n How to implement the endpoint handler \n\nThe instructions below demonstrate some sample code to implement an endpoint handler to send notifications via PagerDuty in an IBM Cloud Function, but you could also adapt this code to run in a location of your choice\n\nNote: the below function is written in Node.js\n\nconst https = require('https');\n\nfunction main(params) {\n\nreturn new Promise((resolve, reject) => {\n\n\/\/ Replace the string \"R4nd0m5tr1ng0fCh4r4ct3r5\" with your own value to secure access to your own specific endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_dr_notifications"},{"document_id":"ibmcld_02718-7-2113","score":15.240459,"text":"\nVideos \n\nYou can watch the videos to learn more about App Configuration service.\n\n\n\n* Video transcript\n\nWhat are Feature Flags?\n\nBefore you begin playing the video: In this video, the narrator draws representational images on the display board to explain the concept. [Draw] is used to represent when the narrator draws the representational image. [Writing] is used to represent when the narrator writes some text.\n\nWhat if you could release a feature to different groups of users without deployment? Is there a way to effectively test features in production, and immediately roll them back if needed?\n\nHi, my name is Dilan Orrino with IBM Cloud. I'll be answering those questions by discussing feature flags, or sometimes referred to as feature toggle, or switches.\n\nFeature flags are conditions that encompass feature code that allow you to flip them on and off at will. Okay, let's use an example. [Draw] Let's say we've got an ice cream shop franchise that's looking to expand to a new city and we've got a [Draw] banner that we want to display on our website. We'll call this open banner. We only want to display this banner to users that are [Draw] nearby our new ice cream shop we can do this by using feature flags.\n\nThere's a couple benefits to using feature flags. [Writing] Number one is we can actually turn these on or off without deployment. [Writing] Number two is we can actually test directly in production. [Writing] And number three we can segment our users based on different attributes.\n\nOkay, there's a couple ways you can do this one way is by using properties in JSON files or config maps. There's a better way however by using a feature flag service.\n\n[Writing] There's a couple benefits to using a feature flag service. Number one is you can have essentially managed place for your features, or excuse me your feature flags. [Writing] Number two is you can turn these on and off without modifying your properties in your future, in your apps or web pages. [Writing] And number three is you get audit and usage data. It's harder to get the audit and usage data by using JSON files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_07146-4392-6391","score":14.905995,"text":"\nInput adapter \n\n\n\n* class - Internal use only; defines the Data Crawler input adapter class. The default value is: com.ibm.watson.crawler.connectorframeworkinputadapter.Crawl\n* config - Internal use only; defines the connector framework configuration. The default configuration key within this block to pass to the chosen input adapter is: connector_framework\n\nThe connector framework is what allows you to talk to your data. It could be internal data within the enterprise, or it could be external data on the web or in the cloud. The connectors allow access to a number of different data sources, while connecting is actually controlled by the crawling process.\n\nData retrieved by the Connector Framework Input Adapter is cached locally. It is not stored encrypted. By default, the data is cached to a temporary directory that you must clear after performing a reboot and it must be readable only by the user who executed the crawler command.\n\nThere is a chance that this directory can outlive the crawler if the connector framework is removed before it can clean up after itself. Consider the location for your cached data. You can put data on an encrypted filesystem, but that might have performance implications. Pick the appropriate balance between speed and security for your crawls.\n* crawl_config_file - The configuration file to use for the crawl. Default value is: connectors\/filesystem.conf\n* crawl_seed_file - The crawl seed file to use for the crawl. Default value is: seeds\/filesystem-seed.conf\n* id_vcrypt_file - Keyfile used for data encryption by the Crawler; the default key included with the crawler is id_vcrypt. Use the vcrypt script in the bin folder if you need to generate a new id_vcrypt file.\n* crawler_temp_dir - The Crawler temporary folder for connector logs. Default value, tmp, is provided. If it doesn't already exist, the tmp folder is created in the current working directory.\n* extra_jars_dir - Adds a directory of extra JARs to the connector framework classpath.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configuring-the-data-crawler"},{"document_id":"ibmcld_13878-13031-14791","score":14.896964,"text":"\nA similar flow is available for [Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-encryption) to encrypt VPC boot and data volumes.\n\n\n\n\n\n Example: Watson services \n\nMany solutions are based on services with artificial intelligence (AI). At IBM they are offered as [Watson services](https:\/\/cloud.ibm.com\/developer\/watson\/services). By default, all data is encrypted. In the Premium plans, you can enhance security by [taking control of the encryption keys (BYOK)](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice). After authorizing the service type, e.g., Watson Assistant, to access Key Protect, the following additional option is offered when creating an instance with Premium plan.\n\nZoom\n\n![Control encryption in Watson services](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution51-extended-app-security\/Sol51_WatsonBYOK.png)\n\nControl encryption in Watson services\n\n\n\n\n\n\n\n Organize and control access \n\nIBM Cloud includes many capabilities for fine-grained access control. Depending on your type of application, project, and account, the following features help you to organize who has access to the application resources and with what set of privileges.\n\n\n\n* [Service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids): Similar to how a user ID identifies a user, a service ID can identify a specific service or application, even a task. The service ID could be considered a \"technical user\". You can assign privileges to a service ID. Moreover, a service ID has its own IAM API keys to authenticate. Thus, a service ID can be used instead of a regular user ID, thereby simplifying resource management and increasing security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_07578-900427-902422","score":14.409382,"text":"\nYou can also revoke access at any time, for example, if you suspect your keys might be compromised. You can also disable or delete a root key, or temporarily revoke access to the key's associated data on the cloud. For more information, see [Managing root keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-manage-root-keys).\n* What are the advantages of using customer-managed encryption over provider-managed encryption?\n\n What are the advantages of using customer-managed encryption over provider-managed encryption? \n\nCustomer-managed encryption encrypts your Block Storage for VPC volumes by using your own root keys. You have complete control over your data security and grant IBM access to use your root keys. For more information, see [Advantages of customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-advantages).\n* What encryption technology is used for customer-managed encryption?\n\n What encryption technology is used for customer-managed encryption? \n\nVirtual disk images for VPC use QEMU Copy On Write Version 2 (QCOW2) file format. LUKS encryption format secures the QCOW2 format files. IBM currently uses the AES-256 cipher suite and XTS cipher mode options with LUKS. This combination provides you a much greater level of security than AES-CBC, along with better management of passphrases for key rotation, and provides key replacement options in case your keys are compromised.\n* What are master encryption keys and how are they assigned to my Block Storage for VPC volumes?\n\n What are master encryption keys and how are they assigned to my Block Storage for VPC volumes? \n\nEach volume is assigned a unique master encryption key, called a data encryption key or DEK, which is generated by the instance's host hypervisor. The master key for each Block Storage for VPC volume is encrypted with a unique KMS-generated LUKS passphrase, which is then encrypted by your customer root key (CRK) and stored in the KMS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-900304-902299","score":14.409382,"text":"\nYou can also revoke access at any time, for example, if you suspect your keys might be compromised. You can also disable or delete a root key, or temporarily revoke access to the key's associated data on the cloud. For more information, see [Managing root keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-manage-root-keys).\n* What are the advantages of using customer-managed encryption over provider-managed encryption?\n\n What are the advantages of using customer-managed encryption over provider-managed encryption? \n\nCustomer-managed encryption encrypts your Block Storage for VPC volumes by using your own root keys. You have complete control over your data security and grant IBM access to use your root keys. For more information, see [Advantages of customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-advantages).\n* What encryption technology is used for customer-managed encryption?\n\n What encryption technology is used for customer-managed encryption? \n\nVirtual disk images for VPC use QEMU Copy On Write Version 2 (QCOW2) file format. LUKS encryption format secures the QCOW2 format files. IBM currently uses the AES-256 cipher suite and XTS cipher mode options with LUKS. This combination provides you a much greater level of security than AES-CBC, along with better management of passphrases for key rotation, and provides key replacement options in case your keys are compromised.\n* What are master encryption keys and how are they assigned to my Block Storage for VPC volumes?\n\n What are master encryption keys and how are they assigned to my Block Storage for VPC volumes? \n\nEach volume is assigned a unique master encryption key, called a data encryption key or DEK, which is generated by the instance's host hypervisor. The master key for each Block Storage for VPC volume is encrypted with a unique KMS-generated LUKS passphrase, which is then encrypted by your customer root key (CRK) and stored in the KMS.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13878-1596-3665","score":14.020039,"text":"\nThis can be part of the regular activities of (agile) development and the next steps towards a fully secure app or by increasing requirements for an app already in production.\n\nIf you tried the tutorial on how to [apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security), you already know how to rotate service credentials. But there is far more to app security than regular changes of passwords and access keys. You may want to assess the application, its deployment and usage characteristics to better understand what needs to, could be and should be addressed. It helps you to move towards a [zero trust security model](https:\/\/en.wikipedia.org\/wiki\/Zero_trust_security_model). Moreover, depending on your industry, country and region, etc. there exist different [security and resiliency requirements](https:\/\/www.ibm.com\/cloud\/compliance). It could mean\n\n\n\n* to isolate the application, its services, the network traffic and stored data from those of other applications,\n* to encrypt data and have control over the management of encryption keys,\n* to log all kind of events, regularly analyze logs and keep them for audits or incident forensics,\n* to organize DevOps activities and the related teams with more fine-grained privileges,\n* and much more.\n\n\n\nTo assess your application and its resources, consider the [IBM Cloud\u00ae Security and Compliance Center](https:\/\/www.ibm.com\/cloud\/security-and-compliance-center). It allows to govern resource configurations. You can set up and manage security and compliance controls. Checks can be automated. Results are directly compared against defined controls, can be exported and integrated into a customized dashboard. Read how to [get started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started) for the first steps.\n\n\n\n\n\n Isolate runtime environments, networks traffic and data \n\nOne of the fundamental principles of Cloud Computing is the sharing of resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14598-9419-11893","score":34.203724,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_14774-27023-28718","score":33.22835,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14738-7598-10031","score":32.159737,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_08669-4740-6634","score":31.280996,"text":"\nYou are responsible for the security and compliance of your application data.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Applications Maintain controls that are commensurate to [various industry compliance standards](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-security-and-compliancecompliance-ready). Set up and maintain security and regulation compliance for your apps and data. For example, you can enable extra security settings to meet your compliance needs by choosing how and when to [import](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [wrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-wrap-keys), [rotate](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [rewrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-rewrap-keys), and [delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) keys. \n Encryption IBM is responsible for the encryption of keys. Keep your root of trust, the master key parts, on either your workstation or smart cards. \n Master key backups IBM never touches your master key. Backup your master key in a regular basis to your smart card or workstation. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_07578-891912-893651","score":30.62658,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":30.62658,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03543-5787-7061","score":30.52607,"text":"\n(https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Meet security and compliance objectives Maintain controls that are commensurate to various industry compliance standards such the Financial Services specification. Set up and maintain security and regulation compliance for your apps and data. \n\n\n\n\n\n\n\n Disaster recovery \n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Restore functionality for Activity Tracker Event Routing Automatically recover and restart Activity Tracker Event Routing components after any disaster event. <br>In case of a regional disaster, IBM Cloud service teams, who are responsible for the operations of services that generate auditing events, will point their service to Activity Tracker Event Routing endpoints in their alternate region within the same regulatory boundaries. [Complete the disaster recovery (DR) steps for Activity Tracker Event Routing](https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-ha_drdr-atracker). \n Backup Activity Tracker Event Routing components Daily backup of the Activity Tracker Event Routing infrastructure and components. N\/A \n\n\n\n[] Recovered and restarted service components will not have customer data reloaded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-shared-responsibilities"},{"document_id":"ibmcld_15843-7468-9604","score":30.329477,"text":"\nAudit records IBM provides audit records of the VPC resource lifecycle through IBM Cloud Activity Tracker. The Customer uses IBM Cloud Activity Tracker tooling to monitor audit records. \n Security groups and ACLs IBM provides the ability to restrict access to virtual server instances by using security groups and networks ACLs. The Customer uses security groups and network ACLs to secure their virtual server instances, such as restricting what IP addresses can SSH into the instance. \n Public Network Access IBM provides options to use a public gateway or floating IP addresses. The Customer chooses how to connect their workload to the public internet, if applicable, either through a public gateway or floating IP. \n Access restriction IBM provides security measures for customers to restrict access to resources and resource groups. The Customer restricts user access to the appropriate resources and resource groups. \n Activity tracker IBM provides logging and monitoring tools. The Customer integrates IBM Cloud Activity Tracker and IBM Cloud Monitoring data into their auditing and monitoring processes. \n Encryption IBM Cloud VPN for VPC supports encrypted traffic by using IKE\/IPsec policies. The Customer ensures that their connection is encrypted end-to-end, if required. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Load balancer and VPN disaster recovery IBM Cloud Load Balancer and VPN for VPC have off-site storage and replication of configuration data in an out-of-region disaster recovery node with daily backups. This data is fully managed by IBM Cloud and no customer input is required to ensure service recovery, although there can be up to a 24-hour loss of configuration data. The Customer sets up their backup and recovery strategies for workload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpc"},{"document_id":"ibmcld_00471-1736-4209","score":30.172369,"text":"\nSee [IBM Cloudant backup and recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery) documentation for recommended tooling. \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Scaling IBM scales infrastructure to meet capacity selected by the customer. Customer chooses the provisioned throughput capacity for their IBM Cloudant instances. \n Upgrades IBM handles all upgrades and patches of the IBM Cloudant service for the customer. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 3. Responsibilities for security and regulation compliance\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n At-rest encryption By default, IBM encrypts all disks by using IBM Cloudant-managed encryption keys. If the customer wants bring-your-own-key (BYOK) encryption, then the customer is required to use Key Protect to store the customer-managed encryption key. The customer must select an appropriate key management service instance, and select a disk encryption key option during provisioning of an IBM Cloudant Dedicated Hardware plan instance. \n Make data unreadable to IBM Cloudant Operators None, IBM does not render data unreadable to IBM Cloudant Operators. If you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-responsibilities"},{"document_id":"ibmcld_07285-5829-8487","score":29.636257,"text":"\nIdentity and access IBM provides the function to restrict access to resources through the IBM Cloud console and REST APIs. The Customer is responsible for managing access to resources through IBM Cloud Identity and Access Management (IAM). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks, such as security controls implementation and compliance certification.\n\n\n\nTable 5. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Encryption IBM does not provide encryption capabilities. The Customer is responsible for encryption of data on disk, in motion, and in backups. The Customer is also responsible for choosing and managing appropriate additional security features. If the Customer uses Key Protect (Bring Your Own Key), or another form of encryption, the Customer is responsible for managing the service authorization and keys. \n Security IBM is responsible for ensuring the security of data on disk and data in motion within its infrastructure. The Customer is responsible for restricting user access to the appropriate resources and resource groups. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks, such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Diversity IBM provides diverse network options for consumption. The Customer must ensure diversity of Direct Link is deployed. \n Redundancy IBM provides diverse network options for consumption. Direct Link is not a redundant service. The Customer is responsible for establishing redundancy, as needed, via BGP schema. The Customer must also understand that Direct Link is not a redundant service. While IBM Cloud supplies Diverse Router (XCR) options, failover must be built into the BGP scheme a customer deploys between multiple Direct Links. \n Host service in multiple regions IBM is responsible for hosting this service in multiple regions. The Customer is responsible for designing and deploying their workload in a way that achieves the wanted availability and Disaster Recovery capabilities by using provided tools. For example, deploy in different zones of a region, use at least two load balancers that are located in different zones, and either use DNS records to point to the load balancers, or ensure that your application can handle a list of IP addresses that it can connect to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02580-7-2046","score":16.384663,"text":"\nRobustness \n\n\n\n Tradeoffs of the robustness principle \n\nJon Postel's [robustness principle](https:\/\/en.wikipedia.org\/wiki\/Robustness_principle) is a fixture of software design and implementation advice. It states:\n\n> Be liberal in what you accept, and conservative in what you send.\n\nIn recent years, this counsel has [proven controversial](https:\/\/datatracker.ietf.org\/doc\/html\/draft-thomson-postel-was-wrong-03). For a number of reasons, this handbook discourages broad application of the principle. This is a reversal of [previous guidance](https:\/\/github.com\/ibm-cloud-docs\/api-handbook\/blob\/086d28c9357b39612ceb816130d0f6ad92f82859\/design\/errors.mdrobustness-tradeoffs).\n\n\n\n Historical meaning \n\nThere are many possible applications of the robustness principle, and its original context (as [highlighted](https:\/\/datatracker.ietf.org\/doc\/html\/draft-thomson-postel-was-wrong-03section-2) by Martin Thomson's dissent) is not applicable to new API design:\n\n> While the goal of this specification is to be explicit about the protocol there is the possibility of differing interpretations. In general, an implementation should be conservative in its sending behavior, and liberal in its receiving behavior.\n\nParaphrased, the narrower, original definition of the robustness principle states that if a protocol's specification exists apart from sundry implementations, a defensive implementor should react to ambiguity (which is a defect of the specification) with:\n\n\n\n* A broad interpretation of what constitutes valid input (but still only within the confines of what the specification leaves open to interpretation)\n* A narrow interpretation of what constitutes valid output\n\n\n\n\n\n\n\n\n\n Best practices \n\nWhen a service team is responsible for developing an API definition and its canonical implementation (the service) in concert, Postel's robustness principle SHOULD NOT be (mis)applied. This section details best practices that contradict adherence to the robustness principle as it is colloquially understood.\n\n\n\n Specificity of validity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustness"},{"document_id":"ibmcld_16729-236774-238783","score":14.996401,"text":"\nManaging your account, resources, and access\n\n\n\n* 20 minutes\n* 2023-03-03\n\n\n\n[Onboarding a virtual server image for VPC](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-vsivpc-tutorial)Onboarding a virtual server image for VPC\n\nThis tutorial walks you through how to onboard a sample virtual server image for virtual private cloud (VPC) to your account. By completing this tutorial, you learn how to create a private catalog, import the image, validate that it can be installed on a selected deployment target, and make the virtual server image available to users who have access to your account. As you complete the tutorial, adapt each step to match your organization's goal.\n\nObject Storage Virtual Private Cloud (VPC)\n\n+1\n\nManaging your account, resources, and access\n\n\n\n* 20 minutes\n* 2022-08-25\n\n\n\n[Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial)Leveraging context-based restrictions to secure your resources\n\nThis tutorial walks you through how to use context-based restrictions as an extra layer of protection to your resources. By completing this tutorial, you learn how to create network zones and rules that define access restrictions to specific resources based on context in addition to IAM identity. For more information, see What are context-based restrictions?\n\nManaging your account, resources, and access\n\n\n\n* 20 minutes\n* 2023-02-08\n\n\n\n[Customizing your IBM Cloud dashboard](https:\/\/cloud.ibm.com\/docs\/account?topic=account-tutorial-custom-dash)Customizing your IBM Cloud dashboard\n\nThis tutorial walks you through how to customize your dashboard in the IBM Cloud\u00ae console to ensure that what is displayed is relevant to you. By completing this tutorial, you learn how to create a new dashboard, add and organize widgets, duplicate a dashboard, share a dashboard with other users, and delete unused dashboards.\n\nManaging your account, resources, and access\n\n\n\n* 10 minutes\n* 2021-09-24","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16507-1455-3632","score":14.987139,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_07578-876467-878287","score":14.460426,"text":"\n* The bx2-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage only.\n* The bx2d-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage and 16 3.2 TB U.2 NVMe SSDs as secondary local storage to support vSAN, or user-managed RAID.\n\n\n\nVPC Block Storage is not supported. VPC File Storage is compatible when it becomes generally available.\n\nCurrently, IBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access. For more information about file storage, see [About File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n\nEncryption in transit is not supported on Bare Metal Servers for VPC.\n* What is required to set up my Bare Metal Servers for VPC?\n\nWhen you are planning to create the bare metal servers, you can go through the configuration checklist on [Planning for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n* What regions are Bare Metal Servers for VPC available?\n\nBare metal servers are available in eu-de, us-east, and us-south regions.\n* Do I need to configure multiple network interfaces on a bare metal server to support the full 100 Gbps bandwidth?\n\nNo. You can add as many or as few vNICs as you need. Every interface can take advantage of the 100 Gbps bandwidth, but the total aggregate is 100 Gbps for each server. Meaning that the bandwidth is shared by all the vNICs. For more information about networking on bare metal, see [Networking overview for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-bare-metal-servers-network).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-876344-878164","score":14.460426,"text":"\n* The bx2-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage only.\n* The bx2d-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage and 16 3.2 TB U.2 NVMe SSDs as secondary local storage to support vSAN, or user-managed RAID.\n\n\n\nVPC Block Storage is not supported. VPC File Storage is compatible when it becomes generally available.\n\nCurrently, IBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access. For more information about file storage, see [About File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n\nEncryption in transit is not supported on Bare Metal Servers for VPC.\n* What is required to set up my Bare Metal Servers for VPC?\n\nWhen you are planning to create the bare metal servers, you can go through the configuration checklist on [Planning for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n* What regions are Bare Metal Servers for VPC available?\n\nBare metal servers are available in eu-de, us-east, and us-south regions.\n* Do I need to configure multiple network interfaces on a bare metal server to support the full 100 Gbps bandwidth?\n\nNo. You can add as many or as few vNICs as you need. Every interface can take advantage of the 100 Gbps bandwidth, but the total aggregate is 100 Gbps for each server. Meaning that the bandwidth is shared by all the vNICs. For more information about networking on bare metal, see [Networking overview for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-bare-metal-servers-network).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03367-4-2117","score":14.263442,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Phone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by your dialog or actions \n\n\n\nVoice context variables set by the dialog or actions\n\n Name Type Description Default \n\n final_utterance_timeout_count Number The time (in milliseconds) that the phone integration waits to receive a final utterance from the Speech to Text service. The timeout occurs if the phone integration does not receive a final utterance within the specified time limit, even if hypotheses continue to be generated. When the timeout occurs, the phone integration sends Watson Assistant a text update that includes the word vgwFinalUtteranceTimeout to indicate that no final utterance was received. N\/A \n post_response_timeout_count Number The time (in milliseconds) to wait for a new utterance after the response is played back to the caller. When this timeout occurs, the phone integration channel sends a text message to the assistant that includes the word vgwPostResponseTimeout and sets the context variable input.integrations.voice_telephony.post_response_timeout_occurred to true. 7000 \n turn_settings.timeout_count Number The time (in milliseconds) to wait for a response from Watson Assistant. If this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_16507-7-2044","score":14.065369,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7-2064","score":14.031749,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_15054-1412-3297","score":13.979861,"text":"\n* The bx2d-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage and 16 3.2 TB U.2 NVMe SSDs as secondary local storage to support vSAN, or user-managed RAID.\n\n\n\nVPC Block Storage is not supported. VPC File Storage is compatible when it becomes generally available.\n\nCurrently, IBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access. For more information about file storage, see [About File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about).\n\nEncryption in transit is not supported on Bare Metal Servers for VPC.\n\n\n\n\n\n What is required to set up my Bare Metal Servers for VPC? \n\nWhen you are planning to create the bare metal servers, you can go through the configuration checklist on [Planning for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n\n\n\n\n\n What regions are Bare Metal Servers for VPC available? \n\nBare metal servers are available in eu-de, us-east, and us-south regions.\n\n\n\n\n\n Do I need to configure multiple network interfaces on a bare metal server to support the full 100 Gbps bandwidth? \n\nNo. You can add as many or as few vNICs as you need. Every interface can take advantage of the 100 Gbps bandwidth, but the total aggregate is 100 Gbps for each server. Meaning that the bandwidth is shared by all the vNICs. For more information about networking on bare metal, see [Networking overview for bare metal servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-bare-metal-servers-network).\n\n\n\n\n\n How many NVMe drives does a bare metal server support? \n\nThe number NVMe drives that are supported depends on the profile that you select.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-bare-metal-server-faq"},{"document_id":"ibmcld_03313-1523-3328","score":13.921768,"text":"\nContext variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11510-1711-3630","score":18.677322,"text":"\nWhat are the benefits of using Qiskit Runtime? \n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n\n\n\n\n\n What are Qiskit Runtime primitives? \n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications. In particular, the Sampler primitive allows a developer to investigate a nonclassical quasi-probability distribution produced by the output of a quantum circuit. The Estimator primitive allows a developer to measure quantum observables on the output of quantum circuits.\n\n\n\n\n\n How is the Qiskit Runtime service offering different from IBM Quantum Experience? \n\nWhether accessing it through IBM Cloud\u00ae or directly through IBM Quantum Experience, users can harness the power of Qiskit Runtime. Qiskit Runtime on IBM Cloud\u00ae allows users to pay only for what they use, and also makes it easy to integrate your quantum computing work with your other IBM Cloud\u00ae tools.\n\n\n\n\n\n Which URLs should I add to our firewall whitelist for IBM Quantum access? \n\n\n\n* IBM Quantum API: .quantum-computing.ibm.com\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n\n\n\n\n What plans are available to use Qiskit Runtime with IBM Cloud\u00ae? \n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n\n\n\n\n\n What is the cost of the Qiskit Runtime Standard plan? \n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_11510-7-2157","score":18.05479,"text":"\nFAQs for IBM Cloud Qiskit Runtime \n\nTo find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is Qiskit Runtime service? \n\nQiskit Runtime service is a runtime environment through the IBM Cloud that provides access to the IBM Quantum processors and simulators. They allow users to run quantum programs, which require specialized quantum hardware that is coupled closely with traditional \u201cclassical\u201d, computer hardware.\n\n\n\n\n\n Why is IBM launching Qiskit Runtime service? \n\nIBM made quantum computers available through the cloud in 2016. In 2022, IBM integrates with IBM Cloud\u00ae accounts to offer Qiskit Runtime API access. This access creates a smoother customer experience and the ability to combine Qiskit Runtime with other kinds of cloud compute resources for their particular workflow or application.\n\n\n\n\n\n What can Qiskit Runtime service not do? \n\nQiskit Runtime service provides access to IBM Quantum systems. Today\u2019s quantum systems are somewhat constrained in the size of problems that they can address due to available scale and quantum volume. Nonetheless, these systems can already be used to solve small problems and to explore this new and exciting field.\n\n\n\n\n\n What skills are required to use the Qiskit Runtime service? \n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.\n\n\n\n\n\n What are the benefits of using Qiskit Runtime? \n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n\n\n\n\n\n What are Qiskit Runtime primitives? \n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_11513-1866-3892","score":17.60644,"text":"\nIt is defined through the catalog. You can define several service instances based on the same or different plans, which offer access to different quantum computing backends. See [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) for more details.\n* Project: A grouping unit that enables users to work on the same resources. This tutorial uses two projects; ml and finance. See [Hierarchical project structures](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-considerations-orgnest-org) for more information.\n\nThis project is not related to the \"project\" concept in IBM Quantum Platform.\n\n\n\n\n\n\n\n\n\n Step 1: Plan your setup \n\nBefore you set up Qiskit Runtime for your organization, you need to make these decisions:\n\n\n\n* How are user identities defined? You can set up IBM Cloud users, users from another IDP, or both.\n\n\n\n* If you are using a different IDP, does the Cloud administrator or the IDP administrator assign users to project resources?\n* If the IDP administrator assigns users to projects, you need a string to be used as a key, such as project (which this tutorial uses) for project comparisons.\n\n\n\n* What are the projects and which service instances will belong to each? You must plan your project names carefully.\n\n\n\n* Do not make project names substrings of another. For example, if you use ml and chemlab for project names, then later you set up a project match for ml, it triggers on both values, accidentally granting more access than expected. Instead, use unique names such as ml and chem-lab. Alternatively, use prefix or suffix values to avoid such unintended substring matches.\n* Using naming conventions, along with prefix or suffix values can help you easily allow access to several projects.\n* Quantum experiments (jobs) belong to service instances, and users that have access to an instance can see its jobs.\n* Service instances can be based on different plans, allowing access to different backends like real devices or simulators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-quickstart-org"},{"document_id":"ibmcld_10568-2761-4463","score":17.508139,"text":"\n: Explore [IBM Cloud Satellite](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqs) to extend the flexibility and scalability of IBM Cloud into your on-premises, edge, or other cloud provider environments.\n\n\n\n\n\n Can I automate my infrastructure deployments? \n\nIf you want to run your app in multiple clusters, public and private environments, or even multiple cloud providers, you might wonder how you can make your deployment strategy work across these environments.\n\nYou can use the open source [Terraform](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-getting-startedgetting-started) tool to automate the provisioning of IBM Cloud infrastructure, including Kubernetes clusters. Follow along with this tutorial to [plan, create, and update deployment environments](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-plan-create-update-deploymentsplan-create-update-deployments). After you create a cluster, you can also set up the [Red Hat OpenShift on IBM Cloud cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc) so that your worker pool scales up and down worker nodes in response to your workload's resource requests.\n\n\n\n\n\n What kind of apps can I run? Can I move existing apps, or do I need to develop new apps? \n\nYour containerized app must be able to run on the supported operating system, RHEL 7 or RHEL 8. You also want to consider the statefulness of your app. For more information about the kinds of apps that can run in Red Hat OpenShift on IBM Cloud, see [Planning app deployments](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployapp_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategy"},{"document_id":"ibmcld_10916-13226-15484","score":17.319952,"text":"\nSee also [host](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2002243).\n\n\n\n\n\n\n\n client secret \n\nA piece of information that is used with an application key to verify the identity of an application. An API can be configured to require that client applications supply their application secret with their application key. The application secret functions effectively as a password known only to the application. The application secret is passed by the client using an HTTP query parameter.\n\n\n\n\n\n cloud computing \n\nA computing platform where users can have access to applications or computing resources, as services, from anywhere through their connected devices. A simplified user interface or application programming interface (API), or both, makes the infrastructure supporting such services transparent to users.\n\n\n\n\n\n cloud portability \n\nThe ability to move applications and services across public or private cloud computing environments, or from different cloud providers.\n\n\n\n\n\n cloud provider \n\nAn organization that provides cloud computing resources.\n\n\n\n\n\n cloud resource name (CRN) \n\nA globally unique identifier for a specific cloud resource. The value is segmented hierarchically by version, instance, type, location, and scope, separated by colons.\n\n\n\n\n\n command-line interface (CLI) \n\nA computer interface in which the input and output are text based.\n\n\n\n\n\n community \n\nA collection of consumer organizations. It is used as a grouping construct when publishing APIs. Communities are used to restrict the visibility and accessibility of APIs.\n\n\n\n\n\n component \n\nIn source control management, a grouping of related artifacts in a stream or repository workspace. A component can contain any number of folders and files.\n\n\n\n\n\n compute \n\nInfrastructure or resources that serve as the basis for building apps in the cloud.\n\n\n\n\n\n config rule \n\nSee [configuration rule](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3084914).\n\n\n\n\n\n configuration rule (config rule) \n\nA JSON document that defines the configuration of resources and validates the compliance based on security requirements when a resource is created or modified.\n\n\n\n\n\n confusion matrix \n\nA table that provides a detailed numeric breakdown of annotated document sets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_06128-2751-4615","score":17.188871,"text":"\n: Explore [IBM Cloud Satellite](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqs) to extend the flexibility and scalability of IBM Cloud into your on-premises, edge, or other cloud provider environments.\n\n\n\n\n\n Can I automate my infrastructure deployments? \n\nIf you want to run your app in multiple clusters, public and private environments, or even multiple cloud providers, you might wonder how you can make your deployment strategy work across these environments.\n\nYou can use the open source [Terraform](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-getting-startedgetting-started) tool to automate the provisioning of IBM Cloud infrastructure, including Kubernetes clusters. Follow along with this tutorial to [plan, create, and update deployment environments](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-plan-create-update-deploymentsplan-create-update-deployments). After you create a cluster, you can also set up the [IBM Cloud Kubernetes Service cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-classic-vpc) so that your worker pool scales up and down worker nodes in response to your workload's resource requests.\n\n\n\n\n\n What kind of apps can I run? Can I move existing apps, or do I need to develop new apps? \n\nYour containerized app must be able to run on the supported operating system, RHEL 7 . You also want to consider the statefulness of your app. For more information about the kinds of apps that can run in IBM Cloud Kubernetes Service, see [Planning app deployments](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deployapp_types).\n\nIf you already have an app, you can [migrate it to IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploymigrate_containerize).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_07578-261594-263338","score":16.87799,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-261568-263312","score":16.87799,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-259882-261964","score":16.466473,"text":"\n* What skills are required to use the Qiskit Runtime service?\n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.\n* What are the benefits of using Qiskit Runtime?\n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n* What are Qiskit Runtime primitives?\n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications. In particular, the Sampler primitive allows a developer to investigate a nonclassical quasi-probability distribution produced by the output of a quantum circuit. The Estimator primitive allows a developer to measure quantum observables on the output of quantum circuits.\n* How is the Qiskit Runtime service offering different from IBM Quantum Experience?\n\nWhether accessing it through IBM Cloud\u00ae or directly through IBM Quantum Experience, users can harness the power of Qiskit Runtime. Qiskit Runtime on IBM Cloud\u00ae allows users to pay only for what they use, and also makes it easy to integrate your quantum computing work with your other IBM Cloud\u00ae tools.\n* Which URLs should I add to our firewall whitelist for IBM Quantum access?\n\n\n\n* IBM Quantum API: .quantum-computing.ibm.com\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-259856-261938","score":16.466473,"text":"\n* What skills are required to use the Qiskit Runtime service?\n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.\n* What are the benefits of using Qiskit Runtime?\n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n* What are Qiskit Runtime primitives?\n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications. In particular, the Sampler primitive allows a developer to investigate a nonclassical quasi-probability distribution produced by the output of a quantum circuit. The Estimator primitive allows a developer to measure quantum observables on the output of quantum circuits.\n* How is the Qiskit Runtime service offering different from IBM Quantum Experience?\n\nWhether accessing it through IBM Cloud\u00ae or directly through IBM Quantum Experience, users can harness the power of Qiskit Runtime. Qiskit Runtime on IBM Cloud\u00ae allows users to pay only for what they use, and also makes it easy to integrate your quantum computing work with your other IBM Cloud\u00ae tools.\n* Which URLs should I add to our firewall whitelist for IBM Quantum access?\n\n\n\n* IBM Quantum API: .quantum-computing.ibm.com\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05707-4888-6797","score":13.083746,"text":"\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https:\/\/www.ibm.com\/docs\/en\/cloud-private\/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_04489-25567-27336","score":12.734581,"text":"\nibmcloud ks cluster config --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster create classic \n\nClassic infrastructure\n\nCreate a cluster with worker nodes on classic infrastructure. For free clusters, you specify the cluster name; everything else is set to a default value. A free cluster is automatically deleted after 30 days. You can have one free cluster at a time. To take advantage of the full capabilities of Kubernetes, create a standard cluster.\n\nibmcloud ks cluster create classic [--hardware HARDWARE] --zone ZONE --flavor FLAVOR --name NAME [--operating-system UBUNTU_20_64|UBUNTU_18_64] [--version MAJOR.MINOR.PATCH] [--no-subnet] [--sm-group GROUP] [--sm-instance INSTANCE] [--private-vlan PRIVATE_VLAN] [--public-vlan PUBLIC_VLAN] [--private-only] [--gateway-enabled] [--private-service-endpoint] [--public-service-endpoint] [--workers WORKER] [--disable-disk-encrypt] [--pod-subnet SUBNET] [--service-subnet SUBNET] [--skip-advance-permissions-check] [-q]\n\nTo create a VPC cluster, use the [ibmcloud ks cluster create vpc-gen2 command](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clicli_cluster-create-vpc-gen2) instead.\n\nMinimum required permissions\n: Administrator platform access role for IBM Cloud Kubernetes Service at the account level\n: Administrator platform access role for IBM Cloud Container Registry at the account level\n: Super User role for IBM Cloud infrastructure\n\nCommand options:\n\n--hardware HARDWARE\n: The level of hardware isolation for your worker node. Use dedicated so that available physical resources are dedicated to you only, or shared to allow physical resources to be shared with other IBM customers. The default is shared. This value is optional for VM standard clusters and is not available for free clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_16729-266570-268549","score":12.698762,"text":"\n[Deploying server pools and origins in a single MZR](https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-ha-pools-origins)Deploying server pools and origins in a single MZR\n\nUse this tutorial to deploy availability pools in a VPC for a single MZR. Creating server pools with origins provides your DevOps team with a staging environment so they can validate near-production ready code in parallel with an existing production environment.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+3\n\nIBM Cloud Load Balancer,Cloud Internet Services (CIS),High availability and resiliency for infrastructure\n\n\n\n* 2021-06-10\n\n\n\n[Deploying critical applications with IBM Cloud MZR](https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-multi-zone-resiliency)Deploying critical applications with IBM Cloud MZR\n\nThis tutorial walks you through setting up a resilient environment for an n-tier application in an IBM Cloud\u00ae MZR. In this tutorial, you create your own VPC in region 1, then create subnets in two different zones of region 1, then you provision the virtual server instances. You create two availability zones and virtual server instances in each availability zone for UI, application, and db.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+2\n\nIBM Cloud Load Balancer,High availability and resiliency for infrastructure\n\n\n\n* 45 minutes\n* 2021-09-03\n\n\n\n[Try out IBM Cloud, for free](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free)Try out IBM Cloud, for free\n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\nIBM Cloud overview\n\n\n\n* 10 minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_04031-1609-3779","score":12.593313,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03994-15948-17676","score":12.429106,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_14868-2707-4225","score":12.281417,"text":"\nManual IP address ranges supported 172.16.0.0\/12, 192.168.0.0\/16, 10.254.0.0\/16, any public IP addresses \n Bring Your Own IP (BYOIP) Supports BYOIP for non-overlapping RFC-1918 IP ranges between VPC networks and on-premise networks (see [Routing considerations for IANA-registered IP assignments](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-interconnectivityrouting-considerations-iana) for details). ADDITIONAL NOTE: While we are focussed on a VPC environment, in some cases you may still have resources on IBM Classic Infrastructure which you will need to include as part of the on-prem connectivity. Be aware that IBM Classic Infrastructure uses a 10.0.0.0\/8 range so additional considerations with BYOIP may need to be made as described in the [documentation](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-interconnectivityrouting-considerations-iana). \n MACsec MACsec support is available in CHI01 and WDC02. Compatible with Cisco switches. \n Bi-directional Forwarding Detection(BFD) All MZRs have Direct Link (2.0) offering support. \n Billing\/Pricing Metered based on the data utilization and unmetered flat rate support. Inbound data transfer to IBM Cloud is free. Data transfer for [egress](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-pricing-for-ibm-cloud-dlmetered-data-transfer-charge) varies based on region. Global routing (access to all IBM Cloud data centers globally) is free. \n\n\n\n\n\n\n\n Connection Patterns \n\nThe following pattern depicts how individual infrastructure (VPC and Classic) can be added as connections !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-directlink"},{"document_id":"ibmcld_14868-3827-5504","score":12.252024,"text":"\nInbound data transfer to IBM Cloud is free. Data transfer for [egress](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-pricing-for-ibm-cloud-dlmetered-data-transfer-charge) varies based on region. Global routing (access to all IBM Cloud data centers globally) is free. \n\n\n\n\n\n\n\n Connection Patterns \n\nThe following pattern depicts how individual infrastructure (VPC and Classic) can be added as connections ![dl-directconnections](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/directlink\/DL_Pattern_VPC_DirectConnections.png) In above pattern, each connections has its own VRF and connection#1 prefixes cannot communicate with connection#2 prefixes by default.\n\nThe following pattern depicts how Transit Gateway (VPC and Classic) can be added as connection and advertise all the learnt routes from VPC and Classic infrastructure across accounts ![dl-directconnections](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/directlink\/DL_Pattern_VPC_TransitGW.png) In above pattern, transit GW will provide connections across infrastructures within IBMCloud and as well advertise all its prefixes to Directlink GW\n\n\n\n\n\n Ordering Direct Link \n\n\n\n* Detailed steps (including screenshots) to order Direct Link Dedicated are available in the [documentation](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-how-to-order-ibm-cloud-dl-dedicated).\n* Detailed steps (including screenshots) to order Direct Link Connect are available in the [documentation](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-how-to-order-ibm-cloud-dl-connect)\n\n\n\n\n\n\n\n Next Steps \n\nThe next step on the deployment journey is:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-directlink"},{"document_id":"ibmcld_04645-5074-6875","score":11.880663,"text":"\nFree level of service [Yes, free tier available, that re-sets every month](https:\/\/www.ibm.com\/cloud\/code-engine\/pricing) [Yes, free limited cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov) No \n Latest community Kubernetes distribution Yes. IBM Cloud Code Engine is built on IBM Cloud Kubernetes Service. Yes Partially. Support is as close as possible to the latest major version.For example, right now OpenShift 4.10 is on Kubernetes 1.23, but we offer OpenShift 4.9 right now, which is on Kubernetes 1.22. Support is typically offered on the Kubernetes N-1 version. \n Scope IBM Cloud IAM access policies to access groups for service access roles that sync to cluster RBAC Yes Yes No \n Classic infrastructure cluster on only the private network Not applicable, built on Gen2 infrastructure. Yes No \n GPU bare metal worker nodes No Yes (but only for Classic, not for VPC) Yes (but only for Classic, not for VPC) \n Integrated IBM Cloud Paks and middleware Not applicable Not applicable Yes \n Built-in containers, builds, and tooling Yes No Yes \n Integrated CI\/CD Yes (with IBM Cloud Toolchain) No Yes (with Jenkins) \n Stricter app security context set up by default Yes No Yes \n Simplified Kubernetes developer experience, with an app console that is suited for beginners Yes No Yes \n Supported operating system Worker node OS same as IKS Container level OS (if using Docker) is what is supplied in the dockerfile Container level OS (if using buildpack) supports all runtimes available on paketo.io Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated) Red Hat Enterprise Linux 7 (RHEL); however, as of 4.9, it will be CoreOS (RHCOS) \n Secured routes encrypted with Hyper Protect Crypto Services No No Yes \n Subscribe to event producers, such as Cloud Object Storage and Cron Yes Yes Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecation_option_comparison"},{"document_id":"ibmcld_04031-10086-11557","score":11.785324,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_05707-6437-8139","score":11.744554,"text":"\nIf you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters). Then, [copy your deployment configuration files](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster) from your free cluster into the standard cluster.\n\n\n\nCharacteristics of free and standard clusters\n\n Characteristics Free clusters Standard clusters \n\n [In-cluster networking](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork) Yes Yes \n [Public network app access by a NodePort service to a non-stable IP address](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) Yes Yes \n [User access management](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_policies) Yes Yes \n [IBM Cloud service access from the cluster and apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingbind-services) Yes Yes \n [Disk space on worker node for non-persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan) Yes Yes \n [Provision Red Hat OpenShift clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started) Yes \n [Create clusters in a Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial) Yes \n [Ability to create cluster in every IBM Cloud Kubernetes Service region](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zones) Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03249-24299-25668","score":15.494221,"text":"\n\"conditions\": \"no\",\n\"output\":{\n\"text\": {\n\"values\": [\n\"Let's try this again. Tell me what size pizza\nyou want and the time...\"\n]\n}\n},\n\"context\":{\n\"size\": null,\n\"time\": null,\n\"confirmation\": null\n}\n}\nShow more\n\n\n\n\n\n Collecting summary information from the customer \n\nYou might want to prompt a user to supply free form text in a dialog node with slots that you can save and refer to later. To do so, follow these steps:\n\n\n\n1. In the Check for field, add the following special property: slot_in_focus.\n2. Optionally, change the context variable name for the slot in the Save it as field. For example, you might want to change it to something like summary.\n3. In the If not present, ask field, ask the user to provide open-ended information. For example, Can you summarize the problem?\n4. To store the input in the customer's exact words, edit what is saved by using the JSON editor.\n5. Open the slot to edit it by clicking the Customize slot![Customize slot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/edit-slot.png) icon. From the Options![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) menu, open the JSON editor.\n6. Change the context variable value.\n\nThe value will look like this:\n\n{\n\"context\": {\n\"summary\": \"slot_in_focus\"\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_03249-20442-21975","score":14.693767,"text":"\nYou can use the JSON editor for the slot to reformat the time value as you save it so it uses the hour:minutes AM\/PM format instead:\n\n{\n\"context\":{\n\"time\": \"<? @sys-time.reformatDateTime('h:mm a') ?>\"\n}\n}\n\nSee [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods) for other reformatting ideas.\n\n\n\n\n\n Dealing with zeros \n\nUsing @sys-number in a slot condition is helpful for capturing any numbers that users specify in their input. However, it does not behave as expected when users specify the number zero (0). Instead of treating zero as a valid number, the condition is evaluated to false, and your assistant prompts the user for a number again. To prevent this behavior, check for an @sys-number mention that is greater than or equal to zero in the slot condition.\n\nTo ensure that a slot condition that checks for number mentions deals with zeros properly, complete the following step:\n\n\n\n1. Add @sys-number >= 0 to the slot condition field, and then provide the context variable name and text prompt.\n\nWhat you check for in the input is also what is saved in the slot context variable. However, in this case, you want only the number (such as 5) to be saved. You do not want to save 5 > = 0. To change what is saved, you must edit the value of the context variable.\n2. Open the slot to edit it by clicking the Customize slot![Customize slot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/edit-slot.png) icon. From the Options!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_00375-9153-11195","score":14.614614,"text":"\nNo. DV SAN certificate configurations are provided to you at no additional charge that is compared with HTTP or HTTPS with a Wildcard certificate.\n\n\n\n\n\n Can my CDN created using HTTPS with Wildcard be updated to use a DV SAN certificate? \n\nNo, a wildcard mapping cannot be changed to SAN certificate.\n\n\n\n\n\n What is a certificate authority? \n\nA certificate authority (CA) is an entity that issues digital certificates.\n\n\n\n\n\n Which CA does IBM Cloud\u00ae CDN service use for issuing a DV SAN certificate? \n\nIBM Cloud CDN service uses LetsEncrypt certificate authority.\n\n\n\n\n\n What SSL certificates are supported for IBM Cloud CDN? \n\nThe SSL certificates that are supported are Wildcard certificate and Domain Validation (DV) Subject Alternate Name (SAN) certificate. The SAN certificate is shared across multiple customers. IBM Cloud CDN does not support uploading custom certificates.\n\n\n\n\n\n I received an email asking me to address a Domain Validation challenge that is related to my CDN. What do I do now? \n\nDomain Validation can be addressed in one of three ways: CNAME, Standard, or Direct.\n\nFor details on how to address any of these, refer to the [Completing Domain Control Validation for HTTPS](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-completing-domain-control-validation-for-https-with-dv-saninitial-steps-to-domain-control-validation) document.\n\n\n\n\n\n What will happen if I don't address the challenge for domain validation of my CDN? \n\nIf the mapping's state is in DOMAIN_VALIDATION_PENDING state for more than 48 hours, the mapping creation is cancelled, and the mapping's state will be CREATE_ERROR. And in this state, you can choose to Retry creation or delete the mapping.\n\n\n\n\n\n Does a Wildcard certificate need to validate a domain for my CDN? \n\nNo, but you can only use the CNAME to retrieve content from your origin. For example, https:\/\/www.example-cname.cdn.appdomain.cloud.\n\n\n\n\n\n I received an email indicating that my domains is not pointed to IBM CDN CNAME. What do I do now? \n\nThis email means that your CDN is not being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-https"},{"document_id":"ibmcld_16507-7-2044","score":14.520828,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_07578-787665-789603","score":14.498291,"text":"\n* Is there any additional cost associated with using a DV SAN certificate for my CDN?\n\nNo. DV SAN certificate configurations are provided to you at no additional charge that is compared with HTTP or HTTPS with a Wildcard certificate.\n* Can my CDN created using HTTPS with Wildcard be updated to use a DV SAN certificate?\n\nNo, a wildcard mapping cannot be changed to SAN certificate.\n* What is a certificate authority?\n\nA certificate authority (CA) is an entity that issues digital certificates.\n* Which CA does IBM Cloud\u00ae CDN service use for issuing a DV SAN certificate?\n\nIBM Cloud CDN service uses LetsEncrypt certificate authority.\n* What SSL certificates are supported for IBM Cloud CDN?\n\nThe SSL certificates that are supported are Wildcard certificate and Domain Validation (DV) Subject Alternate Name (SAN) certificate. The SAN certificate is shared across multiple customers. IBM Cloud CDN does not support uploading custom certificates.\n* I received an email asking me to address a Domain Validation challenge that is related to my CDN. What do I do now?\n\nDomain Validation can be addressed in one of three ways: CNAME, Standard, or Direct.\n\nFor details on how to address any of these, refer to the [Completing Domain Control Validation for HTTPS](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-completing-domain-control-validation-for-https-with-dv-saninitial-steps-to-domain-control-validation) document.\n* What will happen if I don't address the challenge for domain validation of my CDN?\n\nIf the mapping's state is in DOMAIN_VALIDATION_PENDING state for more than 48 hours, the mapping creation is cancelled, and the mapping's state will be CREATE_ERROR. And in this state, you can choose to Retry creation or delete the mapping.\n* Does a Wildcard certificate need to validate a domain for my CDN?\n\nNo, but you can only use the CNAME to retrieve content from your origin. For example, https:\/\/www.example-cname.cdn.appdomain.cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-787538-789476","score":14.498291,"text":"\n* Is there any additional cost associated with using a DV SAN certificate for my CDN?\n\nNo. DV SAN certificate configurations are provided to you at no additional charge that is compared with HTTP or HTTPS with a Wildcard certificate.\n* Can my CDN created using HTTPS with Wildcard be updated to use a DV SAN certificate?\n\nNo, a wildcard mapping cannot be changed to SAN certificate.\n* What is a certificate authority?\n\nA certificate authority (CA) is an entity that issues digital certificates.\n* Which CA does IBM Cloud\u00ae CDN service use for issuing a DV SAN certificate?\n\nIBM Cloud CDN service uses LetsEncrypt certificate authority.\n* What SSL certificates are supported for IBM Cloud CDN?\n\nThe SSL certificates that are supported are Wildcard certificate and Domain Validation (DV) Subject Alternate Name (SAN) certificate. The SAN certificate is shared across multiple customers. IBM Cloud CDN does not support uploading custom certificates.\n* I received an email asking me to address a Domain Validation challenge that is related to my CDN. What do I do now?\n\nDomain Validation can be addressed in one of three ways: CNAME, Standard, or Direct.\n\nFor details on how to address any of these, refer to the [Completing Domain Control Validation for HTTPS](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-completing-domain-control-validation-for-https-with-dv-saninitial-steps-to-domain-control-validation) document.\n* What will happen if I don't address the challenge for domain validation of my CDN?\n\nIf the mapping's state is in DOMAIN_VALIDATION_PENDING state for more than 48 hours, the mapping creation is cancelled, and the mapping's state will be CREATE_ERROR. And in this state, you can choose to Retry creation or delete the mapping.\n* Does a Wildcard certificate need to validate a domain for my CDN?\n\nNo, but you can only use the CNAME to retrieve content from your origin. For example, https:\/\/www.example-cname.cdn.appdomain.cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03233-4-2095","score":14.490136,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Personalizing the dialog with context \n\nTo personalize the conversation, your assistant can collect information from the customer and then refer back to it later in the conversation.\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame. The maximum session inactivity time allowed ranges from 5 minutes to 7 days, depending on your plan type. If you do not add the dialog skill to an assistant, it is your responsibility as the custom application developer to maintain any continuing information that the application needs.\n\nThe application can pass information to the dialog, and the dialog can update this information and pass it back to the application, or to a subsequent node. The dialog does so by using context variables.\n\n\n\n\n\n Context variables \n\nA context variable is a variable that you define in a node. You can specify a default value for it. Other nodes, application logic, or user input can subsequently set or change the value of the context variable.\n\nYou can condition against context variable values by referencing a context variable from a dialog node condition to determine whether to execute a node. You can also reference a context variable from dialog node response conditions to show different reponses depending on a value provided by an external service or by the user.\n\nLearn more:\n\n\n\n* [Passing context from the application](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-from-app)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context"},{"document_id":"ibmcld_10203-1442-2892","score":14.486456,"text":"\nThe Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, use the oc new-app[command](https:\/\/docs.openshift.com\/container-platform\/4.11\/cli_reference\/openshift_cli\/developer-cli-commands.htmlnew-app). For example, you might refer to a public GitHub repo, a public GitLab repo with a URL that ends in .git, or another local or remote repo. For more information, [try out the tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorialopenshift_deploy_app) and review the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10439-9384-11084","score":14.425556,"text":"\nIf you have an app that runs with root permissions, you must modify your deployment to work with the [security context constraints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_scc) that are set for your Red Hat OpenShift cluster. For example, you might set up your project with a service account to control privileged access, and then modify your deployment to use this service account.\n\nBefore you begin: [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n\n\n\n1. As a cluster administrator, create a project.\n\noc adm new-project <project_name>\n2. Target the project so that the subsequent resources that you create are in the project namespace.\n\noc project <project_name>\n3. Create a service account for the project.\n\noc create serviceaccount <sa_name>\n4. Add a privileged security context constraint to the service account for the project. If you want to check what policies are in the privileged SCC, run oc describe scc privileged. For more information about SCCs, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/authentication\/managing-security-context-constraints.html).\n\noc adm policy add-scc-to-user privileged -n <project_name> -z <sa_name>\n5. In your deployment configuration file, refer to the privileged service account and set the security context to privileged.\n\n\n\n* In spec.template.spec, add serviceAccount: <sa_name>.\n* In spec.template.spec.containers, add securityContext: privileged: true.\n\n\n\nExample\n\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\nname: myapp_deployment\nlabels:\napp: myapp\nspec:\n...\ntemplate:\n...\nspec:\nserviceAccount: <sa_name>\ncontainers:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_16444-7-2064","score":14.386874,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11664-3334-5110","score":21.654829,"text":"\nConvert your IBM Cloud account to use [Virtual routing and forwarding (VRF) on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud), using the steps described in [Converting to virtual routing and forwarding](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process).\n\nEnabling VRF permanently alters networking for your IBM Cloud account. Be sure that you have understood both the benefits and minor tradeoffs, which impact your account and resources. After you enable VRF, it cannot be disabled.\n3. Enable the Cloud Service Endpoints (CSE) to provide a secure and unmetered connection to services on IBM Cloud from the IBM Cloud Classic Infrastructure private network. Follow the steps in [enabling service endpoints](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpointservice-endpoint).\n\nThis is not the same as Virtual Private Endpoints (VPE), which is the upgraded equivalent functionality for IBM Cloud VPC Infrastructure environment; this has more benefits that include IAM access control, endpoint with IP in the Subnet Range of the VPC, and does not require Virtual routing and forwarding (VRF).\n\n\n\n\n\n\n\n Provisioning your VMware Software-Defined Datacenter \n\nThe IBM Cloud\u00ae console requires a unique log-in ID, which is an IBMid. Use the following steps to order your IBM Cloud for VMware Solutions Dedicated. Additional information can be found under [Ordering IBM Cloud for VMware Dedicated, vCenter Server instance and vSphere clusters](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_orderinginstance).\n\n\n\n1. Log in to the [IBM Cloud console](https:\/\/cloud.ibm.com) with your unique credentials.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-vmware-sddc-set-up-infrastructure"},{"document_id":"ibmcld_11554-1776-3838","score":19.67857,"text":"\nVPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n\n\n SAP products architecture on IBM Cloud VPC \n\nA [Virtual Private Cloud (VPC)](https:\/\/www.ibm.com\/cloud\/learn\/vpc?mhsrc=ibmsearch_a&mhq=VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. What\u2019s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new concept handles all the networking for every virtual instance running within VPC across regions and zones.\n\n\n\n\n\n 1. Highly available system for SAP NetWeaver on IBM Cloud VPC \n\nIn a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in the following placement groups section.\n\nZoom\n\n![Figure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"},{"document_id":"ibmcld_06926-1815-3739","score":19.168188,"text":"\nUsing VRF, IBM Cloud tenants are allowed to use remote IP addresses that normally would not be allowed to overlap in the Global table. IBM still reserves the following RFC 1918, link-local addresses, and multicast addresses, which are not routable from this VRF service:\n\n\n\n* 10.0.0.0\/14\n* 10.200.0.0\/14\n* 10.198.0.0\/15\n* 169.254.0.0\/16\n* 224.0.0.0\/4\n* 166.9.0.0\/16 (used by the private endpoint service)\n* Any IP ranges assigned to your VLANs on the IBM platform.\n\n\n\nIBM is moving forward with a next-generation Cloud deployment to enable Virtual Private Cloud (VPC) in our availability zones (AZs). This new VPC capability enables Bring-Your-Own-IP (BYoIP) in the VPC-enabled AZs, which are located in Dallas, Washington DC, London, Frankfurt, Tokyo, and Sydney.\n\nFor example, each tenant on the backbone who uses VRF can have only one customer VRF per Direct Link, which provides connectivity among all the tenant\u2019s servers, regardless of location. However, an IBM Cloud tenant might have more than one Direct Link account that feeds into a single cross-connect router.\n\n\n\n* A tenant\u2019s servers in any VLAN, in any pod, in any data center worldwide can reach all of that tenant\u2019s other servers globally.\n* Every tenant\u2019s customer VRF is connected to the common shared services network to provide private reachability for those servers to use DNS, shared storage, monitoring, patching, and more.\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_14884-7-2123","score":19.155962,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"},{"document_id":"ibmcld_11981-4543-6314","score":18.832327,"text":"\nPrivate network configuration when using agents \n\nThe following diagram illustrates a possible agent deployment model on a cluster in an environment with multiple VPCs connected via a transit gateway. Here an agent, running Terraform and Ansible jobs, has direct access to cloud resources over the private cloud network. In this deployment model, your Terraform or Ansible automations' can directly configure your cloud resources using SSH, without the need for bastion hosts to gain access via the public network.\n\nZoom\n\n![Schematics Agents connectivity](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ba89e173287b28d1453d2a327d8a1f74ae2f1662\/schematics\/images\/sc-agents-network.svg)\n\nSchematics Agents connectivity\n\nWith agents you are in control of the network security policies of the Kubernetes cluster and any VPC Security Group or Access Control List policies for the running agent and therefore the ability of the Terraform and Ansible automations\u2019 to access to your private cloud resources.\n\n\n\n\n\n Benefits of using Agents \n\nIBM Cloud\u00ae Schematics is a multi-tenant service supporting concurrent usage by a large number of users. The multi-tenant model imposes a number of restrictions to maintain fair usage across all users and maintain network isolation between users.\n\nThe following are some of the benefits of using agents with the IBM Cloud\u00ae Schematics service:\n\n\n\n* Agent extends the benefits of using [Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics) in conjunction with [IBM Cloud Satellite\u00ae](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-getting-started): To provision and configure hybrid cloud resources, including private cloud resources, private data-center resources, and other public cloud resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-agentb1-about-intro"},{"document_id":"ibmcld_10534-1903-3343","score":18.59524,"text":"\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksoverview-by-resource)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-1011706-1013632","score":18.432592,"text":"\nFile performance and endurance volume\u2019s data migration is not supported, for this, consider that uses a third-party tool such as rsync. A sample script that uses rsync can be found [here](https:\/\/github.com\/IBM-Cloud\/vpc-migration-tools).\n* Is the migration intrusive?\n\nUsually the migration is nonintrusive. It can be done while the server is up and running. However, the source server does need some unused space to do the image capture of the server. In addition, RMM does require SSH (port 22) to be open on both the server and target to run the migration. The CPU consumption for image capture and copying to the target must be minimal.\n* What data does the discovery tool identify from VMware vCenter?\n\nThe discovery tool discovers guest VMs from VMware and it uploads into RMM as the source for migrating in a typical wave. Each wave is named by ESXi host IP address from which guest VMs are discovered.\n* Does the migration solution support auto-provisioning of the target server?\n\nYes. With RMM Auto-Provision feature, you can auto-provision the target server. For more informaation, see \"Bare metal to virtual server migration on a private network that uses RMM\": option 2 of Step 1: [Set up and provision VPC and virtual server instance](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpccloud-vpc-vsi-setup).\n* Why is IBM Cloud\u00ae making the transition from Advanced Monitoring by Nimsoft to IBM Cloud Monitoring?\n\nIBM Cloud is committed to providing you the highest quality of service and is making the transition to a new monitoring offering. IBM Cloud Monitoring offers an improved customer experience, robust functionality, and customizable dashboards for your resource monitoring needs. For more information, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* What benefits does IBM Cloud Monitoring provide?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1011577-1013503","score":18.432592,"text":"\nFile performance and endurance volume\u2019s data migration is not supported, for this, consider that uses a third-party tool such as rsync. A sample script that uses rsync can be found [here](https:\/\/github.com\/IBM-Cloud\/vpc-migration-tools).\n* Is the migration intrusive?\n\nUsually the migration is nonintrusive. It can be done while the server is up and running. However, the source server does need some unused space to do the image capture of the server. In addition, RMM does require SSH (port 22) to be open on both the server and target to run the migration. The CPU consumption for image capture and copying to the target must be minimal.\n* What data does the discovery tool identify from VMware vCenter?\n\nThe discovery tool discovers guest VMs from VMware and it uploads into RMM as the source for migrating in a typical wave. Each wave is named by ESXi host IP address from which guest VMs are discovered.\n* Does the migration solution support auto-provisioning of the target server?\n\nYes. With RMM Auto-Provision feature, you can auto-provision the target server. For more informaation, see \"Bare metal to virtual server migration on a private network that uses RMM\": option 2 of Step 1: [Set up and provision VPC and virtual server instance](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-migrating-images-vmware-vpccloud-vpc-vsi-setup).\n* Why is IBM Cloud\u00ae making the transition from Advanced Monitoring by Nimsoft to IBM Cloud Monitoring?\n\nIBM Cloud is committed to providing you the highest quality of service and is making the transition to a new monitoring offering. IBM Cloud Monitoring offers an improved customer experience, robust functionality, and customizable dashboards for your resource monitoring needs. For more information, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n* What benefits does IBM Cloud Monitoring provide?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14006-7-2487","score":18.423702,"text":"\nFAQs: Dedicated hosts and instances \n\n\n\n What is a dedicated host? \n\nIBM Cloud\u00ae dedicated hosts are physical servers that are committed to a group of users. Dedicated hosts offer virtual server provisioning capacity and maximum placement control.\n\n\n\n\n\n What are the benefits of using dedicated hosts over dedicated instances? \n\nBoth offerings are guaranteed single tenancy. Dedicated hosts provide the flexibility to specify on which host to provision dedicated host instances, and these other benefits:\n\n\n\n* Control over which IBM Cloud data center the server is placed\n* Ability to manage your servers as workload requirements change; for example, migrate virtual servers between your dedicated hosts on the same POD\n\n\n\n\n\n\n\n Can I keep my existing dedicated instances or do I need to set up a dedicated host and dedicated host instances? \n\nYes, you can keep your existing dedicated instances.\n\n\n\n\n\n Can I interchange provisioning of dedicated instances (auto\u2013assigned) and dedicated host instances? \n\nNo. Existing auto-assigned dedicated instances cannot be reprovisioned on dedicated hosts. If you require virtual server placement, you need to provision them on dedicated hosts as dedicated host instances.\n\n\n\n\n\n What type of server, virtual or bare metal, supports the dedicated host offering? \n\nThe offering is supported on virtual servers; IBM Cloud does have a bare metal offering. The differences between virtual hosts and bare metal servers are the time to provision and virtualization management.\n\n\n\n\n\n What is the provisioning lifecycle of a dedicated host? \n\nDedicated hosts are allocated to users when provisioned. They persist to the account until it is reclaimed. Dedicated hosts are offered in only on-demand pricing, hourly or monthly, so when reclaimed, billing models charge as either hourly or monthly IBM Cloud offerings.\n\n\n\n\n\n How is the dedicated host offering billed? \n\nYou can purchase dedicated hosts on-demand with hourly or monthly billing. Hourly only hosts allow only hourly instances to be provisioned; monthly only hosts allow provisioning of monthly and hourly instances. Pricing for dedicated hosts includes core, RAM, local SSD storage, and network port speeds. Premium operating systems, storage area network (SAN) storage, and software add-on prices and licensing are charged based on the instance deployed\u2014hourly or monthly\u2014on the dedicated host. The same pricing model as IBM Cloud public and dedicated instances is followed for these items.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-dedicated-hosts-and-instances"},{"document_id":"ibmcld_08544-7771-9509","score":18.12982,"text":"\n[IBM Cloud image templates](https:\/\/cloud.ibm.com\/docs\/image-templates?topic=image-templates-getting-started-with-image-templatesgetting-started-with-image-templates) You can use IBM Cloud image templates to capture an image of a virtual server to quickly replicate its configuration with minimal changes in the order process. With the End to End (E2E) Encryption feature, you can bring your own encrypted, cloud-init enabled operating system image. [Using End to End Encryption to provision an encrypted instance](https:\/\/cloud.ibm.com\/docs\/image-templates?topic=image-templates-using-end-to-end-e2e-encryption-to-provision-an-encrypted-instanceusing-end-to-end-e2e-encryption-to-provision-an-encrypted-instance) \n [IBM Cloud Virtual Servers for Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers) Virtual Servers for VPC is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility. By integrating with Hyper Protect Crypto Services, you can create an encrypted block storage volume when you create a virtual server instance and use your own root keys to protect the data encryption keys that encrypt your data at rest. [Creating virtual server instances with customer-managed encryption volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-instances-byok) \n [Key Management Interoperability Protocol (KMIP) for VMware\u00ae on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip_standalone_considerations) KMIP for VMware\u00ae works together with VMware native vSphere encryption and vSAN encryption to provide simplified storage encryption management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-integrate-services"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.2463023887}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03216-2369-4600","score":19.287693,"text":"\nFor more information about how to specify each supported response type using JSON objects, see [Response types](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-response-types).\n\nIf you are using an integration, the response is converted at run time into the format expected by the channel. If the response contains multiple media types or attachments, the generic response is converted into a series of separate message payloads as needed. These are sent to the channel in separate messages.\n\nWhen a response is split into multiple messages, the integration sends these messages to the channel in sequence. It is the responsibility of the channel to deliver these messages to the end user; this can be affected by network or server issues.\n\nIf you are building your own client application, your app must implement each response type as appropriate. For more information, see [Implementing responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses).\n\n\n\n\n\n Targeting specific integrations \n\nIf you plan to use integrations to deploy your assistant to multiple channels, you might want to send different responses to different integrations. The channels property of the generic response object provides a way to do this.\n\nThis mechanism is useful if your dialog flow does not change based on the integration in use, and if you cannot know in advance what integration the response will be sent to at run time. By using channels, you can define a single dialog node that supports all integrations, while still customizing the output for each channel. For example, you might want to customize the text formatting, or even send different response types, based on what the channel supports.\n\nUsing channels is particularly useful in conjunction with the channel_transfer response type. Because the message output is processed both by the channel initiating the transfer and by the target channel, you can use channels to define responses that will only be displayed by one or the other. (For more information, and an example, see [Channel transfer](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-channel-transfer).)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"},{"document_id":"ibmcld_03165-6110-8133","score":18.21896,"text":"\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook. For more details, see [Processing input attachments](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-input-attachments).\n* The SMS with Twilio integration does not support chat transfers that are initiated with the Connect to human agent response type.\n* The pause response type is ignored. If you want to add a pause, use a [vgwConversationResponseTimeout](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-commands-smscommands-sms-context-variables) context variable instead.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types, see [Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n* You can include search skill response types in dialog nodes that the phone integration will send as a message. The message includes the introductory text (I searched my knowledge base and so on), and then the body of only the first search result.\n\n\n\nIf you want to use the same dialog for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS with Twilio integration is being used. For more information, see [Building integration-specific responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-condition-by-type).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_02873-5855-7814","score":18.11946,"text":"\nSee [Conditional responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03218-6464-8324","score":17.70654,"text":"\nYou can change the settings that are applied automatically to disambiguation from the Options page.To edit the disambiguation settings, complete the following steps:<-- <ol> -->1. From the Skills menu, click Options.2. Click Disambiguation.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do. For example, None of the above.\nKeep the message short, so it displays inline with the other options. The message must be less than 512 characters. For information about what your assistant does if a user chooses this option, see Handling none of the above]] ! .\n5. If you want to limit the number of disambiguation options that can be displayed to a user, then in the Maximum number of suggestions field, specify a number between 2 and 5.<-- <\/ol> -->Your changes are automatically saved.You can use the API to modify additional disambiguation settings. These settings include the disambiguation sensitivity, which affects how often disambiguation is triggered and how many choices are included. For more information, see the API Reference]] ! ! ! !!.Next, you must decide which dialog nodes you want to make eligible for disambiguation. From the Skills menu, click Dialog.<-- <\/section \"id=\"section-dialog-runtime-disambig-edit\" \"> --><-- <section \"id=\"section-dialog-runtime-disambig-choose-nodes\" \"> --> Choosing nodes to not show as disambiguation options All nodes are eligible to be included in the disambiguation list. - Nodes at any level of the tree hierarchy are included.\n- Nodes that condition on intents, entities, special conditions, context variables, or any combination of these values are included.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_02882-7-2075","score":17.665237,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02882-30440-32604","score":17.578085,"text":"\nYou update context for each individual conditional response; there is no common context editor or JSON editor for all conditional responses.\n* Add rich responses. To add more than one text response or to add response types other than text responses to a single conditional response, you must open the edit response view.\n* Configure a jump. To instruct your assistant to jump to a different node after this conditional response is processed, select Jump to from the And finally section of the response edit view. Identify the node that you want your assistant to process next. See [Configuring the Jump to action](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to-config) for more information.\n\nA Jump to action that is configured for the node is not processed until all of the conditional responses are processed. Therefore, if a conditional response is configured to jump to another node, and the conditional response is triggered, then the jump configured for the node is never processed, and so does not occur.\n\n\n\n3. Click Add response to add another conditional response.\n\n\n\nThe conditions within a node are evaluated in order, just as nodes are. Be sure that your conditional responses are listed in the correct order. If you need to change the order, select a condition and response pair and move it up or down in the list using the arrows that are displayed.\n\n\n\n\n\n\n\n Defining what to do next \n\nAfter making the specified response, you can instruct your assistant to do one of the following things:\n\n\n\n* Wait for user input: Your assistant waits for the user to provide new input that the response elicits. For example, the response might ask the user a yes or no question. The dialog will not progress until the user provides more input.\n* Skip user input: Use this option when you want to bypass waiting for user input and go directly to the first child node of the current node instead.\n\nThe current node must have at least one child node for this option to be available.\n* Jump to another dialog node: Use this option when you want the conversation to go directly to an entirely different dialog node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03185-5335-7134","score":17.432667,"text":"\nIf none of the conditions evaluates to true, then the response from the last node in the tree, which typically has a special anything_else condition that always evaluates to true, is returned.\n\nYou can disrupt the standard first-to-last flow in the following ways:\n\n\n\n* By customizing what happens after a node is processed. For example, you can configure a node to jump directly to another node after it is processed, even if the other node is positioned earlier in the tree. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-jump-to) for more information.\n* By configuring conditional responses to jump to other nodes. See [Conditional responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_03196-43073-44885","score":17.313114,"text":"\n}\n}\nShow more\n\nWhen you define an options list with only 3 items, the options are typically displayed as buttons. When you add a preference property that indicates dropdown as the preference, for example, you can see in the \"Try it out\" pane that the list is displayed as a drop-down list instead.\n\n![Shows a small options list in the Preview that is displayed as a drop-down menu.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/options-dropdown.png)\n\nSome integration types, such as the web chat, reflect your preference. Other integration types, such as Slack, do not reflect your preference when they render the options.\n\n\n\nDo not add more than one option response type to a single dialog node because both lists are displayed at once, but the customer can choose an option from only one of them.\n\nIf you need to be able to populate the list of options with different values based on some other factors, you can design a dynamic options list. For more information, see the [How to Dynamically Add Response Options to Dialog Nodes](https:\/\/medium.com\/ibm-watson\/how-to-dynamically-add-response-options-to-dialog-nodes-in-watson-assistant-e14c5e08beca) blog post.\n\n\n\n\n\n Adding a Pause response type \n\nAdd a pause response type to give the assistant time to respond. For example, you might add a pause response type to a node that calls a webhook. The pause indicates that the assistant is working on an answer, which gives the assistant time to make the webhook call and get a response. Then, you can jump to a child node to show the result.\n\nTo add a Pause response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Pause.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03158-15247-17131","score":17.199799,"text":"\n* You can include search skill response types in dialog nodes that the phone integration will read. The introductory message (I searched my knowledge base and so on), and then the body of only the first search result is read.\n\nThe search skill response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.\n\n\n\nFor more information about dialog response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\nFor more information about how to implement common actions from your dialog, see [Handling phone integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\nIf you want to use the same dialog for an assistant that you deploy to many different platforms, you can add custom responses per integration type. Add a conditioned response that tells the assistant to show the response only when the phone integration is being used. For more information, see [Building integration-specific responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-condition-by-type).\n\n\n\n\n\n Setting up a SIP trunk \n\nYou are responsible for setting up the SIP trunk that will be used by the phone integration. Find a provider and create a SIP trunk account. Your account will be charged for the phone integration's use of the SIP trunk.\n\nYou can set up a SIP trunk in the following ways:\n\n\n\n* [Create a Twilio SIP trunk](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-twilio-setup)\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-request-setup)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_08335-1461-3481","score":17.193035,"text":"\nYou can log in to any node only through the bastion host by using the following command:\n\nssh -J ubuntu@<IP_address_bastion_host> vpcuser@<IP-address-of-nodes>\n\nAlthough all of the nodes of each cluster have passwordless SSH set up among them, due to security constraints, you can't directly log in to a node from one cluster to another cluster.\n\n\n\n\n\n How many compute and storage nodes can I deploy in my Spectrum Scale cluster through this offering? \n\nBefore you deploy a cluster, it is important to ensure that the VPC resource quota settings are appropriate for the size of the cluster that you would like to create (see [Quotas and service limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotas)).\n\nSee the following minimum and maximum number of nodes that are supported in a cluster:\n\n\n\n* Compute nodes: For all storage clusters, a minimum of 3 and a maximum of 64 virtual server instance compute nodes are supported.\n* Scratch and evaluation cluster storage nodes: For a scratch and evaluation storage clusters, a minimum of 3 and a maximum of 18 virtual server instance storage nodes are supported.\n* Persistent cluster storage nodes: For a persistent storage cluster, a minimum of 3 and a maximum of 10 bare metal server storage nodes are supported.\n\n\n\nFor more information, see [Deployment values](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-deployment-values).\n\n\n\n\n\n What storage types are available through this offering? \n\nThe Spectrum Scale solution offers three different storage types: scratch, persistent, and evaluation. For more information, see [Storage types](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-storage-types).\n\n\n\n\n\n Why are there two different resource group parameters that can be specified in the IBM Cloud catalog tile? \n\nThe first resource group parameter entry in the Configure your workspace section in the IBM Cloud catalog applies to the resource group where the Schematics workspace is provisioned on your IBM Cloud account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-spectrum-scale-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03334-20892-22106","score":11.863311,"text":"\nRepeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/delete-c10.png)\n* To delete the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents that are listed on the current page. Click Delete.\n* To delete one or more specific intents, select the intents that you want to delete, and then click Delete.\n\n![Shows that an intent was selected and the delete icon is in focus](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-delete.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03145-1287-2166","score":11.7094555,"text":"\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_02846-0-2023","score":11.643089,"text":"\n\n\n\n\n\n\n  Using content catalogs \n\nContent Catalogs provide an easy way to add common intents to your Watson Assistant dialog skill.\n\nIntents you add from the catalog are meant to provide a starting point. Add to or edit the catalog intents to tailor them for your use case.\n\nThe latest content catalog, named Covid-19, is available in Brazilian Portuguese, English, French, and Spanish only. For more information about language support for the catalogs, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n  Adding a content catalog to your dialog skill \n\n\n\n1.  Open your dialog skill, open the Content Catalog page.\n\n![Screen capture showing available catalogs](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/catalog-overview.png)\n2.  Select a content catalog, such as Banking, to see the intents that are provided with it.\n\n![Screen capture showing Banking category intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/catalog-open.png)\n\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3.  Add a content catalog to your dialog skill by clicking the Add to skill button.\n4.  Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n  Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n*  Rename intents\n*  Delete intents\n*  Add, edit, or delete intent user examples\n*  Move an example to a different intent\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog"},{"document_id":"ibmcld_03010-13387-14939","score":11.533577,"text":"\n[Shows the results from a search for intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-search-results.png)\n\n\n\n\n\n\n\n Exporting intents \n\nYou can export a number of intents to a CSV file, so you can then import and reuse them for another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To export all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Export all intents icon. ![Export option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/export-c10.png)\n* To export the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents on the current page. Click Export.\n* To export one or more specific intents, select the intents that you want to export, and then click Export.\n\n![Shows that two intents are selected and the export icon is in focus](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-export.png)\n\n\n\n2. Specify the name and location in which to store the CSV file that is generated.\n\n\n\n\n\n\n\n Importing intents and examples \n\nIf you have a large number of intents and examples, you might find it easier to import them from a comma-separated value (CSV) file than to define them one by one. Be sure to remove any personal data from the user examples that you include in the file.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03010-19270-20077","score":11.532621,"text":"\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/delete-c10.png)\n* To delete the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents that are listed on the current page. Click Delete.\n* To delete one or more specific intents, select the intents that you want to delete, and then click Delete.\n\n![Shows that an intent was selected and the delete icon is in focus](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-delete.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03145-4-1748","score":11.391318,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Using built-in intents \n\nContent Catalogs provide an easy way to add common intents to your Watson Assistant dialog skill.\n\nIntents you add from the catalog are meant to provide a starting point. Add to or edit the catalog intents to tailor them for your use case.\n\nThe latest content catalog, named Covid-19, is available in Brazilian Portuguese, English, French, and Spanish only. For more information about language support for the catalogs, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n Adding a content catalog to your dialog skill \n\n\n\n1. Open your dialog skill, open the Content Catalog page.\n\n![Screen capture showing available catalogs](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-overview.png)\n2. Select a content catalog, such as Banking, to see the intents that are provided with it.\n\n![Screen capture showing Banking category intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/catalog-open.png)\n\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_03010-12555-13929","score":11.300415,"text":"\n[Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nThe search capability was introduced with the 1.5.0 release.\n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Submit a search term or phrase.\n\nThe first time you search for something, you might get a message that says the skill is being indexed. If so, wait a minute, and then resubmit the search term.\n\nIntents that contain your search term are displayed.\n\n![Shows the results from a search for intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intent-search-results.png)\n\n\n\n\n\n\n\n Exporting intents \n\nYou can export a number of intents to a CSV file, so you can then import and reuse them for another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To export all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Export all intents icon. !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03334-13950-15399","score":11.294829,"text":"\n[Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page, click the Search icon.\n\n![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-search.png)\n2. Submit a search term or phrase.\n\nThe first time you search for something, you might get a message that says the skill is being indexed. If so, wait a minute, and then resubmit the search term.\n\nIntents that contain your search term are displayed.\n\n![Shows the results from a search for intents](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-search-results.png)\n\n\n\n\n\n\n\n Downloading intents \n\nYou can download a number of intents to a CSV file, so you can then upload and reuse them in another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To download all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Download all intents icon. ![Download all intents icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/download-all.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03310-10261-12004","score":11.269576,"text":"\nThe response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned intents list into a JSON object. For example:\n\nRecognized intents are: <? intents.toJson() ?>\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:\n\n\n\n* To execute a node if the user input is \"Yes\", add this expression to the node condition: input.text == 'Yes'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_02988-8862-10727","score":11.199702,"text":"\nThe confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the Try it out pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-887513-889443","score":8.96029,"text":"\nCan I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances. For more information, see [About creating an image from a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc).\n* How is the boot disk created for an instance and how does it relate to the virtual machine image?\n\n How is the boot disk created for an instance and how does it relate to the virtual machine image? \n\nThe boot disk, also called a boot volume, is created when you provision a virtual server instance. The boot disk of an instance is a cloned image of the virtual machine image. For stock images, the boot volume capacity is 100 GB. If you are importing a custom image, the boot volume capacity can be 10 GB to 250 GB, depending on what the image requires. Images smaller than 10 GB are rounded up to 10 GB. The boot volume is deleted when you delete the instance to which it is attached.\n* When can I delete a Block Storage for VPC data volume?\n\n When can I delete a Block Storage for VPC data volume? \n\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n* What happens to my data when I delete a Block Storage for VPC data volume?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-887390-889320","score":8.96029,"text":"\nCan I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances. For more information, see [About creating an image from a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc).\n* How is the boot disk created for an instance and how does it relate to the virtual machine image?\n\n How is the boot disk created for an instance and how does it relate to the virtual machine image? \n\nThe boot disk, also called a boot volume, is created when you provision a virtual server instance. The boot disk of an instance is a cloned image of the virtual machine image. For stock images, the boot volume capacity is 100 GB. If you are importing a custom image, the boot volume capacity can be 10 GB to 250 GB, depending on what the image requires. Images smaller than 10 GB are rounded up to 10 GB. The boot volume is deleted when you delete the instance to which it is attached.\n* When can I delete a Block Storage for VPC data volume?\n\n When can I delete a Block Storage for VPC data volume? \n\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n* What happens to my data when I delete a Block Storage for VPC data volume?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14983-1641-3423","score":8.6099615,"text":"\nWhy it\u2019s happening \n\nLook at the reason_codes property in the response. It might be an internal error or the [snapshot limit](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-faqs&interface=uifaq-snapshot-3) is reached.\n\n How to fix it \n\nContact IBM support if you see an internal error. If the backup snapshot limit is reached, delete the oldest snapshots so new ones can be created. You can create up to 100 backup snapshots of a volume.\n\n\n\n\n\n Backup policy is not created due to incorrect authorizations \n\n What\u2019s happening \n\nA service authorization error is generated when you try to create a backup policy.\n\n Why it\u2019s happening \n\nWhen you attempt to create a backup policy, an s2s service not completed error is generated, which indicates that incorrect service-to-service authorizations were set up. The backup policy creation fails. This behavior is expected and right, it prevents the backup policy from being created without proper authorization.\n\n How to fix it \n\nEstablish correct service-to-service authorizations and try creating a backup policy again. For more information about setting up authorizations for the backup service, see [Establishing service to service authorizations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-s2s-auth).\n\n\n\n\n\n Backup policies are not found \n\n What\u2019s happening \n\nYou receive a backup_policies_not_found error with the following message: Backup policy with ID is not found.\n\n Why it\u2019s happening \n\nThe backup policy that you are trying to find is either deleted or never existed.\n\n How to fix it \n\nTo address this error, list the policies and see whether the backup policy ID that you're looking for is in the list. If you still need help with the error, contact [support](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-troubleshoot&interface=ui"},{"document_id":"ibmcld_04160-7-2159","score":8.343386,"text":"\nGlobal load balancer concepts \n\nThis document contains some concepts and definitions related to the global load balancer and how it affects your IBM Cloud\u00ae Internet Services deployment.\n\n\n\n Global load balancer \n\nA global load balancer manages traffic across server resources located in multiple regions. The origin server can serve up all of the content for a website, provided that the web traffic does not extend beyond the server's processing capabilities and latency is not a primary concern. A global load balancer manages a pool implementation that allows for the traffic to be distributed to multiple origins. This pool capability provides many benefits including:\n\n\n\n* Minimizes response time\n* Creates higher availability through redundancy\n* Maximizes traffic throughput\n\n\n\nA global load balancer routes traffic to the pool with the highest priority, distributing the load among its origin servers. See the following Pool section for how traffic is distributed within a pool. If the primary pool becomes unavailable, traffic is routed automatically to the next pool in the list based on priority.\n\nIf pools are set up for specific regions, traffic from those regions is sent to the pools for the specified region first. Traffic falls back to the default pools only when all pools for a given region are down. In this case the fallback pool is the pool with the lowest priority.\n\n\n\n How it works \n\nWhen a global load balancer is created, a DNS record is automatically added for it with the name of the load balancer. The load balancer then returns one of the origin IP addresses to a client making a DNS request.\n\nFor example, an origin pool is created with two origins identifying IP addresses 169.61.244.18 and 169.61.244.19. If a global load balancer is created with the name glbcust.ibmmo.com using the origin pool, then a client on the internet can execute the command:\n\n$ ping glbcust.ibmmo.com\nPING glbcust.ibmmo.com (169.61.244.18): 56 data bytes\n\nIn this example, CIS:\n\n\n\n* Created a DNS record named glbcust.ibmmo.com.\n* Used the global load balancer to resolve the DNS name to one of the IP addresses identified in the origin pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-global-load-balancer-glb-concepts"},{"document_id":"ibmcld_15994-4553-5739","score":8.334529,"text":"\nWhy it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service). For more information, see [Using authorizations to grant access between services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) to establish IAM service-to-service authorizations in the UI, CLI, or API.\n\n\n\n\n\n Resolving volume resize issues while a snapshot is taken \n\n What\u2019s happening \n\nIf you take a snapshot of a volume and resize the source volume while the snapshot is being created, you get an error.\n\n Why it\u2019s happening \n\nWhile the snapshot is in a pending state, a volume resize error displays with the message \"The resize validation failed.\" The correct message says, \"volume is locked.\"\n\n How to fix it \n\nWait until the snapshot is created and it is in an available state before you resize the source volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-block-storage"},{"document_id":"ibmcld_02711-0-697","score":8.323925,"text":"\n\n\n\n\n\n\n  Why do I see the values of my feature flags or properties as default values (0 for Number type, false for Boolean type and empty string for String type) in certain environments? \n\n  What\u2019s happening \n\nDefault values are assigned to the feature flags or properties in certain environments.\n\n  Why it\u2019s happening \n\nA feature flag is always created under an environment.\n\nThough the flag is created under an environment, it is made available to all environments with default values. Flag Values, tags, and segment values are relevant only to the environment where the update is executed.\n\n  How to fix it \n\nFeature flag or Property values can be updated specifically to an environment.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-troubleshooting-def-value"},{"document_id":"ibmcld_02713-0-440","score":8.235101,"text":"\n\n\n\n\n\n\n  Why can't I toggle a newly created feature flag? \n\n  What\u2019s happening \n\nFeature flag is disabled and cannot be toggled.\n\n  Why it\u2019s happening \n\nA Feature flag is linked to a collection and the flag is toggled per environment.\n\nIf a feature flag is not linked to any collection, it is disabled by default.\n\n  How to fix it \n\nLink the feature flag with an existing collection. This allows you to toggle between ON or OFF state.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-troubleshooting-one"},{"document_id":"ibmcld_15261-11717-12738","score":8.196048,"text":"\nNetwork ACLs \n\nA network ACL cannot be deleted if it is being used by a subnet, or if it is the default network ACL of a VPC. Before you delete the network ACL, detach the network ACL from all subnets, and make sure that the network ACL is not being used as the default network ACL of a VPC.\n\nWhen any VPC is created, it requires a default network ACL. If an existing network ACL is not specified as the default when the VPC is created, a new network ACL is created and set as the default. This default network ACL is deleted automatically when the VPC is deleted, if the ACL is not in use anywhere else.\n\nUnlike security groups, network ACLs can be assigned across VPCs. Therefore, deleting a VPC does not delete the network ACLs.\n\n\n\n\n\n\n\n Next steps \n\nThe following topics provide more examples on how to delete VPC resources by using the IBM Cloud Console, CLI, or API.\n\n\n\n* [Deleting a VPC and its associated resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-a-vpc-and-its-associated-resources&interface=ui)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting"},{"document_id":"ibmcld_00375-13987-15284","score":8.059589,"text":"\nOn this page[For my CDN, what is the difference between HTTPS with a Wildcard certificate and HTTPS with SAN certificate?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpsfor-my-cdn-what-is-the-difference-between-https-with-wildcard-certificate-and-https-with-san-certificate)[How is Domain Validation with redirect accomplished?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpshow-is-domain-validation-with-redirect-accomplished)[How long does Domain Validation take?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpshow-long-does-domain-validation-take)[How long does it take to create and enable HTTPS for my CDN with a DV SAN certificate?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpshow-long-does-it-take-to-create-and-enable-https-for-my-cdn-with-a-dv-san-certificate)[How long does it take to delete a CDN with a DV SAN certificate?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpshow-long-does-it-take-to-delete-a-cdn-with-a-dv-san-certificate)[Is there any additional cost associated with using a DV SAN certificate for my CDN?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-httpsis-there-any-additional-cost-associated-with-using-a-dv-san-certificate-for-my-cdn)[Can my CDN created using HTTPS with Wildcard be updated to use a DV SAN certificate?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faq-for-https"},{"document_id":"ibmcld_15111-5727-7698","score":8.021418,"text":"\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n\n\n\n\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances. For more information, see [About creating an image from a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc).\n\n\n\n\n\n\n\n Volume management questions \n\n\n\n How is the boot disk created for an instance and how does it relate to the virtual machine image? \n\nThe boot disk, also called a boot volume, is created when you provision a virtual server instance. The boot disk of an instance is a cloned image of the virtual machine image. For stock images, the boot volume capacity is 100 GB. If you are importing a custom image, the boot volume capacity can be 10 GB to 250 GB, depending on what the image requires. Images smaller than 10 GB are rounded up to 10 GB. The boot volume is deleted when you delete the instance to which it is attached.\n\n\n\n\n\n When can I delete a Block Storage for VPC data volume? \n\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n\n\n\n\n\n What happens to my data when I delete a Block Storage for VPC data volume? \n\nWhen you delete a Block Storage for VPC volume, your data immediately becomes inaccessible. All pointers to the data on that volume are removed. The inaccessible data is eventually overwritten as new data is written to the data block. IBM guarantees that data deleted cannot be accessed and that deleted data is eventually overwritten.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03085-4-2046","score":17.120956,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_03369-25501-27738","score":11.540473,"text":"\n* New [documentation](https:\/\/cloud.ibm.com\/docs\/watson-assistant) focuses on the workflow of building, deploying, and improving your assistant.\n\n\n\nYou can easily switch to the new Watson Assistant and try it out. Visit the Manage menu for your Watson Assistant instance, then choose Switch to new experience.\n\n\n\n\n\n 21 September 2021 \n\nAnalytics Overview change\n: To improve reliability, the Values column has been removed from Top entities on the Analytics Overview page. Top Entities continues to provide counts of entity types. For more information, see [Top intents and top entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-tops)\n\n\n\n\n\n 16 September 2021 \n\nEnhanced intent detection for French, Italian, and Spanish dialog skills\n: The new intent detection model improves your assistant's ability to understand what customers want. This model is now available in dialog skills using French, Italian, and Spanish.\n\nChange to the irrelevance detection option\n: As of this release, new English dialog skills no longer include the option to choose between the Enhanced or Existing irrelevance detection. By default, intent detection and irrelevance detection are paired like this:\n\n\n\n* If you use the dialog skill options to choose enhanced intent detection, it is automatically paired with enhanced irrelevance detection.\n* If you use the dialog skill options to choose existing intent detection, it is automatically paired with existing irrelevance detection.\n\n\n\nIf necessary, you can use the [Update workspace API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=updateworkspace) to set your English-language assistant to one of the four combinations of intent and irrelevance detection:\n\n\n\n* Enhanced intent recognition and enhanced irrelevance detection\n* Enhanced intent recognition and existing irrelevance detection\n* Existing intent recognition and enhanced irrelevance detection\n* Existing intent recognition and existing irrelevance detection\n\n\n\nFor French, Italian, and Spanish, you can use the API to set your assistant to these combinations:\n\n\n\n* Enhanced intent recognition and enhanced irrelevance detection\n* Existing intent recognition and existing irrelevance detection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_09503-5025-7425","score":11.102742,"text":"\nThis resource does not necessarily have technical skills or access to investigate \/ act upon systems that are failing. The CC may also be expected to triage requests that do not fall within the definition of Severity 1 and communicate with the customer regarding these issues.\n\n\n\nFirst Responder\n\n\n\n* The First Responder (FR) is a technical role that requires access to systems that may be in a failed or failing state, as well as the skills required to understand what can be done to recover affected environment(s). It may not be possible for the FR to correct all problems and he\/she should be equipped to escalate issues to specific individuals for resolution if necessary. The FR remains focused on incident resolution at all times and is not expected to communicate directly with customers; they remain in regular contact with the Client Communicator on duty. It is important to note that the First Responder is precisely that, the first responder - he\/she is not solely responsible for solving every incident.\n\n\n\nThe first responder will respond to alerts and off hours Severity 1 cases to:\n\n\n\n* Determine the impact of the alert or case\n* Determine the cause of the alert or case\n* Initiate corrective action if appropriate\n* Alert the Client Communicator if escalation is determined necessary.\n\n\n\nThe IBM first responder\u2019s priority will be to restore service. The IBM client communicator is notified if there are any challenges to restoring service. The IBM client communicator will lead the recovery activities and escalate to any personnel required to resolve the issue, while also ensuring that continuous communication is maintained with the customer throughout the length of the incident.\n\nEscalation Manager \/ Discipline Team Members Additional support for IRT members is provided by an Escalation Manager as well as dedicated Database and Network discipline team members. These specific SRE individuals are assigned to the IRT schedule to also provide coverage.\n\n\n\n\n\n Client Requests for RCA \n\nRCA (Root Cause Analysis)\n\nFor Severity 1 incidents, IBM SRE and the Incident Response Team (IRT) have a primary goal to restore service and remediate any disruption as soon as possible. Addressing the symptoms of an issue can often be sufficient enough to successfully restore service, but the underlying root cause may not have been identified during this process due to time constraints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-operations"},{"document_id":"ibmcld_03381-7441-8427","score":10.9448805,"text":"\nFor more information about roles, see [Understanding roles](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-controlaccess-control-iam-roles).\n10. Click Add.\n\nYou can repeat the previous step to invite other users and apply different roles to them.\n11. Click Invite to finish the process.\n\nIf you are editing access for an existing user, click Assign access.\n\n\n\nWhen the people you invite next log in to IBM Cloud\u00ae, your account will be included in their list of accounts. If they select your account, they can see your service instance, and open and edit your skills.\n\nWith more people contributing to dialog skill development, unintended changes can occur, including skill deletions. Consider creating backup copies of your dialog skill on a regular basis, so you can roll back to an earlier version if necessary. To create a backup, simply [download the skill as a JSON file](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-download).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03369-109994-112063","score":10.792224,"text":"\nIt is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities)\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-147609-149563","score":10.622322,"text":"\nAll workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German. The revised system entities offer better date and time understanding. They can recognize date and number spans, national holiday references, and classify mentions with more precision.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-61217-63294","score":10.494641,"text":"\n: As of this release, new English dialog skills no longer include the option to choose between the Enhanced or Existing irrelevance detection. By default, intent detection and irrelevance detection are paired like this:\n\n\n\n* If you use the dialog skill options to choose enhanced intent detection, it is automatically paired with enhanced irrelevance detection.\n* If you use the dialog skill options to choose existing intent detection, it is automatically paired with existing irrelevance detection.\n\n\n\nFor more information, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection) and [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\nIf necessary, you can use the [Update workspace API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=updateworkspace) to set your English-language assistant to one of the four combinations of intent and irrelevance detection:\n\n\n\n* Enhanced intent recognition and enhanced irrelevance detection\n* Enhanced intent recognition and existing irrelevance detection\n* Existing intent recognition and enhanced irrelevance detection\n* Existing intent recognition and existing irrelevance detection\n\n\n\nFor French, Italian, and Spanish, you can use the API to set your assistant to these combinations:\n\n\n\n* Enhanced intent recognition and enhanced irrelevance detection\n* Existing intent recognition and existing irrelevance detection\n\n\n\n\n\n\n\n 15 September 2021 \n\nDialog skill \"Try it out\" improvements\n: The Try it out pane now includes these changes:\n\n\n\n* It now includes runtime warnings in addition to runtime errors.\n* For dialog skills, the Try it out pane now uses the [React](https:\/\/reactjs.org\/) UI framework similar to the rest of the Watson Assistant user interface. You shouldn't see any change in behavior or functionality. As a part of the update, dialog skill error handling has been improved within the \"Try it out\" pane. This update was enabled on these dates:\n\n\n\n* September 9, 2021 in the Tokyo and Seoul data centers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-36856-39124","score":10.391703,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_09524-3136-5409","score":10.2007265,"text":"\nThe IBM SRE team has monitoring in place for all sites and infrastructure under our control. These are designed to allow the SRE team to pro-actively respond to service impacting or service threatening events or conditions. When a site is unavailable, or there are infrastructure issues leading to monitor alerts, an incident record is automatically generated within our Incident Management System.\n\nAt the same time, for production environments, a SRE Incident Response Team (IRT) provides 24\/7 critical outage support. The goal of IRT is to ensure our customer's applications are running when they should, and to provide effective and timely customer communication during availability incidents or Severity 1 cases during off hours. IRT is sometimes referred to as the \"on call\" team.\n\nPlease note IRT is not considered standard support. It is for emergency and Sev1 cases only. Please see our Support & Operations section for standard support details and hours of operation.\n\nHow is the IBM SRE Incident Response Team (IRT) organized?\n\nThe IRT is organized into a 2-person rotating schedule on 8-hour cycles over 7 days. This means that there are two IRT members for each 8 hour period: a Client Communicator and a First Responder. IBM SRE uses a region based \u201cfollow the sun\u201d support model. The IRT schedule is maintained and updated by IBM on a regular basis.\n\nClient Communicator\n\n\n\n* The Client Communicator (CC) is responsible for ensuring that any customer affected by a Severity 1 incident or alert is receiving prompt and frequent communication regarding the status of their incident. This resource does not necessarily have technical skills or access to investigate \/ act upon systems that are failing. The CC may also be expected to triage requests that do not fall within the definition of Severity 1 and communicate with the customer regarding these issues.\n\n\n\nFirst Responder\n\n\n\n* The First Responder (FR) is a technical role that requires access to systems that may be in a failed or failing state, as well as the skills required to understand what can be done to recover affected environment(s). It may not be possible for the FR to correct all problems and he\/she should be equipped to escalate issues to specific individuals for resolution if necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-operations"},{"document_id":"ibmcld_16364-72601-74697","score":10.166411,"text":"\nFor more information, see [Actions skill overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overview).\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests. For more information, see [Response types](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-response-types).\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nFor more information, see [Adding and referencing variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-variables).\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03185-5335-7134","score":17.702694,"text":"\nIf none of the conditions evaluates to true, then the response from the last node in the tree, which typically has a special anything_else condition that always evaluates to true, is returned.\n\nYou can disrupt the standard first-to-last flow in the following ways:\n\n\n\n* By customizing what happens after a node is processed. For example, you can configure a node to jump directly to another node after it is processed, even if the other node is positioned earlier in the tree. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-jump-to) for more information.\n* By configuring conditional responses to jump to other nodes. See [Conditional responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_03329-3417-4930","score":17.004124,"text":"\nYou successfully started to build your training data by adding prebuilt content from IBM.\n\n\n\n\n\n Step 4: Build a dialog \n\nA [dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview) defines the flow of your conversation in the form of a logic tree. It matches intents (what users say) to responses (what your virtual assistant says back). Each node of the tree has a condition that triggers it, based on user input.\n\nWe'll create a simple dialog that handles greeting and ending intents, each with a single node.\n\n\n\n Adding a start node \n\n\n\n1. From the Skills menu, click Dialog.\n\nThe following two dialog nodes are created for you automatically:\n\n\n\n* Welcome: Contains a greeting that is displayed to your users when they first engage with the assistant.\n* Anything else: Contains phrases that are used to reply to users when their input is not recognized.\n\n\n\n![A new dialog with two built-in nodes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-new-dialog.png)\n2. Click the Welcome node to open it in the edit view.\n3. Replace the default response with the text, Welcome to the Watson Assistant tutorial!.\n\n![Editing the welcome node response](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-edit-welcome-node.png)\n4. Click ![Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close.png) to close the edit view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_02900-24807-26597","score":16.91435,"text":"\nFrom the Skills menu of the dialog skill where you want to enable disabmiguation, click Options.2. On the Disambiguation page, switch the toggle to On.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do. For example, None of the above.\nKeep the message short, so it displays inline with the other options. The message must be less than 512 characters. For information about what your assistant does if a user chooses this option, see Handling none of the above]] !!.\n5. If you want to limit the number of disambiguation options that can be displayed to a user, then in the Maximum number of suggestions field, specify a number between 2 and 5.\nYour changes are automatically saved.\n6. Now, click Dialog from the Skills menu. Review your dialog to decide which dialog nodes you want the assistant to ask for help with.\n<-- <ul> -->\n\n* You can pick nodes at any level of the tree hierarchy.\n* You can pick nodes that condition on intents, entities, special conditions, context variables, or any combination of these values.\n\n<-- <\/ul> -->\n\nSee Choosing nodes]]!Shows where to add the external node name information in the node edit view.Shows where to add the external node name information in the node edit view_.]!! ! ! for tips.\n\nFor each node that you want to make available from the disambiguation options list, complete the following steps:\n\n<-- <ol> -->\n\n1. Click to open the node in edit view.\n2. In the external node name field, describe the user task that this dialog node is designed to handle. For example, Cancel an account.\n\n!]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_03196-4-2102","score":16.84512,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Creating a dialog \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. From the Skills menu, click Dialog.\n\nThe following nodes are created for you automatically:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs used in integrations with channels such as Facebook or Slack skip nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\nFor more information about these built-in nodes, see [Starting and ending the dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-start).\n2. To add more nodes to the dialog tree, click Add node.\n\nYour new node is added after the Welcome node and before the Anything else node.\n3. Add a name to the node.\n\nUse a short, customer-friendly description of what the node does as its name. For example, Open an account, Get policy information, or Get a weather forecast.\n\nThe name can be up to 512 characters in length.\n\nThis node name is shown to customers or service desk personnel to express the purpose of this branch of the dialog, so take some time to add a name that is concise and descriptive.\n4. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_02961-7-1871","score":16.736015,"text":"\nDialog building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nYou currently know what the node does, but months from now you might not. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_03282-4-1890","score":16.546473,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Conversation building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nToday, you know what the node does, but months from now you might not remember. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_03070-6290-7633","score":16.458467,"text":"\nYour assistant responds by saying, We are always looking for talented people to add to our team. What type of job are you interested in?\n6. Instead of answering this question, ask the bot an unrelated question. Type What time do you open?\n\nYour assistant digresses away from the Job opportunities node to the Restaurant opening hours node to answer your question. Your assistant responds with The restaurant is open from 8:00 AM to 10:00 PM.\n\nUnlike in the previous test, this time the dialog does not pick up where it was in the Job opportunities node. Your assistant does not return to the dialog that was in progress because you changed the setting on the Restaurant opening hours node to not return.\n\n![Shows a conversation that does not return after a digression](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/tut-dig-noreturn.png)\n\n\n\nCongratulations! You have successfully digressed away from a dialog without returning.\n\n\n\n\n\n Summary \n\nIn this tutorial you experienced how digressions work, and saw how individual dialog node settings can impact the digressions behavior.\n\n\n\n\n\n Next steps \n\nFor help as you configure digressions for your own dialog, see [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-digressions"},{"document_id":"ibmcld_03404-6416-7744","score":16.458467,"text":"\nYour assistant responds by saying, We are always looking for talented people to add to our team. What type of job are you interested in?\n6. Instead of answering this question, ask the bot an unrelated question. Type What time do you open?\n\nYour assistant digresses away from the Job opportunities node to the Restaurant opening hours node to answer your question. Your assistant responds with The restaurant is open from 8:00 AM to 10:00 PM.\n\nUnlike in the previous test, this time the dialog does not pick up where it left off in the Job opportunities node. Your assistant does not return to the dialog that was in progress because you changed the setting on the Restaurant opening hours node to not return.\n\n![Shows a conversation that does not return after a digression](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/tut-dig-noreturn.png)\n\n\n\nCongratulations! You successfully digressed away from a dialog without returning.\n\n\n\n\n\n Summary \n\nIn this tutorial you experienced how digressions work, and saw how individual dialog node settings can impact the digressions behavior.\n\n\n\n\n\n Next steps \n\nFor help as you configure digressions for your own dialog, see [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-digressions"},{"document_id":"ibmcld_02998-3401-4882","score":16.376318,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-content-catalog.png)\n3. Open the Intents tab to review the intents and associated example utterances that were added to your training data. You can recognize them because each intent name begins with the prefix General_. You will add the General_Greetings and General_Ending intents to your dialog in the next step.\n\n![Shows the intents that are displayed in the Intents tab after the General catalog is added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-general-content-added.png)\n\n\n\nYou successfully started to build your training data by adding prebuilt content from IBM.\n\n\n\n\n\n Step 5: Build a dialog \n\nA dialog defines the flow of your conversation in the form of a logic tree. It matches intents (what users say) to responses (what the bot says back). Each node of the tree has a condition that triggers it, based on user input.\n\nWe'll create a simple dialog that handles greeting and ending intents, each with a single node.\n\n\n\n Adding a start node \n\n\n\n1. From the Skills menu, click Dialog.\n2. Two nodes were added to the dialog for you:\n\n\n\n* Welcome: Contains a greeting that is displayed to your users when they first engage with the assistant.\n* Anything else: Contains phrases that are used to reply to users when their input is not addressed by any of the existing dialog nodes.\n\n\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_02900-2946-5130","score":16.37152,"text":"\nHowever, the conversation cannot digress away from a node under the following circumstances:\n\n\n\n* If any of the child nodes of the current node contain the anything_else or true condition\n\n\n\nThese conditions are special in that they always evaluate to true. Because of their known behavior, they are often used in dialogs to force a parent node to evaluate a specific child node in succession. To prevent breaking existing dialog flow logic, digression are not allowed in this case. Before you can enable digressions away from such a node, you must change the child node's condition to something else.\n\n\n\n* If the node is configured to jump to another node or skip user input after it is processed\n\n\n\nThe final step section of a node specifies what should happen after the node is processed. When the dialog is configured to jump directly to another node, it is often to ensure that a specific sequence is followed. And when the node is configured to skip user input, it is equivalent to forcing the dialog to process the first child node after the current node in succession. To prevent breaking existing dialog flow logic, digressions are not allowed in either of these cases. Before you can enable digressions away from this node, you must change what is specified in the final step section.\n\n\n\n\n\n\n\n Customizing digressions \n\nYou do not define the start and end of a digression. The user is entirely in control of the digression flow at run time. You only specify how each node should or should not participate in a user-led digression. For each node, you configure whether:\n\n\n\n* a digression can start from and leave the node\n* a digression that starts elsewhere can target and enter the node\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07042-18554-20415","score":11.225594,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Step 8: Not sure what you can build? \n\nFor more information about the types of search solutions you can build, see [Start getting value from your data](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview).\n\nYou can access the product documentation at any time by selecting the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/help.svg) from the page header of the product user interface. The help content is customized to provide information that is related to what you're doing in the product.\n\nNo matter what you build, step one is to create a project. Decide which project type best fits your needs.\n\nIf none of the existing types is quite right, you can choose None of the above to create a custom project instead.\n\n\n\n\n\n Project descriptions \n\n\n\nProject type use cases\n\n Need Goal Project type \n\n Which document contains the answer to my question? Find meaningful information in sources that contain a mix of structured and unstructured data, and surface it in a stand-alone enterprise search application or in the search field of a business application. Document Retrieval \n Where is the part of the contract that I need for my task? Quickly extract critical information from contracts. Document Retrieval for Contracts \n I want the chatbot I'm building to use knowledge that I own. Give a virtual assistant quick access to technical information that is stored in various external data sources and document formats to answer customer questions. Conversational Search \n I want to uncover insights I didn't know to ask about. Gain insights from pattern analysis or perform root cause analysis. Content Mining","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-getting-started"},{"document_id":"ibmcld_16471-188589-190073","score":10.981046,"text":"\n+ arg1Schema.size (), returnSchema.getFieldTypeByIx (i + arg1Schema.size ()), arg2Schema.getFieldTypeByIx (i)); }\n}\n}\n\n}\nShow more\n\n\n\n\n\n\n\n Declaring user-defined functions \n\nYou can make the user-defined scalar functions and machine learning models from PMML files available to AQL by using the create function statement.\n\n\n\n Syntax \n\nThe general syntax of the create function statement is as follows:\n\ncreate function <function-name>(<input-schema-definition>)\nreturn <return-type> [like <column-name>] | table ( <output-schema-definition)\nexternal_name <ext-name>\nlanguage [java | pmml]\n[deterministic | not deterministic]\n[return null on null input | called on null input];\n\n<input-schema-definition>\n<column-name> <data-type> | table (<output-schema-definition>) as locator [,<column-name> <data-type> | table (<output-schema-definition>) as locator ]\n\n<output-schema-definition>\n<column-name> <data-type> [,<column-name> <data-type>]\n\n\n\n\n\n Description \n\n\n\n* <function-name>\n\nThe <function-name> declares the AQL name of the UDF. The UDF is referred to in the AQL code with this name\n* <input-schema-definition>\n\nSpecifies the input parameters of the UDF. An input parameter has a name, which is specified as <column-name>, and can be either a scalar type or a table locator. When the language is PMML, the function must take a single table that is called params as the argument.\n* <column-name>\n\nSpecifies the name of a column in the input or the output of the UDF.\n* <data-type>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_07082-7-2198","score":10.894087,"text":"\nCreating projects \n\nA project is a convenient way to collect and manage the resources in your IBM Watson\u00ae Discovery application. You can assign a Project type and connect your data to the project by creating a collection.\n\nBefore you create a project, decide which project type best fits your needs.\n\n\n\n Project descriptions \n\n\n\nProject type use cases\n\n Need Goal Project type \n\n Which document contains the answer to my question? Find meaningful information in sources that contain a mix of structured and unstructured data, and surface it in a stand-alone enterprise search application or in the search field of a business application. Document Retrieval \n Where is the part of the contract that I need for my task? Quickly extract critical information from contracts. Document Retrieval for Contracts \n I want the chatbot I'm building to use knowledge that I own. Give a virtual assistant quick access to technical information that is stored in various external data sources and document formats to answer customer questions. Conversational Search \n I want to uncover insights I didn't know to ask about. Gain insights from pattern analysis or perform root cause analysis. Content Mining \n\n\n\nIf you created the Discovery service as part of a IBM Cloud Pak for Data as a Service deployment, the Discovery project is separate and distinct from the deployment project that is displayed in IBM Cloud.\n\nTo create a project, complete the following steps:\n\n\n\n1. Open the Projects page by selecting My Projects.\n2. Click New project. Name your project, and then choose the project type.\n\nFor more information about each type, see [Project types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsproject-type).\n\nOtherwise, choose None of the above and a Custom project type is created for you.\n3. If you choose a Document Retrieval project type and your data sources are in English, decide whether to enable the Content Intelligence feature.\n\nIf your data source contains contracts, enable the feature by selecting Apply contracts enrichment. Scroll to see the checkbox, if necessary.\n4. Click Next.\n5. Choose and configure a data source or connect to an existing collection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects"},{"document_id":"ibmcld_16727-781134-783054","score":10.68714,"text":"\n* Why am I unable to reach my web page through my CDN after configuring Hotlink Protection with protectionType ALLOW?\n\nLet's consider an example in which your website's domain for users is configured to be your CDN's domain\/hostname: cdn.example.com. When someone attempts to reach a web page by navigating directly from the browser's navigation bar, the browser typically does not send Referer headers in its HTTP request. For example, when you directly navigate in this way to https:\/\/cdn.example.com\/, your CDN considers that the request contains a non-match against the specified refererValues. When the CDN evaluates the appropriate effect or response through your Hotlink Protection, it determines that a non-match occurred. Therefore, your CDN denies access, rather than 'ALLOW'.\n* Can I use private endpoint of object storage in CDN settings?\n\nNo, CDN can only connect to object storage on public endpoints.\n* Can I use the Brotli feature in the CDN service?\n\nNo, the Brotli feature is not supported by our CDN service with Akamai.\n* How do I create a CDN endpoint without using the domain?\n\nYou can create a CDN endpoint without using the domain, but ONLY for a CDN of type Wildcard HTTPS. While creating a CDN of type Wildcard HTTPS, your CNAME acts as the CDN endpoint, and the CNAME is used to serve the traffic.\n* Is HTTP\/2 supported by the IBM Cloud Content Delivery Network service?\n\nYes, HTTP\/2 is supported by Akamai's Edge servers.\n* Is WebSocket supported by the IBM Cloud Content Delivery Network service?\n\nNo, WebSocket is not supported by Akamai's Edge servers.\n* With multiple file purges, what's the difference between a favorite group and an unfavorite group?\n\nA favorite is a permanent group, which means that it will never be deleted unless you change it to an unfavorite group. An unfavorite group is a temporary group. This type of group is automatically deleted after 15 days of inactivity.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03268-3577-4942","score":10.643038,"text":"\n* [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-sms-actionsdialog-sms-actions-disambiguation)\n\n\n\n\n\n Options list \n\nThe dialog supports an option response type, which shows the customer multiple options to choose from. You can customize how the options that are defined for an option response type are shown to customers and the ways in which a customer can select an option by adding the vgwActSetOptionsConfig action command.\n\nThe following example shows how to customize the option response type.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"title\": \"Which of these items do you want to insure?\",\n\"options\":\n{\n\"label\": \"Boat\",\n\"value\": {\n\"input\": {\n\"text\": \"I want to buy boat insurance.\"\n}\n},\n\"label\": \"Car\",\n\"value\": {\n\"input\": {\n\"text\": \"I want to buy car insurance.\"\n}\n},\n\"label\": \"House\",\n\"value\": {\n\"input\": {\n\"text\": \"I want to buy house insurance.\"\n}\n}\n}\n],\n\"description\": \"Insurance types.\",\n\"response_type\": \"option\"\n}\n]\n},\n\"context\": {\n\"smsAction\": {\n\"command\": \"smsActSetOptionsConfig\",\n\"parameters\": {\n\"prefixText\": \"%s.\"\n}\n}\n}\n}\nShow more\n\nFirst the value specified in the title attribute is displayed to the user. Then, the text specified in each label attribute. For example, Which of these items do you want to insure? 1.Boat 2.Car 3.House\n\nTo configure what the assistant shows before each option, edit the prefixText parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-sms-actions"},{"document_id":"ibmcld_08843-16706-18381","score":10.381148,"text":"\nHow can I run Terraform files sequentially based on the results in IBM Cloud Schematics? \n\nYou can use [module blocks](https:\/\/developer.hashicorp.com\/terraform\/language\/modules\/syntax) which is a container for multiple resources that are used together. The Terraform configuration has at least one module known as its root module, which consists of the resources defined in the .tf files of the main working directory. For more information, about reusing configuration through modules, see [terraform-ibm-modules](https:\/\/github.com\/terraform-ibm-modules\/).\n\n\n\n\n\n Can I always set Terraform to use the latest or default version? \n\nYes, in the payload or JSON file, if the value for the type and template_type parameter is not declared, at runtime the default Terraform version is considered. For more information, refer to [specifying version constraints for the Terraform](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-version-constraintsversion-constraints-terraform). You can specify the Terraform version in the payload by using the type or template_type parameter. However, check whether the version value for the type and template_type contains the same version.\n\n\n\n\n\n If I set \"type\u201d: = \u201cterraform_v1.0\" in the JSON file as shown in the code block, will Terraform version 1.0 continue to use even if Terraform version 2.0 or higher are released? \n\n {: codeblock}\n\/\/Sample JSON file\n{\n\"name\": \"<workspace_name>\",\n\"type\": \"terraform_v1.0\",\n\"resource_group\": \"<resource_group>\",\n\"location\": \"\",\n\"description\": \"<workspace_description>\",\n\"template_repo\": {\n\"url\": \"http:\/\/xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",\n\"type\": \"terraform_v1.0\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-faqs"},{"document_id":"ibmcld_07578-688209-689850","score":10.284445,"text":"\n* How can I run Terraform files sequentially based on the results in IBM Cloud Schematics?\n\nYou can use [module blocks](https:\/\/developer.hashicorp.com\/terraform\/language\/modules\/syntax) which is a container for multiple resources that are used together. The Terraform configuration has at least one module known as its root module, which consists of the resources defined in the .tf files of the main working directory. For more information, about reusing configuration through modules, see [terraform-ibm-modules](https:\/\/github.com\/terraform-ibm-modules\/).\n* Can I always set Terraform to use the latest or default version?\n\nYes, in the payload or JSON file, if the value for the type and template_type parameter is not declared, at runtime the default Terraform version is considered. For more information, refer to [specifying version constraints for the Terraform](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-version-constraintsversion-constraints-terraform). You can specify the Terraform version in the payload by using the type or template_type parameter. However, check whether the version value for the type and template_type contains the same version.\n* If I set \"type\u201d: = \u201cterraform_v1.0\" in the JSON file as shown in the code block, will Terraform version 1.0 continue to use even if Terraform version 2.0 or higher are released?\n\n {: codeblock}\n\/\/Sample JSON file\n{\n\"name\": \"<workspace_name>\",\n\"type\": \"terraform_v1.0\",\n\"resource_group\": \"<resource_group>\",\n\"location\": \"\",\n\"description\": \"<workspace_description>\",\n\"template_repo\": {\n\"url\": \"http:\/\/xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-688167-689808","score":10.284445,"text":"\n* How can I run Terraform files sequentially based on the results in IBM Cloud Schematics?\n\nYou can use [module blocks](https:\/\/developer.hashicorp.com\/terraform\/language\/modules\/syntax) which is a container for multiple resources that are used together. The Terraform configuration has at least one module known as its root module, which consists of the resources defined in the .tf files of the main working directory. For more information, about reusing configuration through modules, see [terraform-ibm-modules](https:\/\/github.com\/terraform-ibm-modules\/).\n* Can I always set Terraform to use the latest or default version?\n\nYes, in the payload or JSON file, if the value for the type and template_type parameter is not declared, at runtime the default Terraform version is considered. For more information, refer to [specifying version constraints for the Terraform](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-version-constraintsversion-constraints-terraform). You can specify the Terraform version in the payload by using the type or template_type parameter. However, check whether the version value for the type and template_type contains the same version.\n* If I set \"type\u201d: = \u201cterraform_v1.0\" in the JSON file as shown in the code block, will Terraform version 1.0 continue to use even if Terraform version 2.0 or higher are released?\n\n {: codeblock}\n\/\/Sample JSON file\n{\n\"name\": \"<workspace_name>\",\n\"type\": \"terraform_v1.0\",\n\"resource_group\": \"<resource_group>\",\n\"location\": \"\",\n\"description\": \"<workspace_description>\",\n\"template_repo\": {\n\"url\": \"http:\/\/xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05374-4649-6424","score":10.270286,"text":"\nAnd now what I'll do is ibmcloud ce project create \u2014name amazing product production app. So this create our nice, little\u2026 Target first. I\u2019ll get my default resource group and then I'll go ahead and create the project. There we go. Should only take a moment - perfect. Now you can change your name to whatever you like. This is just a catch-all for your project, which is useful. Then I will take the next command, which is ibmcloud ce app create \u2014name pythonbackend \u2014 build-source . \u2014strategy build packs\n\nNow because I already have a requirements.txt, this will be, this application is smart enough to figure out, \u201chey it's a python application! So let's go ahead and build it!\", which is nice. So as you can see, it's taking step one here. It's running the build, which is good. It creates a nice, private image for us too, which is useful. It takes a couple moments. There we go and now we see that if we wanted to do this with no wait, which is the -nw, we can actually put this into the background and wait for it to come up and then we can check it via this build run get the actual name. Being that we're going to be looking at this live, we'll go ahead and do this here.\n\nPerfect! So now I go ahead and open up the this URL here and it came over here and as you can see\n\n\u201chello moving from Heroku to Code Engine\u201d\n\nAnd that's it. I took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-heroku-migrate"},{"document_id":"ibmcld_04334-147000-148472","score":10.265235,"text":"\nDeprecated] ibmcloud cis origin-certificate-create DNS_DOMAIN_ID --json-str JSON_STR -i, --instance INSTANCE] --output FORMAT]\nDeprecated] ibmcloud cis origin-certificate-create DNS_DOMAIN_ID --json-file JSON_FILE -i, --instance INSTANCE] --output FORMAT] ! !!!!!!\n<-- <section \"id=\"section-command-options-origin-certificate-create\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.--request-type REQUEST_TYPE: Signature type desired on certificate. Valid values: origin-rsa, origin-ecc.--hostnames HOSTNAME: hostname or wildcard name bound to the certificate.--requested-validity DAYS: The number of days for which the certificate should be valid. The default value is 5475.--csr CSR: The Certificate Signing Request (CSR). If not set, CIS will generate one.--json value: The JSON file or JSON string used to describe an origin certificate.\n<-- <ul> -->\n\n* The required fields in JSON data are request_type, hostnames.\n\n<-- <ul> -->\n\n* request_type: Signature type desired on certificate. Valid values: origin-rsa, origin-ecc.\n* hostnames: Array of hostnames or wildcard names bound to the certificate.\n\n<-- <\/ul> -->\n\n* The optional fields are requested_validity, csr.\n\n<-- <ul> -->\n\n* requested_validity: The number of days for which the certificate should be valid. Valid values: 0, 7, 30, 90, 365, 730, 1095, 5475.\n* csr: The Certificate Signing Request (CSR). If not set, CIS will generate one.\n\n<-- <\/ul> -->\n\n<-- <\/ul> -->\n\nSample JSON data:\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16364-163116-165172","score":27.811981,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03054-18427-20301","score":27.247158,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03049-2703-4536","score":25.285908,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03369-125488-127526","score":25.149488,"text":"\nIf you are looking for other ways to analyze your user conversation logs in more detail, consider using Jupyter notebooks. See [Advanced tasks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources) for more details.\n\n\n\n\n\n 9 November 2018 \n\nMajor user interface revision\n: The Watson Assistant service has a new look and added features.\n\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16263-7-2333","score":25.03936,"text":"\nMigrating to the v2 API \n\nThe Watson Assistant v2 runtime API, which supports the use of assistants and skills, was introduced in November 2018. This API offers significant advantages over the v1 runtime API, including automatic state management, ease of deployment, skill versioning, and the availability of new features such as the search skill.\n\nThe v2 API is available for all users, regardless of service plan, at no additional cost.\n\nThe v2 API currently supports only runtime interaction with an existing assistant. Authoring applications that create or modify workspaces should continue to use the v1 API.\n\n\n\n Overview \n\nWith the v2 API, your client app communicates with an assistant, which is an orchestration layer that offers several capabilities, including automatic state management, skill versioning, and easier deployment.\n\nAll communication with an assistant takes place within the context of a session, which maintains conversation state throughout the duration of the conversation. State data, including any context variables that are defined by your dialog or client application, are automatically stored by Watson Assistant, without any action required on the part of your application.\n\nState data persists until you explicitly delete the session, or until the session times out because of inactivity.\n\nIf you prefer to manage state yourself, the v2 API also provides a stateless message method that functions more like the v1 API. If you use the stateless message method, you do not need to explicitly create or delete sessions, and your app is responsible for maintaining context. For more information about the stateless message method, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\nIf you have an existing application that uses the v1 API to send user input directly to a workspace, migrating your app to use the v2 API is a straightforward process.\n\n\n\n\n\n Assistant ID \n\nThe v2 runtime API sends messages to an assistant. On the Assistant Settings page, find the assistant ID. Your application uses this ID to communicate with the assistant. The service credentials are the same for both the v1 and v2 APIs.\n\nCurrently, there is no API support for retrieving an assistant ID. To find the assistant ID, you must use the Watson Assistant user interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-migration"},{"document_id":"ibmcld_03383-15783-17879","score":24.469763,"text":"\nFor details about how to add a search skill response type, see [Adding a Search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n* My response text is surrounded by brackets: If you notice that your response text is surrounded by brackets and quotation marks ([\"My response text\"]) when you test it from the Preview, for example, you might need to change the source field that you're using in the configuration. The unexpected formatting indicates that the value is stored in the source document as an array. Any field that you extract text from must contain a value with a String data type, not an Array data type. When the chat integration shows a response that is extracted from a field that stores the data as an array, it does a straight conversion of the array value into a string, which produces a response that includes the array syntax.\n\nFor example, maybe the field in the source document contains an array with a single text value as its only array element:\n\n\"title\": [\"a single array element\"]\n\nThe array value is converted by the Watson Assistant into this string value:\n\n\"title\": \"[\"a single array element\"]\"\n\nAs a result, the string is returned in this format in the chat; the surrounding brackets and quotation marks are displayed:\n\n[\"a single array element\"]\n\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-15810-17906","score":24.469763,"text":"\nFor details about how to add a search skill response type, see [Adding a Search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n* My response text is surrounded by brackets: If you notice that your response text is surrounded by brackets and quotation marks ([\"My response text\"]) when you test it from the Preview, for example, you might need to change the source field that you're using in the configuration. The unexpected formatting indicates that the value is stored in the source document as an array. Any field that you extract text from must contain a value with a String data type, not an Array data type. When the chat integration shows a response that is extracted from a field that stores the data as an array, it does a straight conversion of the array value into a string, which produces a response that includes the array syntax.\n\nFor example, maybe the field in the source document contains an array with a single text value as its only array element:\n\n\"title\": [\"a single array element\"]\n\nThe array value is converted by the Watson Assistant into this string value:\n\n\"title\": \"[\"a single array element\"]\"\n\nAs a result, the string is returned in this format in the chat; the surrounding brackets and quotation marks are displayed:\n\n[\"a single array element\"]\n\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03403-33406-33957","score":24.189798,"text":"\nUnlike when you send test utterances to your assistant from the \"Try it out\" pane, standard usage charges apply to API calls that result from utterances that are submited to the chat widget.\n\n\n\n\n\n\n\n Next steps \n\nNow that you have built and tested your dialog skill, you can share it with customers. Deploy your skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03383-17365-19519","score":23.924303,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":23.924303,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03373-7076-8670","score":16.207075,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03054-19820-21851","score":16.15325,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03043-4515-6369","score":16.091606,"text":"\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-diagram.png)\n\nFor help creating a search skill, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Create the skill \n\nYou can add one skill of each skill type to an assistant.\n\n\n\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add)\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add)\n\n\n\n\n\n\n\n Skill limits \n\n\n\nSkill limit details\n\n Skills per service instance \n\n 50 \n\n\n\nSkill versions do not count toward the skill limit.\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants. From the Skills page, find the tile for the skill that you want to delete. The Assistants field lists the assistants that currently use the skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03383-19002-21103","score":16.040333,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-19029-21139","score":16.040333,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03383-17365-19519","score":16.020184,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":16.020184,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-18427-20301","score":15.797522,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-20671-22804","score":15.653142,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":15.653142,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2769189463}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12330-7-2140","score":26.379637,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10817-4371-5701","score":25.715979,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":22.741846,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-7-1802","score":22.502121,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":21.614279,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_12330-1723-4013","score":21.13858,"text":"\nAsynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service. In particular, the SDK should supply the SDK name and version in the User-Agent header of each API request, along with supporting information such as language version, OS name and version, etc. whenever such information is readily available.\n\n\n\n\n\n Parameter validation \n\nThe SDK MUST perform basic validation of method parameters and return errors\/exceptions before invoking the underlying API. For example, the SDK should ensure all required parameters have been supplied before invoking the API.\n\nHowever, validation of specific enum values SHOULD NOT be performed in the SDK, since this would preclude the SDK from being used with a later version of the service that supports new enum values for a parameter.\n\n\n\n\n\n Default values \n\nThe SDK SHOULD NOT supply default values for any parameter not supplied by the caller, even if a default value is clearly specified in the API documentation. Rather, the assignment of the default should be delegated to the service, so that the service can alter the default value when appropriate without impacting the SDK.\n\n\n\n\n\n Serialization and deserialization \n\nThe SDK MUST silently ignore additional properties in response payloads, to allow the SDK to work with newer versions of the service.\n\nThe SDK SHOULD silently ignore additional properties in dictionary- or map-type parameters. This is to allow values that may have been returned from a newer version of the service to be supplied on subsequent method invocations.\n\n\n\n\n\n Retry \n\nThe SDK MAY provide an automated retry mechanism provided that the user can specify:\n\n\n\n* The maximum number of retry attempts, including zero.\n* The minimum and maximum time interval between retry attempts.\n* The HTTP status codes or error classes that should be retried.\n\n\n\nThe retry mechanism should respect a \"retry-after\" response header if one is returned from the service.\n\n\n\n\n\n Logging","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_02698-7-1759","score":21.086628,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_10852-44214-45420","score":21.070156,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12335-0-917","score":20.589218,"text":"\n\n\n\n\n\n\n  Errors \n\n\n\n  Error delivery \n\nSDK methods MUST surface errors to the caller in the manner that is idiomatic for the particular language. For example, a Go SDK should return an error value from the method, but a Java SDK should raise an Exception.\n\n\n\n\n\n  Error content \n\nWhen an SDK method encounters an error, it MUST capture all relevant information about the error and return it in the error structure that is returned to the caller. Relevant information includes the entire contents of the error response and all response headers. The SDK documentation MUST clearly describe how this information is returned and how it can be accessed by the calling program.\n\nErrors that are generated within the SDK MUST give a clear and specific description of the problem. For example, if a method parameter failed a validation, the message should state which parameter is invalid and the reason it is invalid.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-errors"},{"document_id":"ibmcld_10817-5370-6915","score":20.412188,"text":"\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {\ntry whisk.fireTrigger(name: \"locationChanged\", package: \"mypackage\", namespace: \"mynamespace\", parameters: locationParams, callback: {(reply, error) -> Void in\nif let error = error {\nprint(\"Error firing trigger (error.localizedDescription)\")\n} else {\nprint(\"Trigger fired!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nIn the previous example, you are firing a trigger that is called locationChanged.\n\n\n\n\n\n Use mobile SDK actions that return a result \n\nIf the action returns a result, set hasResult to true in the invokeAction call. The result of the action is returned in the reply dictionary, for example:\n\ndo {\ntry whisk.invokeAction(name: \"actionWithResult\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: true, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-1426-3052","score":20.793127,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-7-1743","score":17.469381,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":16.513449,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":16.245623,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-15747-17355","score":15.83641,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-14062-16080","score":14.3390045,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":14.081331,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":13.6009865,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":9.814326,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10534-284670-286038","score":9.29272,"text":"\n[Adding services by using Helm charts](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmhelm)\n\n\n\n* [About Helm in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmabout-helm)\n\n\n\n* [What is Helm and how do I use it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmwhat-is-helm)\n* [What Helm charts are supported in Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helmsupported-charts)\n\n\n\n* [Installing Helm v3 in your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helminstall_v3)\n\n\n\n[Adding services by using IBM Cloud service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingservice-binding)\n\n\n\n* [About service binding](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-about)\n\n\n\n* [What types of services can I bind to my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-types)\n* [What is IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-what)\n* [I already have an IBM Cloud service. Can I still use IBM Cloud service binding?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-bindingsvc-bind-existing)\n* [What if I want to use service credentials that use the private cloud service endpoint?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.6719882468}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-1426-3052","score":25.279383,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":24.54749,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":23.277178,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":22.559006,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":21.108131,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":18.777222,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":18.41384,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-15747-17355","score":18.296862,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_05367-4252-6277","score":16.510782,"text":"\nstatusCode: 302\n}\n}\n\n\n\n\n\n Example 3: Generating a plain text response from a Function \n\nThe following example illustrates how to generate a plain text response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name !== \"\") {\nmsg = Hello, ${params.name}!\n}\nreturn {\nheaders: { 'Content-Type': 'text\/plain;charset=utf-8' },\nbody: ${msg}\n}\n}\n\n\n\n\n\n\n\n Error handling and debugging \n\nFunction invocations can return system or application errors. For example, system errors indicate that the function code did not execute successfully, while application errors indicate a problem in the Function code itself.\n\nWhen a system error occurs, an HTTP response code similar to the following codes is returned.\n\n\n\nTable 1. HTTP response codes\n\n Code Description \n\n 409 The resources that are required by the Function could not be satisfied. \n 413 The request payload exceeds the defined maximum. \n 414 The invocation URI is too long. \n 416 The Function generated a response that exceeds the defined maximum. \n 422 The Function code could not be loaded from a specified source. \n 429 You exceeded your resource quota, could not schedule the Function. \n 431 The request headers exceed the defined maximum. \n 500 Internal server error. \n 502 Bad gateway. \n 503 Function currently unavailable, please try again later. \n 507 Insufficient storage to load the Function or Image. \n\n\n\nIf Code Engine can execute the Functions code, it responds to the invocation with one of the following status codes.\n\n\n\nTable 2. Status codes\n\n Code Description \n\n 200 Function invocation accepted, the Function will be executed delayed. \n 202 Function invocation accepted, the Function will be executed asynchronously. \n 299 The Function exceeded the specified or maximum runtime limit and was aborted. \n\n\n\nAs a developer of a Function, you can generate any arbitrary HTTP status code, even the ones listed previously. Therefore, a response header indicates that the status code was generated by the Function code.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work"},{"document_id":"ibmcld_05363-5023-6990","score":16.228638,"text":"\nMain: main()\n\nNow that your function is created from repository source code, you can update the function to meet your needs by using the [ibmcloud ce function update](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-function-update) command. If you want to update your source to use with your function, you must provide the --build-source option on the function update command.\n\nWhen your function is created from repository source code or from [local source](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-create-local) with the CLI, the resulting build run is not based on a build configuration. Build runs that complete are ultimately automatically deleted. Build runs that are not based on a build configuration are deleted after 1 hour if the build run is successful. If the build run is not successful, this build run is deleted after 24 hours. You can only display information about this build run with the CLI. You cannot view this build run in the console.\n\n\n\n Including dependencies for your Function \n\nYou can create Functions in many different programming languages. When your Function code grows complex, you can add code modules as dependencies for your Function. Each language has its own modules to use with your Function code. For example, Node.js dependencies are usually existing npm modules, whereas Python uses Python packages. These dependencies must be declared and created in a file with your source code\n\n\n\n Including modules for a Node.js Function \n\nCreate a function that includes a dependency for a specific Python module by creating a package.json file. In this case, both the source code and package file are located in the same folder.\n\n\n\n1. Create your source code by writing your code into a main.js file. For example, copy the following code example into a file called main.js.\n\nfunction main(args) {\nconst oneLinerJoke = require('one-liner-joke');\nlet getRandomJoke = oneLinerJoke.getRandomJoke();\n\nreturn {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-create-repo"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":31.671732,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10766-7-2062","score":29.563143,"text":"\nError handing for Cloud Functions \n\nIBM Cloud\u00ae Functions provides error handling through the execution status of each function invocation. Error handling is provided by Cloud Functions for invocations that are exposed through the Cloud Functions API, SDK, CLI, or the console. For more information about the various error types, see [Action executions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_exec).\n\nIn addition, the Cloud Functions service automatically reports errors to the Monitoring service. You can set up the built-in integration for the Monitoring service with the IBM Cloud\u00ae Functions service to automatically react to error messages. For more information about setting up an alert through a subsequent action invocation, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-alerts-notify).\n\nTo handle errors, choose one of the following options.\n\n\n\n1. Handle application errors programmatically within the action implementation itself and handle service errors through the Cloud Functions service API, CLI, SDK, or console by leveraging the automatically set Cloud Functions execution status.\n2. Use the built-in integration with the IBM Cloud Monitoring service to define a subsequent action to be invoked in response to the error. All configuration and execution occurs service-side. For more information, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-notifications) and [Monitoring Cloud Functions entities with IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-monitor-functions).\n3. Handle errors programmatically by including the Composer library within the action implementation. By using the library, you can chain together a sequence of actions or define other types of control-flow logic. When you use this library, all execution of the [error-handling code occurs service-side](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_composererror-handling) and there are no additional components that you must manage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-error-handing-functions"},{"document_id":"ibmcld_10852-45155-46272","score":29.425074,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_05078-7-1706","score":29.124626,"text":"\nData IO and encryption \n\nObject size can have significant impacts on IBM Cloud\u00ae Object Storage performance. Choose the right approach for your workload.\n\n\n\n Multipart transfers \n\nUnder typical conditions, multipart uploads and downloads are a very efficient method for breaking up transfers into many parallel transactions. Depending on the object size, a part size of 100MB is generally recommended. In any case, it is most efficient to set the part size to a multiple of 4MiB in order to optimize the data ingest into and egress out of COS.\n\nAs with AWS S3, using multipart transfers provides the following advantages:\n\n\n\n* Improved throughput \u2014 You can upload parts in parallel to improve throughput.\n* Quick recovery from any network issues \u2014 Smaller part size minimizes the impact of restarting a failed upload due to a network error.\n* Pause and resume object uploads \u2014 Upload object parts over time. Once a multipart upload is initiated a multipart upload there is no expiry; it must explicitly complete or the multipart upload has to be aborted.\n* Begin an upload before the final object size is known \u2014 An object can be uploaded as it is being created.\n\n\n\nDue to the additional complexity of multipart transfers, it is recommended to use appropriate S3 libraries, tools, or SDKs that offer support for managed multipart transfers:\n\n\n\n* [IBM COS SDK for Java](https:\/\/github.com\/IBM\/ibm-cos-sdk-java)\n* [IBM COS SDK for Python](https:\/\/github.com\/IBM\/ibm-cos-sdk-python)\n* [IBM COS SDK for Javascript (Node.js)](https:\/\/github.com\/IBM\/ibm-cos-sdk-js)\n* [IBM COS SDK for Go](https:\/\/github.com\/IBM\/ibm-cos-sdk-go)\n* [IBM COS Plug-in for IBM Cloud CLI](https:\/\/github.com\/IBM\/ibmcloud-cos-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-performance-io"},{"document_id":"ibmcld_02772-1628-3402","score":28.73905,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10805-1522-3235","score":28.67183,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_02731-4670-6607","score":28.600279,"text":"\n: Server SDK: You can protect your back-end resources that are hosted on IBM Cloud and your web apps by using the server SDK. It extracts the access token from a request and validates it with App ID. Client SDK: You can protect your mobile apps with the Android or iOS client SDK. The client SDK communicates with your cloud resources to start the authentication process when it detects an authorization challenge.\n\nIBM Cloud\n: App ID: After successful authentication, App ID returns access and identity tokens to your app. Cloud Directory: Users can sign up for your service with their email and a password. You can then manage your users in a list view through the UI. With Cloud Directory, App ID functions as your identity provider.\n\nExternal (third party)\n: Social and enterprise identity providers: App ID supports Facebook, Google+, and SAML 2.0 Federation as identity provider options. The service arranges a redirect to the identity provider and verifies the returned authentication tokens. If the tokens are valid, the service grants access to your app.\n\n\n\n\n\n Integrations \n\nYou can use App ID with other IBM Cloud offerings.\n\nKubernetes Service\n: By configuring Ingress in a standard cluster you can secure your apps at the cluster level. Check out the [App ID authentication Ingress annotation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsapp-id-authentication) or the [Announcing App ID integration to IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/announcing-app-id-integration-ibm-cloud-kubernetes-service) blog post to get started.\n\nCloud Functions and API Connect\n: When you create your APIs with [Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) and [API Connect](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-getting-started), you can secure your applications at the gateway rather than in your app code.\n\nActivity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-about"},{"document_id":"ibmcld_10817-6582-8092","score":27.852129,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":27.76172,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-4371-5701","score":27.103102,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10863-5217-6577","score":21.85063,"text":"\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our\n\/\/ custom sequence and return it in the last step of the sequence as the overall action result.\n\n\/\/ Although the following .then() blocks are run asynchronously, the main() function acts as a closure that\n\/\/ makes sure that the chained_action_results variable is accessible for all .then() blocks\nconst chained_action_results = [];\n\nconsole.log('Building custom sequence, using openwhisk node-js SDK...');\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking db-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/db-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_05088-31320-33239","score":21.806051,"text":"\nDirectory download in progress: 5632 bytes transferred\nDirectory download in progress: 1047552 bytes transferred\n...\nDirectory download in progress: 53295130 bytes transferred\nDirectory download in progress: 62106855 bytes transferred\nDownload complete!\n\n\n\n\n\n Pause\/Resume\/Cancel \n\nThe SDK provides the ability to manage the progress of file\/directory transfers through the following methods of the AsperaTransferFuture object:\n\n\n\n* pause()\n* resume()\n* cancel()\n\n\n\nThere are no side-effects from calling either of the methods outlined above. Proper clean up and housekeeping is handled by the SDK.\n\n Create Transfer manager\nbucket_name = \"<bucket-name>\"\nlocal_download_directory = \"<absolute-path-to-directory>\"\nremote_directory = \"<object prefix>\"\n\nwith AsperaTransferManager(client) as transfer_manager:\n\n download a directory with Aspera\nfuture = transfer_manager.download_directory(bucket_name, remote_directory, local_download_directory, None, None)\n\n pause the transfer\nfuture.pause()\n\n resume the transfer\nfuture.resume()\n\n cancel the transfer\nfuture.cancel()\nShow more\n\n\n\n\n\n Troubleshooting Aspera Issues \n\nIssue: Developers using any version of Python besides 3.6 may experience failures when installing or using Aspera SDK.\n\nCause: If there are different versions of Python installed on your environment, then you might encounter installation failures when you try to install the Aspera SDK. This can be caused by a missing DLL files or wrong DLL in path.\n\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_10863-7246-8495","score":20.45953,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10863-6347-7636","score":19.493572,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10817-5370-6915","score":18.594248,"text":"\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {\ntry whisk.fireTrigger(name: \"locationChanged\", package: \"mypackage\", namespace: \"mynamespace\", parameters: locationParams, callback: {(reply, error) -> Void in\nif let error = error {\nprint(\"Error firing trigger (error.localizedDescription)\")\n} else {\nprint(\"Trigger fired!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nIn the previous example, you are firing a trigger that is called locationChanged.\n\n\n\n\n\n Use mobile SDK actions that return a result \n\nIf the action returns a result, set hasResult to true in the invokeAction call. The result of the action is returned in the reply dictionary, for example:\n\ndo {\ntry whisk.invokeAction(name: \"actionWithResult\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: true, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_11347-10510-12848","score":18.589636,"text":"\nWhen you attempt to resize the memory as well as CPU of a deployed virtual server instance through a single request it may fail due to the following reasons:\n\n\n\n* There is no free memory available on the host.\n* There is no free memory available on the logical partition as the resources on it are running.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request.\n* You have made multiple attempts for resizing.\n* Currently, there is no preference for memory or CPU on what should be resized first. If the first request being processed fails, the second one will also fail automatically.\n\n\n\nExample: When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3.2 GB for running resources in it), then there is a possibility that both the CPU and memory resize will fail.\n\n\n\n\n\n You request for resizing the memory but you get a partial resize \n\nWhen you attempt to resize the memory of a deployed virtual server instance through a request, it may partially resize or in the worst scenarios even fail due to the following reasons:\n\n\n\n* There is no free memory available on the host will result in failed request.\n* There is no free memory available on the logical partition as the resources are running on it. This will result in a failed request.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request. This will result in a partial resize.\n* You have made multiple attempts for resizing. This will result in a failed request.\n\n\n\nExample:When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3 GB for running resources in it) and can free up only 1 GB, then the partial resize should be possible to reduce the memory to 3GB.\n\nIn the current cloud environment, it may take upto 1.5 hours approximately for the change in memory to be updated to places referring to the memory of the logical partition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-modifying-server"},{"document_id":"ibmcld_05088-32788-34517","score":18.555702,"text":"\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python). This should allow you to install the Aspera SDK on Python 3.6.x without any issues.\n\n\n\n\n\n\n\n Updating metadata \n\nThere are two ways to update the metadata on an existing object:\n\n\n\n* A PUT request with the new metadata and the original object contents\n* Running a COPY request with the new metadata specifying the original object as the copy source\n\n\n\n\n\n Using PUT to update metadata \n\nNote: The PUT request overwrites the existing contents of the object so it must first be downloaded and re-uploaded with the new metadata.\n\ndef update_metadata_put(bucket_name, item_name, key, value):\ntry:\n retrieve the existing item to reload the contents\nresponse = cos_cli.get_object(Bucket=bucket_name, Key=item_name)\nexisting_body = response.get(\"Body\").read()\n\n set the new metadata\nnew_metadata = {\nkey: value\n}\n\ncos_cli.put_object(Bucket=bucket_name, Key=item_name, Body=existing_body, Metadata=new_metadata)\n\nprint(\"Metadata update (PUT) for {0} Complete!n\".format(item_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nlog_error(\"Unable to update metadata: {0}\".format(e))\nShow more\n\n\n\n\n\n Using COPY to update metadata \n\ndef update_metadata_copy(bucket_name, item_name, key, value):\ntry:\n set the new metadata\nnew_metadata = {\nkey: value","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_02674-11255-12899","score":17.909765,"text":"\nThe SDK uses the attribute values to determine if the specified entity satisfies the targeting rules, and returns the appropriate property value.\n\n\n\n\n\n\n\n How to access the payload secret data from the response \n\n\/\/make sure this import statement is added\nimport (sm \"github.com\/IBM\/secrets-manager-go-sdk\/secretsmanagerv1\")\n\nsecret := getSecretRes.Resources[0].(sm.SecretResource)\nsecretData := secret.SecretData.(map[string]interface{})\npayload := secretData[\"payload\"]\n\nThe GetCurrentValue will be sending the three objects as part of response.\n\n\n\n* getSecretRes: this will give the meta data and payload.\n* detailedResponse: this will give entire data which includes the http response header data, meta data and payload.\n* err: this will give the error response if the request is invalid or failed for some reason.\n\n\n\nsecretData[\"payload\"] will return interface{} so based on the data you need to do the type casting.\n\n\n\n\n\n Fetching the appConfigClient across other modules \n\nOnce the SDK is initialized, the appConfigClient can be obtained across other modules as shown below:\n\n\/\/ other modules\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nappConfigClient := AppConfiguration.GetInstance()\nfeature, err := appConfigClient.GetFeature(\"online-check-in\")\nif (err == nil) {\nenabled := feature.IsEnabled()\nfeatureValue := feature.GetCurrentValue(entityId, entityAttributes)\n}\n\n\n\n\n\n\n\n\n\n Supported data types \n\nYou can configure feature flags and properties with App Configuration, supporting the following data types: Boolean, Numeric, String, and SecretRef. The String data type can be a text string, JSON, or YAML.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_05070-17027-18397","score":17.773098,"text":"\nconsole.log(Retrieving HEAD for item: ${itemName} from bucket: ${bucketName});\nconsole.log(JSON.stringify(data, null, 4));\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nSDK References\n\n\n\n* [headObject](https:\/\/ibm.github.io\/ibm-cos-sdk-js\/AWS\/S3.html)\n\n\n\n\n\n\n\n\n\n Updating Metadata \n\nThere are two ways to update the metadata on an existing object:\n\n\n\n* A PUT request with the new metadata and the original object contents\n* Executing a COPY request with the new metadata specifying the original object as the copy source\n\n\n\n\n\n Using PUT to update metadata \n\nNote: The PUT request overwrites the existing contents of the object so it must first be downloaded and re-uploaded with the new metadata.\n\nfunction updateMetadataPut(bucketName, itemName, metaValue) {\nconsole.log(Updating metadata for item: ${itemName});\n\n\/\/retrieve the existing item to reload the contents\nreturn cos.getObject({\nBucket: bucketName,\nKey: itemName\n}).promise()\n.then((data) => {\n\/\/set the new metadata\nvar newMetadata = {\nnewkey: metaValue\n};\n\nreturn cos.putObject({\nBucket: bucketName,\nKey: itemName,\nBody: data.Body,\nMetadata: newMetadata\n}).promise()\n.then(() => {\nconsole.log(Updated metadata for item: ${itemName} from bucket: ${bucketName});\n})\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Using COPY to update metadata","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_01738-14841-16133","score":17.56497,"text":"\nfmt.Println(jsonErr)\nreturn\n}\nprintln(string(jsonData))\n}\n\n\/\nPrints the Event Logs.\n\/\nfunc printLogs(logs []datatypes.Event_Log){\nfmt.Printf(\"| %35s | %25s |%10s |n\",\"Event Name\",\"Event Create Date\",\"User Type\")\nfor _, log := range logs {\nif log!=(datatypes.Event_Log{}){\nfmt.Printf(\"| %35s \", log.EventName)\nfmt.Printf(\"| %25s \", log.EventCreateDate)\nfmt.Printf(\"| %10s |n\", log.UserType)\n}\n}\n}\n\nTo get all Events logs, use [SoftLayer_Event_Log::getAllObjects()](https:\/\/softlayer.github.io\/reference\/services\/SoftLayer_Event_Log\/getAllObjects\/). In this case, just the first 50 events are returned by using pagination limit resultLimit=0,50. For more information, see [Using Result Limits in the SoftLayer API](https:\/\/sldn.softlayer.com\/article\/using-result-limits-softlayer-api\/). A mask is shown in this example, mask[eventName,eventCreateDate,userType], that restricts other local fields and limits the amount of information returned.\n\nThis example deals with a few ways of pulling data from SoftLayer_Event_Log. There can be many Logs, so by using a filter, like the recentLogs function, you can limit how far back you search for Events.\n\nThis example deals with a few ways of pulling data from [SoftLayer_Event_Log](https:\/\/sldn.softlayer.com\/reference\/services\/SoftLayer_Event_Log\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-audit-log"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-6582-8092","score":46.903145,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":35.962826,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10805-1522-3235","score":34.244762,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_10817-2884-4620","score":33.965496,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-45155-46272","score":33.507275,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-3694-5102","score":30.14078,"text":"\nTutorials \n\n[Calling an action from another action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_actiontutorial_action)\n\n\n\n* [Create the cos-access action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_actiontutorial_action_cos-action)\n* [Create the db-access action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_actiontutorial_action_db-access)\n* [Create the ow-sdk-action action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_actiontutorial_action_ow-sdk-action)\n\n\n\n[Build a database driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watsonslack-chatbot-database-watson)\n\n[Combining serverless and Cloud Foundry for data retrieval and analytics](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-github-traffic-analyticsserverless-github-traffic-analytics)\n\n[Mobile application with serverless backend](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-mobile-backendserverless-mobile-backend)\n\n[Serverless web application and API](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-api-webappserverless-api-webapp)\n\n\n\n\n\n Release notes for Cloud Functions \n\n[Release notes for Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-openwhisk-relnotesopenwhisk-relnotes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02731-4670-6607","score":30.00453,"text":"\n: Server SDK: You can protect your back-end resources that are hosted on IBM Cloud and your web apps by using the server SDK. It extracts the access token from a request and validates it with App ID. Client SDK: You can protect your mobile apps with the Android or iOS client SDK. The client SDK communicates with your cloud resources to start the authentication process when it detects an authorization challenge.\n\nIBM Cloud\n: App ID: After successful authentication, App ID returns access and identity tokens to your app. Cloud Directory: Users can sign up for your service with their email and a password. You can then manage your users in a list view through the UI. With Cloud Directory, App ID functions as your identity provider.\n\nExternal (third party)\n: Social and enterprise identity providers: App ID supports Facebook, Google+, and SAML 2.0 Federation as identity provider options. The service arranges a redirect to the identity provider and verifies the returned authentication tokens. If the tokens are valid, the service grants access to your app.\n\n\n\n\n\n Integrations \n\nYou can use App ID with other IBM Cloud offerings.\n\nKubernetes Service\n: By configuring Ingress in a standard cluster you can secure your apps at the cluster level. Check out the [App ID authentication Ingress annotation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsapp-id-authentication) or the [Announcing App ID integration to IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/announcing-app-id-integration-ibm-cloud-kubernetes-service) blog post to get started.\n\nCloud Functions and API Connect\n: When you create your APIs with [Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) and [API Connect](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-getting-started), you can secure your applications at the gateway rather than in your app code.\n\nActivity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-about"},{"document_id":"ibmcld_00642-6293-7424","score":28.99054,"text":"\nTombstones are used for more consistent deletion of documents from databases. This purpose is especially important for mobile devices: without tombstone documents, a deletion might not replicate correctly to a mobile device, with the result that documents might never be deleted from the device.\n\nIf you re-create a database, for example, a new target for a replication. Any clients that use the target database as a server must work through all the changes again because the database sequence numbers are likely to be different.\n\nIf you're using a validate_doc_update function, avoid replicating that function to clients. This rule is to prevent the possibility of unwanted side effects that result from having the function present on the client.\n\n[IBM Cloudant sync](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-librariesmobile-supported) libraries don't replicate design documents, so replication of validate_doc_update functions is not normally a problem for IBM Cloudant. However, other clients might replicate the design documents or validate_doc_update functions, potentially resulting in unwanted side effects.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-tombstone-docs"},{"document_id":"ibmcld_10864-5549-7975","score":28.690075,"text":"\nAdditionally, Cloud Functions actions can be connected to an API Management tool of choice. Similar to other use cases, all considerations for scalability, and other Qualities of Services apply.\n\nSee the following example that includes a discussion of [using Serverless as an API backend](https:\/\/martinfowler.com\/articles\/serverless.htmlACoupleOfExamples).\n\n\n\n\n\n Mobile back end \n\nMany mobile applications require server-side logic. However, mobile developers usually don\u2019t have experience in managing server-side logic, and would rather focus on the app that is running on the device. This development goal is easily obtained by using Cloud Functions as the server-side back end, and is a good solution. In addition, the built-in support for server-side Swift allows developers to reuse their existing iOS programming skills. Since mobile applications often have unpredictable load patterns, you want to use a Cloud Functions solution like IBM Cloud\u00ae. This solution can scale to meet practically any demand in workload without the need to provision resources ahead of time.\n\n\n\n\n\n Data processing \n\nWith the amount of data now available, application development requires the ability to process new data, and potentially react to it. This requirement includes processing both structured database records as well as unstructured documents, images, or videos. Cloud Functions can be configured by system-provided or custom feeds to react to changes in data, and automatically execute actions on the incoming feeds of data. Actions can be programmed to process changes, transform data formats, send and receive messages, invoke other actions, and update various data stores. Supported data stores include SQL based relational databases, in-memory data grids, NoSQL database, files, messaging brokers, and various other systems. Cloud Functions rules and sequences provide flexibility to change the processing pipeline without programming, and is performed through simple configuration updates. The data store options and low administrative maintenance make a Cloud Functions based system highly agile, and easily adaptable to changing requirements.\n\n\n\n\n\n Cognitive \n\nCognitive technologies can be effectively combined with Cloud Functions to create powerful applications. For example, Watson Visual Recognition can be used with Cloud Functions to automatically extract useful information from videos without having to watch them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"},{"document_id":"ibmcld_05277-7697-8260","score":28.588175,"text":"\nFunctions can be packaged in three different ways.\n\n\n\n* as a single file\n* as multiple files (with a folder structure and dependent modules)\n* as a container image\n\n\n\n\n\n\n\n\n\n How can I get started with Functions? \n\nTo deploy a simple Code Engine application with a hello-world sample image, see [Running IBM Code Engine Functions](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-tutorial) tutorial.\n\nTo dive deeper into working with Functions, see [Working with Functions in Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cefunctions"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16233-7-2298","score":33.539597,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_07148-7-2060","score":32.615784,"text":"\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question\/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https:\/\/medium.com\/ibm-watson\/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit"},{"document_id":"ibmcld_16254-0-2109","score":32.453094,"text":"\n\n\n\n\n\n\n  High availability and disaster recovery \n\nIBM Watson\u00ae Assistant is highly available within multiple IBM Cloud\u00ae locations (for example, Dallas and Washington, DC). However, recovering from potential disasters that affect an entire location requires planning and preparation.\n\nYou are responsible for understanding your configuration, customization, and usage of Watson Assistant. You are also responsible for being ready to re-create an instance of the service in a new location and to restore your data in any location. See [How do I ensure zero downtime?](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimezero-downtime) for more information.\n\n\n\n  High availability \n\nWatson Assistant supports high availability with no single point of failure. The service achieves high availability automatically and transparently by using the multi-zone region feature provided by IBM Cloud.\n\nIBM Cloud enables multiple zones that do not share a single point of failure within a single location. It also provides automatic load balancing across the zones within a region.\n\n\n\n\n\n  Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because the multi-zone region feature is not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud. See [Backing up and restoring data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-backup-restore) for information about how to back up your service instances.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-recovery"},{"document_id":"ibmcld_03368-0-2267","score":32.31223,"text":"\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n  High availability and disaster recovery \n\nIBM Watson\u00ae Assistant is highly available within multiple IBM Cloud\u00ae locations (for example, Dallas and Washington, DC). However, recovering from potential disasters that affect an entire location requires planning and preparation.\n\nYou are responsible for understanding your configuration, customization, and usage of Watson Assistant. You are also responsible for being ready to re-create an instance of the service in a new location and to restore your data in any location. See [How do I ensure zero downtime?](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimezero-downtime) for more information.\n\n\n\n  High availability \n\nWatson Assistant supports high availability with no single point of failure. The service achieves high availability automatically and transparently by using the multi-zone region feature provided by IBM Cloud.\n\nIBM Cloud enables multiple zones that do not share a single point of failure within a single location. It also provides automatic load balancing across the zones within a region.\n\n\n\n\n\n  Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because the multi-zone region feature is not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud. See [Backing up and restoring data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup) for information about how to back up your service instances.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-recovery"},{"document_id":"ibmcld_03330-4-2191","score":32.304337,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_03330-3253-5192","score":32.039043,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_13160-14797-16607","score":31.645136,"text":"\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http:\/\/localhost](http:\/\/localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/Slackbot_event.png)\n\nSlack with the eventbot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_06310-0-1139","score":31.506401,"text":"\n\n\n\n\n\n\n  FAQs - General \n\nThis is a collection of frequently asked questions (FAQ) about the Watson Query service.\n\n\n\n  How do I generate credentials for my instance? \n\n\n\n1.  Log in to [IBM Cloud](https:\/\/cloud.ibm.com).\n2.  Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3.  Under Databases, locate your Watson Query instance and click the service name. This list includes all instances that were created under a resource group or that were migrated into a resource group.\n4.  Click Service credentials > New credentials > Add to generate your Watson Query Manager credentials.\n5.  Expand View credentials, which displays your service connectivity information including your credentials (username and password).\n6.  The Manager credentials can be used to connect to both Watson Query and the web console.\n\n\n\n\n\n\n\n  Now that I generated credentials, how do I access my Watson Query instance? \n\nYou can access your Watson Query instance by using a dedicated Data virtualization workspace in IBM Cloud Pak for Data as a Service or the [Watson Query Rest APIs](https:\/\/cloud.ibm.com\/apidocs\/data-virtualization-on-cloud).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-faq_dv"},{"document_id":"ibmcld_09228-7-1878","score":31.269178,"text":"\nSample apps \n\nIBM is announcing the deprecation of the IBM Watson\u00ae Language Translator service for IBM Cloud\u00ae in all regions. As of 10 June 2023, the Language Translator tile will be removed from the IBM Cloud Platform for new customers; only existing customers will be able to access the product. As of 10 June 2024, the service will reach its End of Support date. As of 10 December 2024, the service will be withdrawn entirely and will no longer be available to any customers.\n\nCheck out the following sample applications to see what you can build with Language Translator.\n\nThese systems are for demonstration purposes only and are not intended to process Personal Data. No Personal Data is to be entered into these systems as they may not have the necessary controls in place to meet the requirements of the General Data Protection Regulation (EU) 2016\/679.\n\n\n\n Snap and translate text in images (Node.js) \n\nThis sample app explains how to create a hybrid mobile app that uses Watson Language Translator and Tesseract OCR. With this sample app you can capture an image, extract the text, and translate that text.\n\n\n\n* [Read the blog](https:\/\/developer.ibm.com\/announcements\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [Code Pattern](https:\/\/developer.ibm.com\/patterns\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [View on GitHub](https:\/\/github.com\/IBM\/snap-and-translate)\n\n\n\n\n\n\n\n Multilingual Chatbot (Node.js, Python) \n\nThis chatbot that is built with Watson Assistant and Cloud Functions adds support for multiple languages with Language Translator.\n\n\n\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_07578-499040-500999","score":29.986889,"text":"\nOpen your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Databases, locate your Watson Query instance and click the service name. This list includes all instances that were created under a resource group or that were migrated into a resource group.\n4. Click Service credentials > New credentials > Add to generate your Watson Query Manager credentials.\n5. Expand View credentials, which displays your service connectivity information including your credentials (username and password).\n6. The Manager credentials can be used to connect to both Watson Query and the web console.\n\n\n\n* Now that I generated credentials, how do I access my Watson Query instance?\n\nYou can access your Watson Query instance by using a dedicated Data virtualization workspace in IBM Cloud Pak for Data as a Service or the [Watson Query Rest APIs](https:\/\/%7BDomainName%7D\/apidocs\/data-virtualization-on-cloud).\n\n\n\nIBM watsonx.data\n\n\n\n* What is watsonx.data?\n\nwatsonx.data is an open, hybrid, and governed fit-for-purpose data store optimized to scale all data, analytics and AI workloads to get greater value from your analytics ecosystem.\n* What can I do with watsonx.data?\n\nYou can connect to data in multiple locations and get started in minutes with built-in governance, security and automation. You can leverage multiple query engines to run analytics and AI workloads, reducing your data warehouse costs by up to 50%.\n* What are the key features of watsonx.data?\n\nKey features of watsonx.data are:\n\n\n\n* The architecture fully separates compute, metadata, and storage to provide ultimate flexibility.\n* Fit for purpose query engines designed to handle modern data formats that are highly elastic and scalable.\n* Data sharing between watsonx.data, Db2\u00ae Warehouse on Cloud, and Netezza or any other data management solution through common Iceberg table format support, connectors, and a shareable metadata store.\n\n\n\n* How can I create a watsonx.data service instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13160-14797-16607","score":13.887932,"text":"\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http:\/\/localhost](http:\/\/localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/Slackbot_event.png)\n\nSlack with the eventbot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_07223-4208-5090","score":13.315528,"text":"\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=uigisF50F8s&feature=youtu.be)\n\n\n\n[Cognitive Banking Chatbot](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/?cm_sp=Developer-_-code-_-banking_chatbot) Create a web UI chatbot using the IBM Watson Node.js SDK to include conversation interaction, anger detection, natural language understanding, and answer discovery. Answers are discovered from a collection of FAQ documents. Built as a fictional financial institution, this app calls out to simple banking services code as an example of how to include external business data in a conversation response.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sample-apps"},{"document_id":"ibmcld_02293-7-2005","score":12.942542,"text":"\nCustomizing your IBM Cloud dashboard \n\nThis tutorial walks you through how to customize your dashboard in the IBM Cloud\u00ae console to ensure that what is displayed is relevant to you. By completing this tutorial, you learn how to create a new dashboard, add and organize widgets, duplicate a dashboard, share a dashboard with other users, and delete unused dashboards.\n\nThe tutorial uses a fictitious project manager who is named Cora. She wants to understand total resource usage over the past year and how her team's budget is used to build a new chatbot with specific resources related to AI and machine learning. As you complete the tutorial, adapt each step to match your project's needs.\n\n\n\n Step 1: Create a dashboard \n\nFirst, create a new dashboard and select a template.\n\n\n\n1. In the IBM Cloud console, click the Actions icon ![Action icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg), and select Create a dashboard.\n2. Select the Management template from the available options, and then click Create.\n\nThe Management template is optimized to provide a mix of billing, access management, and other administrative widgets that Cora needs.\n3. Enter your dashboard title in 30 characters or less.\n4. Next, use the Dashboard settings panel to add relevant widgets to your dashboard. To add widgets, drag the widgets onto your dashboard. Add the Notes widget to your dashboard. This widget is where Cora can provide essential information that's custom for the team that she shares the dashboard with.\n5. Click the Scope tab to select from the available resources in the account that you have access to. The scope determines the data that populates for the selected resources. You can filter the resource by group, tag, and location. Cora wants to select only resources that are related to AI and machine learning, so she filters by the resource group that exists for her team's chatbot project. Not all widgets can be scoped.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-tutorial-custom-dash"},{"document_id":"ibmcld_16364-199341-201521","score":12.939418,"text":"\nAnd the links between nodes are represented in a way that makes it easier to understand the relationships between the nodes.\n\n\n\n\n\n 21 June 2017 \n\nArabic support\n: Language support for Arabic is now generally available. For details, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\nLanguage updates\n: The Watson Assistant service algorithms have been updated to improve overall language support. See the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03330-4-2191","score":12.926762,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_09118-9294-10691","score":12.923719,"text":"\n[Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Tone Analyzer](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Watson OpenScale](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09920-5038-6185","score":12.7839155,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_05727-14301-16089","score":12.57899,"text":"\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization \n\nWatson Assistant provides tools to quickly scaffold a chatbot that can provide the correct benefits information to users.\n\n\n\n\n\n Step 4: Deliver continuously across the globe \n\n\n\n* IBM Cloud\u00ae Continuous Delivery helps Developers to quickly provision an integrated toolchain, by using customizable, shareable templates with tools from IBM, third parties, and open source. Automate builds and tests, controlling quality with analytics.\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI\/CD toolchains to deploy apps into Production clusters across the globe.\n* IBM Cloud Kubernetes Service provides easy rollout and roll-back of apps. Tailored apps are deployed to meet regional requirements through the intelligent routing and load balancing of Istio.\n* Built-in HA tools in IBM Cloud Kubernetes Service balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* With tools like the chatbot, the HR team proved to their workforce that innovation was part of the corporate culture, not just buzz words.\n* Authenticity with personalization in the site addressed the changing expectations of the airline\u2019s workforce today.\n* Last-minute updates to the HR site, including ones that driven by the employees chatbot conversations, went live quickly because Developers were pushing changes at least 10 times daily.\n* With infrastructure management taken care of by IBM, the Development team was freed up to deliver the site in only 3 weeks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_transport"},{"document_id":"ibmcld_07223-2330-3654","score":12.478186,"text":"\n* [Get the Code](https:\/\/github.com\/IBM\/watson-discovery-analyze-data-breaches?cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=zAu9tHefdDc&cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-View-the-Demo)\n\n\n\n[Cognitive Retail Chatbot](https:\/\/developer.ibm.com\/patterns\/create-cognitive-retail-chatbot\/?cm_sp=Developer-_-code-_-retail_chatbot) Create a chatbot dialog using Watson Assistant, a Cloudant NoSQL database, Watson Discovery, and a Slack group.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-online-store\/?cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=b-94B3O1czU&cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-View-the-Demo)\n\n\n\n[Cognitive News Search App](https:\/\/developer.ibm.com\/patterns\/create-a-cognitive-news-search-app\/?cm_sp=Developer-_-code-_-trending_news) Build your own news mining web application using JavaScript, Node.js, and the Watson Discovery service. Use the Watson Node.js SDK to build your news app to search the latest news, find trends, and even integrate it with other applications, such as Slack.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-discovery-news\/?cm_sp=IBMCode-_-create-a-cognitive-news-search-app-_-Get-the-Code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sample-apps"},{"document_id":"ibmcld_16233-7-2298","score":12.430841,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10283-0-1125","score":20.353651,"text":"\n\n\n\n\n\n\n  Why can't I use the Red Hat annotations to restrict access to the Red Hat OpenShift Console? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nWhen you use the Red Hat ip_whitelist allowlist annotation to allow only certain source IP addresses to access the Red Hat OpenShift Console, it does not work as expected.\n\n  Why it\u2019s happening \n\nBy default, the source IP address is not preserved from the client (console web browser) through the load balancer and to the router pod. Because the source IP address isn't available when the filtering is done in the router pod, you can't use the ip_whitelist annotation to allow certain IP addresses to access the console.\n\n  How to fix it \n\nDo not use the Red Hat ip_whitelist annotation to restrict Red Hat OpenShift Console access to specific IP address or IP address ranges. Instead, use Context Based Restrictions (CBR) for this purpose.\n\nFor more information, see [Allowing Red Hat OpenShift on IBM Cloud to access other IBM Cloud resources by using CBR](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr&interface=uicbr-integrations).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ip_whitelist"},{"document_id":"ibmcld_07578-1061453-1063204","score":19.381063,"text":"\n* How do I view my commitment usage?\n\nTo view your commitment usage, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Commitments & subscriptions.\n\n\n\n* Click the tabs to view information on active or upcoming commitments.\n* Use the graph to view what you've spent toward your overall committed amount.\n* View monthly breakdown of the spending history for the commitment in the table.\n\n\n\n* How do I view my commitment terms?\n\nAfter you consult with a sales representative to sign up for IBM Cloud Enterprise Savings Plan, the sales team will email you a copy of your quote and information about IBM Cloud's Terms and Conditions.\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1062857-1064983","score":18.762789,"text":"\nUnlike a subscription, when you have a commitment, you commit to spend a certain amount and receive discounts across the platform even after your commitment term ends. Any overage that is incurred on the account continues to receive a discount.\n* How do I sign up for an Enterprise Savings Plan?\n\nContact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to sign up for IBM Cloud Enterprise Savings Plan. To view your account ID, select \"Register with a Code\" during account registration. After you consult with a sales representative, you receive a confirmation email with your commitment quote details and information about IBM Cloud's Terms and Conditions. Your account is activated upon order processing.\n* How do I view existing commitments?\n\nTo view your existing commitments, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Commitments & subscriptions.\n\nClick the tabs to view the remaining credit in your active commitments and any upcoming commitments that aren't yet valid. A commitment is expired if its term expires or all of its credit is spent.\n* How do I view my commitment usage?\n\nTo view your commitment usage, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Commitments & subscriptions.\n\n\n\n* Click the tabs to view information on active or upcoming commitments.\n* Use the graph to view what you've spent toward your overall committed amount.\n* View monthly breakdown of the spending history for the commitment in the table.\n\n\n\n* How do I view my commitment terms?\n\nAfter you consult with a sales representative to sign up for IBM Cloud Enterprise Savings Plan, the sales team will email you a copy of your quote and information about IBM Cloud's Terms and Conditions.\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03733-1761-2662","score":18.623667,"text":"\nAfter you consult with a sales representative to sign up for IBM Cloud Enterprise Savings Plan, the sales team will email you a copy of your quote and information about IBM Cloud's Terms and Conditions.\n\n\n\n\n\n How do I add a new commitment? \n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n\n\n\n\n\n Why am I getting invoiced for a commitment I didn\u2019t use? \n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n\n\n\n\n\n Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have? \n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-commitmentfaqs"},{"document_id":"ibmcld_02276-0-1677","score":18.321722,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a new service instance? \n\nYou are unable to create or add a new service instance.\n\n  What\u2019s happening \n\nYou might receive one of the following error messages when you create a service:\n\n> Create service error.\n\nor\n\n> Create Service [500, Internal Server Error]. An error occurred while trying to create the service. Please try again later.\n\n  Why it\u2019s happening \n\nCreating a service instance can fail when you don't have access, exceed a plan limit, or experience a problem with your web browser. An active incident or planned maintenance might also affect your ability to create a service instance.\n\n  How to fix it \n\nTo resolve this issue, use one of the following options:\n\n\n\n*  You might not have the correct access. You must have the editor role or higher to create a service instance. Contact the account owner to request the correct access. For more information, see [Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesiamusermanrol).\n*  Creating an instance might exceed a plan or account limit. Review the plan features on the catalog page or in the specific service's documentation. From the Resource list page, you can view what instances currently exist that count towards the plan or account limit. For example, there's a limit of one instance per Lite plan.\n*  If you're experiencing a web browser issue, see [Why do I encounter console pages that don't load?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_err).\n*  Go to the [IBM Cloud - Status](https:\/\/cloud.ibm.com\/status) page to check whether an active incident or planned maintenance is affecting your ability to create a service instance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_create_service"},{"document_id":"ibmcld_05256-7949-9726","score":18.197674,"text":"\nNote that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n\nYes! [Here is how](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n\nYes, you can edit the existing [IAM policy of the service ID](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace. Before you can customize registry IAM policies, you must [enable IBM Cloud IAM policies for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n\nCan I use a service ID?\n: Yes, you can create a service ID and assign authorities to it. Note that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n: Yes! [Here is how](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n: Yes, you can edit the existing [IAM policy of the service ID](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_16727-1064600-1066235","score":18.004768,"text":"\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-76848-78640","score":17.80832,"text":"\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?\n\nUnfortunately, the IP address ranges from which Watson Assistant might call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Use the https transport and specify an authorization header to control access to the webhook.\n* What do I do if the training process seems stuck?\n\nIf the training process gets stuck, first check whether for an outage for the service by going to the [Cloud status page](https:\/\/cloud.ibm.com\/status). You can start a new training process to stop the current process and start over.\n* How do I see my monthly active users in Watson Assistant?\n\nTo see your monthly active users (MAU):\n\n\n\n1. Sign in to [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com)\n2. Click the Manage menu, then choose Billing and usage.\n3. Click Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month that you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Can I see what web browser users are using with Watson Assistant?\n\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-76823-78615","score":17.80832,"text":"\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?\n\nUnfortunately, the IP address ranges from which Watson Assistant might call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Use the https transport and specify an authorization header to control access to the webhook.\n* What do I do if the training process seems stuck?\n\nIf the training process gets stuck, first check whether for an outage for the service by going to the [Cloud status page](https:\/\/cloud.ibm.com\/status). You can start a new training process to stop the current process and start over.\n* How do I see my monthly active users in Watson Assistant?\n\nTo see your monthly active users (MAU):\n\n\n\n1. Sign in to [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com)\n2. Click the Manage menu, then choose Billing and usage.\n3. Click Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month that you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Can I see what web browser users are using with Watson Assistant?\n\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13761-5201-6996","score":17.624212,"text":"\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/wav\" --output partial-cheerful-style.wav --data \"{\"text\":\"<express-as style='cheerful'>Oh, that's good news!<\/express-as> Do you need any further help?\"}\" \"{url}\/v1\/synthesize?voice=en-US_EmmaExpressive\"\n\n\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a number of common interjections based on context. In the resulting audio, it gives them the natural emphasis that a human would use in normal conversation.\n\nTable 2 lists the interjections that the service recognizes and provides examples of how they are pronounced in synthesized speech. The samples use the en-US_AllisonExpressive voice. The table shows the primary spelling of each interjection. The service recognizes alternative spellings for some of the interjections. For example, oh and ohh produce the same sound, as do hmm and hmmm. However, the service produces slightly different pronunciations for other alternative spellings, such as ooh and uhm,\n\n\n\nTable 2. Interjections that are emphasized\n\n Interjection Example sentence Audio sample \n\n aha \"Aha. So that's the secret.\" Your browser does not support the audio tag. \n hmm \"Hmm. I'm not sure I understand.\" Your browser does not support the audio tag. \n huh \"Huh, I hadn't noticed that.\" Your browser does not support the audio tag. \n oh \"Oh, let me get that for you.\" Your browser does not support the audio tag. \n uh \"Uh, let me check.\" Your browser does not support the audio tag. \n uh-huh \"Uh-huh, that's right.\" Your browser does not support the audio tag. \n um \"That's, um, not quite right.\" Your browser does not support the audio tag. \n\n\n\n\n\n Enabling or disabling interjections with SSML","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":22.370985,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":21.582382,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16471-3249-4882","score":16.04604,"text":"\nTwo types of case-sensitive AQL identifiers exist:\n\n\n\n* Simple identifier\n\nA simple identifier must start with a lowercase (a-z) or uppercase (A-Z) letter or the underscore character (_). Subsequent characters can be lowercase or uppercase letters, the underscore character, or digits (0-9). A simple identifier must be different from any AQL key word.\n* Double-quoted identifier\n\nA double-quoted identifier starts and ends with a double quotation mark character (\"). You can use any character between the beginning and ending double quotation mark characters. Double-quoted identifiers cannot contain a period (.) character. If a double quotation mark character occurs within name, it must be escaped by prefixing it with the backslash character (\\), for example \u201d.\n\n\n\n\n\n\n\n Reserved words \n\nReserved words are words that have a fixed meaning within the context of the AQL structure, and cannot be redefined. Keywords are reserved words that have special meanings within the language syntax.\n\nThe following AQL-reserved keywords cannot be used as identifiers because each has a well-defined purpose within the language:\n\n\n\n* all\n* allow\n* allow_empty\n* always\n* and\n* annotate\n* as\n* ascending\n* ascii\n* attribute\n* between\n* blocks\n* both\n* by\n* called\n* case\n* cast\n* ccsid\n* character\n* characters\n* columns\n* consolidate\n* content_type\n* count\n* create\n* default\n* descending\n* detag\n* detect\n* deterministic\n* dictionary\n* dictionaries\n* document\n* element\n* else\n* empty_fileset\n* entries\n* exact\n* export\n* external\n* external_name\n* extract\n* fetch\n* file\n* first\n* flags\n* folding\n* from\n* function\n* group\n* having\n* import","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_13770-10069-11773","score":14.072398,"text":"\nWhen you create a prompt, the text of the prompt must reasonably match the spoken audio. The service does its best to align the specified text with the audio, and it can often compensate for mismatches between the two. If the differences between the text and the audio are too pronounced, however, the service cannot create the prompt. The longer the prompt, the greater the chance for misalignment between its text and audio. Multiple shorter prompts are therefore preferable to a single long prompt.\n\nThere is always the chance that the service might fail to detect a mismatch or might not produce a prompt that completely satisfies your needs. Therefore, you must listen to and evaluate all prompts before using them in production. Evaluating a prompt also allows you to detect unusual words that the service might not pronounce correctly. And it lets you be certain that the service\u2019s voice speaks the prompt exactly as you intend.\n\nAlways listen to and evaluate a prompt to determine its quality before using it in production. To evaluate a prompt, include only the single prompt in a speech synthesis request by using the following SSML extension, in this case for a prompt whose ID is goodbye:\n\n<ibm:prompt id=\"goodbye\"\/>\n\nYou call the same methods to evaluate a custom prompt and to use it in an application. For example, the following request uses the POST \/v1\/synthesize method to synthesize the prompt:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/wav\" --data \"{\"text\":\"<ibm:prompt id='goodbye'\/>\"}\" \"{url}\/v1\/synthesize?customization_id=82f4809a-bf63-89a6-52ca-22731fe467ba&voice=en-US_AllisonV3Voice\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-create"},{"document_id":"ibmcld_06847-7-2266","score":13.526836,"text":"\nConfiguring detect-secrets scan \n\nDetect-secrets is a client-side security tool that detects secrets within a codebase to remediate and prevent secret leaks.\n\nFor more information, see [IBM\/detect-secrets](https:\/\/github.com\/IBM\/detect-secrets).\n\nDetect-secrets scans the entire current codebase and outputs a snapshot of currently identified secrets. The secrets list is then used to audit the identified secrets as true positives or false positives, the DevSecOps toolchains then create Git issues for the true positives.\n\n\n\n Using the baseline file \n\nA baseline file is the snapshot of a detect secret scan. The file lists potential secrets on every run and marks false positives, which are not flagged as issues in subsequent runs.\n\nThe baseline file must be updated periodically. Update and audit the baseline file by committing it and pushing it back into the repo. Including these false positives in the baseline ensures that no issues are created for these existing files during future scans.\n\n\n\n\n\n Classifying secrets \n\nWhen a detect-secrets scan is complete, the detected secrets have yet to be classified as real positives or false positives.\n\nThree conditions classify a potentially detected secret:\n\n\n\n* Unaudited - A secret is categorized as unaudited if it is a potential secret that must be reviewed in the audit process.\n* Audited as real - A secret is categorized as audited as real if it is marked as a true positive during an audit and the baseline file still contains the secret.\n* Live - A secret is categorized as live if the secret is confirmed as a live secret by the plug-ins that are used by detect-secrets.\n\n\n\n\n\n\n\n Managing the baseline \n\nThe following commands manage the secrets baseline:\n\n\n\n* The detect-secrets scan command generates a baseline file or updates the existing file to contain a snapshot of all detected potential secrets of the run.\n* The detect-secrets audit command labels secrets so that you can narrow down your checklist of secrets to migrate.\n\n\n\nAudits identify the detected secrets as either true or false positives, you can then update the baseline file so the false positives can be excluded from the future scan runs.\n\n\n\n\n\n Updating the baseline \n\nTake the following steps to update your baseline:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-detect-secrets-scan"},{"document_id":"ibmcld_13761-7-2364","score":13.027153,"text":"\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_06847-1729-3780","score":13.004531,"text":"\n* The detect-secrets scan command generates a baseline file or updates the existing file to contain a snapshot of all detected potential secrets of the run.\n* The detect-secrets audit command labels secrets so that you can narrow down your checklist of secrets to migrate.\n\n\n\nAudits identify the detected secrets as either true or false positives, you can then update the baseline file so the false positives can be excluded from the future scan runs.\n\n\n\n\n\n Updating the baseline \n\nTake the following steps to update your baseline:\n\n\n\n1. Install detect-secrets on your local computer:\n\npip install --upgrade \"git+https:\/\/github.com\/ibm\/detect-secrets.git@masteregg=detect-secrets\"\n2. Run the following commands to scan, generate, or update the baseline file in your repo:\n\n\n\n1. Run the following command to scan the repo folder:\n\ndetect-secrets scan --update .secrets.baseline\n\nYou can use the --exclude-files flag when you want to ignore certain files that are known to contain false positives or do not require scanning. The exclusion rules are based on regular expressions format.\n\nTo perform a scan with file and folder exclusions, use the following command:\n\ndetect-secrets scan --update .secrets.baseline --exclude-files '<folder_to_ignore>|<file_to_ignore>'\n\nExample : detect-secrets scan --update .secrets.baseline --exclude-files \"package-lock.json|go.sum\"\n\nThe list of excluded files is recorded in the baseline file.\n\nIf no --exclude-files option is provided in subsequent scans, detect secrets automatically respects the existing exclude list from the baseline file.\n\nHowever, if you want to specify a new exclude list during the detect-secrets scan, the new list overwrites the existing exclude list in the baseline file.\n2. Run the following command to review and audit the baseline file that is created with the scan step:\n\ndetect-secrets audit .secrets.baseline\n\nThis command brings up an interactive terminal to mark false positives. You can indicate (y)es if the secret found is an actual secret or (n)o if it is a false positive.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-detect-secrets-scan"},{"document_id":"ibmcld_06818-8701-10855","score":12.776857,"text":"\nIf you want to use something other than our latest image, you can use this parameter.\n\nExample: icr.io\/continuous-delivery\/toolchains\/devsecops\/baseimage:some-other-tag\n\n\n\n\n\n custom-exempt-label \n\nThis is an optional parameter for the CI and CC pipelines. If you marked an incident issue permanently exempted with a custom label, then this parameter should hold the value of the custom label.\n\n\n\n\n\n customer-impact \n\nThis parameter is for the promotion pull request, it records the impact of the change request on the customer. By default the parameter is the pipe separated string 'Critical | High | Moderate | Low | No_Impact'. Edit the default string to select one of the options.\n\n\n\n\n\n description \n\nThis parameter is for the promotion pull request. This parameter contains the description of the change, that will be appended to the Change Request Description. By default it is empty.\n\n\n\n\n\n detect-secrets-baseline-filename \n\nThis parameter specifies a custom file name for the baseline file that is used by detect-secrets. By default, detect-secrets looks for a file that is named .secrets.baseline in the repository root directory. However, if you name your baseline file differently, you can provide its file name by using this parameter.\n\n\n\n\n\n detect-secrets-exclusion-list \n\nThis parameter is an environment property that overrides the default exclusion list when a run is done without an existing baseline file. This p\u00e0rameter identifies files to ignore so that issues are not created that are linked to them.\n\n\n\n\n\n detect-secrets-verbose \n\nThis parameter, when set to 1, logs the name of the current file being scanned.\n\n\n\n\n\n impact \n\nThis parameter is for the promotion pull request. Additional notes on what this Change Implementation will impact. By default it is empty.\n\n\n\n\n\n pipeline-debug \n\nIf this is set to 1, the pipeline will run in debug mode, and the logs will show more information. By default, it is set to 0.\n\n\n\n\n\n priority \n\nThis parameter is for the promotion pull request. The priority of the change request. By default it is 'Critical | High | Moderate | Low | Plan'. You can change it to one of these values.\n\n\n\n\n\n purpose","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-pipeline-parm"},{"document_id":"ibmcld_06847-3309-5447","score":12.67103,"text":"\nHowever, if you want to specify a new exclude list during the detect-secrets scan, the new list overwrites the existing exclude list in the baseline file.\n2. Run the following command to review and audit the baseline file that is created with the scan step:\n\ndetect-secrets audit .secrets.baseline\n\nThis command brings up an interactive terminal to mark false positives. You can indicate (y)es if the secret found is an actual secret or (n)o if it is a false positive.\n3. Commit and push the .secrets.baseline file back to the repo, his process must be done locally on a periodic basis.\n\n\n\n\n\n\n\n\n\n Detect-secrets scan parameters \n\nIf you have an existing baseline file, the scan uses the existing configuration. Your previous auditing results and settings are not overwritten. If no baseline file exists, a temporary baseline is created automatically for the run.\n\nThe detect-secrets-baseline-filename parameter specifies a custom file name for the baseline file that is used by detect-secrets. By default, detect-secrets looks for a file that is named .secrets.baseline in the repository root directory. However, if you name your baseline file differently, you can provide its file name by using this parameter.\n\nThe detect-secrets-exclusion-list parameter overrides the default exclusion list when a run is done without an existing baseline file. This p\u00e0rameter identifies files to ignore so that issues are not created that are linked to them.\n\nThe detect-secrets-verbose parameter, when set to 1, logs the name of the current file that is being scanned.\n\n\n\nTable 1. Secrets-scan parameters\n\n Name Type Description Required or Optional \n\n detect-secrets-baseline-filename String The name of the baseline file in your app repository. Defaults to .secrets.baseline. Required if your baseline file is not the default name .secrets.baseline. \n detect-secrets-exclusion-list String A regex list of files to be excluded in the detect-secrets scan. Defaults to requirements.txt go.modgo.sumpom.xmlbuild.gradlepackage-lock.json. Optional, This file list overrides the general exclusion list only when there is no .secrets.baseline file present.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-detect-secrets-scan"},{"document_id":"ibmcld_12082-1693-3713","score":12.386563,"text":"\nIBM Cloud Schematics enables, to predictably [manage the resource lifecycle](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-manage-lifecycle) of your infrastructure by using Terraform. Drift occurs when the real-world state of your infrastructure differs from the state that is defined in your Terraform template configuration.\n\nTerraform cannot detect drift in resources and attributes that are not managed or configured by using Terraform. For example, Terraform cannot not detect changes in a virtual machine that results from installing applications locally or by using configuration management tools like Chef or Ansible.\n\n\n\n\n\n Drift detection in IBM Cloud \n\nDrift detection for your Terraform automation workspaces is possible in IBM Cloud Schematics. You can use following three methods to check the drift detection.\n\n\n\n\n\n Drift detection using the UI \n\nYou can initiate drift detection for workspaces from the Schematics Workspaces job page. It initiates a job to detect drift for the workspace and its deployed resources. During execution, the drift detection job is in progress, on completion it has a failure or success. To review the details of the drift job, you need to check the drift job log for the drift status.\n\n\n\n Viewing detect drift logs using the UI \n\nUse the following steps to view the drift job log.\n\n\n\n1. From the [workspace dashboard](https:\/\/cloud.ibm.com\/schematics\/workspaces), select the workspace that you want check for drift.\n2. Select and open your workspace.\n3. Select the Actions drop down list.\n4. Select Detect drift option to initiate the detect drift job.\n5. During execution, the status shows in progress moving to a success or a job failure status on completion.\n6. The drift status can be determined by reviewing the output of the job logon when the job is in a success state. A sample success job execution with detected drift is shown in the screen capture.\n\nReview the success job log to identify the drift details.\n\n2022\/04\/19 10:10:44 ----- Terraform DRIFT -----","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-drift-note&interface=api"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08302-1330-3354","score":14.7228,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an authorization error? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Request is not authorized. Check your user permissions and authorizations and try again.\n\n Why it\u2019s happening \n\nYou don't have the required access to get any VPC resources provisioned.\n\n How to fix it \n\nContact your account administrator and get all of the required accesses. For more information, see [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error that the provided name is not unique? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-troubleshooting-slurm"},{"document_id":"ibmcld_08266-1330-3354","score":14.7228,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an authorization error? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Request is not authorized. Check your user permissions and authorizations and try again.\n\n Why it\u2019s happening \n\nYou don't have the required access to get any VPC resources provisioned.\n\n How to fix it \n\nContact your account administrator and get all of the required accesses. For more information, see [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error that the provided name is not unique? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-troubleshooting-hpc-openshift"},{"document_id":"ibmcld_08341-7-1942","score":14.081356,"text":"\nTroubleshooting \n\n\n\n Why is IBM Cloud Schematics not able to clone the public GitHub repo? \n\nSchematics isn't able to clone the public GitHub repository, and you are seeing one of the following error messages:\n\n What\u2019s happening \n\n\n\n* Fatal, could not download repo, Failed to clone git repository, authentication required (or the git url is incorrect). Problems found with the Repository. Please Rectify and Retry\n* Template error: Failed to clone git repository, authentication required (or the git url is incorrect)\n\n\n\n Why it\u2019s happening \n\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the [public repo](https:\/\/github.com\/IBM\/ibm-spectrum-scale-ibm-cloud-schematics).\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service for the resource group where you want to deploy the cluster resources.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service for the resource group where you want to deploy the cluster resources.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an authorization error? \n\n What\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-troubleshooting-spectrum-scale"},{"document_id":"ibmcld_08918-1330-3310","score":14.039195,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error message for the lsf_license_confirmation variable? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Error: Invalid value for variable \"lsf_license_confirmation\"\n\n Why it\u2019s happening \n\nYou entered a value other than \"true\" for the property lsf_license_confirmation.\n\nThe property lsf_license_confirmation only accepts \"true\" as a valid value. A \"true\" value indicates that you have agreed to one of the following two conditions:\n\n\n\n1. If you are deploying a production cluster, you have confirmed with your business team that you have enough licenses to deploy the IBM Spectrum LSF on IBM Cloud and that these licenses are covered for use under the International Program License Agreement (IPLA).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-troubleshooting-spectrum-lsf"},{"document_id":"ibmcld_08391-1352-3519","score":13.650145,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error message for the symphony_license_confirmation variable? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Error: Invalid value for variable \"symphony_license_confirmation\"\n\n Why it\u2019s happening \n\nYou entered a value other than \"true\" for the property symphony_license_confirmation.\n\nThe property symphony_license_confirmation only accepts \"true\" as a valid value. A \"true\" value indicates that you have agreed to one of the following two conditions:\n\n\n\n1. If you are deploying a production cluster, you have confirmed with your business team that you have enough licenses to deploy the IBM Spectrum LSF on IBM Cloud and that these licenses are covered for use under the International Program License Agreement (IPLA).\n2. You are deploying an evaluation cluster with IBM Spectrum LSF on IBM Cloud and agree to abide by the International License Agreement for Evaluation of Program (ILAE).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-troubleshooting-spectrum-symphony"},{"document_id":"ibmcld_07578-170959-172888","score":12.675344,"text":"\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n* Why did my capture fail?\n\nWhen a capture fails, an error occurred. If the error can be resolved, you might be contacted by our support personnel. Until the error is resolved, a completed image isn't in the portal. If you want to know why the capture failed, you can [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n* Why don't I see my captured images?\n\nIf you don\u2019t see a captured image in your portal, the capture experienced an unrecoverable error. For more information, [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n* Can the Operating System (OS) be changed on the device?\n\nYou can change your OS and the software that you installed by reloading an OS. After you select OS Reload on the device, the system displays a link to update the software on your system. You can update the OS, control panel, antivirus packages, and database software.\n* Do you provide complimentary OS Reloads?\n\nAutomated OS reloads are free, including customized OS reloads such as changing operating systems, addition or removal of control panels, partition editing, and other options. Open the Customer Portal for more information.\n* How can I track the status of the OS reload?\n\nUnder Hardware, you see a Notes section for each of your servers. The Notes includes links to information about the current step of the reload and the estimated time to finish that portion of the reload.\n* Can an OS reload erase secondary disks?\n\nAn OS reload formats only the primary disk on the system. All other disks are left alone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-170933-172862","score":12.675344,"text":"\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n* Why did my capture fail?\n\nWhen a capture fails, an error occurred. If the error can be resolved, you might be contacted by our support personnel. Until the error is resolved, a completed image isn't in the portal. If you want to know why the capture failed, you can [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n* Why don't I see my captured images?\n\nIf you don\u2019t see a captured image in your portal, the capture experienced an unrecoverable error. For more information, [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n* Can the Operating System (OS) be changed on the device?\n\nYou can change your OS and the software that you installed by reloading an OS. After you select OS Reload on the device, the system displays a link to update the software on your system. You can update the OS, control panel, antivirus packages, and database software.\n* Do you provide complimentary OS Reloads?\n\nAutomated OS reloads are free, including customized OS reloads such as changing operating systems, addition or removal of control panels, partition editing, and other options. Open the Customer Portal for more information.\n* How can I track the status of the OS reload?\n\nUnder Hardware, you see a Notes section for each of your servers. The Notes includes links to information about the current step of the reload and the estimated time to finish that portion of the reload.\n* Can an OS reload erase secondary disks?\n\nAn OS reload formats only the primary disk on the system. All other disks are left alone.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03655-0-1101","score":12.362343,"text":"\n\n\n\n\n\n\n  FAQs for custom image templates \n\n\n\n  Why don\u2019t I see some of my disks as choices on the 'Create image template' page? \n\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n\n\n\n\n\n  Why did my capture fail? \n\nWhen a capture fails, an error occurred. If the error can be resolved, you might be contacted by our support personnel. Until the error is resolved, a completed image isn't in the portal. If you want to know why the capture failed, you can [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n  Why don't I see my captured images? \n\nIf you don\u2019t see a captured image in your portal, the capture experienced an unrecoverable error. For more information, [contact support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-faqs-image-templates"},{"document_id":"ibmcld_03707-0-719","score":12.168571,"text":"\n\n\n\n\n\n\n  Why can\u2019t I access details about my commitments? \n\nYou are unable to view your account's commitments and subscriptions in the IBM Cloud\u00ae console.\n\n  What\u2019s happening \n\nYou try to view the Commitments and Subscriptions page, but a message is displayed that says Looks like you don't have access to view this page.\n\n  Why it\u2019s happening \n\nYou don't have the correct access to view this information. To access this information, you need an access policy with the Viewer role or higher on the Billing account management service.\n\n  How to fix it \n\nContact your administrator for access. For more information, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) for more information.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-access-commit-page"},{"document_id":"ibmcld_08335-6269-8320","score":12.060219,"text":"\nWhy does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation? \n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffic from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a multiple IP address range.\n\n\n\n\n\n What is an IBM Customer Number and what happens if I don't provide it? \n\nAn IBM Customer Number (ICN) is the unique number that IBM issues its customers during the post-contract signing process. The ICN is important because it allows IBM to identify your company and support contract. Without an ICN, you can't deploy the Spectrum Scale resources through IBM Cloud Schematics.\n\nIf the storage_type deployment value is set as either \"scratch\" or \"persistent\", the ICN can't be set as an empty value. An empty value is accepted only if the storage_type is set as \"evaluation\".\n\n\n\n\n\n Can I directly destroy all Spectrum Scale resources from the CLI? \n\nDo not delete all of the resources from the CLI directly. The required resources that configure the Spectrum Scale cluster are created in two different phases of automation. To cleanly destroy a cluster, see [Destroying resources](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-deleting-resources&interface=cli).\n\n\n\n\n\n What are trusted profiles and what permissions are required to set up the offering? \n\nWith Spectrum Scale, trusted profiles are used to set up granular authorization for applications that are running in compute resources; therefore, you are not required to create or use service IDs or API keys for the creation of compute resources.\n\nThe required set of permissions to create the compute resources are already added as part of the automation code. For more information, see [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n\n\n\n\n\n Why did the destroy process fail to remove resources?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-spectrum-scale-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13013-7-1889","score":22.51108,"text":"\nNode.js TLS Mutual Authentication \n\nThis sample will go over how to configure Mutual Authentication for both sides of an on-premises destination: User Authentication and Resource Authentication.\n\nI know that the resource I want to connect to will be hosted on the same machine as the Secure Gateway Client, it will be listening on port 8999, and that it requires mutual authentication to allow a connection. With this information, I can begin creating my destination.\n\n![Initial TLS Mutual Authentication](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/690bf9a59650e0582967be8899e39840589532f7\/SecureGateway\/images\/tlsMA.png?raw=true)\n\n\n\n User Authentication \n\nI'm creating a brand new application, so I don't have any pre-existing certificate\/key pairs for my application to use, so I will have the Secure Gateway servers automatically generate a pair for me. To do this, I just have to leave the User Authentication upload field empty. If I already had a pair that my application would be using, I would upload my certificate into this field, instead.\n\n\n\n\n\n Resource Authentication \n\n\n\n On-Premises Authentication \n\nIn order for the Secure Gateway Client to authenticate the resource it is connecting to, I have to provide the client with the certificate (or certificate chain) that the resource will be presenting. My resource doesn't have a full certificate chain, so I just need to upload its certificate to the On-Premises Authentication field. This field accepts up to 6 separate certificate files (.pem, .cer, .der, .crt).\n\n\n\n\n\n Client Certificate and Key \n\nIf I need to specify how the Secure Gateway Client will identify itself to my resource, I can upload a certificate and key here for the Client to use. Because the Client and the resource are running on the same machine, I can leave these empty and have the Secure Gateway servers automatically generate a pair for me.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/SecureGateway?topic=SecureGateway-nodejs-tls-ma"},{"document_id":"ibmcld_07578-530183-531933","score":21.822433,"text":"\n* I am deploying my applications to on-premises environments or other public clouds. Can I publish build records, test records, deployment records to DevOps Insights, and use quality gates for these applications?\n\nYes, it doesn't matter where your applications are deployed.\n* Why can't I see my app on the Quality Dashboard page?\n\nFor an application to show up in the Quality Dashboard page, it must have a build record for the selected branch, and at least one test record for that build. For more information about build and test records, see [Integrating your Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-setting-values-cli).\n\nYou can find published build records on the Build Frequency page. For more information, see [Viewing the build frequency](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publish-build-clibuild-frequency-cli).\n* How do I delete DevOps Insights?\n\nDeleting your tool integration deletes all data that is associated with that toolchain. For more information about how to delete your DevOps Insights instance, see [Deleting a DevOps Insights tool integration](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-deleting_data).\n* Can I delete build, test, and deploy data from DevOps Insights?\n\nYou can delete data sets from for toolchain, environment, application, and for a branch. For more information about how to delete a specific data set, see [Deleting DevOps Insights data sets](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-deleting_data).\n* Can I manage DevOps Insights by using Terraform or APIs?\n\nYou can use Terraform or APIs to add DevOps Insights to a toolchain or to remove it from a toolchain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-530137-531887","score":21.822433,"text":"\n* I am deploying my applications to on-premises environments or other public clouds. Can I publish build records, test records, deployment records to DevOps Insights, and use quality gates for these applications?\n\nYes, it doesn't matter where your applications are deployed.\n* Why can't I see my app on the Quality Dashboard page?\n\nFor an application to show up in the Quality Dashboard page, it must have a build record for the selected branch, and at least one test record for that build. For more information about build and test records, see [Integrating your Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-setting-values-cli).\n\nYou can find published build records on the Build Frequency page. For more information, see [Viewing the build frequency](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publish-build-clibuild-frequency-cli).\n* How do I delete DevOps Insights?\n\nDeleting your tool integration deletes all data that is associated with that toolchain. For more information about how to delete your DevOps Insights instance, see [Deleting a DevOps Insights tool integration](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-deleting_data).\n* Can I delete build, test, and deploy data from DevOps Insights?\n\nYou can delete data sets from for toolchain, environment, application, and for a branch. For more information about how to delete a specific data set, see [Deleting DevOps Insights data sets](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-deleting_data).\n* Can I manage DevOps Insights by using Terraform or APIs?\n\nYou can use Terraform or APIs to add DevOps Insights to a toolchain or to remove it from a toolchain.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00776-7-1983","score":21.383673,"text":"\nFAQs for DevOps Insights \n\nGet answers to frequently asked questions about using DevOps Insights.\n\n\n\n Can DevOps Insights be installed and run in an on-premises environment? \n\nDevOps Insights isn't available for an on-premises environment. It's only available in IBM Public Cloud.\n\n\n\n\n\n My Jenkins or Travis CI is running in an on-premises environment or in another public cloud. Can I still publish build records, test records, deployment records to DevOps Insights, and use quality gates? \n\nYes, it doesn't matter from where your pipeline tool is running.\n\n\n\n\n\n I am deploying my applications to on-premises environments or other public clouds. Can I publish build records, test records, deployment records to DevOps Insights, and use quality gates for these applications? \n\nYes, it doesn't matter where your applications are deployed.\n\n\n\n\n\n Why can't I see my app on the Quality Dashboard page? \n\nFor an application to show up in the Quality Dashboard page, it must have a build record for the selected branch, and at least one test record for that build. For more information about build and test records, see [Integrating your Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-setting-values-cli).\n\nYou can find published build records on the Build Frequency page. For more information, see [Viewing the build frequency](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publish-build-clibuild-frequency-cli).\n\n\n\n\n\n How do I delete DevOps Insights? \n\nDeleting your tool integration deletes all data that is associated with that toolchain. For more information about how to delete your DevOps Insights instance, see [Deleting a DevOps Insights tool integration](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-deleting_data).\n\n\n\n\n\n Can I delete build, test, and deploy data from DevOps Insights? \n\nYou can delete data sets from for toolchain, environment, application, and for a branch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-faq_insights"},{"document_id":"ibmcld_05444-178874-180170","score":20.951628,"text":"\n(https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsfind-code-samples)\n* [!I need more memory Can I increase my limits?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsincrease-ce-limits)\n* [Do I need a Docker Hub account to use Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsdockerhub-options)\n* [What is the difference between a Docker build on my system and a build in Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsdockerbld-cebuild)\n* [Why do images that are built by using a Code Engine buildpacks build show up in my container registry as being more than 15,000 days old?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsbuildpacksbld-image-size)\n* [Why do images that are built with non-Intel processors not work with Code Engine?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsbuildimage-nonintel)\n* [Do Code Engine apps support WebSockets?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsapp-websockets)\n* [How can I review the Code Engine service terms?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsreview-service-terms)\n* [How can I give feedback?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-faqsgive-feedback)\n\n\n\n\n\n\n\n Learning paths for Code Engine","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-sitemap"},{"document_id":"ibmcld_10534-120502-121876","score":20.051983,"text":"\n[Planning your worker node setup](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n\n\n\n* [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesshared_dedicated_node)\n\n\n\n* [What flavors are available to me?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesavailable-flavors)\n* [Can I combine different flavors in a cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodescombine-flavors)\n* [How can I change worker node flavors?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodeschange-flavors)\n* [Are the worker nodes encrypted?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesencrypted-flavors)\n* [How do I manage my worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-manage)\n* [What limitations do I need to be aware of?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-limitations)\n* [Why do my worker nodes have the master role?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-master-role)\n* [How can I check the operating system that my worker nodes run?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-os-check)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-104785-106966","score":19.960676,"text":"\nYou can only install packages that are available in the CentOS repositories by using the packageadmin tool that comes with IBM Analytics Engine. You do not require sudo or root privileges to install or run any packages from the CentOS repositories.\n\nYou should perform all cluster customization by using customization scripts at the time the cluster is started to ensure repeatability and consistency when creating further new clusters.\n* Can I monitor the cluster?\n\nCan I configure alerts? Ambari components can be monitored by using the built-in Ambari metrics alerts.\n* How do I scale my cluster?\n\nYou can scale a cluster by adding nodes to it. Nodes can be added through the IBM Analytics Engine UI or by using the CLI tool.\n* Can I scale my cluster while jobs are running on it?\n\nYes, you can add new nodes to your cluster while jobs are still running. As soon as the new nodes are ready, they will be used to execute further steps of the running job.\n* Can I adjust resource allocation in a Spark interactive application?\n\nIf you need to run large Spark interactive jobs, you can adjust the kernel settings to tune resource allocation, for example, if your Spark container is too small for your input work load. To get the maximum performance from your cluster for a Spark job, see [Kernel settings](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-kernel-settings).\n* Does the IBM Analytics Engine operations team monitor and manage all service instances?\n\nYes, the IBM Cloud operations team ensures that all services are running so that you can spin up clusters, submit jobs and manage cluster lifecycles through the interfaces provided. You can monitor and manage your clusters by using the tools available in Ambari or additional services provided by IBM Analytics Engine.\n* Where are my job log files?\n\nFor most components, the log files can be retrieved by using the Ambari GUI. Navigate to the respective component, click Quick Links and select the respective component GUI. An alternative method is to SSH to the node where the component is running and access the \/var\/log\/<component> directory.\n* How can I debug a Hive query on IBM Analytics Engine?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-104764-106945","score":19.960676,"text":"\nYou can only install packages that are available in the CentOS repositories by using the packageadmin tool that comes with IBM Analytics Engine. You do not require sudo or root privileges to install or run any packages from the CentOS repositories.\n\nYou should perform all cluster customization by using customization scripts at the time the cluster is started to ensure repeatability and consistency when creating further new clusters.\n* Can I monitor the cluster?\n\nCan I configure alerts? Ambari components can be monitored by using the built-in Ambari metrics alerts.\n* How do I scale my cluster?\n\nYou can scale a cluster by adding nodes to it. Nodes can be added through the IBM Analytics Engine UI or by using the CLI tool.\n* Can I scale my cluster while jobs are running on it?\n\nYes, you can add new nodes to your cluster while jobs are still running. As soon as the new nodes are ready, they will be used to execute further steps of the running job.\n* Can I adjust resource allocation in a Spark interactive application?\n\nIf you need to run large Spark interactive jobs, you can adjust the kernel settings to tune resource allocation, for example, if your Spark container is too small for your input work load. To get the maximum performance from your cluster for a Spark job, see [Kernel settings](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-kernel-settings).\n* Does the IBM Analytics Engine operations team monitor and manage all service instances?\n\nYes, the IBM Cloud operations team ensures that all services are running so that you can spin up clusters, submit jobs and manage cluster lifecycles through the interfaces provided. You can monitor and manage your clusters by using the tools available in Ambari or additional services provided by IBM Analytics Engine.\n* Where are my job log files?\n\nFor most components, the log files can be retrieved by using the Ambari GUI. Navigate to the respective component, click Quick Links and select the respective component GUI. An alternative method is to SSH to the node where the component is running and access the \/var\/log\/<component> directory.\n* How can I debug a Hive query on IBM Analytics Engine?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04083-40459-42275","score":19.864233,"text":"\nFollow the instructions in the [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network-create-peer-org1) to create a new peer identity with the correct type and peer.\n\n\n\n\n\n Why is my peer unable to communicate with my ordering node? \n\n What\u2019s happening \n\nA peer node has a timeout or connection refused error when trying to communicate with the orderer.\n\n Why it\u2019s happening \n\nThis problem can occur due to the network policies applied by the operator, which occurs when the environment variable IBPOPERATOR_CONSOLE_APPLYNETWORKPOLICY is set to \"true\".\n\n How to fix it \n\n[Disable the network policies in your namespace](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-disable-network-policies). This should resolve connectivity issues with your nodes.\n\n\n\n\n\n When I hover over my node, the status is red, what does this mean? \n\n What\u2019s happening \n\nA CA, peer, or ordering node has a red status box, meaning there may be connectivity issues with the node. Ideally, when you hover over any node, the node status should be Running.\n\n Why it\u2019s happening \n\nThis problem can occur due to the network policies applied by the operator, which occurs when the environment variable IBPOPERATOR_CONSOLE_APPLYNETWORKPOLICY is set to \"true\".\n\n How to fix it \n\n[Disable the network policies in your namespace](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-disable-network-policies). This should resolve connectivity issues with your nodes.\n\n\n\n\n\n How do I disable the network policies in my namespace? \n\n What\u2019s happening \n\nYou may need to disable the network policies in your namespace to address connectivity issues in your network.\n\n How to fix it","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_04082-32711-34677","score":18.96181,"text":"\nHow do I get support for running the IBM Blockchain Platform Ansible playbook? \n\nAnsible is an open source technology and this product is not officially supported by IBM. For support related to the usage of the IBM Blockchain Platform and Ansible playbooks use the [GitHub repository](https:\/\/github.com\/IBM-Blockchain\/ansible-collection\/issues).\n\n\n\n\n\n Can the IBM Blockchain Platform monitor the health of a client application? \n\nThe IBM Blockchain Platform console does not monitor the health of blockchain client applications, but IBM Cloud does offer tooling such as [IBM Log Analysis](https:\/\/cloud.ibm.com\/catalog\/services\/ibm-log-analysis) and [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/catalog\/services\/ibm-cloud-monitoring) that can be used for their health monitoring.\n\n\n\n\n\n Where does IBM store the customer's logs and how long does IBM keep the audit logs for the blockchain platform service? \n\nThe logs are stored in the customer's Kubernetes cluster. IBM does not have access to the logs and it is up to the customer to manage all of their log data including retention management.\n\n\n\n\n\n Do we have access to logging services and what logs are available to me? \n\nWith IBM Blockchain Platform, you can now directly access logs from your Kubernetes dashboard. It is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n\n\n\n\n\n Where can I see the price breakdown for IBM Cloud Kubernetes Service, Storage, and Blockchain in my monthly invoice? \n\nActual cost breakdowns are visible from your Invoices in the IBM Cloud Dashboard. For detailed steps, see the [Billing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-billing) section in the Pricing topic.\n\n\n\n\n\n Is there a best practice for monitoring my blockchain resources? \n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02953-3805-5544","score":27.162956,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_06209-21345-23408","score":24.242191,"text":"\nThis type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node. However, the replacement worker node is assigned a new private IP address, and loses any custom labels or taints that you applied to the old worker node (worker pool labels and taints are still applied to the replacement worker node).\n\nWhat if I replace multiple worker nodes at the same time?\n: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n\nWhat if a replacement worker node is not created?\n: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off).\n\n\n\n Prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10534-120502-121876","score":23.893963,"text":"\n[Planning your worker node setup](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n\n\n\n* [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesshared_dedicated_node)\n\n\n\n* [What flavors are available to me?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesavailable-flavors)\n* [Can I combine different flavors in a cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodescombine-flavors)\n* [How can I change worker node flavors?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodeschange-flavors)\n* [Are the worker nodes encrypted?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesencrypted-flavors)\n* [How do I manage my worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-manage)\n* [What limitations do I need to be aware of?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-limitations)\n* [Why do my worker nodes have the master role?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-master-role)\n* [How can I check the operating system that my worker nodes run?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesflavor-os-check)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10642-20176-22071","score":23.803173,"text":"\nFor more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the VPC worker node to the same patch by using the ibmcloud oc worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06056-5254-7468","score":23.631262,"text":"\n* Workloads that you want to increase high availability for by creating replicas in different zones and regions\n\n\n\nCan I convert existing worker nodes to reserved worker nodes to save money?\n: No. Instead, you can create reservations and contracts for the worker nodes in your clusters. Then, create worker pools in your existing clusters that use the reserved worker nodes. Consider using labels to reschedule your existing workloads to the new reserved worker pools. Then, delete your old, on demand worker pools.\n\nHow do reservations impact quotas?\n: By default, IBM Cloud Kubernetes Service sets a certain quota limit on the number of worker nodes that you can have across all clusters in a region. Contracts that exceed the worker node quota are blocked from creating. You can try a different region or increase the quota. If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. After the quota is increased, you can create a contract.\n\nWhat happens when my contract ends? Are my worker nodes deleted?\n: When a contract ends, your reservation is checked for extra capacity from other contracts. If you have more worker nodes than capacity, the worker nodes that exceed the reservation's total capacity are deleted.\n\nFor example, you might have a reservation with one contract for 10 worker nodes and another contract for 5 worker nodes, for a total capacity of 15 worker nodes. You use 14 of the 15 worker nodes. When the 5-worker node contract expires, your reservation total capacity reduces to 10 worker nodes. Therefore, 4 of your 14 running worker nodes are deleted, to make the number of worker nodes equal to the total capacity of 10 reserved worker nodes.\n\nTo avoid an unexpected deletion, scale down your worker pools before the contract ends to the remaining capacity in the reservation. Or, add contracts to your reservation so that you continue to have enough reserved capacity for the worker nodes that you need.\n\n\n\n\n\n Billing and discounts \n\nHow much is the discount? Can I combine reservations with other discounts?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservations"},{"document_id":"ibmcld_10487-5257-7473","score":23.631262,"text":"\n* Workloads that you want to increase high availability for by creating replicas in different zones and regions\n\n\n\nCan I convert existing worker nodes to reserved worker nodes to save money?\n: No. Instead, you can create reservations and contracts for the worker nodes in your clusters. Then, create worker pools in your existing clusters that use the reserved worker nodes. Consider using labels to reschedule your existing workloads to the new reserved worker pools. Then, delete your old, on demand worker pools.\n\nHow do reservations impact quotas?\n: By default, Red Hat OpenShift on IBM Cloud sets a certain quota limit on the number of worker nodes that you can have across all clusters in a region. Contracts that exceed the worker node quota are blocked from creating. You can try a different region or increase the quota. If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. After the quota is increased, you can create a contract.\n\nWhat happens when my contract ends? Are my worker nodes deleted?\n: When a contract ends, your reservation is checked for extra capacity from other contracts. If you have more worker nodes than capacity, the worker nodes that exceed the reservation's total capacity are deleted.\n\nFor example, you might have a reservation with one contract for 10 worker nodes and another contract for 5 worker nodes, for a total capacity of 15 worker nodes. You use 14 of the 15 worker nodes. When the 5-worker node contract expires, your reservation total capacity reduces to 10 worker nodes. Therefore, 4 of your 14 running worker nodes are deleted, to make the number of worker nodes equal to the total capacity of 10 reserved worker nodes.\n\nTo avoid an unexpected deletion, scale down your worker pools before the contract ends to the remaining capacity in the reservation. Or, add contracts to your reservation so that you continue to have enough reserved capacity for the worker nodes that you need.\n\n\n\n\n\n Billing and discounts \n\nHow much is the discount? Can I combine reservations with other discounts?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservations"},{"document_id":"ibmcld_10444-3882-5785","score":23.042082,"text":"\nAfter you create a worker pool, you might notice that the worker node flavor has .encrypted in the name, such as b3c.4x16.encrypted.\n\n\n\n\n\n How do I manage my worker nodes? \n\nWorker nodes in classic clusters are provisioned into your IBM Cloud account. You can manage your worker nodes by using Red Hat OpenShift on IBM Cloud, but you can also use the [classic infrastructure dashboard](https:\/\/cloud.ibm.com\/classic\/) in the IBM Cloud console to work with your worker node directly.\n\nUnlike classic clusters, the worker nodes of your VPC cluster are not listed in the [VPC infrastructure dashboard](https:\/\/cloud.ibm.com\/vpc\/overview). Instead, you manage your worker nodes with Red Hat OpenShift on IBM Cloud only. However, your worker nodes might be connected to other VPC infrastructure resources, such as VPC subnets or VPC Block Storage. These resources are in the VPC infrastructure dashboard and can be managed separately from there.\n\n\n\n\n\n What limitations do I need to be aware of? \n\nKubernetes limits the maximum number of worker nodes that you can have in a cluster. Review [worker node and pod quotas](https:\/\/kubernetes.io\/docs\/setup\/best-practices\/cluster-large\/) for more information.\n\n[Reserved capacity and reserved instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-provisioning-reserved-capacity-and-instances) are not supported.\n\nRed Hat OpenShift on IBM Cloud also sets compute resource reserves that limit available compute resources on each worker node. For more information, see [worker node resource reserves](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_10534-130739-132089","score":22.994677,"text":"\n[Accessing the cluster master with admission controllers and webhooks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks)\n\n\n\n* [Can I create my own admission controllers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks_create_controllers)\n* [What are the best practices for using webhooks?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhookswebhook-best-practice)\n* [What other types of apps use admission controllers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks-app-use-controllers)\n* [I need help with a broken webhook. What can I do?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks-help)\n\n\n\n[Accessing private clusters by using the WireGuard VPN](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-access-wireguardcluster-access-wireguard)\n\n\n\n\n\n Managing the cluster and worker node lifecycle \n\n[Adding worker nodes and zones to clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersadd_workers)\n\n\n\n* [Adding worker nodes by resizing an existing worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool)\n* [Adding worker nodes in VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersvpc_pools)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06063-33190-34970","score":22.898111,"text":"\nTo set up public connectivity for cluster that is connected to a private VLAN only, you can configure a firewall, such as a [Virtual Router Appliance](https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-about-the-vra), in front of your worker nodes and enable network traffic to these URLs and IP addresses. \n Limit public internet connectivity with edge nodes If you don't create a cluster with a gateway enabled, every worker node is configured to accept app pods and associated load balancer or ingress pods. You can label worker nodes as [edge nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-edgeedge) to force load balancer and Ingress pods to be deployed to these worker nodes only. In addition, you can [taint your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-edgeedge_workloads) so that app pods can't schedule onto the edge nodes. With edge nodes, you can isolate the networking workload on fewer worker nodes in your cluster and keep other worker nodes in the cluster private. \n\n\n\n\n\n\n\n What if I want to connect my cluster to an on-prem data center? \n\nTo connect your worker nodes and apps to an on-prem data center, you can configure a [VPN IPSec endpoint with a strongSwan service, a Virtual Router Appliance, or with a Fortigate Security Appliance](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpnvpn).\n\n\n\n\n\n Network segmentation and privacy for VPC clusters \n\nTo protect your network and limit the range of damage that a user can do when access to a network is granted, you must make sure that your workloads are as isolated as possible and that you limit the number of apps and worker nodes that are publicly exposed.\n\n\n\n\n\n What network traffic is allowed for my VPC cluster by default?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_08917-4604-6551","score":22.867636,"text":"\nCluster nodes that are deployed with this offering include IBM Spectrum LSF 10.1 Standard Edition plus Data Manager plus License Scheduler. See the following for a brief description of each of those programs: [IBM Spectrum LSF 10 family of products](https:\/\/www.ibm.com\/common\/ssi\/ShowDoc.wss?docURL=\/common\/ssi\/rep_ca\/4\/897\/ENUS220-174\/index.html&lang=en&request_locale=en)\n\nIf the cluster uses Spectrum Scale storage, the storage nodes include IBM Spectrum Scale 5.1.3.1 software. For more information, see the [IBM Spectrum Scale](https:\/\/www.ibm.com\/docs\/en\/spectrum-scale\/5.1.3) product documentation.\n\n\n\n\n\n How many compute worker and storage nodes can I deploy in my Spectrum LSF cluster through this offering when spectrum_scale is enabled? \n\nBefore you deploy a cluster, it is important to ensure that the VPC resource quota settings are appropriate for the size of the cluster that you would like to create (see [Quotas and service limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotas)).\n\nThe maximum number of compute nodes that are supported for the deployment value total_compute_cluster_instances is 64. The maximum number of storage nodes that are supported for the deployment value total_storage_cluster_instances is 18.\n\n\n\n\n\n Why is the CPU number displayed on an LSF worker node different than what is shown in the LSF Application Center GUI? \n\nThe CPU column in the LSF Application Center GUI and the ncpus column when you run the lscpu command on an LSF worker node might not show the same value.\n\nThe CPU column output that you get by running lscpu | egrep 'Model name|Socket|Thread|NUMA|CPU(s)' on an LSF worker node shows the number of CPU threads (not physical cores) on that compute instance.\n\nIf EGO_DEFINE_NCPUS=threads, then \u201cncpus=number of processors x number of cores x number of threads\u201d and the CPU column value in the LSF Application Center GUI will match what you see when running lscpu on an LSF worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-spectrum-lsf-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09864-5103-6606","score":14.871977,"text":"\n\"moreInformation\": \"https:\/\/example.com\",\n\"queueManagerLocation\": \"qm.us-south.mq.appdomain.cloud\",\n\"queueManagers\": [{\n\"hostname\": \"qm1-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM1\"\n}, {\n\"hostname\": \"qm2-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM2\"\n}],\n\"region\": \"us-south\",\n\"serviceInstance\": \"crn:v1:staging:public:mqcloud:region:a\/ab90cde12f345:ab5c678d-e90a-b5678c9::\"\n}\nShow more\n\nThe notification will contain the following keys:\n\n\n\n* datestamp: the date and time the notification was sent\n* description: an explanation of the problem and what action was taken\n* moreInformation: this may contain an external link to further explain the cause behind the DR\n* queueManagerLocation: the location of the cluster on which the queue manager is deployed\n* queueManagers: a list of hostnames and names of all affected queue managers\n* region: the physical location of your service instance\n* serviceInstance: the unique CRN of the containing service instance\n\n\n\n\n\n\n\n How to implement the endpoint handler \n\nThe instructions below demonstrate some sample code to implement an endpoint handler to send notifications via PagerDuty in an IBM Cloud Function, but you could also adapt this code to run in a location of your choice\n\nNote: the below function is written in Node.js\n\nconst https = require('https');\n\nfunction main(params) {\n\nreturn new Promise((resolve, reject) => {\n\n\/\/ Replace the string \"R4nd0m5tr1ng0fCh4r4ct3r5\" with your own value to secure access to your own specific endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_dr_notifications"},{"document_id":"ibmcld_16628-0-1541","score":14.021164,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_11164-6586-7646","score":13.875396,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_05550-16121-17665","score":13.715772,"text":"\nThe allowlist includes subnets that you manually added and subnets that are automatically added and managed by IBM, such as worker node subnets.\n\nibmcloud ks cluster master private-service-endpoint allowlist get --cluster <cluster_name_or_ID>\n\n\n\nYour authorized users can now continue with [Accessing clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_private_se).\n\n\n\n\n\n\n\n Accessing VPC clusters through the Virtual Private Endpoint Gateway \n\n[Virtual Private Endpoint Gateway](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe) is created for VPC clusters automatically. The Kubernetes master is accessible through this Virtual Private Endpoint gateway if authorized cluster users are connected to the same VPC where the cluster is deployed, such as through a [IBM Cloud VPC VPN](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-overview). In this case, the kubeconfig is configured with the Virtual Private Endpoint (VPE) URL which is private DNS name and could be resolved only by the IBM Cloud VPC Private DNS service. The IBM Cloud VPC Private DNS server addresses are 161.26.0.7 and 161.26.0.8.\n\n\n\n1. Set up your IBM Cloud VPC VPN and connect to your VPC through VPN.\n\n\n\n1. Configure a [client-to-site](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-client-to-site-overview) or [site-to-site](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-onprem-example) VPN to your VPC. For example, you might choose to set up a client-to-site connection with an OpenVPN Client.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster"},{"document_id":"ibmcld_02718-7-2113","score":13.691026,"text":"\nVideos \n\nYou can watch the videos to learn more about App Configuration service.\n\n\n\n* Video transcript\n\nWhat are Feature Flags?\n\nBefore you begin playing the video: In this video, the narrator draws representational images on the display board to explain the concept. [Draw] is used to represent when the narrator draws the representational image. [Writing] is used to represent when the narrator writes some text.\n\nWhat if you could release a feature to different groups of users without deployment? Is there a way to effectively test features in production, and immediately roll them back if needed?\n\nHi, my name is Dilan Orrino with IBM Cloud. I'll be answering those questions by discussing feature flags, or sometimes referred to as feature toggle, or switches.\n\nFeature flags are conditions that encompass feature code that allow you to flip them on and off at will. Okay, let's use an example. [Draw] Let's say we've got an ice cream shop franchise that's looking to expand to a new city and we've got a [Draw] banner that we want to display on our website. We'll call this open banner. We only want to display this banner to users that are [Draw] nearby our new ice cream shop we can do this by using feature flags.\n\nThere's a couple benefits to using feature flags. [Writing] Number one is we can actually turn these on or off without deployment. [Writing] Number two is we can actually test directly in production. [Writing] And number three we can segment our users based on different attributes.\n\nOkay, there's a couple ways you can do this one way is by using properties in JSON files or config maps. There's a better way however by using a feature flag service.\n\n[Writing] There's a couple benefits to using a feature flag service. Number one is you can have essentially managed place for your features, or excuse me your feature flags. [Writing] Number two is you can turn these on and off without modifying your properties in your future, in your apps or web pages. [Writing] And number three is you get audit and usage data. It's harder to get the audit and usage data by using JSON files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_10264-5544-7334","score":13.289785,"text":"\nFor a list, see [Supported IBM Cloud and third-party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-supported_integrations). \n Locations and versions VPC clusters are available worldwide in the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc). \n Service interface VPC clusters are supported by the [next version (v2) of the IBM Cloud Kubernetes Service API](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_api_install), and you can manage your VPC clusters through the same CLI and console as classic clusters. \n Service compliance See the VPC section in [What standards does the service comply to?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsstandards). \n Service limitations See [Service limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationstech_limits). For VPC-specific limitations in Red Hat OpenShift on IBM Cloud, see [VPC cluster limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits). For general VPC infrastructure provider limitations, see [Limitations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-limitations). \n\n\n\n\n\n\n\n Satellite \n\nSatellite\n\n\n\nTable 2. Satellite infrastructure overview.\n\n Component Description \n\n Compute and worker node resources Worker nodes can be virtual machines using either shared infrastructure or dedicated hosts, or even bare metal servers. You manage maintenance and billing activity for the worker nodes through your host infrastructure provider whether that is IBM Cloud, your own on-premises hardware, or another cloud provider. You also manage billing through IBM Cloud. For more information about pricing, see [What am I charged for when I use IBM Cloud Satellite?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers"},{"document_id":"ibmcld_02934-31538-33861","score":13.232574,"text":"\nFor Not found responses (that are displayed when the user does not provide a valid value), you can choose one of these actions to perform:\n\n\n\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_03249-32329-34629","score":13.232574,"text":"\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next. For example, if after capturing the one-way flight information, the slot prompt is, Are you buying round trip tickets?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_05713-133554-135176","score":12.963371,"text":"\n* [Accessing clusters through the public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_public_se)\n* [Accessing clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_private_se)\n\n\n\n* [Accessing VPC clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clustervpc_private_se)\n* [Accessing classic clusters through the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusterclassic_private_se)\n* [Creating an allowlist for the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusterprivate-se-allowlist)\n\n\n\n* [Accessing VPC clusters through the Virtual Private Endpoint Gateway](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clustervpc_vpe)\n\n\n\n[Accessing the cluster master with admission controllers and webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooksaccess_webhooks)\n\n\n\n* [What are the default admission controllers in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooksaccess_webhooks-default-controllers)\n* [Can I create my own admission controllers?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooksaccess_webhooks_create_controllers)\n* [What are the best practices for using webhooks?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhookswebhook-best-practice)\n* [What other types of apps use admission controllers?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10444-1564-3232","score":12.854326,"text":"\n[Hardware options for worker nodes in a standard cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/cs_clusters_hardware.png)\n\nFigure 1. Hardware options for worker nodes in a standard cluster\n\n\n\n What flavors are available to me? \n\nClassic standard clusters can be created on [virtual](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) and [bare metal](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) worker nodes. If you require additional local disks, you can also choose one of the bare metal flavors that are designed for [software-defined storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodessds) solutions, such as Portworx. Depending on the level of hardware isolation that you need, virtual worker nodes can be set up as shared or dedicated nodes, whereas bare metal machines are always set up as dedicated nodes. If you create a free classic cluster, your cluster is provisioned with the smallest virtual worker node flavor on shared infrastructure.\n\nVPC clusters can be provisioned as standard clusters on shared [virtual](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) worker nodes only, and must be created in one of the supported [multizone locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc). Free VPC clusters are not supported.\n\nVPC clusters can be provisioned using virtual worker nodes on standard infrastructure or dedicated hosts. Free VPC clusters are not supported.\n\n\n\n\n\n Can I combine different flavors in a cluster? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05713-115081-116576","score":15.070372,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapp_kinds)\n* [What about serverless apps?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyapps_serverless-strategy)\n* [What skills should I have before I move my apps to a cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyknowledge)\n\n\n\n* [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_resources)\n* [What else besides my app might use resources in the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_other)\n* [What type of availability do I want my workload to have?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_availability)\n* [How many worker nodes do I need to handle my workload?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_workers)\n* [How do I monitor resource usage and capacity in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing_manage)\n\n\n\n* [Structuring your Kubernetes environment](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-109008-110371","score":14.86738,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyknowledge)\n\n\n\n* [Sizing your Red Hat OpenShift cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing)\n\n\n\n* [How many resources does my app require?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_resources)\n* [What else besides my app might use resources in the cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_other)\n* [What type of availability do I want my workload to have?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_availability)\n* [How many worker nodes do I need to handle my workload?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_workers)\n* [How do I monitor resource usage and capacity in my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing_manage)\n\n\n\n* [Structuring your Red Hat OpenShift environment](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_multicluster)\n* [How can I set up my resources within the cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_08879-1441-3139","score":14.321204,"text":"\nFor more information, about how network traffic flows when a public and a private service endpoint is enabled, see Worker-to-master and user-to-master communication: Service endpoints in [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clusters) and [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_clustersworkeruser-master).\n\n\n\nKeep in mind that creating a cluster incurs costs. Make sure to review [What am I charged for when I use IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqscharges) or [What am I charged for when I use Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges) before you proceed.\n\n\n\n Objectives \n\nIn this tutorial, you will:\n\n\n\n* Learn how to create a single zone IBM Cloud Kubernetes Service or Red Hat OpenShift on IBM Cloud cluster with Terraform on IBM Cloud.\n* Convert your single zone cluster into a multizone cluster for higher availability.\n* Add a new worker pool to the cluster.\n* Remove the default worker pool that is automatically set up during cluster creation.\n\n\n\n\n\n\n\n Audience \n\nThis tutorial is intended for system administrators that want to learn how to create an IBM Cloud Kubernetes Service or Red Hat OpenShift on IBM Cloud cluster and spread this cluster across zones.\n\n\n\n\n\n Prerequisites \n\n\n\n* If you do not have one, create an [IBM Cloud Pay-As-You-Go or Subscription IBM Cloud account](https:\/\/cloud.ibm.com\/registration).\n* Install the [IBM Cloud command line and the IBM Cloud Kubernetes Service command line plug-in](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-tutorial-tf-clusters"},{"document_id":"ibmcld_07578-101552-103555","score":14.266274,"text":"\nAlthough you can change the Hive configuration on IBM Analytics Engine clusters, it is your responsibility that the cluster functions correctly after you have made any such changes.\n* How much time does it take for the cluster to get started?\n\nWhen using the Spark software pack, a cluster takes about 7 to 9 minutes to be started and be ready to run applications. When using the Hadoop and Spark software pack, a cluster takes about 15 to 20 minutes to be started and be ready to run applications.\n* How can I access or interact with my cluster?\n\nThere are several interfaces which you can use to access the cluster.\n\n\n\n* SSH\n* Ambari console\n* REST APIs\n* Cloud Foundry CLI\n\n\n\n* How do I get data into the cluster?\n\nThe recommended way to read data to a cluster for processing is from IBM Cloud Object Storage. Upload your data to IBM Cloud Object Storage (COS) and use COS, Hadoop or Spark APIs to read the data. If your use-case requires data to be processed directly on the cluster, you can use one of the following ways to ingest the data:\n\n\n\n* SFTP\n* WebHDFS\n* Spark\n* Spark-streaming\n* Sqoop\n\n\n\nSee [Uploading files to HDFS](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-upload-files-hdfs).\n* How do I configure my cluster?\n\nYou can configure a cluster by using customization scripts or by directly modifying configuration parameters in the Ambari console. Customization scripts are a convenient way to define different sets of configurations through a script, to spin up different types of clusters, or to use the same configuration repeatedly for repetitive jobs. See [Customizing a cluster](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-cluster).\n* Can I stop or shutdown my IBM Analytics Engine clusters to be charged on a per-use basis?\n\nYou are charged as long as the cluster is active and not on a per-use basis. For this reason, you should delete the instance after your job has completed and create a new instance before you start another job.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-101531-103534","score":14.266274,"text":"\nAlthough you can change the Hive configuration on IBM Analytics Engine clusters, it is your responsibility that the cluster functions correctly after you have made any such changes.\n* How much time does it take for the cluster to get started?\n\nWhen using the Spark software pack, a cluster takes about 7 to 9 minutes to be started and be ready to run applications. When using the Hadoop and Spark software pack, a cluster takes about 15 to 20 minutes to be started and be ready to run applications.\n* How can I access or interact with my cluster?\n\nThere are several interfaces which you can use to access the cluster.\n\n\n\n* SSH\n* Ambari console\n* REST APIs\n* Cloud Foundry CLI\n\n\n\n* How do I get data into the cluster?\n\nThe recommended way to read data to a cluster for processing is from IBM Cloud Object Storage. Upload your data to IBM Cloud Object Storage (COS) and use COS, Hadoop or Spark APIs to read the data. If your use-case requires data to be processed directly on the cluster, you can use one of the following ways to ingest the data:\n\n\n\n* SFTP\n* WebHDFS\n* Spark\n* Spark-streaming\n* Sqoop\n\n\n\nSee [Uploading files to HDFS](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-upload-files-hdfs).\n* How do I configure my cluster?\n\nYou can configure a cluster by using customization scripts or by directly modifying configuration parameters in the Ambari console. Customization scripts are a convenient way to define different sets of configurations through a script, to spin up different types of clusters, or to use the same configuration repeatedly for repetitive jobs. See [Customizing a cluster](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-cluster).\n* Can I stop or shutdown my IBM Analytics Engine clusters to be charged on a per-use basis?\n\nYou are charged as long as the cluster is active and not on a per-use basis. For this reason, you should delete the instance after your job has completed and create a new instance before you start another job.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08266-4335-5783","score":14.137333,"text":"\nWhy am I receiving an error when I apply a change to my workspace? \n\n What\u2019s happening \n\nYou are receiving the following error when you try to apply a change to your workspace: Apply failed due to \"Error: Error Deleting Volume : The volume is still attached to an instance.\"\n\n Why it\u2019s happening \n\nAfter reconfiguring the volume profile, capacity, or IOPS, your workspace needs to be cleaned up before you apply the change.\n\n How to fix it \n\nYou need to destroy your existing resources and try applying the change again. Your data on the storage node will be deleted if you destroy your existing resources.\n\n\n\n\n\n Why do I get a node status of \"Critical\" after I attempt to create a cluster? \n\nYou enter valid parameters and attempt to create a cluster. When you navigate to the [Red Hat\u00ae OpenShift\u00ae URL](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), you see the following status:\n\n What\u2019s happening \n\n\n\n* Node status: Critical\n* Add-on status: Warning\n* Master status: Error\n\n\n\n Why it\u2019s happening \n\nThere might be multiple reasons for the status not being \"Normal\" for the cluster and its components, especially if you create a large cluster (for example, a cluster with greater than 50 worker nodes).\n\n How to fix it \n\nFor more information on resolving this issue, see the Red Hat OpenShift on IBM Cloud troubleshooting information on [Debugging clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-troubleshooting-hpc-openshift"},{"document_id":"ibmcld_07578-203259-205040","score":14.117156,"text":"\nAvailable regions and zones for deploying VPC resources and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations). While any of the available regions can be used, resources are provisioned only in a single availability zone within the selected region.\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access), and [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n* How do I SSH among nodes?\n\nThe IBM Spectrum Scale solution consists of two separate clusters (storage and compute). The SSH key parameter that is provided through Schematics (storage_cluster_key_pair and compute_cluster_key_pair) can be used to log in to the respective cluster nodes. You can log in to any node only through the bastion host by using the following command:\n\nssh -J ubuntu@<IP_address_bastion_host> vpcuser@<IP-address-of-nodes>\n\nAlthough all of the nodes of each cluster have passwordless SSH set up among them, due to security constraints, you can't directly log in to a node from one cluster to another cluster.\n* How many compute and storage nodes can I deploy in my Spectrum Scale cluster through this offering?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-203233-205014","score":14.117156,"text":"\nAvailable regions and zones for deploying VPC resources and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations). While any of the available regions can be used, resources are provisioned only in a single availability zone within the selected region.\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access), and [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n* How do I SSH among nodes?\n\nThe IBM Spectrum Scale solution consists of two separate clusters (storage and compute). The SSH key parameter that is provided through Schematics (storage_cluster_key_pair and compute_cluster_key_pair) can be used to log in to the respective cluster nodes. You can log in to any node only through the bastion host by using the following command:\n\nssh -J ubuntu@<IP_address_bastion_host> vpcuser@<IP-address-of-nodes>\n\nAlthough all of the nodes of each cluster have passwordless SSH set up among them, due to security constraints, you can't directly log in to a node from one cluster to another cluster.\n* How many compute and storage nodes can I deploy in my Spectrum Scale cluster through this offering?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04083-6522-7841","score":14.060104,"text":"\n(https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-status-error)\n* [How do I disable the network policies in my namespace?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-disable-network-policies)\n* [How do I delete a peer pod?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-troubleshooting-delete-peer)\n* [How can I recover a contract after a failed upgrade of the smart contract container?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-troubleshooting-contract-fail)\n\n\n\nIssues on IBM Cloud\n\n\n\n* [My Kubernetes cluster on IBM Cloud expired. What does this mean?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-cluster-expired)\n* [After I deploy a node, I'm seeing a message in my Kubernetes cluster on IBM Cloud reporting that the pod has unbound immediate persistent volume claims. Is this an error?](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshootingibp-v2-troubleshooting-unbound-persistent-volume-claim)\n* [After I deploy a node, I'm seeing a message in my Kubernetes cluster on IBM Cloud reporting that the pod has hit a crash loop backoff. Is this an error?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_05713-126762-128234","score":14.024086,"text":"\n* [Multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters)\n\n\n\n* [Why do I need worker nodes in three zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-cluster-zones)\n* [How is my IBM Cloud Kubernetes Service master set up?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-master-setup)\n* [Do I have to do anything so that the master can communicate with the workers across zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-master-communication)\n* [Can I convert my single zone cluster to a multizone cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersconvert-sz-to-mz)\n* [Do my apps automatically spread across zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultizone-apps-faq)\n\n\n\n* [Multiple public clusters connected with a global load balancer](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb)\n\n\n\n* [Why do I need 3 clusters in three zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmulticluster-three-zones)\n* [What if I want to set up multiple clusters across regions?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-regions-setup)\n* [What options do I have to load balance workloads across multiple clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-cluster-lb-options)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-593375-595353","score":25.441587,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-593333-595311","score":25.441587,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11997-5537-6386","score":21.555119,"text":"\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12093-4-1896","score":21.476824,"text":"\nIBM Cloud Schematics Agent beta-1 delivers a simplified agent installation process and policy for agent assignment.. You can review the [beta-1 release](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-relnotes&interface=clischematics-mar2223) documentation and explore.\n\nSchematics Agent are a [beta-1 feature](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-agent-beta1-limitations) that are available for evaluation and testing purposes. It is not intended for production usage.\n\n\n\n Agent \n\nAnswers to common questions about the Agent for IBM Cloud Schematics.\n\n\n\n What are the updates in the agent beta-1 release? \n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n\n\n\n\n What are the costs of installing and using Agents? \n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service\n\n\n\n* There is no cost involved in running the agent service.\n* Post beta, the agent feature may be a priced service.\n\n\n\n\n\n\n\n Can I install more than one Agent on a cluster? \n\nYou can install only one agent on a Kubernetes cluster on IBM Cloud Kubernetes Service. You can install additional agents on different clusters.\n\nYou cannot install more than one agent in a single Kubernetes cluster. You will get a failure with namespace conflict error.\n\n\n\n\n\n What type of Schematics jobs can I run in my Agent? \n\nYou can run Schematics Workspace Terraform jobs on an Agent. You can also run Schematics Action jobs, Ansible playbooks on an Agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-faqs-agent&interface=ui"},{"document_id":"ibmcld_07578-594919-596894","score":20.717915,"text":"\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service\n\n\n\n* There is no cost involved in running the agent service.\n* Post beta, the agent feature may be a priced service.\n\n\n\n* Can I install more than one Agent on a cluster?\n\nYou can install only one agent on a Kubernetes cluster on IBM Cloud Kubernetes Service. You can install additional agents on different clusters.\n\nYou cannot install more than one agent in a single Kubernetes cluster. You will get a failure with namespace conflict error.\n* What type of Schematics jobs can I run in my Agent?\n\nYou can run Schematics Workspace Terraform jobs on an Agent. You can also run Schematics Action jobs, Ansible playbooks on an Agent.\n* How can I see the Schematics job results and logs, for the workloads running on an agent?\n\nThe workspace job or action job logs are available in Schematics UI console. You can also access these job logs using the Schematics Workspace API, or CLI.\n* How many Schematics jobs can run in parallel in the Agent?\n\nCurrently, an agent can run three Schematics jobs in parallel. Any additional jobs are queued and will execute when prior jobs complete execution.\n\nIn future, you will be able to customize an agent to increase the number of job Pods, to increase the number of jobs that can run concurrently.\n* What is the minimum cluster configuration required in Agent release?\n\nThe agent needs IBM Cloud Kubernetes Service Service with minimum three worker nodes, with a flavor of b4x16 or higher.\n* How many workspaces can be assigned to an agent?\n\nCurrently, you can assign any number of workspaces to an agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-594877-596852","score":20.717915,"text":"\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service\n\n\n\n* There is no cost involved in running the agent service.\n* Post beta, the agent feature may be a priced service.\n\n\n\n* Can I install more than one Agent on a cluster?\n\nYou can install only one agent on a Kubernetes cluster on IBM Cloud Kubernetes Service. You can install additional agents on different clusters.\n\nYou cannot install more than one agent in a single Kubernetes cluster. You will get a failure with namespace conflict error.\n* What type of Schematics jobs can I run in my Agent?\n\nYou can run Schematics Workspace Terraform jobs on an Agent. You can also run Schematics Action jobs, Ansible playbooks on an Agent.\n* How can I see the Schematics job results and logs, for the workloads running on an agent?\n\nThe workspace job or action job logs are available in Schematics UI console. You can also access these job logs using the Schematics Workspace API, or CLI.\n* How many Schematics jobs can run in parallel in the Agent?\n\nCurrently, an agent can run three Schematics jobs in parallel. Any additional jobs are queued and will execute when prior jobs complete execution.\n\nIn future, you will be able to customize an agent to increase the number of job Pods, to increase the number of jobs that can run concurrently.\n* What is the minimum cluster configuration required in Agent release?\n\nThe agent needs IBM Cloud Kubernetes Service Service with minimum three worker nodes, with a flavor of b4x16 or higher.\n* How many workspaces can be assigned to an agent?\n\nCurrently, you can assign any number of workspaces to an agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12297-16930-18453","score":20.043015,"text":"\n[Best practices for securing the Schematics objects](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-secure-objects)\n\n\n\n* [Best practices for creating Terraform Templates or modules in Git repositories](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-secure-repo)\n\n\n\n* [What are the best practices that you must follow in developing the Terraform templates, and publishing the same in the Git repositories?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-template-strategy)\n* [Can you create tfvars files with the IBM Cloud\u00ae provider templates?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-security-tfvars)\n* [How can the Terraform developers ensure that the sensitive data is not leaked in the log files?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-security-leak)\n\n\n\n* [Best practices of managing Schematics Workspaces](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-workspaces)\n\n\n\n* [What are the best practices that you must follow in creating a workspace for the Terraform template?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-security-wks)\n* [How can you ensure that the sensitive data used by the Terraform automation, do not leak in the logs or outputs?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objectsbp-security-leak-log)\n* [How can you protect the access to workspaces and its data?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_12297-101461-102908","score":19.529772,"text":"\n* [Accessing the IBM Cloud and GitHub](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentaccess-automate-template)\n* [Creating your IBM Cloud Schematics Workspace](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentcreate-wkspace)\n* [Configuring variables](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentconfigure-the-variables)\n* [Automating the continuous deployment process](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentcontinuous-deployment)\n* [Analyzing the pipeline execution process](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentanalyze-deployment)\n* [Analyzing the Schematics Workspace](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentanalyze-workspace-process)\n* [What's next?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deploymentautomate-what-next)\n\n\n\n\n\n\n\n Importing Schematics templates into the IBM Cloud catalog \n\n[Importing Schematics templates into the IBM Cloud catalog](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-private-catalogprivate-catalog)\n\n\n\n* [Objectives](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-private-catalogprivate-tut-obj)\n* [Time required](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-private-catalogprivate-timereq)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_12297-142362-143679","score":19.491537,"text":"\n* [What are the Git repositories that are supported by Blueprints?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-repos)\n* [Are variable operators and functions supported in blueprint templates?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-values)\n* [How are blueprint module dependencies and execution order determined?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-dependencies)\n* [How do I edit and validate blueprint templates?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-editing)\n* [Why do blueprints get the error 'Length for variable variable name greater than the given length'?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-length)\n* [Why do blueprint operations require a blueprint ID?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-install)\n* [What URL format is used for referencing blueprint templates and input files?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-url)\n* [How is resource provisioning performed?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprints-faqfaqs-bp-resource)\n* [How do you view the blueprint provisioned resources in your cloud account?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_12326-5411-7531","score":19.37716,"text":"\nWith this setup, you have a 1:1 relationship between your workspace and Git repository and you can apply separate permissions for each of your Git repositories. Make sure that your team can manage multiple Git repositories and keep them in sync. \n\n\n\n\n\n\n\n How can I reuse configuration files across environments and workspaces? \n\nTry to minimize the number of Terraform configuration files that you need to manage by creating standardized Terraform templates and by using variables to customize the template to your needs.\n\nNow, you can use Terraform modules from the Terraform module registry for IBM Cloud.\n\nWith standardized Terraform templates or Terraform modules, you can ensure that development best practices are followed within your organization and that all Terraform configuration files have the same structure. Knowing the structure of a Terraform configuration file makes it easier for your developers to understand a file, declare variables, contribute to the code, and troubleshoot the errors.\n\n\n\n\n\n How do I control access to my workspaces? \n\nIBM Cloud Schematics is fully integrated with IBM Cloud\u00ae Identity and Access Management. To control access to a workspace, and who can execute your infrastructure code with IBM Cloud Schematics, see [Managing user access](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access).\n\n\n\n\n\n What do I need to be aware of when I have a repository that I managed with native Terraform? \n\nBecause IBM Cloud Schematics delivers Terraform-as-a-Service, you can import your existing Terraform templates into Schematics Workspaces. Depending on how your Terraform templates and Git repositories are structured, you might need to make changes so that you can successfully use IBM Cloud Schematics.\n\n\n\n* Provider block declaration: Because IBM Cloud Schematics is integrated with IBM Cloud\u00ae Identity and Access Management, your IBM Cloud API key is automatically retrieved for all IAM-enabled resources and you don't have to provide this information in the provider block. However, the API key is not retrieved for classic infrastructure and IBM Cloud Foundry resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03797-4528-6268","score":14.804582,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_05666-3176-5101","score":14.296086,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_07578-809203-811361","score":13.651283,"text":"\nFor example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n* What extra charges will I incur from other parties with Direct Link?\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n* What is planned for Direct Link on Classic Exchange?\n\nThe marketplace has evolved since Direct Link Exchange was established. With data center operators now blurring the lines as network service providers, IBM will be combining the Exchange offering with Connect on the new \"next generation\" platform to reflect both this change and simplify the Direct Link portfolio. Direct Link Exchange will service only the Direct Link classic infrastructure. After migrations of the partner inter-connections to the XCRs are complete, Exchange will be moved to End of Marketing (EoM).\n* Will Direct Link be available in non-MZRs, or is it only a solution for MZRs?\n\nInitial rollout plans are for the Multi-Zone Regions (MZRs) to be prioritized. Other PoPs across the portfolio will support the new Direct Link access model, enabling access to the classic infrastructure and VPC expansions as they occur.\n* If Direct Link is not available for single-campus multizone regions, how do financial services clients handle the data that they need to keep in their regions?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-809076-811234","score":13.651283,"text":"\nFor example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n* What extra charges will I incur from other parties with Direct Link?\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n* What is planned for Direct Link on Classic Exchange?\n\nThe marketplace has evolved since Direct Link Exchange was established. With data center operators now blurring the lines as network service providers, IBM will be combining the Exchange offering with Connect on the new \"next generation\" platform to reflect both this change and simplify the Direct Link portfolio. Direct Link Exchange will service only the Direct Link classic infrastructure. After migrations of the partner inter-connections to the XCRs are complete, Exchange will be moved to End of Marketing (EoM).\n* Will Direct Link be available in non-MZRs, or is it only a solution for MZRs?\n\nInitial rollout plans are for the Multi-Zone Regions (MZRs) to be prioritized. Other PoPs across the portfolio will support the new Direct Link access model, enabling access to the classic infrastructure and VPC expansions as they occur.\n* If Direct Link is not available for single-campus multizone regions, how do financial services clients handle the data that they need to keep in their regions?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03797-3428-4809","score":13.572857,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_07578-278658-280528","score":13.303663,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-278632-280502","score":13.303663,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11408-11687-13539","score":12.867862,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_03704-5798-7955","score":12.71755,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n\n\n\n\n\n What is Business Continuity Insurance? \n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n\n\n\n\n\n What is the Service: Support and Services charge on my invoice? \n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n\n\n\n\n\n What's the difference between promo codes and feature codes? \n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1047268-1049406","score":12.71755,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14007-0-1917","score":23.326038,"text":"\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"},{"document_id":"ibmcld_07578-335595-337885","score":22.183512,"text":"\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-335569-337859","score":22.183512,"text":"\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14546-7-1993","score":18.448944,"text":"\nVMware Shared pricing \n\nIBM Cloud\u00ae for VMware Solutions Shared offers two pricing plans for creating VMware\u00ae virtual data centers. Virtual data centers incur charges for the following virtual data center resource usages:\n\n\n\n* Storage allocations with tiered pricing based on storage performance\n* Virtual CPU (vCPU) usage\n* Virtual memory usage\n* Egress on public networking\n* Commercial operating system licenses used\n* Third-party VMware services\n\n\n\n\n\nTable 1. Pricing plans\n\n Plans Description \n\n VMware Shared On-demand <br><br> * The vCPU and RAM virtual data center are allocated based on the demand. Resources are not preallocated. If you have a large regional demand, delays in availability can occur.<br> <br> <br> <br> <br> * The limits that are established for the amount of vCPU and RAM are maximums.<br> * vCPU and RAM resource limits can be increased and decreased later as required.<br> * The price is calculated hourly and it is based on the resource usage in the virtual data center.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n VMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_00558-20425-22479","score":18.144485,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":18.144485,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_10116-1581-3594","score":18.095816,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-1575-3588","score":18.095816,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_16666-1400-3500","score":18.043095,"text":"\nThe Summary section displays an information dialog box with the promotion code and the free credits information.\n\n\n\n\n\n\n\n Review price estimate and plan resource \n\nYour watsonx.data features an elastic scalable computation method with cost per hour that is computed in Resource Units per Hour (RU\/Hr). The cost varies depending on the resources that you add. It is important to right size the resources so that you can maximize the promotion credits. Take the time to carefully review the section and select minimum resources to conserve your promotion credits. You can estimate the Resource Unit per Hour consumption of your starter sized watsonx.data by using the pricing estimator in the About tab on the watsonx.dataIBM Cloud\u00ae catalog page.\n\nHere, you learn how to review the price estimate and plan the resources.\n\n\n\n1. Go to the watsonx.dataIBM Cloud\u00ae catalog page.\n2. Select the About tab.\n3. You can read through the Summary and Features.\n4. In the Pricing estimator, you can provide the following inputs and review the Estimate summary so that you can assess the hourly cost for the resource units added.\n\n\n\nThe provisioning of your engine with the infrastructures (bucket, database) happens after you create the watsonx.data instance. For more information about provisioning, see [Getting started](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_introhp_start). The price estimation helps you to have an idea of the hourly resource consumption before you create the watsonx.data instance.\n\n\n\nTable 1. Pricing Estimator\n\n Field Description \n\n Coordinator node type Select either storage optimized or compute optimized. Recommend storage optimized to reduce promo credit consumption. \n Number of coordinator nodes By default, it is one. \n Resource units Displays the cost per hour for the type and number of coordinator nodes that you selected \n Worker node type Select either storage optimized or compute optimized. Recommend storage optimized to reduce promo credit consumption. \n Number of worker nodes By default, it is one. Select the required number of worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_14546-2844-4906","score":17.785892,"text":"\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-7085-8964","score":30.819246,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":30.579334,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_11142-7-1829","score":30.537207,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_07578-1076793-1078629","score":30.411238,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":30.411238,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13336-7-1965","score":30.17304,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_07578-1075256-1077185","score":29.490719,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":29.490719,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-8584-10307","score":29.313492,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_12824-7-1978","score":29.12874,"text":"\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-migrated-products"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4217734095}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":18.275505,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":18.275505,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-8584-10307","score":17.542313,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-261594-263338","score":17.368826,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-261568-263312","score":17.368826,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11510-3230-5079","score":16.966927,"text":"\nPay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n\n\n\n\n\n What is the cost of the Qiskit Runtime Standard plan? \n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n\n\n\n\n\n What is the pricing metric of the Qiskit Runtime service? \n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n\n\n\n\n\n Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account? \n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n\n\n\n\n\n Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae? \n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).\n\nYou can set up spending notifications to get notified when your account or a particular service reaches a specific spending threshold that you set. For information, see the [IBM Cloud account Type description](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts). IBM Cloud\u00ae spending notifications trigger only after cost surpasses the specified limit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_16727-1133881-1135817","score":16.94308,"text":"\nYour account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n* Can an existing enterprise be a child of another enterprise?\n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n* How do I add child accounts to my enterprise?\n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise. For more information, see [Import existing accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uiexisting_accounts_tutorial) and [Create new accounts](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uicreate-accounts_tutorial).\n* Can I import a Lite account into an enterprise?\n\nYes, but your Lite account is automatically upgraded to a Pay-As-You-Go account. Billing for the account is then managed at the enterprise level. For more information, see [Centrally managing billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n* Can I remove my account from an enterprise?\n\nAfter you import your account into an enterprise, you can't remove it.\n* Can I move an account within an enterprise?\n\nYes, you can move your account anywhere within an enterprise. For example, you can move your account directly under the enterprise or from one account group to another.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1320438-1322384","score":16.769567,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1323103-1325049","score":16.769567,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05013-1381-3329","score":16.719673,"text":"\nTypically, this is easily done from the IBM Cloud Object Storage console found here [https:\/\/cloud.ibm.com\/objectstorage\/](https:\/\/cloud.ibm.com\/objectstorage\/), select the correct name of Cloud Object Storage Instance you wish to upgrade,click on Plan in the navigation menu, located after Instance Usage. Select the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n\n\n\n\n\n Are bucket names case-sensitive? \n\nBucket names are required to be DNS addressable and are not case-sensitive.\n\n\n\n\n\n What is the maximum number of characters that can be used in a key, or Object name? \n\nKeys have a 1024-character limit.\n\n\n\n\n\n What are some tools unable to render object names? \n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n\n\n\n\n\n Can I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1320438-1322384","score":30.093912,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1323103-1325049","score":30.093912,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":29.649021,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":29.649021,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13336-7-1965","score":29.199816,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_11510-3230-5079","score":28.655989,"text":"\nPay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n\n\n\n\n\n What is the cost of the Qiskit Runtime Standard plan? \n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n\n\n\n\n\n What is the pricing metric of the Qiskit Runtime service? \n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n\n\n\n\n\n Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account? \n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n\n\n\n\n\n Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae? \n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).\n\nYou can set up spending notifications to get notified when your account or a particular service reaches a specific spending threshold that you set. For information, see the [IBM Cloud account Type description](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts). IBM Cloud\u00ae spending notifications trigger only after cost surpasses the specified limit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_05012-4837-6709","score":28.466745,"text":"\nSimilarly, a bucket in ca-tor will incur archive pricing for ca-tor.\n\n\n\n\n\n Can I move my existing buckets from Standard plan to One-Rate plan? \n\nExisting buckets in the Standard plan cannot be moved to the One-rate plan. Clients must first enroll in the One-Rate plan, create a new service instance and new buckets before data can be populated.\n\n\n\n\n\n Can I upgrade my Cloud Object Storage Lite plan instance to One-Rate plan? \n\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n\n\n\n\n\n Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan? \n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n\n\n\n\n\n What is the cost of data retrieval from One Rate Active buckets? \n\nThere is no data retrieval charge for the One Rate Active buckets.\n\n\n\n\n\n What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests? \n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n\n\n\n\n\n Is the overage pricing tiered for Outbound bandwidth and Operational requests? \n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n\n\n\n\n\n I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads? \n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-onerate"},{"document_id":"ibmcld_09055-104201-105670","score":27.847033,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_07578-261594-263338","score":27.825176,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-261568-263312","score":27.825176,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06932-9469-10014","score":19.489319,"text":"\nFor detailed instructions on how to provision a VRA, see the [VRA Getting Started Guide](https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-getting-startedgetting-started).\n\n\n\n\n\n Provisioning IBM Cloud Object Storage (COS) \n\n\n\n* For detailed instructions on how to provision COS, refer to the [Cloud Object Storage Guide](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage).\n* Use one of the private endpoints (listed previously) to create an interface with your bucket or any object in your provisioned COS account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storage"},{"document_id":"ibmcld_10906-15537-17317","score":19.331783,"text":"\n<br><br> * Configure streaming of IBM Cloud Activity Tracker (optional)<br><br><br> You can stream data from an IBM Cloud Activity Tracker instance to another IBM Cloud Activity Tracker instance across regions or to other corporate tools such as Security Information and Event Management (SIEM) tools. Learn more about [streaming data](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-streaming). \n <br><br> * Secure your resources with context-based restrictions<br><br><br> Context-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud resources based on the network location of access requests. These restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials.<br><br>Learn more about [what context-based restrictions are](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis) and follow the guide to [secure your resources using context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial). \n <br><br> * Encrypt and protect your data<br><br><br> You can choose from various secrets management and data protection products that help you to protect your sensitive data and centralize your secrets. Review [Which data protection service is best for me?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloudwhich-data-protection-service) to better understand the different offerings that you can use with IBM Cloud to protect your application secrets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_02104-1628-3678","score":19.003345,"text":"\nSetting up the integration between your App ID instance, which is already configured with your IdP, and your IBM Cloud account makes it so you can continue to manage all users externally in your IdP. It also simplifies the log in process to your cloud account for users in your enterprise. After the integration is complete, you must provide your users with a custom URL that they use to log in each time. There is no need to invite anyone to your account because if they exist as a user in your connected IdP's user repository, they can log in with their credentials through the custom URL.\n\n\n\n Before you begin \n\n\n\n* To decide which is the right federation option for you, check the [IBM Cloud SAML Federation Guide](https:\/\/www.ibm.com\/cloud\/blog\/ibm-cloud-saml-federation-guide).\n* Create an instance of App ID from the IBM Cloud catalog. For more information, see the [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-getting-started).\n* Configure your App ID instance. For more information about how to do this depending on your use case, see the App ID documentation about [managing authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp).\n* Make sure you have the required access to view and manage IdP references, if you aren't the account owner. You must be assigned the operator role or higher on the App ID instance and the operator or administration role on the [IAM Identity Service](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesidentity-service-account-management).\n\n\n\n\n\n\n\n Configuration of your App ID instance for IAM integration \n\nReview the following requirements about how your App ID instance must be configured to work properly as an IAM IdP for your IBM Cloud account.\n\nIf you plan to use your App ID instance for IAM IdP integration, then any user can log in to your account who can authenticate with that App ID instance. Therefore, consider following these guidelines when you configure your instance:\n\nDisable the following types of authentication:\n\n\n\n* Facebook","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-idp-integration"},{"document_id":"ibmcld_04240-7-1782","score":18.913887,"text":"\nGetting started with Citrix DaaS for IBM Cloud \n\nCitrix Virtual Apps and Desktops on IBM Cloud\u00ae is now Citrix DaaS for IBM Cloud\u00ae. If you are using bookmarks to access the documentation, you should update them to the new product name path.\n\nUse Citrix DaaS for IBM Cloud\u00ae to create a dedicated Citrix DaaS service environment at any of our global data centers. You have the option of creating a Classic solution, VMware solution, or VPC solution.\n\n\n\n Before you begin \n\nBefore you begin, review the following information.\n\n\n\n* Want to learn more about Citrix DaaS and how it works? To learn more, see [About Citrix DaaS for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-about-citrix-virtual-apps-and-desktops).\n* Review the supported products and versions in the [Product compatibility guide](https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-product-compatibility-guide).\n\n\n\nYou must have either an active trial or paid subscription to Citrix Cloud. To learn more or to create an account, see [Citrix Cloud](https:\/\/onboarding.cloud.com\/).\n\nAfter you review this information, you are ready to get started. To begin, you need to complete the following prerequisites.\n\n\n\n1. Sign up for an IBM Cloud account\n2. Create required API keys\n3. Verify Citrix and operating system entitlements\n4. Set up network connectivity for logging on to IBM Cloud\n5. (VMWare only) Enable VLAN spanning or VRF on your account\n6. Set up user permissions in IAM\n\n\n\n\n\n\n\n Step 1. Sign up for an IBM Cloud account \n\nTo order and use IBM Cloud services, you need to sign up for an IBM Cloud account. Billing information is associated with your IBM Cloud account and the cost of the physical and virtual infrastructure and the resulting licenses are charged to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-getting-started-tutorial"},{"document_id":"ibmcld_07578-490326-491911","score":18.895184,"text":"\nUpdates to the service are posted on our [What's New](https:\/\/www.ibm.com\/support\/pages\/whats-new-ibm-db2-warehouse-cloud) page.\n\nYou can find pricing information and deploy a Db2 Warehouse on Cloud instance through the IBM Cloud [catalog](https:\/\/cloud.ibm.com\/catalog\/services\/db2-warehouse) page for IBM Cloud. To learn more, contact [IBM Sales](https:\/\/www.ibm.com\/contact\/us\/en\/).\n* Where can I find help for a problem that I'm having?\n\nFor information about posting questions on a forum or opening a support ticket, see [Help & support](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-help_support).\n\n\n\nDb2 on Cloud\n\n\n\n* How do I sign up for Db2 on Cloud?\n\nYou can provision an instance of Db2 on Cloud directly through the IBM Cloud\u00ae catalog. You can [create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse) and get an IBM Cloud credit of $200 that you can use towards an enterprise Db2 on Cloud plan. Or, you can sign up for a free Lite plan.\n* How do I choose the Db2 on Cloud plan that's right for me?\n\nDb2 on Cloud offers several configurations to meet your workload requirements. The Flex plan is recommended because it allows you to dynamically scale RAM\/CPU and storage as your requirements change. Other plans with fixed resources are also available. For more information, see [About](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-about).\n* How do I generate credentials for my instance?\n\n\n\n1. Log into [IBM Cloud](https:\/\/cloud.ibm.com).\n2. Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-490308-491893","score":18.895184,"text":"\nUpdates to the service are posted on our [What's New](https:\/\/www.ibm.com\/support\/pages\/whats-new-ibm-db2-warehouse-cloud) page.\n\nYou can find pricing information and deploy a Db2 Warehouse on Cloud instance through the IBM Cloud [catalog](https:\/\/cloud.ibm.com\/catalog\/services\/db2-warehouse) page for IBM Cloud. To learn more, contact [IBM Sales](https:\/\/www.ibm.com\/contact\/us\/en\/).\n* Where can I find help for a problem that I'm having?\n\nFor information about posting questions on a forum or opening a support ticket, see [Help & support](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-help_support).\n\n\n\nDb2 on Cloud\n\n\n\n* How do I sign up for Db2 on Cloud?\n\nYou can provision an instance of Db2 on Cloud directly through the IBM Cloud\u00ae catalog. You can [create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse) and get an IBM Cloud credit of $200 that you can use towards an enterprise Db2 on Cloud plan. Or, you can sign up for a free Lite plan.\n* How do I choose the Db2 on Cloud plan that's right for me?\n\nDb2 on Cloud offers several configurations to meet your workload requirements. The Flex plan is recommended because it allows you to dynamically scale RAM\/CPU and storage as your requirements change. Other plans with fixed resources are also available. For more information, see [About](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-about).\n* How do I generate credentials for my instance?\n\n\n\n1. Log into [IBM Cloud](https:\/\/cloud.ibm.com).\n2. Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01095-7-1787","score":18.56387,"text":"\nFAQs \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae Warehouse on Cloud service.\n\n\n\n How do I sign up for Db2 Warehouse on Cloud? \n\nYou can provision an instance of Db2 Warehouse on Cloud directly through the IBM Cloud\u00ae catalog. You can [create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse) and get an IBM Cloud credit of $200 that you can use towards Db2 Warehouse on Cloud. Take the [tutorial](https:\/\/www.ibm.com\/cloud\/garage\/dte\/tutorial\/ibm-db2-warehouse-cloud-getting-started-part-1) that walks you through provisioning your first instance of Db2 Warehouse on Cloud.\n\n\n\n\n\n How do I choose the Db2 Warehouse on Cloud plan that's right for me? \n\nDb2 Warehouse on Cloud offers several elastic data warehouse configurations to meet your workload requirements. For more information, see [About](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-about).\n\n\n\n\n\n How do I generate credentials for my instance? \n\n\n\n1. Log into [IBM Cloud](https:\/\/cloud.ibm.com).\n2. Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Cloud Foundry services, locate your Db2 Warehouse on Cloud instance and click on the service name.\n4. Select the Service credentials tab > New credentials+ > Add in order to generate your service admin credentials.\n5. Expand View credentials, which displays your service connectivity information including your admin credentials (username and password).\n6. The admin credentials can be used to connect to both Db2 and the web console.\n\n\n\n\n\n\n\n Now that I've generated credentials, how do I access my Db2 Warehouse on Cloud instance? \n\nYou can access your Db2 Warehouse on Cloud instance through several methods, including a dedicated web console and a REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-faq_db2woc"},{"document_id":"ibmcld_05068-4-2148","score":18.511242,"text":"\n* CLI\n\n\n\n\n\n\n\n Using IBM Cloud Monitoring with IBM Cloud Object Storage \n\nUse the IBM Cloud\u00ae Monitoring service to monitor your IBM Cloud\u00ae Object Storage (COS) data in the IBM Cloud. The results of the activity can be measured for compliance and other analysis through the web dashboard UI.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\n\n\n Features \n\nIBM Cloud Monitoring is a cloud-native management system. Documentation from [Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboards) can guide you in how to use the comprehensive dashboards. In this guide we will focus on how to measure activity on individual buckets in your instance of IBM Cloud Object Storage.\n\n\n\n Working with Metrics \n\nAccording to the [Monitoring documentation](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-startedgetting-started), \"A metric is a quantitative measure that has one or more labels to define its characteristics.\" When you configure your buckets to forward data to a Monitoring instance, that data is automatically collected and available for analysis through the web UI.\n\n\n\n\n\n\n\n Before you begin \n\nBefore you provision an instance of IBM Cloud Monitoring, consider the following guidance:\n\n\n\n* The account owner can create, view, and delete an instance of a service in the IBM Cloud. This user can also grant permissions to other users to work with the IBM Cloud Monitoring service.\n* Other IBM Cloud users with administrator or editor permissions can manage the IBM Cloud Monitoring service in the IBM Cloud. These users must also have platform permissions to create resources within the context of the resource group where they plan to provision the instance.\n\n\n\nIn this guide, we will examine using both the IBM Cloud Console as well as the IBM Cloud Developer Tools (CLI) to integrate Monitoring in your Object Storage instance. For more information about IBM Cloud Developer Tools, check out the [documentation](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration&programming_language=Console"},{"document_id":"ibmcld_07578-487562-489312","score":18.492592,"text":"\n* How do I sign up for Db2 Warehouse on Cloud?\n\nYou can provision an instance of Db2 Warehouse on Cloud directly through the IBM Cloud\u00ae catalog. You can [create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse) and get an IBM Cloud credit of $200 that you can use towards Db2 Warehouse on Cloud. Take the [tutorial](https:\/\/www.ibm.com\/cloud\/garage\/dte\/tutorial\/ibm-db2-warehouse-cloud-getting-started-part-1) that walks you through provisioning your first instance of Db2 Warehouse on Cloud.\n* How do I choose the Db2 Warehouse on Cloud plan that's right for me?\n\nDb2 Warehouse on Cloud offers several elastic data warehouse configurations to meet your workload requirements. For more information, see [About](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-about).\n* How do I generate credentials for my instance?\n\n\n\n1. Log into [IBM Cloud](https:\/\/cloud.ibm.com).\n2. Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Cloud Foundry services, locate your Db2 Warehouse on Cloud instance and click on the service name.\n4. Select the Service credentials tab > New credentials+ > Add in order to generate your service admin credentials.\n5. Expand View credentials, which displays your service connectivity information including your admin credentials (username and password).\n6. The admin credentials can be used to connect to both Db2 and the web console.\n\n\n\n* Now that I've generated credentials, how do I access my Db2 Warehouse on Cloud instance?\n\nYou can access your Db2 Warehouse on Cloud instance through several methods, including a dedicated web console and a REST API. For more information, see [Interfaces](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-interfaces).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-487544-489294","score":18.492592,"text":"\n* How do I sign up for Db2 Warehouse on Cloud?\n\nYou can provision an instance of Db2 Warehouse on Cloud directly through the IBM Cloud\u00ae catalog. You can [create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse) and get an IBM Cloud credit of $200 that you can use towards Db2 Warehouse on Cloud. Take the [tutorial](https:\/\/www.ibm.com\/cloud\/garage\/dte\/tutorial\/ibm-db2-warehouse-cloud-getting-started-part-1) that walks you through provisioning your first instance of Db2 Warehouse on Cloud.\n* How do I choose the Db2 Warehouse on Cloud plan that's right for me?\n\nDb2 Warehouse on Cloud offers several elastic data warehouse configurations to meet your workload requirements. For more information, see [About](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-about).\n* How do I generate credentials for my instance?\n\n\n\n1. Log into [IBM Cloud](https:\/\/cloud.ibm.com).\n2. Open your [Resource list](https:\/\/cloud.ibm.com\/resources).\n3. Under Cloud Foundry services, locate your Db2 Warehouse on Cloud instance and click on the service name.\n4. Select the Service credentials tab > New credentials+ > Add in order to generate your service admin credentials.\n5. Expand View credentials, which displays your service connectivity information including your admin credentials (username and password).\n6. The admin credentials can be used to connect to both Db2 and the web console.\n\n\n\n* Now that I've generated credentials, how do I access my Db2 Warehouse on Cloud instance?\n\nYou can access your Db2 Warehouse on Cloud instance through several methods, including a dedicated web console and a REST API. For more information, see [Interfaces](https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-interfaces).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":37.91388,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":37.91388,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-8584-10307","score":34.350285,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_03704-1531-3564","score":32.951477,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":32.9441,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":32.9441,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03729-1672-3956","score":31.605194,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-3519-5413","score":28.549383,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_07578-261594-263338","score":28.09353,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-261568-263312","score":28.09353,"text":"\n* IBM Cloud Quantum API: .quantum-computing.cloud.ibm.com\n* IBM Cloud: .cloud.ibm.com\n\n\n\n* What plans are available to use Qiskit Runtime with IBM Cloud\u00ae?\n\nCurrently, there are two plans. The Lite plan allows the user to access only quantum simulators and is free of charge. Pay-as-you-go access to IBM Quantum hardware and simulators is provided with the Standard plan. For more information, see [Manage the cost](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n* What is the cost of the Qiskit Runtime Standard plan?\n\nThe Qiskit Runtime Standard plan is a pay-as-you-go service and costs $1.6 per QR second when running on physical systems. For more information, see the [Qiskit Runtime Standard plan](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost) topic.\n* What is the pricing metric of the Qiskit Runtime service?\n\nFor this service, you are charged for Quantum Runtime usage. QR usage is the time counted by QR to process a job, and is determined by the use of internal resources. Queue time is not included. For more information, see the [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans) topic.\n* Can I use Qiskit Runtime with my IBM Cloud\u00ae lite account?\n\nYes, but with the Lite plan you can access only quantum simulators. To use IBM Quantum systems, you need to upgrade to an IBM pay-as-you-go cloud account and use the Standard plan.\n* Do I get a monthly bill and what does it look like for Qiskit Runtime with IBM Cloud\u00ae?\n\nYou will receive a monthly invoice that provides details about your resource charges. You can check how much you've spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-7-1620","score":26.789185,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-8584-10307","score":24.479189,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00479-7-2264","score":24.358633,"text":"\nLearning about IBM Cloudant architecture and workload isolation \n\nReview the following sample architecture for IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, and learn more about different isolation levels. After that, you can choose the solution that best meets the requirements of the workloads that you want to run in the cloud.\n\n\n\n IBM Cloudant isolation models and architecture \n\nIBM Cloudant is a multi-tenant-capable database system with mechanisms in place to distribute any shared resources like CPU or I\/O fairly among the active tenants. IBM Cloudant implements isolation in the database layer itself, and not by relying on containers. Instances are isolated from each other for access control, meaning that it is not possible to read or write data in one instance from another.\n\nWorkload isolation is an important consideration for many customers. To select the best IBM Cloudant plan choice for your workload isolation requirements, see the following architectural information:\n\n\n\n1. Standard and Lite plans on Multi-Tenant Hardware, which offer excellent isolation.\n2. Standard plan provisioned on a Dedicated Hardware plan instance, which offers improved isolation over Standard on Multi-Tenant Hardware.\n\n\n\n\n\n Standard and Lite \n\nStandard and Lite plans are provisioned onto large, shared IBM Cloudant database deployments where customers share compute and storage resource. Standard and Lite plans apply provisioned throughput rate-limiting, along with other resource and access isolation mechanisms within the database layer itself. Together, these provide strong security guarantees alongside robust resource separation within the shared environment.\n\nZoom\n\n![Diagram about how to isolate data with the IBM Cloudant Standard plan for two customers.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/Isolation-Standard.svg)\n\nFigure 1. Data isolation on IBM Cloudant Standard plan\n\nDisk encryption is used to provide encryption at rest by using an IBM owned and managed encryption key. Customer data resides in different files on disk.\n\n\n\n\n\n Standard on Dedicated Hardware \n\nA Dedicated Hardware instance offers improved storage and compute isolation for your most valuable data, including use of BYOK.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compute-isolation"},{"document_id":"ibmcld_07578-1076793-1078629","score":24.287003,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":24.287003,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03729-1672-3956","score":23.795502,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_09795-1650-3805","score":22.331572,"text":"\nIn your monthly usage charges, consumption is measured hourly and your bill breaks down into the following concepts:\n\n\n\nTable 2. Billing usage metrics\n\n Metric Description \n\n NODE_HOURS Tracks the number of agents that are running in an agent for orchestrated environments.<br><br>This does not include the agents tracked by LITE_NODE_HOURS<br><br>For example, if you have 1 agent connected continuously, that agent will be billed 720 NODE_HOURS at the end of the month. \n TIME_SERIES_HOURS Reflects the total number of custom metrics time series you are sending to IBM Cloud Monitoring during a 1 hour time window. This is an aggregation of all time series from agents and other metrics sources. Platform metrics, Prometheus remote write, metric streaming and custom metrics collected with the agent (Prometheus, JMX or StatsD) contribute to TIME_SERIES_HOURS.<br><br>Only custom metrics are counted for TIME_SERIES_HOURS. Default infrastructure metrics (such as host, container, program, or Kubernetes state) and CPU, memory, disk, and network are included in the agent price and do not contribute to TIME_SERIES_HOURS. \n LITE_NODE_HOURS Tracks the number of agents that are monitoring non-containerized infrastructures such as VMs or bare metal servers, and are using the agent for non-orchestrated environments. \n API_CALL_HOURS Represents how many calls are being made to the API per month. All instances include 1M API calls. \n CONTAINER_HOURS Represents how many containers are monitored across all hosts that are being monitored by agents. \n\n\n\nTo monitor how the IBM Cloud Monitoring service is used and the costs associated to its usage, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage).\n\nAll metrics that start with sysdig_* and kube_ are collected automatically by an agent and are included in the agent price.\n\n\n\n\n\n Service plans \n\nThe following service plans are available when you provision an instance of the IBM Cloud Monitoring service:\n\n\n\n Lite plan \n\nYou can provision a Monitoring instance with the Lite service plan to try out the Monitoring service for free for 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"},{"document_id":"ibmcld_07578-96541-98515","score":21.716396,"text":"\nSee this whitepaer on [Splitting the load](https:\/\/www.ibm.com\/downloads\/cas\/KDPB1REE) to learn more about this topic. The Hadoop Distributed File System (HDFS) should be used at most only for intermediate storage during processing. All final data (or even intermediate data) should be written to IBM Cloud Object Storage before the cluster is deleted. If your intermediate storage requirements exceed the HDFS space available on a node, you can add more nodes to the cluster.\n* How many IBM Analytics Engine clusters can I spin up?\n\nThere is no limit to the number of clusters you can spin up.\n* Is there a free usage tier to try IBM Analytics Engine?\n\nYes, we provide the Lite plan which can be used free of charge. However, this plan is available only to institutions that have signed up with IBM to try out the Lite plan. See [How does the Lite plan work](https:\/\/cloud.ibm.com\/docs\/faqslite-plan)?\n\nWhen you move to a paid plan, you are entitled to $200 in credit that can be used against IBM Analytics Engine or any service on IBM Cloud. This credit is only allocated once.\n* How does the Lite plan work?\n\nThe Lite plan provides 50 node-hours of free IBM Analytics Engine usage. One cluster can be provisioned every 30 days. After the 50 node-hours are exhausted, you can upgrade to a paid plan within 24 hours to continue using the same cluster. If you do not upgrade within 24 hours, the cluster will be deleted and you have to provision a new one after the 30 day limit has passed.\n\nA cluster created using a Lite plan has 1 master and 1 data node (2 nodes in total) and will run for 25 hours on the clock (50 hours\/2 nodes). The node-hours cannot be paused, for example, you cannot use 10 node-hours, pause, and then come back and use the remaining 40 node-hours.\n\nRemember that you must sign up with IBM to try out the Lite plan.\n* What types of service maintenance exist in IBM Analytics Engine?\n\nOccasionally, we need to update the IBM Analytics Engine service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-96516-98494","score":21.716396,"text":"\nSee this whitepaer on [Splitting the load](https:\/\/www.ibm.com\/downloads\/cas\/KDPB1REE) to learn more about this topic. The Hadoop Distributed File System (HDFS) should be used at most only for intermediate storage during processing. All final data (or even intermediate data) should be written to IBM Cloud Object Storage before the cluster is deleted. If your intermediate storage requirements exceed the HDFS space available on a node, you can add more nodes to the cluster.\n* How many IBM Analytics Engine clusters can I spin up?\n\nThere is no limit to the number of clusters you can spin up.\n* Is there a free usage tier to try IBM Analytics Engine?\n\nYes, we provide the Lite plan which can be used free of charge. However, this plan is available only to institutions that have signed up with IBM to try out the Lite plan. See [How does the Lite plan work](https:\/\/cloud.ibm.com\/docs?tab=faqslite-plan)?\n\nWhen you move to a paid plan, you are entitled to $200 in credit that can be used against IBM Analytics Engine or any service on IBM Cloud. This credit is only allocated once.\n* How does the Lite plan work?\n\nThe Lite plan provides 50 node-hours of free IBM Analytics Engine usage. One cluster can be provisioned every 30 days. After the 50 node-hours are exhausted, you can upgrade to a paid plan within 24 hours to continue using the same cluster. If you do not upgrade within 24 hours, the cluster will be deleted and you have to provision a new one after the 30 day limit has passed.\n\nA cluster created using a Lite plan has 1 master and 1 data node (2 nodes in total) and will run for 25 hours on the clock (50 hours\/2 nodes). The node-hours cannot be paused, for example, you cannot use 10 node-hours, pause, and then come back and use the remaining 40 node-hours.\n\nRemember that you must sign up with IBM to try out the Lite plan.\n* What types of service maintenance exist in IBM Analytics Engine?\n\nOccasionally, we need to update the IBM Analytics Engine service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16061-1467-3195","score":21.401329,"text":"\n__ Determine whether your account can authorize access: <br>For Cloud Block Storage as the [source service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-planningbyok-volumes-prereqs), Lite accounts must [upgrade to a Pay-As-You-Go](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-accountupgrade-paygo) account or a Subscription account. For more information, see IBM Cloud [account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).<br><br>For File Storage for VPC, specify VPC Infrastructure Services under (source service), check the box (Resource type), and choose File Storage for VPC and Key Protect (target service).<br><br>For custom images, authorize access between Image Service for VPC (source service) and IBM Cloud Object Storage (target service). Specify reader access for the role.<br><br>For all VPC Source services, do not filter by resource group. Do not select the resource group checkbox. \n __ For customer-managed encryption, consider importing or creating multiple root keys and [rotating your keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-key-rotation) for greater security. \n __ When you're provisioning an instance with encrypted volumes, make sure that your [VPC is created and configured](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-startedcreate-and-configure-vpc). \n __ Decide how many secondary volumes you require and how many are to use customer-managed encryption. \n __ Choose the secondary volume [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles) that best meets your needs. IOPS profiles offer pre-defined performance. When you select the Custom profile, you can choose from a range of capacity and IOPS for your volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-planning"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-11723-13541","score":25.409216,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01029-0-4062","score":25.005032,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"},{"document_id":"ibmcld_07578-447531-449109","score":24.765377,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":24.765377,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":24.369772,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-448564-450242","score":24.288921,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":24.288921,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16729-112397-114109","score":24.214598,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01183-7-2154","score":24.104929,"text":"\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https:\/\/cloud.ibm.com\/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose"},{"document_id":"ibmcld_08069-7-2230","score":23.918633,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11163-68646-70819","score":23.450476,"text":"\nFor more information, see [Support subscriptions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssupport-subscriptions).\n\nYou can also now view your support subscriptions in the IBM Cloud console so you can keep track of your available credit. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n 12 September 2019 \n\nRedirecting SoftLayer to IBM Cloud\n: SoftLayer account owners who previously didn't have access to the IBM Cloud platform can now manage their infrastructure, services, and applications from one location: [cloud.ibm.com](https:\/\/cloud.ibm.com).\n\n\n\n\n\n\n\n July 2019 \n\n\n\n 25 July 2019 \n\nIBM Cloud enterprises for centrally managing multiple accounts\n: You can now centrally manage billing and usage for multiple accounts by creating an IBM Cloud enterprise. With an enterprise, you can create a multitiered hierarchy of accounts by organizing related accounts into account groups. Enterprises simplify management of multiple accounts with the following key features:\n\n\n\n* Consolidated billing means that you can manage billing, invoicing, and payment for all accounts from a single place, the enterprise account.\n* Subscription credit is aggregated into a credit pool and shared with all accounts in the enterprise. Not only is tracking your subscriptions easier, but you can get fewer, larger subscriptions for a better discount because the credit is shared.\n* Top-down usage reporting gives you a unified view of usage costs from all accounts, organized according to your enterprise hierarchy.\n\n\n\nIf you have multiple accounts, at least one of which is a Subscription account, you can create an enterprise. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) and [Introducing IBM Cloud Enterprises](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/introducing-ibm-cloud-enterprises) for more information.\n\nSubscriptions page for tracking subscription credit spending\n: If you have a Subscription account, you can now view all of your subscriptions and analyze your credit spending on the Subscriptions page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_07037-3003-4984","score":22.411858,"text":"\nFor example, in the URL \/collections\/5a525eb7-b175-3820-0000-017d00f0fcd1\/activity, the collection ID is 5a525eb7-b175-3820-0000-017d00f0fcd1.)\n\n\n\n* If the problem has to do with documents failing to load, provide the following information if known:\n\n\n\n* What kind of documents are being uploaded (such as PDF, Json, CSV). Was optical character recognition (OCR) enabled for the collection?\n* How were the documents loaded into the collection? (using the API, from the product UI, data source connector)\n* Did you identify fields in the collection by using Smart Document Understanding? If so, what type of SDU model was applied to the collection (user-trained or pretrained)?\n* What enrichments were applied to the collection?\n\n\n\n* If the problem is related to a particular document (of a small set of documents), provide the document_id of the document, if known. You can share example documents if they might be helpful.\n* If the problem is related to querying documents, describe the kind of query being used.\n\n\n\n\n\n\n\n\n\n IBM Cloud Pak for Data Contacting IBM Support for installed deployments \n\nInstalled deployments are deployment that you provision on IBM Cloud Pak for Data.\n\nYou can get help by opening a case from IBM Support from [IBM Support](https:\/\/www.ibm.com\/mysupport\/s\/topic\/0TO50000000IYkUGAW\/cloud-pak-for-data).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Software versions of both the Discovery service version and IBM Cloud Pak for Data version.\n* Relevant details about configuration choices that were made during installation and deployment.\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-get-help"},{"document_id":"ibmcld_10906-5101-6829","score":22.221785,"text":"\nConsider the following when determining whether you need an enterprise or a stand-alone account:<br><br><br><br> * In an enterprise, subscription discounts and cloud credits are available to all accounts that are in the enterprise.<br> * Stand-alone accounts control their own billing. If your company is globally distributed, you might have a mix of multiple enterprises and stand-alone accounts to support regional billing requirements.<br><br><br><br>Review the [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) documentation to determine whether you need an enterprise. \n <br><br> * Create and configure your IBM Cloud account<br><br><br> Even if you plan on using an enterprise, you need to create an IBM Cloud account. You can create your account by going to the [account registration](https:\/\/cloud.ibm.com\/registration) page and providing an email address and other additional information. The email address that is used to register becomes the account owner, but you can change this if required later on by following the steps in [Transferring ownership of your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-transfer&interface=ui).<br><br>When setting up an account for your company or organization, it is best to use a functional ID, some teams call them service accounts, associated with your company. Keep in mind that you will need to monitor for automated emails sent to this email address for warnings about service usage, services being deprecated, new services available, and more.<br><br>When you log in to the account for the first time, you are required to provide a credit card or subscription code to complete your account set up.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_10906-3434-5590","score":22.171286,"text":"\nThis checklist is for administrators who are responsible for creating and setting up an account structure in IBM Cloud and enabling users within their company to create and manage cloud resources. IBM Cloud offers you the ability to create a stand-alone account and an enterprise.\n\nStand-alone account\n: This type of account allows an account owner, for example a department or business unit administrator to add users to the account, assign access roles and permissions, manage billing and payments, and more.\n\nEnterprise\n: An enterprise manages the billing for the entire company, with usage costs from multiple accounts being rolled up and paid for from the enterprise account. Accounts that are created as part of an enterprise are just like stand-alone accounts, but the main difference is that these accounts don't manage their own billing or payments.\n\nUse the following checklist to track all of the tasks to create and configure your IBM Cloud account or enterprise.\n\n\n\nTable 2. Getting started tasks for setting up accounts and enterprises\n\n Task Description \n\n <br><br> * What's in an account?<br><br><br> Your IBM Cloud account includes many interacting components and systems for resource, user, and access management. Understanding concepts like how certain components are connected or how access works help you effectively set up your account. For more information, see [What's in an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-overview). \n <br><br> * Determine if you need an enterprise<br><br><br> When you create an enterprise to manage your billing, you can move existing stand-alone accounts to it, or create new accounts as needed. Consider the following when determining whether you need an enterprise or a stand-alone account:<br><br><br><br> * In an enterprise, subscription discounts and cloud credits are available to all accounts that are in the enterprise.<br> * Stand-alone accounts control their own billing. If your company is globally distributed, you might have a mix of multiple enterprises and stand-alone accounts to support regional billing requirements.<br><br><br><br>Review the [What is an enterprise?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_01877-1597-3577","score":21.144503,"text":"\nFor more information, see [Known issues and limitations](https:\/\/cloud.ibm.com\/docs\/account?topic=account-known-issues).\n\n\n\n\n\n Managing access to products for all users in the console \n\nYou can use filters to manage which products in the public catalog are available to all users in your account. For example, you might want to restrict access to third-party products. Or, you might want users to work with a specific software type. If your account is a parent account in an IBM Cloud enterprise, the filters that you set apply to all child account groups and accounts. For more information, see [Managing products for IBM Cloud enterprise](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-enterprise-restrict).\n\n\n\n1. Go to Manage > Catalogs > Settings in the IBM Cloud console.\n2. Confirm that the visibility of the public catalog is set to On.\n3. In the What products are available? section, select Exclude all products in the IBM Cloud catalog.\n4. Set one or more [filters](https:\/\/cloud.ibm.com\/docs\/account?topic=account-filter-account&interface=uicatalog-filters-customize) to customize what products are available by category.\n5. (Optional) Add exceptions to the filter rules that you set in the previous step.\n6. Use the Preview table to confirm your selections, and click Update.\n\n\n\n\n\n\n\n Managing access to products for specific users in the console \n\nSet filters at a private catalog level for fine-grained control of which products in the public catalog are available only to the users you choose.\n\n\n\n1. Go to Manage > Catalogs, Private catalogs in the IBM Cloud console.\n2. Select a catalog from the list to navigate to its details page.\n\nThe Products in the IBM Cloud catalog table that's displayed on the page shows the list of products that are available at the account level. The availability is based on the filters the account owner or administrator set. Account-level filters apply to all the private catalogs in the account.\n3. Click Manage filters.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-filter-account&interface=ui"},{"document_id":"ibmcld_01875-1597-3564","score":21.119457,"text":"\nFor more information, see [Known issues and limitations](https:\/\/cloud.ibm.com\/docs\/account?topic=account-known-issues).\n\n\n\n\n\n Managing access to products for all users in the console \n\nYou can use filters to manage which products in the public catalog are available to all users in your account. For example, you might want to restrict access to third-party products. Or, you might want users to work with a specific software type. If your account is a parent account in an IBM Cloud enterprise, the filters that you set apply to all child account groups and accounts. For more information, see [Managing products for IBM Cloud enterprise](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-enterprise-restrict).\n\n\n\n1. Go to Manage > Catalogs > Settings in the IBM Cloud console.\n2. Confirm that the visibility of the public catalog is set to On.\n3. In the What products are available? section, select Exclude all products in the IBM Cloud catalog.\n4. Set one or more [filters](https:\/\/cloud.ibm.com\/docs\/account?topic=account-filter-accountcatalog-filters-customize) to customize what products are available by category.\n5. (Optional) Add exceptions to the filter rules that you set in the previous step.\n6. Use the Preview table to confirm your selections, and click Update.\n\n\n\n\n\n\n\n Managing access to products for specific users in the console \n\nSet filters at a private catalog level for fine-grained control of which products in the public catalog are available only to the users you choose.\n\n\n\n1. Go to Manage > Catalogs, Private catalogs in the IBM Cloud console.\n2. Select a catalog from the list to navigate to its details page.\n\nThe Products in the IBM Cloud catalog table that's displayed on the page shows the list of products that are available at the account level. The availability is based on the filters the account owner or administrator set. Account-level filters apply to all the private catalogs in the account.\n3. Click Manage filters.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-filter-account"},{"document_id":"ibmcld_02361-7-2094","score":20.990221,"text":"\nAdoption guidelines for regulated and highly available workloads \n\nFor regulated and highly available workloads, consider the following adoption guidelines when using the IBM Cloud\u00ae Activity Tracker (AT) service:\n\n\n\n Define resources naming standards for compliance \n\nWhen you create resources in the IBM Cloud, you can choose how to name them, what information to include in their description fields, which tags to use to group them, associate metadata, and more.\n\nDefine naming standards that do not include PII and other sensitive information for all resources that are created in the IBM Cloud.\n\n\n\n\n\n Define the account management strategy \n\nIn IBM Cloud, you can have 1 or more stand-alone accounts. You can manage each account individually or within an enterprise by configuring a multitiered hierarchy of accounts.\n\nWithin an enterprise account, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level. [Learn more](https:\/\/cloud.ibm.com\/docs\/account?topic=account-what-is-enterprise).\n\n\n\n* The enterprise account serves as the parent account to all other accounts in the enterprise.\n* Users and access management is isolated between the enterprise and its child accounts. No access is automatically inherited between the two types of accounts.\n* Resources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups.\n\n\n\nAn enterprise can contain up to 5 tiers of accounts and account groups. In its most basic form, an enterprise has two tiers: the enterprise account, and a single child account.\n\nThe following table highlights some of the key features per account management strategy:\n\n\n\nTable 1. Types of accounts\n\n Feature Stand-alone account management Enterprise account management \n\n Multitiered hierarchy of accounts ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) \n Billing and payments managed from 1 account !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09275-7-2097","score":20.866508,"text":"\nAdoption guidelines for regulated and highly available workloads \n\nFor regulated and highly available workloads, consider the following adoption guidelines when using the IBM Log Analysis service:\n\n\n\n Define resources naming standards for compliance \n\nWhen you create resources in the IBM Cloud, you can choose how to name them, what information to include in their description fields, which tags to use to group them, associate metadata, and more.\n\nDefine naming standards that do not include PII and other sensitive information across all resources that are created in the IBM Cloud.\n\n\n\n\n\n Define the account management strategy \n\nIn IBM Cloud, you can have 1 or more stand-alone accounts. You can manage each account individually or within an enterprise by configuring a multitiered hierarchy of accounts.\n\nWithin an enterprise account, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level. [Learn more](https:\/\/cloud.ibm.com\/docs\/account?topic=account-what-is-enterprise).\n\n\n\n* The root enterprise account serves as the parent account to all other accounts in the enterprise.\n* Users and access management is isolated between the enterprise and its child accounts. No access is automatically inherited between the two types of accounts.\n* Resources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups.\n\n\n\nNotice that an enterprise can contain up to 5 tiers of accounts and account groups. In its most basic form, an enterprise has two tiers: the enterprise account, and a single child account.\n\nThe following table highlights some of the key features per account management strategy:\n\n\n\nTable 1. Types of accounts\n\n Feature Stand-alone account management Enterprise account management \n\n Multitiered hierarchy of accounts NO ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) \n Billing and payments managed from 1 account !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_07578-1129740-1131838","score":20.654787,"text":"\nA resource restoration can fail if you try to restore a resource in a deleted resource group or the resource restoration request isn't submitted in time. Most requests must be submitted within 7 days.\n* How do I retrieve details on a resource that is scheduled for reclamation?\n\nAfter the instance is deleted from the console, you can view it in your account by using the CLI in the SCHEDULED state. The SCHEDULED state indicates that this instance is scheduled for reclamation. For more information, see [Working with resources and resource groups](https:\/\/cloud.ibm.com\/docs\/account?topic=cli-ibmcloud_commands_resourcecommand-options-37).\n* Can you restore a resource that is in a deleted resource group?\n\nYou can restore a resource from a deleted resource group. [Create a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add) in the IBM Cloud Support Center and specify in the description of the case that you want to restore the resource that's in a deleted resource group.\n\n\n\nRunning secure enterprise workloads\n\n\n\n* How do I set up an enterprise account?\n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n* When I create an enterprise, does my IBM Cloud account become the enterprise account?\n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1132221-1134319","score":20.654787,"text":"\nA resource restoration can fail if you try to restore a resource in a deleted resource group or the resource restoration request isn't submitted in time. Most requests must be submitted within 7 days.\n* How do I retrieve details on a resource that is scheduled for reclamation?\n\nAfter the instance is deleted from the console, you can view it in your account by using the CLI in the SCHEDULED state. The SCHEDULED state indicates that this instance is scheduled for reclamation. For more information, see [Working with resources and resource groups](https:\/\/cloud.ibm.com\/docs\/account?topic=cli-ibmcloud_commands_resourcecommand-options-37).\n* Can you restore a resource that is in a deleted resource group?\n\nYou can restore a resource from a deleted resource group. [Create a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add) in the IBM Cloud Support Center and specify in the description of the case that you want to restore the resource that's in a deleted resource group.\n\n\n\nRunning secure enterprise workloads\n\n\n\n* How do I set up an enterprise account?\n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n* When I create an enterprise, does my IBM Cloud account become the enterprise account?\n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00531-7-2145","score":25.788733,"text":"\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-authenticating-cloudant"},{"document_id":"ibmcld_00589-8040-10059","score":25.615213,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-414710-416563","score":24.514467,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-414684-416537","score":24.514467,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-419683-421572","score":24.155636,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-419665-421554","score":24.155636,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00589-9560-11733","score":22.831928,"text":"\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-900427-902422","score":22.097824,"text":"\nYou can also revoke access at any time, for example, if you suspect your keys might be compromised. You can also disable or delete a root key, or temporarily revoke access to the key's associated data on the cloud. For more information, see [Managing root keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-manage-root-keys).\n* What are the advantages of using customer-managed encryption over provider-managed encryption?\n\n What are the advantages of using customer-managed encryption over provider-managed encryption? \n\nCustomer-managed encryption encrypts your Block Storage for VPC volumes by using your own root keys. You have complete control over your data security and grant IBM access to use your root keys. For more information, see [Advantages of customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-advantages).\n* What encryption technology is used for customer-managed encryption?\n\n What encryption technology is used for customer-managed encryption? \n\nVirtual disk images for VPC use QEMU Copy On Write Version 2 (QCOW2) file format. LUKS encryption format secures the QCOW2 format files. IBM currently uses the AES-256 cipher suite and XTS cipher mode options with LUKS. This combination provides you a much greater level of security than AES-CBC, along with better management of passphrases for key rotation, and provides key replacement options in case your keys are compromised.\n* What are master encryption keys and how are they assigned to my Block Storage for VPC volumes?\n\n What are master encryption keys and how are they assigned to my Block Storage for VPC volumes? \n\nEach volume is assigned a unique master encryption key, called a data encryption key or DEK, which is generated by the instance's host hypervisor. The master key for each Block Storage for VPC volume is encrypted with a unique KMS-generated LUKS passphrase, which is then encrypted by your customer root key (CRK) and stored in the KMS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-900304-902299","score":22.097824,"text":"\nYou can also revoke access at any time, for example, if you suspect your keys might be compromised. You can also disable or delete a root key, or temporarily revoke access to the key's associated data on the cloud. For more information, see [Managing root keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-manage-root-keys).\n* What are the advantages of using customer-managed encryption over provider-managed encryption?\n\n What are the advantages of using customer-managed encryption over provider-managed encryption? \n\nCustomer-managed encryption encrypts your Block Storage for VPC volumes by using your own root keys. You have complete control over your data security and grant IBM access to use your root keys. For more information, see [Advantages of customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-advantages).\n* What encryption technology is used for customer-managed encryption?\n\n What encryption technology is used for customer-managed encryption? \n\nVirtual disk images for VPC use QEMU Copy On Write Version 2 (QCOW2) file format. LUKS encryption format secures the QCOW2 format files. IBM currently uses the AES-256 cipher suite and XTS cipher mode options with LUKS. This combination provides you a much greater level of security than AES-CBC, along with better management of passphrases for key rotation, and provides key replacement options in case your keys are compromised.\n* What are master encryption keys and how are they assigned to my Block Storage for VPC volumes?\n\n What are master encryption keys and how are they assigned to my Block Storage for VPC volumes? \n\nEach volume is assigned a unique master encryption key, called a data encryption key or DEK, which is generated by the instance's host hypervisor. The master key for each Block Storage for VPC volume is encrypted with a unique KMS-generated LUKS passphrase, which is then encrypted by your customer root key (CRK) and stored in the KMS.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00579-7-1988","score":20.957724,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":31.71386,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":31.71386,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-4961-6763","score":23.436346,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":23.436346,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_16324-1477-3681","score":15.491774,"text":"\nIf you have an existing interactive voice response (IVR) system with a branching structure (\u201cpress 1 for billing, press 2 for payments\u201d), you might choose the [phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone) as your initial channel. You can integrate Watson Assistant with your existing system to automate the IVR experience so customers can talk with your assistant over the phone.\n\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform. For more information about ways to deploy an assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\n\n\n\n\n 2. Pick your assistant's domain of expertise \n\nDecide which general domain of expertise you want your assistant to cover (for example, billing support or scheduling appointments). To make an informed decision, review any support call logs that you have access to or ask your customer service representatives. After you choose a domain, be sure that it aligns with a channel that you can control and change. For example, don\u2019t choose to automate billing support questions if you're unable to add the web chat client to the billing web pages.\n\nAfter you select a domain, you can decide which specific questions or tasks the assistant will help customers with. Start small. Pick one or a handful of customer issues that will deliver the highest value to start. It might be valuable for your assistant to answer a simple question that is asked all the time. Or maybe there's a task, such as scheduling appointments, that you can offload to the assistant to tackle incoming customer requests.\n\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_07118-10351-11416","score":14.921651,"text":"\n[Shows the data source options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-0.png)\n\nFigure 19. Data source options\n2. In the Collection name field, add FRED papers.\n\nZoom\n\n![Shows the Web crawl name field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-1.png)\n\nFigure 20. Web crawl connector\n3. In the Starting URLs field, add the following URL:\n\nhttps:\/\/research.stlouisfed.org\/wp\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-2.png)\n\nFigure 21. Starting URL field\n\nYou will add only one starting URL. In a real scenario, you might add multiple URLs that go to other pages with information about the same topic. By adding more URLs, you can expand the breadth of the expertise of your assistant.\n4. Click Add.\n5. Click the Edit icon for the URL that you just added.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred"},{"document_id":"ibmcld_11110-54716-55462","score":14.700186,"text":"\nRed Hat\u00ae, JBoss\u00ae, OpenShift\u00ae, Fedora\u00ae, Hibernate\u00ae, Ansible\u00ae, CloudForms\u00ae, RHCA\u00ae, RHCE\u00ae, RHCSA\u00ae, Ceph\u00ae, and Gluster\u00ae are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in the United States and other countries.\n\nSalesforce is a trademark of Salesforce.com, Inc.\n\nBox is a trademark of Box, Inc.\n\nOther company, product, and service names may be trademarks or service marks of others.\n\n\n\n\n\n Terminology \n\nWhile IBM values the use of inclusive language, terms that are outside of IBM's direct influence are sometimes required for the sake of maintaining user understanding. As other industry leaders join IBM in embracing the use of inclusive language, IBM will continue to update the documentation to reflect those changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-notices"},{"document_id":"ibmcld_15149-1596-3071","score":14.626161,"text":"\n* Subsystem: XenSource, Inc. Device 0001\n* Kernel driver in use: ata_piix\n* Kernel modules: ata_piix, pata_acpi, ata_generic\n\n\n\n\n\n* USB controller:\n\n\n\n* USB controller: Intel Corporation 82371SB PIIX3 USB [Natoma\/Triton II] - (rev 01)\n\n\n\n* Subsystem: XenSource, Inc. Device 0001\n* Kernel driver in use: uhci_hcd\n\n\n\n\n\n* Bridge:\n\n\n\n* Intel Corporation 82371AB\/EB\/MB PIIX4 ACPI (rev 01)\n\n\n\n* Subsystem: Red Hat, Inc. Qemu virtual machine\n* Kernel modules: i2c_piix4\n\n\n\n\n\n* VGA compatible controller:\n\n\n\n* Cirrus Logic GD 5446 (prog-if 00 [VGA controller])\n\n\n\n* Subsystem: XenSource, Inc. Device 0001\n* Expansion ROM: [disabled]\n* Kernel driver in use: cirrus\n* Kernel modules: cirrus\n\n\n\n\n\n* SCSI storage controller:\n\n\n\n* XenSource, Inc. Xen Platform Device (rev 01)\n\n\n\n* Subsystem: XenSource, Inc. Xen Platform Device\n* Kernel driver in use: xen-platform-pci\n\n\n\n\n\n* System peripheral:\n\n\n\n* XenSource, Inc. Citrix XenServer PCI Device for Windows Update (rev 01)\n\n\n\n* Subsystem: XenSource, Inc. Citrix XenServer PCI Device for Windows Update\n\n\n\n\n\n* Ethernet controller:\n\n\n\n* TSO is supported\n* GRO is supported\n* GSO is supported\n* Checksum offload\n\n\n\n* Rx-checksum is supported\n* Tx-checksum is supported\n\n\n\n\n\n\n\n\n\n\n\n Custom Linux kernel build options \n\nThe following kernel options are required when you build a Linux operating system for IBM Cloud.\n\n\n\n* CONFIG_ETHERNET = y\n\n\n\n* Ethernet driver support\n\n\n\n* CONFIG_NETDEVICES = y\n\n\n\n* Network device support\n\n\n\n* CONFIG_PCI = y","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configuration-requirements-for-custom-linux-kernels"},{"document_id":"ibmcld_11110-53251-55141","score":14.590491,"text":"\nA current list of IBM trademarks is available on the web at [Copyright and trademark information](https:\/\/www.ibm.com\/legal\/copytrade).\n\nAdobe, the Adobe logo, PostScript, and the PostScript logo are either registered trademarks or trademarks of Adobe Systems Incorporated in the United States, and\/or other countries.\n\nThe Android robot is reproduced or modified from work created and shared by Google and used according to terms described in the [Creative Commons 3.0 Attribution License](https:\/\/creativecommons.org\/licenses\/by\/3.0\/).\n\nMicrosoft, Windows, Windows NT, and the Windows logo are trademarks of Microsoft Corporation in the United States, other countries, or both.\n\nNode.js is a trademark of Joyent, Inc. and is used with its permission. This documentation is not formally endorsed by or affiliated with Joyent.\n\nUNIX is a registered trademark of The Open Group in the United States and other countries.\n\nJava and all Java-based trademarks and logos are trademarks or registered trademarks of Oracle and\/or its affiliates.\n\nVMware, the VMware logo, VMware Cloud Foundation, VMware Cloud Foundation Service, VMware vCenter Server, and VMware vSphere are registered trademarks or trademarks of VMware, Inc. or its subsidiaries in the United States and\/or other jurisdictions.\n\nThe registered trademark Linux\u00ae is used pursuant to a sublicense from the Linux Foundation, the exclusive licensee of Linus Torvalds, owner of the mark on a worldwide basis.\n\nRed Hat\u00ae, JBoss\u00ae, OpenShift\u00ae, Fedora\u00ae, Hibernate\u00ae, Ansible\u00ae, CloudForms\u00ae, RHCA\u00ae, RHCE\u00ae, RHCSA\u00ae, Ceph\u00ae, and Gluster\u00ae are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in the United States and other countries.\n\nSalesforce is a trademark of Salesforce.com, Inc.\n\nBox is a trademark of Box, Inc.\n\nOther company, product, and service names may be trademarks or service marks of others.\n\n\n\n\n\n Terminology","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-notices"},{"document_id":"ibmcld_02719-9578-11382","score":13.654571,"text":"\nibmcloud ac collection list [--sort SORT] [--limit LIMIT] [--offset OFFSET] [--features FEATURES] [--properties PROPERTIES] [--tags TAGS] [--expand EXPAND] [--include INCLUDE]\n\n\n\n Command options \n\n--limit LIMIT (optional)\n: Used for pagination. The number of records to retrieve.\n\n--offset OFFSET (optional)\n: Used for pagination. The number of records to skip.\n\n--features FEATURES (optional)\n: Filter collections by a list of comma-separated features.\n\n--properties PROPERTIES (optional)\n: Filter collections by a list of comma-separated properties.\n\n--tags TAGS (optional)\n: Filter based on the tags.\n\n--sort SORT (optional)\n: Sort the details based on the specified attribute.\n\n--expand EXPAND (optional)\n: Expanded view of the item.\n\n--include INCLUDE (optional)\n: Include feature and property details in the response.\n\n\n\n\n\n Example \n\nTo list all collections, run the following command:\n\nibmcloud ac collection list\n\n\n\n Output \n\nThe command returns the following output:\n\nname collection_id\nsample sampleId\nGHz Inc ghzinc1\n\n\n\n\n\n\n\n\n\n ibmcloud ac collection create \n\nYou can create a collection, by using the command:\n\nibmcloud ac collection create {--file FILE-PATH | --name NAME [--collection_id COLLECTION_ID] [--description DESCRIPTION] [--tags TAGS]}\n\n\n\n Command options \n\n--name NAME\n: Collection name. Required field - input either as a flag or from file.\n\n--collection_id COLLECTION_ID (optional)\n: Collection ID. If this value is not provided, name will automatically become the ID. Optional field - input either as a flag or from file.\n\n--description DESCRIPTION (optional)\n: Description of the collection. Optional field - input either as a flag or from file.\n\n--tags TAGS (optional)\n: Tags associated with the collection. Optional field - input either as a flag or from file.\n\n--file FILE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-cli-plugin-app-configuration-cli"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-7-2136","score":34.679943,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":34.679943,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_06808-1384-2991","score":34.284283,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_04831-50613-52356","score":33.69059,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_04991-50585-52328","score":33.69059,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_02361-24500-26305","score":33.669716,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_05168-15740-17188","score":33.58296,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04866-1541-3629","score":33.341476,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":33.341476,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_09275-31436-33181","score":33.315292,"text":"\n[Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.\n\n[4]: You can define a retention policy to retain data for a long period of time and have the data available for downloads and queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05010-7-1832","score":37.028233,"text":"\nFAQ - General \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n How can I find out the total size of my bucket by using the API? \n\nYou can use the [Resource Configuration API](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) to get the bytes used for a given bucket.\n\n\n\n\n\n How can I view my buckets? \n\nYou can view and navigate your buckets using the console, CLI or the API.\n\nFor example, the CLI command ibmcloud cos buckets will list all buckets associated with the targeted service instance.\n\n\n\n\n\n Can I migrate data from AWS S3 into IBM Cloud Object Storage? \n\nYes, you can use your existing tools to read and write data into IBM Cloud Object Storage. You need to configure HMAC credentials allow your tools to authenticate. Not all S3-compatible tools are currently unsupported. For details, see [Using HMAC credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-uhc-hmac-credentials-main).\n\n\n\n\n\n Can I use AWS S3 SDKs with IBM Cloud Object Storage? \n\nYes, IBM COS SDKs are based on the official AWS S3 API SDKs, but are modified to use IBM Cloud features, such as IAM, Key Protect, Immutable Object Storage, and others. When using these SDKs, use HMAC authorization and an explicit endpoint. For details, see [About IBM COS SDKs](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-sdk-about).\n\n\n\n\n\n Is there a 100-bucket limit to an account? What happens if I need more? \n\nYes, 100 is the current bucket limit. Generally, prefixes are a better way to group objects in a bucket, unless the data needs to be in a different region or storage class. For example, to group patient records, you would use one prefix per patient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_05158-5495-7180","score":32.520172,"text":"\nFor the parameters to set a region or endpoint, refer to the documentation for [Cloud Object Storage CLI](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli) or [AWS CLI](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-aws-cli).\n\n\n\n\n\n How do I copy or move files to another bucket in a different location? \n\nRefer to [Move data between buckets](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-region-copy) for an example of how to use the rclone command line utility for copying data. If you use other 'sync' or 'clone' tools, be aware that you might need to implement a script to move files to a bucket in a different location because multiple endpoints are not allowed in a command.\n\n\n\n\n\n Other support options \n\n\n\n* If you have technical questions about Object Storage, post your question on [Stack Overflow](https:\/\/stackoverflow.com\/search?q=object-storage+ibm) and tag your question with ibm and object-storage.\n* For questions about the service and getting started instructions, use the [IBM Developer dW Answers forum](https:\/\/developer.ibm.com\/answers\/topics\/objectstorage\/). Include the objectstorage tag.\n\n\n\n\n\n\n\n Next Steps \n\nFor more information about asking questions, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatarasking-a-question).\n\nSee [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\nFor more information about opening an IBM support ticket, see how to [create a request](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-troubleshooting-cos"},{"document_id":"ibmcld_07578-21559-23441","score":32.037426,"text":"\nFor information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n* Where can I learn more about uploading documents to Watson Discovery?\n\nYou can upload documents using the API or the Discovery tooling. You can also connect to several different data sources (including Box, Salesforce, SharePoint Online, SharePoint 2016, and IBM Cloud Object Storage), or do a web crawl. For details, see [Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent).\n* What document types are supported for ingestion?\n\nRefer to [Supported document types and browsers](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdudoctypes) for a list of the available document types by plan.\n* How do you use the Smart Document Understanding editor?\n\nThe SDU editor functions are available in the Discovery tooling. Read [Using the Smart Document Understanding editor](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sduannotate) to get started.\n* How much does Discovery cost?\n\nDiscovery has several options available. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans).\n* How do I upgrade my existing Discovery plan?\n\nFor information on resizing your plan from Lite to Advanced, or switching from one Advanced tier to another, see [Upgrading your plan](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-plan).\n* How do I create a stopwords list?\n\nDiscovery applies a default list of stopwords for several languages at query time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-21559-23441","score":32.037426,"text":"\nFor information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n* Where can I learn more about uploading documents to Watson Discovery?\n\nYou can upload documents using the API or the Discovery tooling. You can also connect to several different data sources (including Box, Salesforce, SharePoint Online, SharePoint 2016, and IBM Cloud Object Storage), or do a web crawl. For details, see [Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent).\n* What document types are supported for ingestion?\n\nRefer to [Supported document types and browsers](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdudoctypes) for a list of the available document types by plan.\n* How do you use the Smart Document Understanding editor?\n\nThe SDU editor functions are available in the Discovery tooling. Read [Using the Smart Document Understanding editor](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sduannotate) to get started.\n* How much does Discovery cost?\n\nDiscovery has several options available. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans).\n* How do I upgrade my existing Discovery plan?\n\nFor information on resizing your plan from Lite to Advanced, or switching from one Advanced tier to another, see [Upgrading your plan](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-plan).\n* How do I create a stopwords list?\n\nDiscovery applies a default list of stopwords for several languages at query time.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16729-3879-5767","score":29.131975,"text":"\n* 20 minutes\n* 2023-03-31\n\n\n\n[Power your assistant with answers from web resources](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred)Power your assistant with answers from web resources\n\nIn this tutorial, you will use the Watson Discovery and Watson Assistant services to create a virtual assistant that can answer questions about the latest research from the US Federal Reserve. The assistant will answer questions by using up-to-date, existing research publications from the Federal Reserve Economic Data (FRED) website.\n\nDiscovery v2\n\n\n\n* 2 hours\n* 2023-03-24\n\n\n\n[Use Smart Document Understanding (SDU) to improve search results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu)Use Smart Document Understanding (SDU) to improve search results\n\nIn this tutorial, you use the Smart Document Understanding feature of the Discovery service to create a user-trained Smart Document Understanding (SDU) model. You then split a single document into many smaller documents so that some types of answers are easier to find.\n\nDiscovery v2\n\n\n\n* 3 hours\n* 2023-03-16\n\n\n\n[Text analysis with Code Engine](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-text-analysis-code-engine)Text analysis with Code Engine\n\nIn this tutorial, you will learn about IBM Cloud\u00ae Code Engine by deploying a text analysis with Natural Language Understanding application. You will create a Code Engine project, select the project and deploy Code Engine entities - applications and jobs - to the project. You will learn how to bind IBM Cloud services to your Code Engine entities. You will also understand the auto-scaling capability of Code Engine where instances are scaled up or down (to zero) based on incoming workload.\n\nCode Engine Kubernetes service\n\n+2\n\nObject Storage,Natural Language Understanding\n\n\n\n* 2 hours\n* 2023-05-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-449817-451754","score":28.985308,"text":"\nFor more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n* Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant?\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n* Who do I contact if I have questions?\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n* Modeling data to scale FAQ\n\n Modeling data to scale FAQ \n\nThe way you model data on IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae significantly impacts how your application can scale. The underlying data model differs substantially from a relational model, and ignoring this distinction can be the cause of performance issues down the road.\n\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-449799-451736","score":28.985308,"text":"\nFor more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n* Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant?\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n* Who do I contact if I have questions?\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n* Modeling data to scale FAQ\n\n Modeling data to scale FAQ \n\nThe way you model data on IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae significantly impacts how your application can scale. The underlying data model differs substantially from a relational model, and ignoring this distinction can be the cause of performance issues down the road.\n\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02361-24500-26305","score":28.307482,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09755-1450-3171","score":28.000275,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Monitoring service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and monitoring.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-gettinghelp"},{"document_id":"ibmcld_16692-1490-3300","score":28.000275,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Security and Compliance Center Workload Protection service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and workload-protection.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-gettinghelp"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":58.433838,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":52.09824,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":45.38116,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":38.877594,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":29.323774,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-2946-5057","score":27.228033,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_03126-3707-6008","score":22.223465,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_04223-7-2128","score":21.851753,"text":"\nUsing page rules \n\nA page rule specifies settings and values that you can apply to a specific URL pattern that references your domain. Page rules help you manage security, performance, and reliability based on each individual URL in your site. The following table describes the page rules that are available to customers, the behaviors they produce, and any special considerations you should keep in mind before you use them.\n\n\n\n Security \n\n\n\nTable 1. Security rules\n\n Setting Behavior Considerations \n\n Browser Integrity Check Looks for common HTTP headers that are abused by spammers, and denies access to your page. It also blocks visitors that do not have a user agent, or add a non-standard user agent (also commonly used by abuse bots, crawlers, or APIs). \n Disable Security Disables the following features: Email Obfuscation, Server Side Excludes and WAF (Web Application Firewall). If a rule is set to disable security, and another rule is set to enable the WAF, the WAF rule takes precedence regardless of the order in which they appear. \n Email Obfuscation Toggles email obfuscation feature on or off. When the email obfuscation feature is turned on, email addresses on your web page are obfuscated (hidden) from bots, but visible to humans. There are no visible changes to your website for visitors. \n IP Geolocation Header Includes the country code of the visitor location with all requests to your website. The information can be found in the CF-IPCountry HTTP header. \n Security Level Controls how high a client threat score must be so that a client encounters a challenge page. Use this setting to present visitors with a Defense Mode challenge when they visit your site. \n Server Side Excludes Toggles server-side excludes on or off. Server-side excludes gives you the ability to hide sensitive content from suspicious visitors, but keep it visible to normal visitors. SSE only works with HTML. \n TLS Controls which TLS mode is used. \n WAF Toggles WAF rules on or off. Individual WAF rules cannot be turned on or off using page rules. \n Automatic HTTPS Rewrites Toggles automatic HTTPS rewrites on or off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-use-page-rules"},{"document_id":"ibmcld_04187-0-872","score":21.815212,"text":"\n\n\n\n\n\n\n  Why is my rule not working? \n\n  What\u2019s happening \n\nYou have a rule that should execute, but it isn't working.\n\n  Why it\u2019s happening \n\nThe order of execution can sometimes disrupt the rules you have in place.\n\n  How to fix it \n\nCheck to confirm that the rule you are expecting to execute is not getting dropped because another rule is executing before it.\n\nThe following list shows the execution order from our partner, Cloudflare. Evaluate where your rule lands in the order of execution and adjust the rule as needed.\n\n\n\n1.  L7 DDoS mitigation\n2.  URL rewrites\n3.  Page rules\n4.  Origin rules\n5.  Cache rules\n6.  Configuration rules\n7.  Redirect rules\n8.  IP Firewall (Access Rules)\n9.  Bots\n10. Web Application Firewall (including CIS Rule set, OWASP, and Custom rules)\n11. Header modification\n12. Cloudflare Access\n13. Edge Functions\n14. Load balancing\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-order-of-execution"},{"document_id":"ibmcld_04334-43529-45385","score":21.664017,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":80.71804,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":77.78771,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":70.04747,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":61.1131,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":45.924946,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04146-2946-5057","score":44.17567,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-1603-3385","score":41.80429,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04136-7-2226","score":39.460472,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_04175-0-1274","score":37.581955,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04187-0-872","score":37.49492,"text":"\n\n\n\n\n\n\n  Why is my rule not working? \n\n  What\u2019s happening \n\nYou have a rule that should execute, but it isn't working.\n\n  Why it\u2019s happening \n\nThe order of execution can sometimes disrupt the rules you have in place.\n\n  How to fix it \n\nCheck to confirm that the rule you are expecting to execute is not getting dropped because another rule is executing before it.\n\nThe following list shows the execution order from our partner, Cloudflare. Evaluate where your rule lands in the order of execution and adjust the rule as needed.\n\n\n\n1.  L7 DDoS mitigation\n2.  URL rewrites\n3.  Page rules\n4.  Origin rules\n5.  Cache rules\n6.  Configuration rules\n7.  Redirect rules\n8.  IP Firewall (Access Rules)\n9.  Bots\n10. Web Application Firewall (including CIS Rule set, OWASP, and Custom rules)\n11. Header modification\n12. Cloudflare Access\n13. Edge Functions\n14. Load balancing\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-order-of-execution"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":30.04379,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":27.550556,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":19.877897,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04107-6095-8145","score":19.612171,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04105-7-2225","score":18.353622,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04107-4464-6614","score":17.066196,"text":"\n* Specific URLs - For example, you can allow IP 1.2.3.4 access to directory example.com\/foo\/ and allow IP 5.6.7.8 access to directory example.com\/bar\/, but not allow the reverse.\n\n\n\nThis capability is useful when you need more granularity in your access rules because, with IP rules, you can either apply the block to all subdomains of the current domain, or all domains on your account. You cannot specify URIs.\n\n\n\n\n\n\n\n Firewall rules \n\nCreate rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nIn general, firewall rules are designed for properties that are exposed in OSI Layer-7 (HTTP), such as request headers and body content characteristics. Therefore, firewall rules apply to HTTP\/HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps.\n\n\n\n\n\n Events \n\nView events that are triggered by an active web application firewall rule. For each event, you can change the triggered action based on the requesting IP address, or the requesting region as a whole.\n\n\n\n\n\n Range \n\nExtend the power of CIS DDoS, TLS, and IP firewall to your web servers and your TCP-based services by using Range applications, keeping them online and secure.\n\n\n\n\n\n Advanced security \n\nAdvanced security settings include the following features, which you can change, enable, or disable.\n\n\n\n* Browser integrity check - The browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks or challenges visitors that do not have a user agent, or who add a nonstandard user agent. This tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04187-0-872","score":16.712374,"text":"\n\n\n\n\n\n\n  Why is my rule not working? \n\n  What\u2019s happening \n\nYou have a rule that should execute, but it isn't working.\n\n  Why it\u2019s happening \n\nThe order of execution can sometimes disrupt the rules you have in place.\n\n  How to fix it \n\nCheck to confirm that the rule you are expecting to execute is not getting dropped because another rule is executing before it.\n\nThe following list shows the execution order from our partner, Cloudflare. Evaluate where your rule lands in the order of execution and adjust the rule as needed.\n\n\n\n1.  L7 DDoS mitigation\n2.  URL rewrites\n3.  Page rules\n4.  Origin rules\n5.  Cache rules\n6.  Configuration rules\n7.  Redirect rules\n8.  IP Firewall (Access Rules)\n9.  Bots\n10. Web Application Firewall (including CIS Rule set, OWASP, and Custom rules)\n11. Header modification\n12. Cloudflare Access\n13. Edge Functions\n14. Load balancing\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-order-of-execution"},{"document_id":"ibmcld_04113-1734-4014","score":15.789788,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04334-39121-41053","score":15.558918,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_03126-3707-6008","score":14.917248,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07067-22055-24017","score":24.508324,"text":"\n: You cannot deploy models directly to Discovery v2 service instances from Knowledge Studio. Instead, you must export the machine learning models from Knowledge Studio, and then import them into Discovery. The model must have been exported from Knowledge Studio after 16 July 2020. If you have a model that was exported before that date, you must reexport the model from Knowledge Studio. Only paid Knowledge Studio plans support exporting models.\n\nFor more information, see one of the following topics:\n\n\n\n* IBM Cloud Pak\u00ae for Data: [Exporting a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-mlexporting-a-machine-learning-model)\n* IBM Cloud: [Deploying a machine learning model to Watson Discovery](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_madiscovery)\n\n\n\nFor information about how to import a model to Discovery v2, see [Importing Machine Learning models](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml).\n\n\n\n\n\n Update your application to use the v2 API \n\nThe Watson Developer SDKs support both Discovery v1 and v2.\n\nThese instructions assume that your application is using the latest version of the v1 API (version 2019-04-30).\n\nWhen you port an application that currently uses the Discovery v1 API to use v2, you must plan how to address the following high-level differences between the two versions.\n\nIn addition to these high-level changes, review the differences at a per-method level to understand what else you might need to change. For more information, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\n* v2 organizes data by project and collections; there is no concept of an environment. For example, compare the following requests to get a collection:\n\nv1 [Get collection](https:\/\/cloud.ibm.com\/apidocs\/discoverygetcollection)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_16550-0-1162","score":23.9403,"text":"\n\n\n\n\n\n\n  How do I troubleshoot an error when deploying a model? \n\nYou try to deploy a custom model, but it fails with an error if you exceed a machine learning model limit.\n\n  What\u2019s happening \n\nWhen you try to deploy your custom model, the following error appears in a dialog: \u201cowner exceeds allowable model limit\u201d\n\n  How to fix it \n\nTo resolve the error, you must reduce the number of models by either undeploying or deleting a model.\n\nIf you want to undeploy a model or find a model ID, view the Deployed Models page. See [Undeploying models](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlpm-um).\n\nIf the model does not show on the Deployed Models page, list the models in your Natural Language Understanding instance, and then delete the model with the [Natural Language Understanding API](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understandingdeletemodel).\n\n\n\n1.  Use list models method to get model id(s)\n2.  Use delete model method with model id\n\n\n\nIf you see an error message other than this one, check Cloud Status for any service outages, then go to Support Center for more options to get help.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_exceeds_limit"},{"document_id":"ibmcld_16511-10740-12806","score":23.235703,"text":"\nFrom the list of deployed models, find the model you want to view or undeploy.\n4. To undeploy the model, from the last column of that row, click Undeploy model.\n5. To find the model ID, see the Model ID column.\n\n\n\nAlternatively, you can undeploy models from the Versions pages for rule-based models and machine learning models.\n\n\n\n\n\n\n\n Deleting a version \n\nIf you wish to delete a specific version a same machine learning model, navigate to the Versions page and click the Delete link on the row of the version that you want to delete. Note: The Delete model version link is only active if there are no deployed models associated with it. Undeploy all associated models before deleting the a version.\n\n\n\n\n\n Leveraging a machine learning model in IBM Watson Explorer \n\nExport the trained machine learning model so it can be used in IBM Watson Explorer.\n\n\n\n Before you begin \n\nIf you choose to identify relation types and annotate them, then you must define at least two relation types, and annotate instances of the relationships in the ground truth before you export the model. Defining and annotating only one relation type can cause subsequent issues in IBM Watson Explorer, release 11.0.1.0.\n\n\n\n\n\n About this task \n\nNow that the machine learning model is trained to recognize entities and relationships for a specific domain, you can leverage it in IBM Watson Explorer.\n\n[Watch a brief video](https:\/\/www.youtube.com\/watch?v=1VoS-xczBow&feature=youtu.be) that illustrates how to export a model and use it in IBM Watson Explorer.\n\n\n\n\n\n Procedure \n\nTo leverage a machine learning model in IBM Watson Explorer, complete the following steps.\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n4. Download the file to your local system.\n5. From the IBM Watson Explorer application, import the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"},{"document_id":"ibmcld_16451-7-2278","score":22.588768,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16524-7-2263","score":22.588768,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16563-20012-20766","score":22.374315,"text":"\nFor example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_04175-0-1274","score":22.327394,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_16551-0-1579","score":22.03225,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_16464-20282-21209","score":21.68323,"text":"\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16437-6323-8690","score":21.654795,"text":"\nTo prevent accuracy from being tainted (for example, by making changes based only on annotations in known documents), blind data should be data that has not previously been viewed by users involved with creating the model. Reported results should come only from tests that are run on blind data. After you run a test on the blind set, look at only the most high-level scores, such as the overall mention and relation F1 scores. You don't want to learn too many details about the performance or it might influence the improvements that you choose to make to the model.\n\n\n\nThe goal of Knowledge Studio is to enable large teams to work together to build models. As such, it assumes that models are being produced by a team that includes a group of human annotators and a separate person or group of people that builds and tests the model, and makes improvements to it. Due to this assumption, the application is configured to push an equally proportioned grouping of documents from a single document set into the test, train, and blind sets. However, if your team is not segregated - if the people doing human annotation are also reviewing model test results in detail, for example - then you might need to change the allocation of documents into these sets to more explicitly separate the documents that are being used in each one.\n\n\n\n Why do I need a blind set? \n\nBecause you use test data to assess accuracy in detail, you get to know the documents and their features after a while. For example, you start to know which entity types, relation types, and text types in the documents are best understood by the machine learning model, and which are not. This information is important because it helps you focus on making the right improvements - refining the type system, supplementing the training data to fill gaps, or adding dictionaries, for example. As the test documents get used iteratively to improve the model, they can start to influence the model training indirectly. That's why the \"blind\" set of documents is so important.\n\n\n\n\n\n How do I control which documents are allocated to a set? \n\nWhen you create a machine learning model, you must specify the ratio of documents from the set to allocate to the train, test, or blind sets. Knowledge Studio automatically applies a ratio of 70\/23\/7 to the document sets that you use to build a machine learning model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":27.924765,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":27.372686,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":23.623709,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":18.03873,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04105-5067-6335","score":17.759634,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-2946-5057","score":14.909783,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_07578-321875-323689","score":14.000087,"text":"\n* A primary private range of 64 IP addresses\n\n\n\nIn addition, the following management subnets are also reserved for IBM Cloud for VMware Solutions:\n\n\n\n* Two portable private subnets of 64 IP addresses on the first VLAN - one for management and the other one for VTEPS\n* Two portable private subnets of 64 IP addresses on the second VLAN - one for VMotion and one for vSAN\n* A public portable subnet of 16 IP addresses on the public VLAN\n\nDo not use these components for other purposes, do not change their names, and do not delete them, or the stability of your environment is severely compromised.\n\n\n\nIf you need more subnets to use, you can obtain IP addresses to use in one of the following ways.\n\n\n\n* Option 1 (recommended) - Use VMware NSX\u00ae virtual network overlays. A sample VXLAN template is provided upon order. This VXLAN can be used as a starting point for building software-defined networking (SDN). For more information, see [Configuring your network to use the customer-managed NSX Edge](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_esg_config).\n* Option 2 - Order your own portable public or private subnets to obtain IP addresses. To distinguish the subnets that you order from the management subnets, you can add notes to all the subnets that you are ordering.\n\n\n\n\n\nVMware as a Service\n\n\n\n* What user accounts do I need for VMware as a Service?\n\nSee [User accounts](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-getting-startedgetting-started-user-accts).\n* What if I have issues with VMware as a Service?\n\nIf you need assistance with VMware as a Service, contact IBM Support through one of the support channels. For more information, see [Contacting IBM Support](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-support).\n\n\n\nVMware for Classic","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-321849-323663","score":14.000087,"text":"\n* A primary private range of 64 IP addresses\n\n\n\nIn addition, the following management subnets are also reserved for IBM Cloud for VMware Solutions:\n\n\n\n* Two portable private subnets of 64 IP addresses on the first VLAN - one for management and the other one for VTEPS\n* Two portable private subnets of 64 IP addresses on the second VLAN - one for VMotion and one for vSAN\n* A public portable subnet of 16 IP addresses on the public VLAN\n\nDo not use these components for other purposes, do not change their names, and do not delete them, or the stability of your environment is severely compromised.\n\n\n\nIf you need more subnets to use, you can obtain IP addresses to use in one of the following ways.\n\n\n\n* Option 1 (recommended) - Use VMware NSX\u00ae virtual network overlays. A sample VXLAN template is provided upon order. This VXLAN can be used as a starting point for building software-defined networking (SDN). For more information, see [Configuring your network to use the customer-managed NSX Edge](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_esg_config).\n* Option 2 - Order your own portable public or private subnets to obtain IP addresses. To distinguish the subnets that you order from the management subnets, you can add notes to all the subnets that you are ordering.\n\n\n\n\n\nVMware as a Service\n\n\n\n* What user accounts do I need for VMware as a Service?\n\nSee [User accounts](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-getting-startedgetting-started-user-accts).\n* What if I have issues with VMware as a Service?\n\nIf you need assistance with VMware as a Service, contact IBM Support through one of the support channels. For more information, see [Contacting IBM Support](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-support).\n\n\n\nVMware for Classic","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-922163-923777","score":13.865302,"text":"\nYou can create virtual server instances for IBM Cloud\u00ae Virtual Private Cloud in Dallas (us-south), Washington DC (us-east), London (eu-gb), Sydney (au-syd), Tokyo (jp-tok), Osaka (jp-osa), Frankfurt (eu-de), Madrid (eu-es), Toronto (ca-tor), and S\u00e3o Paulo (br-sao).\n* Can I use existing virtual server instances from my classic infrastructure with an IBM Cloud VPC?\n\nYou can migrate a virtual server instance from the classic infrastructure to a VPC. You need to create an image template, export it to IBM Cloud Object Storage, and then customize the image to meet the requirements of the VPC infrastructure. For more information, see [Migrating a virtual server from the classic infrastructure](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-migrate-vsi-to-vpc).\n* What virtual server families are supported in IBM Cloud VPC?\n\nCurrently, public virtual servers in the balanced, memory, and compute families are supported. For more information, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles).\n* What do I do if an instance is in a bad state, such as continually starting or stopping?\n\nYou can issue a command to force the instance to stop. Use the IBM Cloud CLI to obtain the instance ID, and then run the following command, ibmcloud is instance-stop --no-wait -f. When the instance is stopped, you can either restart it or delete it.\n* When I attempt to update my Ubuntu image with apt, I receive an error about the grub menu.lst file. How do I fix it?\n\nEdit the file \"\/boot\/grub\/menu.lst\" by changing groot=LABEL... into groot=(hd0). Then, run following command, sudo update-grub-legacy-ec2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-922035-923649","score":13.865302,"text":"\nYou can create virtual server instances for IBM Cloud\u00ae Virtual Private Cloud in Dallas (us-south), Washington DC (us-east), London (eu-gb), Sydney (au-syd), Tokyo (jp-tok), Osaka (jp-osa), Frankfurt (eu-de), Madrid (eu-es), Toronto (ca-tor), and S\u00e3o Paulo (br-sao).\n* Can I use existing virtual server instances from my classic infrastructure with an IBM Cloud VPC?\n\nYou can migrate a virtual server instance from the classic infrastructure to a VPC. You need to create an image template, export it to IBM Cloud Object Storage, and then customize the image to meet the requirements of the VPC infrastructure. For more information, see [Migrating a virtual server from the classic infrastructure](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-migrate-vsi-to-vpc).\n* What virtual server families are supported in IBM Cloud VPC?\n\nCurrently, public virtual servers in the balanced, memory, and compute families are supported. For more information, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles).\n* What do I do if an instance is in a bad state, such as continually starting or stopping?\n\nYou can issue a command to force the instance to stop. Use the IBM Cloud CLI to obtain the instance ID, and then run the following command, ibmcloud is instance-stop --no-wait -f. When the instance is stopped, you can either restart it or delete it.\n* When I attempt to update my Ubuntu image with apt, I receive an error about the grub menu.lst file. How do I fix it?\n\nEdit the file \"\/boot\/grub\/menu.lst\" by changing groot=LABEL... into groot=(hd0). Then, run following command, sudo update-grub-legacy-ec2.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":35.39821,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":25.82045,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":23.492928,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_15453-5897-6935","score":20.812115,"text":"\nAssign a floating IP address to the Hyper Protect Virtual Server for VPC instance and click Save.\n9. To open the PayNow website, copy and paste the floating IP address and use your browser to open the PayNow website under the URL https:\/\/<floatingip>:8443\/index.html.\n\n\n\nNow, by using Confidential Computing with IBM Cloud Hyper Protect Virtual Server for VPC, you can ensure that you have a level of data security that is unmatched in the industry.\n\n\n\n\n\n\n\n Next steps \n\nCheck out the [demo video](https:\/\/mediacenter.ibm.com\/media\/IBM+Cloud+Show+Me-+Hyper+Protect+Services+for+Confidential+Computing+Demo\/1_f7e970ig) that demonstrates the data protection that is provided by Confidential Computing by comparision between two servers:\n\n\n\n* One without Confidential Computing, where a malicious root user can dump contents of the server memory that's not protected to steal PII and credit card data.\n* One with Confidential Computing, where even the root user can\u2019t access the server memory as it's protected by the Hyper Protect platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-financial-transaction-confidential-computing-on-hyper-protect-virtual-server-for-vpc"},{"document_id":"ibmcld_04107-6095-8145","score":17.134167,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04105-5067-6335","score":16.632498,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04136-7-2226","score":15.550921,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_06063-53153-55320","score":14.144838,"text":"\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_01391-16119-17644","score":13.444861,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04186-16084-17604","score":13.444861,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-148466-149913","score":19.354994,"text":"\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-owner)\n* [How does my worker node setup look?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworker-node-setup)\n\n\n\n* [Network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork)\n\n\n\n* [Network segmentation and privacy for classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation)\n* [What network traffic is allowed for my Classic cluster by default?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitydefault-network-traffic-allowed)\n* [What is network segmentation and how can I set it up for a Classic cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork-segmentation-setup)\n* [What else can I do to reduce the surface for external attacks for Classic clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityexternal-what-else)\n* [What if I want to connect my cluster to an on-prem data center?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-151674-153233","score":19.354994,"text":"\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-owner)\n* [How does my worker node setup look?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-setup)\n\n\n\n* [Network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork)\n\n\n\n* [Network segmentation and privacy for classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation)\n* [What network traffic is allowed for my Classic cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitydefault-network-traffic-allowed)\n* [What is network segmentation and how can I set it up for a Classic cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork-segmentation-setup)\n* [What else can I do to reduce the surface for external attacks for Classic clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityexternal-what-else)\n* [What if I want to connect my cluster to an on-prem data center?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-network-traffic-default)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_08671-107301-108547","score":17.71681,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-do-with-hpcs)\n* [How do I know whether Hyper Protect Crypto Services is right for my company?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-choose-hs-crypto)\n* [How does Hyper Protect Crypto Services work?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-how-hpcs-work)\n* [What crypto card does Hyper Protect Crypto Services use?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-crypto-card)\n* [Which IBM regions are Hyper Protect Crypto Services available in?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-hpcs-regions)\n* [I have workloads in a data center where Hyper Protect Crypto Services is not available. Can I still subscribe to this service?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-data-center)\n\n\n\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_05713-152846-154383","score":17.648254,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-network-traffic-default)\n* [What is network segmentation and how can I set it up for a VPC cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork-segment-what-is)\n* [What else can I do to reduce the surface for external attacks for VPC clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityvpc-external-what-else)\n* [Securely expose apps with LoadBalancer and Ingress services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork_lb_ingress)\n* [Can I use security groups to manage my cluster's network traffic?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycan-i-use-security-groups)\n* [How can I secure the source IP within the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecure-source-ip-cluster)\n* [How can I do TLS termination with LoadBalancer and Ingress services?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitytls-termination-lb)\n\n\n\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitystorage)\n* [Monitoring and logging](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitymonitoring_logging)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-149622-151010","score":17.495363,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityonprem-network-setup)\n* [Network segmentation and privacy for VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc)\n* [What network traffic is allowed for my VPC cluster by default?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityvpc-network-traffic-default)\n* [What is network segmentation and how can I set it up for a VPC cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork-segment-what-is)\n* [What else can I do to reduce the surface for external attacks for VPC clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityvpc-external-what-else)\n* [Securely expose apps with routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityexpose-apps-with-routes)\n* [Securely expose apps with LoadBalancer and Ingress services](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_lb_ingress)\n* [Can I use security groups to manage my cluster's network traffic?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitycan-i-use-security-groups)\n* [How can I do TLS termination with LoadBalancer and Ingress services?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitytls-termination-lb)\n\n\n\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitystorage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_04168-8986-10255","score":17.334097,"text":"\n* [Troubleshooting your CIS network connection](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshoot-your-cis-network-connection)\n* [What do I do if I use the Cloudflare Origin root certificate, and it's expiring?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-update-origin-root-ca)\n* [Why is my website offline?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshooting-cis-website-offline)\n* [Why do I see a privacy warning?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshooting-cis-privacy-warning)\n* [What do I do if I\u2019m under a DDoS attack?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshooting-cis-ddos-attack)\n* [Why am I not seeing any network traffic?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshooting-cis-network-traffic)\n* [How do I troubleshoot false positives and false negatives in WAF?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-false-pos-neg)\n* [Troubleshooting CIS error codes](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshooting-cis-error-codes)\n* [Why is my rule not working?](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-order-of-execution)\n* [Troubleshooting 500 class errors](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-html-5xx-errors)\n* [Troubleshooting 1000 class errors](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-html-1xxx-errors)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_08671-108191-109525","score":17.076603,"text":"\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs-uko)\n* [Is there a free trial for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-free-trial)\n\n\n\n[FAQs: Provisioning and operations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-provisioning-operations)\n\n\n\n* [Are there any prerequisites for using Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-hpcs-prerequisites)\n* [How to initialize Hyper Protect Crypto Services service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-how-to-initialize)\n* [Can I initialize my service instance through the TKE CLI plug-in by using a proxy?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-tke-proxy)\n* [Are there any recommendations on how to set up smart cards?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_01660-11040-12906","score":16.783104,"text":"\nFrom the VPN subnets section, click the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_write.svg) to enter a new VPN password.\n4. Click Apply.\n\n\n\n\n\n\n\n What can I do if I forget my password? \n\nIf you don't remember your password for your IBMid and can't log in to IBM Cloud, you can reset your password by using our [automated system](https:\/\/www.ibm.com\/account\/reg\/us-en\/reset-password).\n\n\n\n\n\n Can I remove my personal data from IBM Cloud? \n\nTo understand how IBM handles your personal information, see the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). In the Your Rights section, review the information about what you can request to remove. Click the link in the section to submit a request to remove your personal information.\n\n\n\n\n\n Why is my account deactivated? \n\nYour account might be deactivated for the following reasons:\n\n\n\n* For trial accounts, the trial period ended. To reactivate your account, log in to your account and upgrade it to a Pay-As-You-Go account.\n* An authorized user closed the account.\n* An account has past due invoices and several contact attempts have been made by IBM Cloud Support to make payment arrangements.\n* At the discretion of IBM, accounts that violate the acceptable usage behavior of the IBM Cloud services can be disabled without notice. Some services can be restored if users correct their usage behaviors after they're notified of the offensive action. For more information, see [Acceptable Internet use policy for IBM services](https:\/\/www.ibm.com\/services\/us\/imc\/html\/aup1.html).\n\n\n\nIf you believe that your account was deactivated in error, contact support by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n What are my options for contacting IBM Cloud Support? \n\nFrom the IBM Cloud console menu bar, click the Help icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1079422-1081287","score":16.783104,"text":"\n[Edit icon](https:\/\/cloud.ibm.com\/icons\/icon_write.svg) to enter a new VPN password.\n4. Click Apply.\n\n\n\n* What can I do if I forget my password?\n\nIf you don't remember your password for your IBMid and can't log in to IBM Cloud, you can reset your password by using our [automated system](https:\/\/www.ibm.com\/account\/reg\/us-en\/reset-password).\n* Can I remove my personal data from IBM Cloud?\n\nTo understand how IBM handles your personal information, see the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). In the Your Rights section, review the information about what you can request to remove. Click the link in the section to submit a request to remove your personal information.\n* Why is my account deactivated?\n\nYour account might be deactivated for the following reasons:\n\n\n\n* For trial accounts, the trial period ended. To reactivate your account, log in to your account and upgrade it to a Pay-As-You-Go account.\n* An authorized user closed the account.\n* An account has past due invoices and several contact attempts have been made by IBM Cloud Support to make payment arrangements.\n* At the discretion of IBM, accounts that violate the acceptable usage behavior of the IBM Cloud services can be disabled without notice. Some services can be restored if users correct their usage behaviors after they're notified of the offensive action. For more information, see [Acceptable Internet use policy for IBM services](https:\/\/www.ibm.com\/services\/us\/imc\/html\/aup1.html).\n\n\n\nIf you believe that your account was deactivated in error, contact support by calling 1-866-325-0045 and selecting the third option.\n* What are my options for contacting IBM Cloud Support?\n\nFrom the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center. The options that are available to you depend on your support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1081918-1083783","score":16.783104,"text":"\n[Edit icon](https:\/\/cloud.ibm.com\/icons\/icon_write.svg) to enter a new VPN password.\n4. Click Apply.\n\n\n\n* What can I do if I forget my password?\n\nIf you don't remember your password for your IBMid and can't log in to IBM Cloud, you can reset your password by using our [automated system](https:\/\/www.ibm.com\/account\/reg\/us-en\/reset-password).\n* Can I remove my personal data from IBM Cloud?\n\nTo understand how IBM handles your personal information, see the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). In the Your Rights section, review the information about what you can request to remove. Click the link in the section to submit a request to remove your personal information.\n* Why is my account deactivated?\n\nYour account might be deactivated for the following reasons:\n\n\n\n* For trial accounts, the trial period ended. To reactivate your account, log in to your account and upgrade it to a Pay-As-You-Go account.\n* An authorized user closed the account.\n* An account has past due invoices and several contact attempts have been made by IBM Cloud Support to make payment arrangements.\n* At the discretion of IBM, accounts that violate the acceptable usage behavior of the IBM Cloud services can be disabled without notice. Some services can be restored if users correct their usage behaviors after they're notified of the offensive action. For more information, see [Acceptable Internet use policy for IBM services](https:\/\/www.ibm.com\/services\/us\/imc\/html\/aup1.html).\n\n\n\nIf you believe that your account was deactivated in error, contact support by calling 1-866-325-0045 and selecting the third option.\n* What are my options for contacting IBM Cloud Support?\n\nFrom the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center. The options that are available to you depend on your support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":31.191242,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":31.191242,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":30.016966,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":30.016966,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01494-97628-98949","score":29.46922,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01533-6329-8623","score":28.392406,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":28.392406,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":26.44534,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_01415-6473-8616","score":25.457811,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00670-2280-3822","score":24.894554,"text":"\nClick the Overflow icon ![ellipsis icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/overflow-icon-2.svg) > Configure data set.\n6. Click Add Quality Data Set.\n7. Select Predefined Quality Data Sets.\n8. Complete all required fields, and click Submit\n\n\n\nThe following are the seven pre-defined tags that are provided by DevOps Insights.\n\n\n\nTable 1. Default DevOps Insights data sets\n\n Pre-defined Data Set Tag Display label Data Type Supported Data Formats \n\n unittest Unit Tests Test Case JUnit (JSON), xUnit (xml), Mocha (JSON), KarmaMocha (JSON) \n code Code Coverage Code Coverage Cobertura (xml), lcov (info), JaCoCo (xml) \n fvt Functional Verification Tests Test Case JUnit (JSON), xUnit (xml), Mocha (JSON), KarmaMocha (JSON) \n sonarqube SonarQube SonarQube SonarQube \n dynamicsecurityscan Dynamic Security Scan Dynamic Security Scan IBM Cloud\u00ae Application Security (xml) \n staticsecurityscan Static Security Scan Static Security Scan IBM Cloud\u00ae Application Security (xml) \n vulnerabilityadvisor Vulnerability Advisor Vulnerability Advisor Vulnerability Advisor (JSON) \n\n\n\n\n\n\n\n Adding custom data sets \n\nYou can add your own custom data sets. Custom data sets support JUnit or XUnit, Mocha, Cobertura, lcov, and JaCoCo. To add custom data sets, use the following steps:\n\n\n\n1. Click the menu icon ![hamburger icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/icon_hamburger.svg), and select DevOps.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-adding-data-sets"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-365833-367834","score":47.639698,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":47.639698,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01494-97628-98949","score":45.831467,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01533-4546-6910","score":41.589443,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":41.589443,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":37.710773,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":37.587154,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":37.587154,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":35.347054,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_01488-11005-12525","score":34.69981,"text":"\nView the security.yaml file in the [GitHub repository](https:\/\/github.com\/IBM\/registry-va-workflow), and read about customizing [policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-security_enforce_portierispolicies_portieris) to understand this file's contents. In short, this policy requires all images in your namespace to have no issues reported by Vulnerability Advisor.\n3. Update the following line in the security.yaml file by replacing <my_namespace> with your namespace:\n\n- name: us.icr.io\/<my_namespace>\/\n4. Apply the custom policies:\n\nkubectl apply -f security.yaml\n5. To update hello-world.yaml so that it references your vulnerable image, change the tag from 1 to 2 as shown here:\n\nimage: us.icr.io\/<my_namespace>\/hello-world:2\n6. Try to patch the existing deployment by running the following command:\n\nkubectl apply -f hello-world.yaml\n\nYou see the following error message:\n\nDeny \"us.icr.io\/<my_namespace>\/hello-world:2\", the Vulnerability Advisor image scan assessment\nfound issues with the container image that are not exempted. Refer to your image vulnerability\nreport for more details by using the ibmcloud cr va command.\n\nThe Vulnerability Advisor verdict is subject to any [exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_managing_policy) that you create. If you want to use an image that Vulnerability Advisor considers vulnerable, you can exempt one, or more vulnerabilities so that Vulnerability Advisor doesn't consider them in its verdict.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":29.87431,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":29.87431,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_07578-370529-372403","score":29.489021,"text":"\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\nKubernetes service\n\n\n\n* What is Kubernetes?\n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-370503-372377","score":29.489021,"text":"\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\nKubernetes service\n\n\n\n* What is Kubernetes?\n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01494-97628-98949","score":29.254633,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01441-7-2257","score":28.928535,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":28.928535,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01471-5654-7396","score":28.452286,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_07578-365833-367834","score":26.980894,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":26.980894,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.5154852516}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":31.69584,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":31.69584,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01494-97628-98949","score":30.227848,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01329-58331-60199","score":29.369528,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01441-7-2257","score":29.224274,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":29.224274,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_04340-56606-58228","score":27.949713,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_07578-367408-369576","score":26.314157,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":26.314157,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16726-3149-4636","score":26.182093,"text":"\nSystems Virtual Server Service[VMware Shared V2.0 API](https:\/\/cloud.ibm.com\/apidocs\/vmware-solutions-shared-v2.0.0)VMware Shared V2.0 API Service SDK[VMware Solutions](https:\/\/cloud.ibm.com\/apidocs\/vmware-solutions)VMware Solutions Service[VMware as a Service](https:\/\/cloud.ibm.com\/apidocs\/vmware-service)VMware as a Service Service[VPC Instance Metadata](https:\/\/cloud.ibm.com\/apidocs\/vpc-metadata)VPC Instance Metadata Service[VPC Instance Metadata (Beta)](https:\/\/cloud.ibm.com\/apidocs\/vpc-metadata-beta)VPC Instance Metadata (Beta) Service Beta[Virtual Private Cloud](https:\/\/cloud.ibm.com\/apidocs\/vpc\/latest)Virtual Private Cloud Service SDK[Virtual Private Cloud (Beta)](https:\/\/cloud.ibm.com\/apidocs\/vpc-beta)Virtual Private Cloud (Beta) Service BetaContainers[IBM Cloud Code Engine](https:\/\/cloud.ibm.com\/apidocs\/codeengine\/v2)IBM Cloud Code Engine Service SDK[IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry)IBM Cloud Container Registry SDK[Vulnerability Advisor 3 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va)Vulnerability Advisor 3 for IBM Cloud Container Registry SDK[Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4)Vulnerability Advisor 4 for IBM Cloud Container Registry SDKDatabases[Cloud Databases v4 API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api\/cloud-databases-api-v4)Cloud Databases v4 API Service[Cloud Databases v5 API","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=api-docs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":43.23963,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":43.23963,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01494-97628-98949","score":36.087246,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01329-58331-60199","score":35.650566,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01441-7-2257","score":34.905197,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":34.905197,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_04340-56606-58228","score":34.677944,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_07578-367408-369576","score":32.51603,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":32.51603,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-12177-14097","score":31.872015,"text":"\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.\n* [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list).\n* [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests).\n\n\n\nTo retrieve results from version 4 instead of version 3, run the following [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nibmcloud cr va-version-set v4\n\nAlternatively, you can set an environment variable, va_version, and specify the Vulnerability Advisor version that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Reviewing a vulnerability report \n\nBefore you deploy an image, you can review its Vulnerability Advisor report for details about any vulnerable packages and nonsecure container or app settings.\n\nYou can also check whether the image is compliant with organizational policies.\n\nIf you don't address any discovered issues, those issues can impact the security of containers that are using that image. If you use enforcement in your container runtime environment, you might be prevented from deploying that image unless all issues are exempted by your policy.\n\nIf your image does not meet the requirements that are set by your organization's policy, you must configure the image to meet those requirements before you can deploy it. For more information about how to view and change the organization policy, see [Setting organizational exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_managing_policy).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01494-97628-98949","score":35.459793,"text":"\n* [Do I have any untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_1)\n* [Do I need untagged images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_untagged_image_2)\n* [What are eligible images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_eligible_image)\n* [What regions are available?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_regions)\n\n\n\n* [Frequently asked questions about Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_va)\n\n\n\n* [How much does Vulnerability Advisor cost?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_cost)\n* [Can images from other registries be scanned?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_reg)\n* [How is a Vulnerability Advisor scan triggered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_trigger_scan)\n* [Why doesn't a new image scan?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_new_scan_error)\n* [How often are the security notices updated?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_va_update_security_notice)\n* [Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01533-4546-6910","score":35.232513,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":35.232513,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":33.24689,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":33.24689,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10510-58427-60403","score":32.95671,"text":"\nPush images with trusted content only Ensure the integrity of your images by enabling [content trust](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) in your image repository. With trusted content, you can control who can sign images as trusted and push images to a specific registry namespace. After trusted signers push an image to a registry namespace, users can pull the signed content so that they can verify the publisher and the integrity of the image. \n Automatic vulnerability scans When you use IBM Cloud Container Registry, you can leverage the built-in security scanning that is provided by [Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_registry_cli). Every image that is pushed to your registry namespace is automatically scanned for vulnerabilities against a database of known CentOS, Debian, Red Hat, and Ubuntu issues. If vulnerabilities are found, Vulnerability Advisor provides instructions for how to resolve them to ensure image integrity and security. \n Block deployments from vulnerable images or untrusted users Create an admission controller with custom policies so that you can verify container images before you deploy them. With the [open source Portieris project](https:\/\/github.com\/IBM\/portieris), you control where the images are deployed from and ensure that they meet content trust requirements. If a deployment does not meet the policies that you set, the admission controller blocks the deployment in your cluster. \n\n\n\nWhat options do I have to scan running containers for vulnerabilities?\n: You can install third-party solutions in your cluster, such as [Twistlock](https:\/\/www.paloaltonetworks.com\/prisma\/cloud) or [StackRox](https:\/\/www.redhat.com\/en\/technologies\/cloud-computing\/openshift\/advanced-cluster-security-kubernetes) to scan running containers and block malicious activities when they are detected.\n\n\n\n\n\n Container isolation and security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_01415-6473-8616","score":32.000057,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01488-11005-12525","score":31.082043,"text":"\nView the security.yaml file in the [GitHub repository](https:\/\/github.com\/IBM\/registry-va-workflow), and read about customizing [policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-security_enforce_portierispolicies_portieris) to understand this file's contents. In short, this policy requires all images in your namespace to have no issues reported by Vulnerability Advisor.\n3. Update the following line in the security.yaml file by replacing <my_namespace> with your namespace:\n\n- name: us.icr.io\/<my_namespace>\/\n4. Apply the custom policies:\n\nkubectl apply -f security.yaml\n5. To update hello-world.yaml so that it references your vulnerable image, change the tag from 1 to 2 as shown here:\n\nimage: us.icr.io\/<my_namespace>\/hello-world:2\n6. Try to patch the existing deployment by running the following command:\n\nkubectl apply -f hello-world.yaml\n\nYou see the following error message:\n\nDeny \"us.icr.io\/<my_namespace>\/hello-world:2\", the Vulnerability Advisor image scan assessment\nfound issues with the container image that are not exempted. Refer to your image vulnerability\nreport for more details by using the ibmcloud cr va command.\n\nThe Vulnerability Advisor verdict is subject to any [exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_managing_policy) that you create. If you want to use an image that Vulnerability Advisor considers vulnerable, you can exempt one, or more vulnerabilities so that Vulnerability Advisor doesn't consider them in its verdict.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"},{"document_id":"ibmcld_07971-2155-4528","score":30.75968,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-6329-8623","score":30.493969,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-71418-73421","score":21.469767,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_09730-2163-3807","score":21.32693,"text":"\nContainer services \n\nIBM Cloud Container Registry\n: You can configure one monitoring instance in each region to collect platform metrics for IBM Cloud\u00ae Container Registry. For information about the locations where the automatic collection of Container Registry service metrics is enabled, see [Monitoring metrics for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_monitorregistry_monitor_locations).\n\nIBM Cloud Kubernetes Service\n: You can choose the monitoring instance where you want to collect IBM Cloud\u00ae Kubernetes Service service metrics.\n\nRed Hat OpenShift on IBM Cloud\n: You can choose the monitoring instance where you want to collect Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae service metrics.\n\n\n\n\n\n Satellite \n\nIBM Cloud Satellite\n: You can monitor IBM Cloud Satellite\u00ae through the monitoring instance that is configured with service platform metrics in the same region that your Satellite location is managed from.\n\n\n\n\n\n Developer tools \n\nEurope\n\nAmerica\n\nAsia Pacific\n\n\n\nDeveloper tools and DevOps services in Europe locations\n\n Service Frankfurt (eu-de) London (eu-gb) \n\n IBM Cloud\u00ae Continuous Delivery ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/checkmark-icon.svg) \n IBM Cloud\u00ae App Configuration ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/checkmark-icon.svg) \n IBM Cloud\u00ae Event Notifications !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services_locations"},{"document_id":"ibmcld_01476-7-2157","score":21.038784,"text":"\nSetting up Container Registry as a private registry on Red Hat OpenShift \n\nYou can add value to your Red Hat\u00ae OpenShift\u00ae Container Platform clusters by using IBM Cloud\u00ae Container Registry even where an internal registry is already provided.\n\nFor example, if you have multiple clusters, Container Registry integrates conveniently with Red Hat OpenShift Container Platform clusters so that you can build, share, synchronize, and scan image assets across clusters. For more information, see [Choosing an image registry solution](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_registry_options).\n\nYou can set up Container Registry to work with the internal registry of [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhosregistry_rhos_rhoks) or [other Red Hat OpenShift Container Platform providers](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhosregistry_rhos_os).\n\n\n\n Set up Red Hat OpenShift on IBM Cloud to use Container Registry \n\nBy default, your Red Hat OpenShift on IBM Cloud clusters are set up with an internal registry that stores images locally in your cluster. The clusters are also set up with image pull secrets in the default project to pull images that you store in your private Container Registry repositories.\n\nYou can use either registry separately or in combination. When you set up the Red Hat OpenShift on IBM Cloud internal registry to import images from Container Registry, you get the advantage of a private registry that is common to multiple clusters. Another benefit is that copies of the pulled images from Container Registry are stored locally on the cluster, therefore reducing latency and external traffic, but you are subject to storage limitations.\n\nTo set up your Red Hat OpenShift on IBM Cloud clusters to use the internal registry in combination with Container Registry, see the following topics in the Red Hat OpenShift on IBM Cloud documentation:\n\n\n\n* [Importing images from IBM Cloud Container Registry into the internal registry image stream](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryimagestream_registry).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_rhos"},{"document_id":"ibmcld_09309-1182-2866","score":20.552011,"text":"\n[Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) \n Code Engine ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Container services \n\nIBM Cloud Container Registry\n: IBM Cloud Container Registry generates platform services logs that are displayed in your logging instances. For informataion about the locations where the automatic collection of Container Registry service logs is enabled, see [Analyzing logs for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_logsregistry_logs_locations).\n\nIBM Cloud Kubernetes Service\n: You can choose the logging instance where you want to collect IBM Cloud Kubernetes Service service logs.\n\nIBM Cloud Satellite\n: You can monitor IBM Cloud Satellite\u00ae service logs through the logging instance that is configured with service platform logs in the same region that your Satellite location is managed from.\n\nRed Hat OpenShift on IBM Cloud\n: You can choose the logging instance where you want to collect Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae service logs.\n\n\n\n\n\n Database services \n\nThe following tables list the locations where automatic collection of database service logs is enabled. You can monitor logs through the Log Analysis instance that is available in the same location as your database resources, if you enable 1 instance in this location to host service platform logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-cloud_services_locations"},{"document_id":"ibmcld_01434-7-1897","score":20.523672,"text":"\nMonitoring metrics for Container Registry \n\nYou can use IBM Cloud\u00ae Monitoring to monitor platform metrics of IBM Cloud\u00ae Container Registry usage for your account and to create alerts based on these metrics.\n\nPlatform metrics for Container Registry must be enabled in each Container Registry region that you want to monitor, see [Enabling metrics for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_monitorregistry_enable_platform_metrics).\n\n\n\n Enabling metrics for Container Registry \n\nYou must enable Container Registry metrics in each region that you want to see metrics.\n\nYou can create a Monitoring instance in the region that you want to monitor and enable platform metrics for it. Alternatively, you can enable platform metrics on an existing Monitoring instance in that region.\n\nComplete the following steps to create and configure platform metrics for Container Registry.\n\n\n\n1. Create and configure an IBM Cloud Monitoring instance that is configured with platform metrics in the region that you want to monitor, see [Getting started with IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started).\n\nFor more information about the locations where Container Registry is enabled for monitoring, see [Locations of platform metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_monitorregistry_monitor_locations).\n2. Log in to IBM Cloud.\n\nibmcloud login\n3. Target the [region](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions) where you want to enable metrics by running the [ibmcloud cr region-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_region_set) command. Replace <region> with the name of the [region](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions_local).\n\nibmcloud cr region-set <region>\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_monitor"},{"document_id":"ibmcld_10480-7-2184","score":20.226007,"text":"\nSetting up an image registry \n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters include an internal registry to build, deploy, and manage container images locally. For a private registry to manage and control access to images across your enterprise, you can also set up your cluster to use IBM Cloud\u00ae Container Registry.\n\n\n\n Choosing an image registry solution \n\nYour container images must be stored in a container registry that your cluster can access to deploy apps into your cluster. You can choose to use the built-in registry of your Red Hat OpenShift cluster, a private registry with access restricted to select users, or a public registry. Review the following table to choose the best option for your use case.\n\nInternal Red Hat OpenShift Container Registry (OCR)\n: Your cluster is set up with the internal Red Hat OpenShift Container Registry so that Red Hat OpenShift can automatically build, deploy, and manage your application lifecycle from within the cluster. Images are stored in a backing IBM Cloud classic file storage device that is provisioned at cluster creation time. If you need more storage, you can resize the device. Use cases:\n\n\n\n* Red Hat OpenShift-native image stream, build, and app deployment process on a per cluster basis.\n* Images can be shared across all projects in the cluster, with access that is controlled through RBAC roles.\n* Integrating the internal registry with other Red Hat products like CloudForms for extended features such as vulnerability scanning.\n* Option to expose the internal registry with a route so that users can pull images from the registry over the public network.\n* Option to set up the internal registry to [pull images](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryimagestream_registry) from or [push images](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrybuilds_registry) to a private registry such as IBM Cloud Container Registry.\n\n\n\n: For more information, see [Using the internal registry](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry).\n\nPrivate registry\n: Private registries are a good choice to protect your images from unauthorized users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registry"},{"document_id":"ibmcld_01393-7-1816","score":20.203022,"text":"\nAccessing Container Registry \n\nTo access your IBM Cloud\u00ae Container Registry namespaces so that you can push and pull images, use IBM Cloud\u00ae Identity and Access Management (IAM).\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nAccess to IBM Cloud Container Registry is either [automated](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_automating), which typically uses [API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manapikey), or [interactive](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_interactive), which typically uses bearer tokens.\n\nIf you have an IAM access policy, but you are getting Access denied errors, see [Why am I getting Access denied errors?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-access-denied) for assistance.\n\nIf you want to use your container images in Kubernetes deployments, see [Using an image pull secret to access images in other IBM Cloud accounts or external private registries from nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-registryother).\n\n\n\n Accessing your namespaces in automation \n\nYou can use service ID API keys to automate the pushing and pulling of container images to and from your namespaces.\n\nAPI keysare linked to user IDs or service IDs in your account and you can use them across IBM Cloud\u00ae. You can use an API key in the CLI or as part of automation to authenticate as your user or service identity. A [user API key](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_user_apikey_create) is associated with a user and their access policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_access"},{"document_id":"ibmcld_09297-1333-2870","score":20.17123,"text":"\n[IBM Cloud\u00ae Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) Cloud Functions is a polyglot Functions-as-a-Service (FaaS) programming platform based on Apache OpenWhisk that you can use to write lightweight code called actions. [More info](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-logs) \n [IBM Cloud\u00ae Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) Code Engine is a fully managed, serverless platform that runs your containerized workloads, including web apps, micro-services, event-driven functions, or batch jobs [More info](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-view-logs). \n\n\n\n\n\n\n\n Container services \n\nThe following table lists services that send logs to IBM Log Analysis:\n\n\n\nTable 3. List of container services\n\n Service Description More info \n\n [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-started) You can use IBM Cloud Container Registry to provide a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account. [More info](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_logs) \n [IBM Cloud\u00ae Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [More info](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-healthlogdna)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-cloud_services"},{"document_id":"ibmcld_01388-7-1807","score":20.165682,"text":"\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https:\/\/cloud.ibm.com\/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_05348-7-1939","score":20.062685,"text":"\nDeploying app workloads from images in IBM Cloud Container Registry \n\nDeploy your app with Code Engine that uses an image in IBM Cloud\u00ae Container Registry. You can create an app from the console or with the CLI.\n\nBefore you begin\n\n\n\n* You must have an image in IBM Cloud\u00ae Container Registry. For more information, see [Getting started with Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Or, you can build an image from [repository source](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-source-code) or from [local source](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-local-source-code).\n* Verify that you can access the registry. See [Setting up authorities for container registries](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorities-registry).\n\n\n\nInterested in configuring your project such that all users of the project can store and access images in Container Registry without having to manually create registry secrets? With sufficient permissions, you can configure this default registry access on a per location (region) basis. If you don't have sufficient permissions to perform these actions, you can use this page to help you understand the required permissions. See [Configuring project-wide settings](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-project-integrations).\n\n\n\n Deploying an app that references an image in Container Registry with the console \n\nDeploy an application that uses an image in Container Registry by using the Code Engine console.\n\nCode Engine can automatically pull images from a Container Registry namespace in your account. To pull images from a different Container Registry account or from a private Docker Hub account, see [Deploying application workloads from images in a private registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-app-private).\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-app-crimage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-362072-363770","score":24.899765,"text":"\nibmcloud cr image-digests\n* Run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command:\n\nibmcloud cr image-list --no-trunc\n\nIf you run the ibmcloud cr image-list command without the --no-trunc option, you see the truncated format of the digest.\n\n\n\n* How do I use digests to work with images?\n\n How do I use digests to work with images? \n\nThe [digest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_digest) identifies an image by using the sha256 hash of the [image manifest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_manifest).\n\nTo find the digests for your images, run the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. You can refer to an image by using a combination of the content of the Repository column (repository) and the Digest column (digest) separated by an at (@) symbol to create the image name in the format repository@digest.\n* How do you use access control?\n\n How do you use access control? \n\nYou can create IBM Cloud Identity and Access Management (IAM) policies to control access to your namespaces in IBM Cloud Container Registry. For more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-362046-363744","score":24.899765,"text":"\nibmcloud cr image-digests\n* Run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command:\n\nibmcloud cr image-list --no-trunc\n\nIf you run the ibmcloud cr image-list command without the --no-trunc option, you see the truncated format of the digest.\n\n\n\n* How do I use digests to work with images?\n\n How do I use digests to work with images? \n\nThe [digest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_digest) identifies an image by using the sha256 hash of the [image manifest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_manifest).\n\nTo find the digests for your images, run the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. You can refer to an image by using a combination of the content of the Repository column (repository) and the Digest column (digest) separated by an at (@) symbol to create the image name in the format repository@digest.\n* How do you use access control?\n\n How do you use access control? \n\nYou can create IBM Cloud Identity and Access Management (IAM) policies to control access to your namespaces in IBM Cloud Container Registry. For more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-363349-365063","score":23.827135,"text":"\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-363323-365037","score":23.827135,"text":"\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05256-7949-9726","score":23.26285,"text":"\nNote that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n\nYes! [Here is how](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n\nYes, you can edit the existing [IAM policy of the service ID](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace. Before you can customize registry IAM policies, you must [enable IBM Cloud IAM policies for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user).\n\nCan I use a service ID?\n: Yes, you can create a service ID and assign authorities to it. Note that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n: Yes! [Here is how](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n: Yes, you can edit the existing [IAM policy of the service ID](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_01494-95446-96938","score":23.207294,"text":"\n(https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-manifest-error-versiontroubleshoot-manifest-error-version)\n\n[Why do I get a manifest list invalid error?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-manifest-list-errortroubleshoot-manifest-list-error)\n\n\n\n\n\n Troubleshooting networking \n\n[Why can't I access the registry through a custom firewall?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-firewalltroubleshoot-firewall)\n\n[Why can't I connect to Container Registry?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-connecttroubleshoot-connect)\n\n\n\n\n\n Troubleshooting Portieris \n\n[Why don't my pods restart after my workers were down?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-podstroubleshoot-pods)\n\n\n\n\n\n\n\n Frequently asked questions (FAQs) \n\n[Frequently asked questions (FAQs)](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq)\n\n\n\n* [Frequently asked questions about Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqregistry_faq_registry)\n\n\n\n* [How do you list public images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_list_public_images)\n* [What tools can I use to build and push images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_tools)\n* [How many namespaces can you have?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faqfaq_namespace)\n* [Can I rename a namespace?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01415-2488-4243","score":23.045753,"text":"\n* Run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command:\n\nibmcloud cr image-list --no-trunc\n\nIf you run the ibmcloud cr image-list command without the --no-trunc option, you see the truncated format of the digest.\n\n\n\n\n\n\n\n How do I use digests to work with images? \n\nThe [digest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_digest) identifies an image by using the sha256 hash of the [image manifest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_manifest).\n\nTo find the digests for your images, run the [ibmcloud cr image-digests](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_digests) command. You can refer to an image by using a combination of the content of the Repository column (repository) and the Digest column (digest) separated by an at (@) symbol to create the image name in the format repository@digest.\n\n\n\n\n\n How do you use access control? \n\nYou can create IBM Cloud Identity and Access Management (IAM) policies to control access to your namespaces in IBM Cloud Container Registry. For more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam).\n\n\n\n\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any\n\nnamespacethat is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_07578-536143-538148","score":22.956085,"text":"\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries. To add the ClusterImagePolicy type to your Kubernetes cluster, you must install several [Helm charts](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_helm_charts).\n* How do I self-host container images for Delivery Pipeline Private Worker?\n\nSecurity constraints might prevent you from pulling images from the icr.io\/continuous-delivery\/pipeline container registry. In such scenarios, complete the following steps:\n\n\n\n1. Provision the container images on a supported container registry.\n2. Install the deployment.yaml file to reference the container images in this container registry.\n3. For each container image that is referenced in the regular deployment yaml file, complete the following steps:\n\n\n\n* Docker pull the image to a local Dockerfile.\n* Docker tag the image with the new reference on the supported container registry.\n* Docker push this new image.\n\n\n\nYou can obtain the deployment yaml file from https:\/\/private-worker-service.$region.devops.cloud.ibm.com\/install.\n4. Replace the reference to each image in the installation file with the tag for the new image.\n5. Run the following command to install the private worker by using the specific container registry: kubectl apply \u2013filename updated_deployment.yaml.\n6. Continue the [installation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui).\n\n\n\n* How do I provision and update the private worker installation file for IBM Cloud\u00ae Private?\n\nIf your pipeline worker is installed on IBM Cloud Private, you can use the following script to provision and update the private worker installation file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-536097-538102","score":22.956085,"text":"\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries. To add the ClusterImagePolicy type to your Kubernetes cluster, you must install several [Helm charts](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_helm_charts).\n* How do I self-host container images for Delivery Pipeline Private Worker?\n\nSecurity constraints might prevent you from pulling images from the icr.io\/continuous-delivery\/pipeline container registry. In such scenarios, complete the following steps:\n\n\n\n1. Provision the container images on a supported container registry.\n2. Install the deployment.yaml file to reference the container images in this container registry.\n3. For each container image that is referenced in the regular deployment yaml file, complete the following steps:\n\n\n\n* Docker pull the image to a local Dockerfile.\n* Docker tag the image with the new reference on the supported container registry.\n* Docker push this new image.\n\n\n\nYou can obtain the deployment yaml file from https:\/\/private-worker-service.$region.devops.cloud.ibm.com\/install.\n4. Replace the reference to each image in the installation file with the tag for the new image.\n5. Run the following command to install the private worker by using the specific container registry: kubectl apply \u2013filename updated_deployment.yaml.\n6. Continue the [installation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui).\n\n\n\n* How do I provision and update the private worker installation file for IBM Cloud\u00ae Private?\n\nIf your pipeline worker is installed on IBM Cloud Private, you can use the following script to provision and update the private worker installation file.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01529-7-1595","score":22.792086,"text":"\nTroubleshooting Container Registry \n\nAnswers to common troubleshooting questions about how to use IBM Cloud\u00ae Container Registry.\n\n\n\n Troubleshooting topics \n\nThe following troubleshooting topics are available to help you:\n\n\n\n Troubleshooting CLI login \n\nTroubleshoot logging in problems.\n\n\n\n* [Why can't I log in to Container Registry?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-login)\n* [Why does the Container Registry login keep expiring?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-login-expire)\n* [Why do commands fail saying that I'm not logged in?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-login-cloud)\n* [Why do cr commands fail saying they\u2019re not registered?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-login-error)\n* [Why is Docker login on my Mac failing?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-docker-mac)\n\n\n\n\n\n\n\n Troubleshooting pull and push errors \n\nTroubleshoot pull and push problems.\n\n\n\n* [Why can't I push or pull a Docker image?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-push-pull-docker)\n* [Why is pulling images so slow?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-pull-performance)\n* [Why am I getting Authorization required errors?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-auth-req)\n\n\n\n* [Why am I getting an Unauthorized error when I'm using Code Engine?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-unauthorized-ce)\n\n\n\n* [Why am I getting Access denied errors?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ts_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10773-1311-3056","score":18.854149,"text":"\nFor more information about Platform and Service level access roles, see [Platform management roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_platform_roles) and [Service-specific roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice_specific_roles).\n\nWant to learn more about IAM key concepts? Check out [the IAM overview](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverview) or the [Best practices for assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setup).\n\n\n\n\n\n How do I set IAM policies so that others can create namespaces in my account? \n\nTo allow other users to manage Cloud Functions namespaces, including creating new namespaces, you must set the following access policies for those users.\n\n\n\n* The user's Platform role must be set to Administrator. This policy applies to all resources of Cloud Functions.\n* The user's Service role must be set to Manager. This policy applies to all resources of Cloud Functions.\n\n\n\n\n\n\n\n How do I know which access policies have set for me? \n\nYou can see which access policies have been set for you in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog) console.\n\n\n\n1. From the console, click Manage > Access (IAM) > Users. Or, navigate to https:\/\/cloud.ibm.com\/iam\/users.\n2. Click your name in the user table.\n3. Click the Access policies tab to see your access policies.\n\n\n\n\n\n\n\n Platform management roles \n\nThe following table details the actions that are mapped to platform management roles. Platform management roles enable users to perform tasks on service resources at the platform level. For example, assign user access for the service, create or delete service IDs, create instances, and bind instances to applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iam"},{"document_id":"ibmcld_10852-36156-37516","score":16.985727,"text":"\n* [How do I set IAM policies so that others can work with my namespace?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_policies)\n* [How do I set IAM policies so that others can create namespaces in my account?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_namespace_create)\n* [How do I know which access policies have set for me?](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_set_policies_me)\n* [Platform management roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamiam_platform_roles)\n* [Service-specific roles](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice_specific_roles)\n* [Setting access policies for a service ID](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-policy)\n\n\n\n* [Setting access policies for a service ID in the console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamservice-id-set-ui)\n* [Setting an access policy for your Cloud Functions service ID through the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iamcli-set)\n\n\n\n\n\n\n\n\n\n Integrating serverless apps \n\n[Binding IBM Cloud services to Cloud Functions entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices)\n\n\n\n* [Binding a service to an action or package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-servicesservices_bind)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_00620-3894-5347","score":16.672956,"text":"\nIf you supply include_docs=true, then another doc attribute is added to each \"row\" in the result set that includes the document body.<-- <\/section \"id=\"section-what-is-the_all_docs_endpoint\" \"> --><-- <section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --> The limit, startkey, and endkey parameters To access data from _all_docs in reasonably sized pages, you must supply the limit parameter to tell IBM Cloudant how many documents to return: get me 5 documents\nGET $SERVICE_URL\/$DATABASE\/_all_docs?limit=5 HTTP\/1.1\nYou can also limit the range of document _ids that you want by supplying one or more values to startkey or endkey.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> get me 5 documents from _id order00057 onwards\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&startkey=\"order00057\"\"\n get me 5 documents between _id order00057 --> order00077\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&startkey=\"order00057\"&endkey=\"order00077\"\"\n get me 5 documents up to _id order00077\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&endkey=\"order00077\"\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\n\/\/ get me 5 documents from _id order00057 onwards","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_12789-7-2028","score":16.059956,"text":"\nFAQs about selling services \n\nFAQs about selling products on IBM Cloud\u00ae might include questions about how and when to receive disbursements, how to view and test a service as a customer, and available metering models. Additional information about selling products on IBM Cloud can be found in the Digital Platform Reseller Agreement in IBM Cloud Partner Center that must be accepted to offer paid products.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What are the different metering options for plans? \n\nIBM Cloud\u00ae supports multiple models for aggregating service usage. Service providers measure various metrics on the created instances and submit those measures to the metering service. The rating service aggregates the submitted usage into different buckets (instance, resource group, and account) based on the model that service providers choose. The aggregation and rating models for all the metrics in a plan are contained in the metering and rating definition documents for the plan.\n\nYou're required to automate hourly usage submission by using the metering service API if you offer a metered plan.\n\nFor more information on metering, see [Metering integration](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-meteringinterameteringintera). For more information about submitting metered usage, see [Submitting usage for metered plans](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-submitusagesubmitusage).\n\n\n\n\n\n How do I receive payments for my services? \n\nThird-party services that offer paid usage-based pricing plans receive disbursements through an Electronic Funds Transfer (EFT). To set up this method to receive disbursements in IBM Cloud Partner Center Sell, you must submit the EFT form when you set up your first usage-based pricing plan. You can download the form from the Payments to me page.\n\n\n\n\n\n When are disbursements sent to me? \n\nIf any disbursements are due to a third-party provider, they are sent on the last business day of the second calendar month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-3p-faqs"},{"document_id":"ibmcld_06128-22186-24066","score":15.977194,"text":"\nTo get the most out of your worker node's performance, consider the following: - Keep up your core strength: Each machine has a certain number of cores. Depending on your app's workload, set a limit for the number of pods per core, such as 10. - Avoid node overload: Similarly, just because a node can contain more than 100 pods doesn't mean that you want it to. Depending on your app's workload, set a limit for the number of pods per node, such as 40. - Don't tap out your cluster bandwidth**: Keep in mind that network bandwidth on scaling virtual machines is around 1000 Mbps. If you need hundreds of worker nodes in a cluster, split it up into multiple clusters with fewer nodes, or order bare metal nodes. - Sorting out your services: Plan out how many services that you need for your workload before you deploy. Networking and port forwarding rules are put into Iptables. If you anticipate a larger number of services, such as more than 5,000 services, split up the cluster into multiple clusters.\n\n\n\n\n\n Provision different types of machines for a mix of computing resources \n\nEveryone likes choices, right? With IBM Cloud Kubernetes Service, you have [a mix of flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources. For example, you might want to limit a database application to a bare metal machine with a significant amount of local disk storage like the md1c.28x512.4x4tb.\n\n\n\n\n\n Set up multiple namespaces when you have multiple teams and projects that share the cluster \n\nNamespaces are kind of like a cluster within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_10568-22837-24687","score":15.701672,"text":"\nWith Red Hat OpenShift on IBM Cloud, you have [a mix of flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources. For example, you might want to limit a database application to a bare metal machine with a significant amount of local disk storage like the md1c.28x512.4x4tb.\n\n\n\n\n\n Set up multiple namespaces when you have multiple teams and projects that share the cluster \n\nNamespaces are kind of like a cluster within the cluster. They are a way to divide up cluster resources by using [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) and [default limits](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/manage-resources\/memory-default-namespace\/). When you make new namespaces, be sure to set up proper [RBAC policies](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersrbac) to control access. For more information, see [Share a cluster with namespaces](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/namespaces\/) in the Kubernetes documentation.\n\nIf you have a small cluster, a couple dozen users, and resources that are similar (such as different versions of the same software), you probably don't need multiple namespaces. You can use labels instead.\n\n\n\n\n\n Set resource quotas so that users in your cluster must use resource requests and limits \n\nTo ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategy"},{"document_id":"ibmcld_10637-7-2078","score":15.58165,"text":"\nWhy do I get an error about a cloud object storage bucket when I create a cluster? \n\nInfrastructure provider: VPC\n\n What\u2019s happening \n\nWhen you create a cluster, you see an error message similar to the following.\n\nCould not store the cloud object storage bucket and IAM service key.\n\nCould not find the specified cloud object storage instance.\n\nCould not create an IAM service key to access the cloud object storage bucket '{{.Name}}'.\n\nCould not create a bucket in your cloud object storage instance.\n\nVerify your user permissions and the API key permissions to Cloud Object Storage, or use a different instance that you have permissions to, and try again. For more information, see 'http:\/\/ibm.biz\/roks_cos_ts'.\n\n Why it\u2019s happening \n\nWhen you create a Red Hat OpenShift on IBM Cloud version 4 cluster on VPC generation 2 compute infrastructure, a bucket is automatically created in a standard IBM Cloud Object Storage instance that you select in your account.\n\nHowever, the bucket might not create for several reasons such as:\n\n\n\n* IBM Cloud Object Storage is temporarily unavailable.\n* No standard IBM Cloud Object Storage instance exists in your account, or the person whose API key is set for the region and resource group does not have permissions to view the instance.\n* The person who created your cluster did not have the Administrator platform access role to IBM Cloud Object Storage in IAM.\n* The service failed to set up service key access to the object storage instance, such as if the API key lacks permissions or IBM Cloud IAM is unavailable.\n* Other conflicts, such as naming conflicts that exhaust the preset number of retries or saving the bucket and service key data in the backend service.\n\n\n\n How to fix it \n\nManually set up your cluster to back up the internal registry to an IBM Cloud Object Storage bucket.\n\n\n\n1. Make sure that the API key for the region and resource group is set and that you have the [required permissions to create a cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts_cos_bucket_cluster_create"},{"document_id":"ibmcld_06153-1585-3257","score":15.329312,"text":"\n* Review the [1.25 version information and update actions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_125).\n* Review the [Migrating from PSPs to Pod Security Admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission-migration) guide.\n\n\n\nIf you are not ready to migrate to Pod Security Admission, you can clear the status message by performing a cluster master refresh.\n\n How to fix it \n\nIf you already performed the Pod Security Admission upgrade prerequisite actions, the error message indicates an action that you might have missed or an unexpected change to IBM Cloud Kubernetes Service defined resources that you need to address. Complete the following steps based on the message you are seeing.\n\n\n\n Could not get PodSecurityPolicies \n\n\n\n1. Run the following to command to get your PSPs.\n\nkubectl get podsecuritypolicies\n2. If there is no error, try again to upgrade the cluster master.\n\n\n\n\n\n\n\n Found non-IBM PodSecurityPolicy \n\nThere are additional PSPs that need to be removed.\n\nBefore you upgrade your cluster to version 1.25, verify that only the following PSPs exist.\n\n\n\n* ibm-privileged-psp\n* ibm-anyuid-psp\n* ibm-anyuid-hostpath-psp\n* ibm-anyuid-hostaccess-psp\n* ibm-restricted-psp\n\n\n\n\n\n1. List your PSPs.\n\nkubectl get podsecuritypolicies\n2. If the additional PodSecurityPolicy is no longer in use, delete it. If there are additional pod security policies, [review the migration guide](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission-migration).\n\nkubectl delete podsecuritypolicies PSP\n3. Retry the cluster upgrade.\n\n\n\n\n\n\n\n Could not get ClusterRoleBinding privileged-psp-user","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-app-pod-security"},{"document_id":"ibmcld_06128-23630-25505","score":15.294535,"text":"\nWhen you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources. For example, you might want to limit a database application to a bare metal machine with a significant amount of local disk storage like the md1c.28x512.4x4tb.\n\n\n\n\n\n Set up multiple namespaces when you have multiple teams and projects that share the cluster \n\nNamespaces are kind of like a cluster within the cluster. They are a way to divide up cluster resources by using [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) and [default limits](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/manage-resources\/memory-default-namespace\/). When you make new namespaces, be sure to set up proper [RBAC policies](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersrbac) to control access. For more information, see [Share a cluster with namespaces](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/namespaces\/) in the Kubernetes documentation.\n\nIf you have a small cluster, a couple dozen users, and resources that are similar (such as different versions of the same software), you probably don't need multiple namespaces. You can use labels instead.\n\n\n\n\n\n Set resource quotas so that users in your cluster must use resource requests and limits \n\nTo ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace. Resource quotas determine the deployment constraints for a namespace, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources. After you set a quota, users must include resource requests and limits in their deployments.\n\n\n\n\n\n Organize your Kubernetes objects with labels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_01518-0-1200","score":15.264729,"text":"\n\n\n\n\n\n\n  Why don't all my namespaces show in the Resource list? \n\nMy IBM Cloud\u00ae Container Registry namespaces don't all show up in the IBM Cloud Resource list page in the IBM Cloud console.\n\n  What\u2019s happening \n\nWhen you view your namespaces in the IBM Cloud Resource list page, they don't all show up.\n\n  Why it\u2019s happening \n\nOnly namespaces that are assigned to\n\nresource groupsshow in the IBM Cloud Resource list page.\n\nNamespaces created in version 0.1.485 of the Container Registry CLI or later, or in the IBM Cloud console on or after 29 July 2020, are created in the resource group that you specify. If you don't specify a resource group, and a resource group isn't targeted, the default resource group is used.\n\nNamespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020, aren't assigned to resource groups.\n\n  How to fix it \n\nIf you want to see all your namespaces in the IBM Cloud Resource list page, you must assign each namespace to a resource group, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-namespace-resource-list"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10642-1365-3347","score":18.5236,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10642-7-1848","score":18.048063,"text":"\nUpdating clusters, worker nodes, and cluster components \n\nYou can install updates to keep your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters up-to-date.\n\nYou must update your cluster by using the Red Hat OpenShift on IBM Cloud API, CLI, or console tools. You can't update your cluster version from OpenShift Container Platform tools such as the Red Hat OpenShift web console.\n\n\n\n Updating the master \n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). Updates can affect the API server version or other components in your master. IBM updates the patch version, but you must update the master major and minor versions.\n\n\n\n About updating the master \n\nHow do I know when to update the master?\n: You are notified in the IBM Cloud console and CLI when updates are available, and can also check the [supported versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) page.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master. Additionally, your worker nodes can only be one version behind the master version (n-1). First, [update your master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateupdate_master) to the latest Kubernetes version. Then, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-7-1817","score":17.623592,"text":"\nUpdating clusters, worker nodes, and cluster components \n\nYou can install updates to keep your Kubernetes clusters up-to-date in IBM Cloud\u00ae Kubernetes Service.\n\n\n\n Updating the Kubernetes master \n\nPeriodically, the Kubernetes project releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). Updates can affect the Kubernetes API server version or other components in your Kubernetes master. IBM updates the patch version, but you must update the master major and minor versions.\n\n\n\n About updating the master \n\nHow do I know when to update the master?\n: You are notified in the IBM Cloud console and CLI when updates are available, and can also check the [supported versions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) page.\n\nHow many versions behind the latest can the master be?\n: IBM generally supports three versions of Kubernetes at a time. You can update the Kubernetes API server only to the next version ahead of its current version (n+1). Additionally, your worker nodes can be up to two versions behind the master version (n-2).\n\nFor example, if your current Kubernetes API server version is 1.18 (n) and you want to update to 1.20, you must first update to 1.19 (n+1) and then to 1.20 (n+2). Next, you can update the worker nodes up to two version ahead, such as 1.18 to 1.20 (n+2).\n\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-2829-4687","score":17.3119,"text":"\nIn any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/\/images\/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\nTo update the Kubernetes master major or minor version:\n\n\n\n1. Review the [Kubernetes changes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) and make any updates marked Update before master.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-2898-4503","score":17.247433,"text":"\nYour worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/\/images\/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\nTo update the Red Hat OpenShift master major or minor version:\n\n\n\n1. Review the [Red Hat OpenShift changes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) and make any updates marked Update before master.\n2. Review any [Kubernetes helpful warnings](https:\/\/kubernetes.io\/blog\/2020\/09\/03\/warnings\/), such as deprecation notices.\n3. Check the add-ons and plug-ins that are installed in your cluster for any impact that might be caused by updating the cluster version.\n\n\n\n* Checking add-ons\n\n\n\n1. List the add-ons in the cluster.\n\nibmcloud oc cluster addon ls --cluster CLUSTER\n2. Check the supported Red Hat OpenShift version for each add-on that is installed.\n\nibmcloud oc addon-versions\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05713-116249-117792","score":16.767448,"text":"\n* [Structuring your Kubernetes environment](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategykube_env)\n\n\n\n* [What type of cluster and flavors should I get?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_multicluster)\n* [How can I set up my resources within the cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyenv_resources)\n* [How can I keep my cluster in a supported state?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyupdating_kube)\n\n\n\n* [Making your resources highly available](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategykube_ha)\n\n\n\n[Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clustersplan_clusters)\n\n[Understanding network basics of VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsplan_vpc_basics)\n\n\n\n* [Worker-to-worker communication using VPC subnets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-worker)\n* [Worker-to-master and user-to-master communication using Virtual private endpoints or cloud service endpoints](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-workeruser-master)\n* [Worker-to-master communication in VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsworker-to-master-comms)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_06209-8154-10055","score":16.744871,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10534-110083-111436","score":16.631216,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_flavors)\n* [Do I use multiple clusters, or just add more workers to an existing cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_multicluster)\n* [How can I set up my resources within the cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyenv_resources)\n* [How can I keep my cluster in a supported state?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategyupdating_kube)\n\n\n\n* [Making your resources highly available](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategykube_ha)\n\n\n\n[Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_clustersplan_clusters)\n\n[Understanding network basics of VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsplan_vpc_basics)\n\n\n\n* [Worker-to-worker communication using VPC subnets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-worker-worker)\n* [Worker-to-master and user-to-master communication using Virtual private endpoints or cloud service endpoints](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master)\n* [Worker-to-master communication in VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsworker-to-master-comms)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-126762-128234","score":15.983076,"text":"\n* [Multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters)\n\n\n\n* [Why do I need worker nodes in three zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-cluster-zones)\n* [How is my IBM Cloud Kubernetes Service master set up?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-master-setup)\n* [Do I have to do anything so that the master can communicate with the workers across zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-master-communication)\n* [Can I convert my single zone cluster to a multizone cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersconvert-sz-to-mz)\n* [Do my apps automatically spread across zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultizone-apps-faq)\n\n\n\n* [Multiple public clusters connected with a global load balancer](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb)\n\n\n\n* [Why do I need 3 clusters in three zones?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmulticluster-three-zones)\n* [What if I want to set up multiple clusters across regions?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-regions-setup)\n* [What options do I have to load balance workloads across multiple clusters?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-cluster-lb-options)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-118549-119833","score":15.96417,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clusterssz-workload-failover)\n\n\n\n* [Multizone cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmz-clusters)\n\n\n\n* [Why do I need worker nodes in three zones?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmz-cluster-zones)\n* [How is my Red Hat OpenShift on IBM Cloud master set up?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmz-master-setup)\n* [Do I have to do anything so that the master can communicate with the workers across zones?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmz-master-communication)\n* [Can I convert my single zone cluster to a multizone cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersconvert-sz-to-mz)\n* [Do my apps automatically spread across zones?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmultizone-apps-faq)\n\n\n\n* [Multiple public clusters connected with a global load balancer](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmultiple-clusters-glb)\n\n\n\n* [Why do I need 3 clusters in three zones?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmulticluster-three-zones)\n* [What if I want to set up multiple clusters across regions?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05713-329078-330562","score":30.937891,"text":"\n* [What does the benchmark cover?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-worker-test)\n\n\n\n\n\n Version 1.27 \n\n[1.27 version information and update actions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127cs_versions_127)\n\n\n\n* [Release timeline](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127release_timeline_127)\n* [Preparing to update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127prep-up-127)\n\n\n\n* [Update before master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127before_127)\n\n\n\n\n\n[Kubernetes version 1.27 change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_127changelog_127)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10070-4689-6311","score":30.61257,"text":"\nWhat else can I do to increase the security and compliance of my cluster? \n\nSee [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nThese steps apply to clusters that run Red Hat OpenShift version 4.5 or later only.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Create a project for the resources to run the benchmark.\n\noc create ns ibm-kube-bench-test\n2. Create a ConfigMap with the config and node configuration files from the [kube-samples](https:\/\/github.com\/IBM-Cloud\/kube-samples\/tree\/master\/cis-kube-benchmark\/cis-1.5\/ibm) GitHub repository.\n\n\n\n1. Download the the config and node configuration files into a local directory called ibm. You can also clone the repository and navigate into the ibm directory.\n\n\n\n* [config file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/config.yaml)\n* [node file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/node.yaml)\n\n\n\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05612-7-1934","score":28.690313,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_10534-328324-329702","score":28.078812,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test)\n\n\n\n[Comparing the CIS Kubernetes and the Compliance Operator benchmarks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison)\n\n\n\n* [Major differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-major)\n* [Minor differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-minor)\n\n\n\n\n\n Version 4.13 \n\n[4.13 version information and update actions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413cs_versions_413)\n\n\n\n* [Release timeline](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413release_timeline_413)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06063-6174-8378","score":27.919456,"text":"\n* Konnectivity: IBM Cloud Kubernetes Service-specific component to provide secured network connectivity for all Kubernetes master to worker node communication. The Konnectivity server works with the Konnectivity agent to securely connect the master to the worker node. This connection supports apiserver proxy requests to your pods and services, and kubectl top, exec, attach, and logs requests to the kubelet. The connection from the worker nodes to the master is automatically secured with TLS certificates.\n\n\n\nContinuous monitoring by IBM Site Reliability Engineers (SREs)\n: The Kubernetes master, including all the master components, compute, networking, and storage resources are continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of IBM Cloud Kubernetes Service.\n\nCIS Kubernetes master benchmark\n: To configure IBM Cloud Kubernetes Service, IBM engineers follow relevant cybersecurity practices from the Kubernetes master benchmark that is published by the [Center of Internet Security (CIS)](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). The cluster master and all worker nodes are deployed with images that meet the benchmark.\n\nSecure communication via TLS\n: To use IBM Cloud Kubernetes Service, you must authenticate with the service by using your credentials. When you are authenticated, IBM Cloud Kubernetes Service generates TLS certificates that encrypt the communication to and from the Kubernetes API server and etcd data store to ensure a secure end-to-end communication between the worker nodes and the Kubernetes master. These certificates are never shared across clusters or across Kubernetes master components.\n\nNeed to revoke existing certificates and create new certificates for your cluster? Check out [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate).\n\nConnectivity to worker nodes\n: Although Kubernetes secures the communication between the master and worker nodes by using the https protocol, no authentication is provided on the worker node by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05608-3099-5358","score":27.408234,"text":"\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure pod security policies for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05608-1309-3624","score":27.321644,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_10070-2817-5073","score":27.242401,"text":"\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause Red Hat OpenShift on IBM Cloud is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure security context constraints for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05618-7-2074","score":27.199846,"text":"\nKubernetes version 1.27 CIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.27. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark-use).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127"},{"document_id":"ibmcld_05610-7-1993","score":27.193087,"text":"\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06090-3328-5351","score":21.750017,"text":"\nYour service might not yet support private cloud service endpoints. If you have a private-only cluster, you must use service credentials that use the private cloud service endpoint, or open up the public IP address and port to connect to your service.\n\n\n\n\n\n Can I use all IBM Cloud services in my cluster? \n\nYou can use service binding only for services that support service keys so that the service credentials can automatically be created and stored in a Kubernetes secret. To find a list of services that support service keys, see [Enabling external apps to use IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-externalappexternalapp).\n\nServices that don't support service keys usually provide an API that you can use in your app. The service binding method does not automatically set up API access for your app. Make sure to review the API documentation of your service and implement the API interface in your app.\n\n\n\n\n\n Can I bind multiple IBM Cloud services to multiple clusters at once? \n\nIBM Cloud service binding is on a per-cluster, per-service basis, and works by creating a Kubernetes secret that your pods can mount.\n\nFor multiple clusters and services, you can [use IAM trusted profiles instead](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-iam-identity). In IAM, you create a trusted profile with access policies for the IBM Cloud services that you want. Then, you link the trusted profile with as many clusters as you want, based on conditions such as all the prod Kubernetes namespaces in clusters in a resource group. Finally, your pods mount the Kubernetes service account projected volume to get a token that can be exchanged for an IAM token that your apps use to authenticate with the IBM Cloud services.\n\n\n\n\n\n\n\n Adding IBM Cloud services to clusters \n\nUse IBM Cloud service binding to automatically create service credentials for your IBM Cloud services and store these credentials in a Kubernetes secret.\n\nBefore you begin:\n\n\n\n* Ensure you have the following roles:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-binding"},{"document_id":"ibmcld_10529-2968-5168","score":20.860027,"text":"\nBy default, the ibmcloud oc cluster service bind command creates service credentials with the public cloud service endpoint. To use the private cloud service endpoint, you must manually create service credentials for your service that use the private cloud service endpoint, and then use the --key option to specify the name of the existing service credentials.\n\nYour service might not yet support private cloud service endpoints.\n\n\n\n\n\n Can I use all IBM Cloud services in my cluster? \n\nYou can use service binding only for services that support service keys so that the service credentials can automatically be created and stored in a Kubernetes secret. To find a list of services that support service keys, see [Enabling external apps to use IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-externalappexternalapp).\n\nServices that don't support service keys usually provide an API that you can use in your app. The service binding method does not automatically set up API access for your app. Make sure to review the API documentation of your service and implement the API interface in your app.\n\n\n\n\n\n Can I bind multiple IBM Cloud services to multiple clusters at once? \n\nIBM Cloud service binding is on a per-cluster, per-service basis, and works by creating a Kubernetes secret that your pods can mount.\n\nFor multiple clusters and services, you can [use IAM trusted profiles instead](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod-iam-identity). In IAM, you create a trusted profile with access policies for the IBM Cloud services that you want. Then, you link the trusted profile with as many clusters as you want, based on conditions such as all the prod Kubernetes namespaces in clusters in a resource group. Finally, your pods mount the Kubernetes service account projected volume to get a token that can be exchanged for an IAM token that your apps use to authenticate with the IBM Cloud services.\n\n\n\n\n\n\n\n Adding IBM Cloud services to clusters \n\nUse IBM Cloud service binding to automatically create service credentials for your IBM Cloud services and store these credentials in a Kubernetes secret.\n\nBefore you begin:\n\n\n\n* Ensure you have the following roles:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-binding"},{"document_id":"ibmcld_06010-3038-4965","score":20.028114,"text":"\nVPC clusters can be provisioned using virtual worker nodes on standard infrastructure or dedicated hosts. Free VPC clusters are not supported.\n\n\n\n\n\n Can I combine different flavors in a cluster? \n\nYes. To add different flavors to your cluster, you must [create another worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_create). You can't resize existing worker pools to have different compute resources such as CPU or memory.\n\n\n\n\n\n How can I change worker node flavors? \n\nSee [updating flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type).\n\n\n\n\n\n Are the worker nodes encrypted? \n\nThe secondary disk of the worker node is encrypted. For more information, see [Overview of cluster encryption](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionencrypt_ov). After you create a worker pool, you might notice that the worker node flavor has .encrypted in the name, such as b3c.4x16.encrypted.\n\n\n\n\n\n How do I manage my worker nodes? \n\nWorker nodes in classic clusters are provisioned into your IBM Cloud account. You can manage your worker nodes by using IBM Cloud Kubernetes Service, but you can also use the [classic infrastructure dashboard](https:\/\/cloud.ibm.com\/classic\/) in the IBM Cloud console to work with your worker node directly.\n\nUnlike classic clusters, the worker nodes of your VPC cluster are not listed in the [VPC infrastructure dashboard](https:\/\/cloud.ibm.com\/vpc\/overview). Instead, you manage your worker nodes with IBM Cloud Kubernetes Service only. However, your worker nodes might be connected to other VPC infrastructure resources, such as VPC subnets or VPC Block Storage. These resources are in the VPC infrastructure dashboard and can be managed separately from there.\n\n\n\n\n\n What limitations do I need to be aware of? \n\nKubernetes limits the maximum number of worker nodes that you can have in a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes"},{"document_id":"ibmcld_05713-285775-287414","score":19.060492,"text":"\n* [What if I want to use service credentials that use the private cloud service endpoint?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingsvc-bind-private-cse)\n* [Can I use all IBM Cloud services in my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingsvc-bind-which)\n* [Can I bind multiple IBM Cloud services to multiple clusters at once?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingsvc-bind-trusted-profile)\n\n\n\n* [Adding IBM Cloud services to clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingbind-services)\n* [Accessing service credentials from your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingadding_app)\n\n\n\n* [Mounting the secret as a volume to your pod](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingmount_secret)\n* [Referencing the secret in environment variables](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingreference_secret)\n\n\n\n* [Removing a service from a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingunbind-service)\n\n\n\n[Understanding high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha)\n\n\n\n* [About high availability](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha-about)\n* [Overview of potential points of failure in IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-hafault_domains)\n\n\n\n\n\n\n\n API reference \n\n[IBM Cloud Kubernetes Service API](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05777-8738-10765","score":18.875809,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05590-1834-3804","score":18.770517,"text":"\nYou can create context-based restrictions (CBR) for IBM Cloud Kubernetes Service resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect IBM Cloud Kubernetes Service resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbrresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbrprotect-api-types-cbr).\n\nApplications running on IBM Cloud Kubernetes Service clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting IBM Cloud Kubernetes Service resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific IBM Cloud Kubernetes Service cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects IBM Cloud Kubernetes Service resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.\n: If you use the CLI, you can specify the --region REGION option to protect resources in a specific region.\n: If you use the API, you can specify \"name\": \"region\",\"value\": \"REGION\" field in the resource attributes.\n\nResource group\n: Protects IBM Cloud Kubernetes Service resources in a specific resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr"},{"document_id":"ibmcld_05592-1834-3752","score":18.572588,"text":"\nYou can create context-based restrictions (CBR) for IBM Cloud Kubernetes Service resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect IBM Cloud Kubernetes Service resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=cliresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=cliprotect-api-types-cbr).\n\nApplications running on IBM Cloud Kubernetes Service clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting IBM Cloud Kubernetes Service resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific IBM Cloud Kubernetes Service cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects IBM Cloud Kubernetes Service resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.\n: If you use the CLI, you can specify the --region REGION option to protect resources in a specific region.\n: If you use the API, you can specify \"name\": \"region\",\"value\": \"REGION\" field in the resource attributes.\n\nResource group","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=cli"},{"document_id":"ibmcld_05593-1834-3750","score":18.572588,"text":"\nYou can create context-based restrictions (CBR) for IBM Cloud Kubernetes Service resources or for specific APIs. With Context-based restrictions, you can protect the following resources.\n\nProtect IBM Cloud Kubernetes Service resources\n: [Restrict access to clusters, resource groups, or regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=uiresources-types-cbr).\n\nProtect specific APIs\n: Restrict accessing to provisioning and managing clusters and workers. Or, restrict access to Kubernetes APIs such as viewing pods and nodes. For more information, see [Protecting specific APIs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=uiprotect-api-types-cbr).\n\nApplications running on IBM Cloud Kubernetes Service clusters, for example web servers exposed by a Kubernetes LoadBalancer are not restricted by CBR rules.\n\n\n\n Protecting IBM Cloud Kubernetes Service resources \n\nYou can create CBR rules to protect specific regions, and clusters.\n\nCluster\n: Protects a specific IBM Cloud Kubernetes Service cluster. If you select a cluster in your CBR rule, only traffic from resources in the network zones that you associate with the rule can interact with that cluster.\n: If you use the CLI, you can specify the --service-instance CLUSTER-ID option to protect a specific cluster.\n: If you use the API, you can specify \"name\": \"serviceInstance\",\"value\": \"CLUSTER-ID\" in the resource attributes.\n\nRegion\n: Protects IBM Cloud Kubernetes Service resources in a specific region. If you select a region in your CBR rule, then only traffic from resources in the network zones that you associate with the rule can interact with resources in that region.\n: If you use the CLI, you can specify the --region REGION option to protect resources in a specific region.\n: If you use the API, you can specify \"name\": \"region\",\"value\": \"REGION\" field in the resource attributes.\n\nResource group","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr&interface=ui"},{"document_id":"ibmcld_10444-2675-4364","score":18.56451,"text":"\nVPC clusters can be provisioned as standard clusters on shared [virtual](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) worker nodes only, and must be created in one of the supported [multizone locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc). Free VPC clusters are not supported.\n\nVPC clusters can be provisioned using virtual worker nodes on standard infrastructure or dedicated hosts. Free VPC clusters are not supported.\n\n\n\n\n\n Can I combine different flavors in a cluster? \n\nYes. To add different flavors to your cluster, you must [create another worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_create). You can't resize existing worker pools to have different compute resources such as CPU or memory.\n\n\n\n\n\n How can I change worker node flavors? \n\nSee [updating flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type).\n\n\n\n\n\n Are the worker nodes encrypted? \n\nThe secondary disk of the worker node is encrypted. For more information, see [Overview of cluster encryption](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionencrypt_ov). After you create a worker pool, you might notice that the worker node flavor has .encrypted in the name, such as b3c.4x16.encrypted.\n\n\n\n\n\n How do I manage my worker nodes? \n\nWorker nodes in classic clusters are provisioned into your IBM Cloud account. You can manage your worker nodes by using Red Hat OpenShift on IBM Cloud, but you can also use the [classic infrastructure dashboard](https:\/\/cloud.ibm.com\/classic\/) in the IBM Cloud console to work with your worker node directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_06038-14006-15657","score":18.513584,"text":"\nUse the [global endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zonesendpoint) instead. If you must use regional endpoints, [use the ibmcloud ks api command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cli_api).\n\nBy using IBM Cloud Kubernetes Service regions, you can create or access Kubernetes clusters in a region other than the IBM Cloud region that you are logged in to. IBM Cloud Kubernetes Service region endpoints refer specifically to the IBM Cloud Kubernetes Service, not IBM Cloud as a whole.\n\nYou might want to log in to another IBM Cloud Kubernetes Service region for the following reasons: * You created IBM Cloud services or private Docker images in one region and want to use them with IBM Cloud Kubernetes Service in another region. * You want to access a cluster in a region that is different from the default IBM Cloud region that you are logged in to.\n\nTo switch regions, use the ibmcloud ks init[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_init).\n\n\n\nCorresponding Kubernetes Service and IBM Cloud regions, with zones. Multizone-capable zones are in bold.\n\n IBM Cloud Kubernetes Service region Corresponding IBM Cloud regions Available zones in the region \n\n AP North (standard clusters only) Tokyo che01, sng01, tok02, tok04, tok05 \n AP South Sydney syd01, syd04, syd05 \n EU Central Frankfurt ams03, fra02, fra04, fra05, mil01, par01 \n UK South London lon02, lon04, lon05, lon06 \n US East (standard clusters only) Washington DC mon01, tor01, wdc04, wdc06, wdc07 \n US South Dallas dal10, dal12, dal13, sjc03, sjc04, sao01","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zones"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12348-3-1571","score":20.433495,"text":"\nSecrets Manager docs \n\nExplore recommended content and resources to help you get started with IBM Cloud Secrets Manager.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2)[CLI reference](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-cli)[Terraform reference](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/secrets_manager_secret)\n\n Recommended content \n\n[What is a secret? Learn about secret types that you can create and manage with the service.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)[Creating secrets Try out the service by storing your first secret.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets)[Best practices for organizing your secrets and assigning access Review suggested guidelines for organizing your secrets.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets)\n\n Video library \n\n[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/secrets-manager\/\/images\/what-is-secrets-mgmt-video-thumbnail.png)<br><br>What is secrets management?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/secrets-manager\/\/images\/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https:\/\/www.youtube.com\/watch?v=rOp7aGyavnk)\n\n Latest updates","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager"},{"document_id":"ibmcld_12353-3-1455","score":20.263695,"text":"\nSecrets Manager docs \n\nExplore recommended content and resources to help you get started with IBM Cloud&reg; Secrets Manager.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager)[CLI reference](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-cli)\n\n Recommended content \n\n[What is a secret? Learn about secret types that you can create and manage with the service.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)[Creating secrets Try out the service by storing your first secret.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets)[Best practices for organizing your secrets and assigning access Review suggested guidelines for organizing your secrets.](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets)\n\n Video library \n\n[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/secrets-manager-cli-plugin\/\/images\/what-is-secrets-mgmt-video-thumbnail.png)<br><br>What is secrets management?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/secrets-manager-cli-plugin\/\/images\/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https:\/\/www.youtube.com\/watch?v=rOp7aGyavnk)\n\n Latest updates","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager-cli-plugin"},{"document_id":"ibmcld_00961-1582-3266","score":19.010221,"text":"\n[Tekton](https:\/\/www.ibm.com\/cloud\/blog\/tekton-a-modern-approach-to-continuous-delivery) is an open source, vendor-neutral, Kubernetes-native framework that you can use to build, test, and deploy apps. Tekton provides a set of shared components for building [continuous integration](https:\/\/www.ibm.com\/garage\/method\/practices\/code\/practice_continuous_integration\/) and [continuous delivery](https:\/\/www.ibm.com\/garage\/method\/practices\/deliver\/practice_continuous_delivery\/) systems. As an open source project, Tekton is managed by the [Continuous Delivery Foundation](https:\/\/cd.foundation\/). The goal is to modernize continuous delivery by providing industry specifications for pipelines, workflows, and other building blocks. With Tekton, you can build, test, and deploy across cloud providers or on-premises systems by abstracting the underlying implementation details. Tekton pipelines are built into [Continuous Delivery](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/build-and-deliver-using-tekton-enabled-pipelines). For more information about the IBM Cloud\u00ae Kubernetes Service, see [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/garage\/method\/practices\/run\/tool_ibm_container).\n\nThe template that is used in this tutorial works with the Standard plan for Kubernetes.\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https:\/\/cloud.ibm.com\/registration). Depending on your IBM Cloud account type, access to certain resources might be limited. Depending on your account plan limits, certain capabilities that are required by some of the deployment strategies might not be available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-satellite"},{"document_id":"ibmcld_10439-4150-5836","score":18.28466,"text":"\nDev-to-prod parity: Set up a [continuous integration](https:\/\/www.ibm.com\/garage\/method\/practices\/code\/practice_continuous_integration) and [continuous delivery](https:\/\/www.ibm.com\/garage\/method\/practices\/deliver\/practice_continuous_delivery) pipeline for your app, with minimal difference between the app in development and the app in prod.\n11. Logs: Treat logs as event streams: the outer or hosting environment processes and routes log files. Important: In Red Hat OpenShift on IBM Cloud, logs are not turned on by default. To enable, see [Configuring log forwarding](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health).\n12. Admin processes: Keep any one-time admin scripts with your app and run them as a [Kubernetes Job object](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) to ensure that the admin scripts run with the same environment as the app itself. For orchestration of larger packages that you want to run in your Kubernetes clusters, consider using a package manager such as [Helm](https:\/\/helm.sh\/).\n\n\n\n\n\n\n\n What about serverless apps? \n\nYou can run serverless apps and jobs through the [IBM Cloud Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) service. Code Engine can also build your images for you.\n\n\n\n\n\n I already have an app. How can I migrate it to Red Hat OpenShift on IBM Cloud? \n\nYou can take some general steps to containerize your app as follows.\n\n\n\n1. Use the [Twelve-Factor App](https:\/\/12factor.net\/) as a guide for isolating dependencies, separating processes into separate services, and reducing the statefulness of your app as much as possible.\n2. Find an appropriate base image to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_05557-7-1853","score":18.035387,"text":"\nAccessing the cluster master with admission controllers and webhooks \n\nAdmission controllers intercept authorized API requests from various Kubernetes resources before the requests reach the API server that runs in your IBM Cloud Kubernetes Service cluster master. Mutating admission webhooks might modify the request, and validating admission webhooks check the request. If either webhook rejects a request, the entire request fails. Advanced features, whether built-in or added on, often require admission controllers as a security precaution and to control what requests are sent to the API server. For more information, see [Using Admission Controllers](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/) and [Dynamic Admission Control](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/) in the Kubernetes documentation.\n\n\n\n What are the default admission controllers in my cluster? \n\nReview the order of default admission controllers by cluster version in the [kube-apiserver component reference information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-settingskube-apiserver).\n\n\n\n\n\n Can I create my own admission controllers? \n\nYes, see the [Kubernetes](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/) documentation for more information.\n\nAs noted in the Kubernetes documentation, you can use admission controllers for operations that are otherwise handled by the control plane. As such, take great caution when you configure a custom admission controller. You are responsible for any changes that happen in your cluster because of a custom admission controller.\n\n\n\n\n\n What are the best practices for using webhooks? \n\nKeep in mind the following best practices and considerations when you configure a webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_04113-7-2190","score":17.840393,"text":"\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_02812-1652-3484","score":17.799927,"text":"\nTekton provides a set of shared components for building [continuous integration](https:\/\/www.ibm.com\/garage\/method\/practices\/code\/practice_continuous_integration\/) and [continuous delivery](https:\/\/www.ibm.com\/garage\/method\/practices\/deliver\/practice_continuous_delivery\/) systems. As an open source project, Tekton is managed by the [Continuous Delivery Foundation](https:\/\/cd.foundation\/). The goal is to modernize continuous delivery by providing industry specifications for pipelines, workflows, and other building blocks. With Tekton, you can build, test, and deploy across cloud providers or on-premises systems by abstracting the underlying implementation details. Tekton pipelines are built into [Continuous Delivery](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/build-and-deliver-using-tekton-enabled-pipelines). For more information about the IBM Cloud\u00ae Kubernetes Service, see [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/garage\/method\/practices\/run\/tool_ibm_container).\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https:\/\/cloud.ibm.com\/registration). Depending on your IBM Cloud account type, access to certain resources might be limited. Depending on your account plan limits, certain capabilities that are required by some of the deployment strategies might not be available. For more information about IBM Cloud accounts, see [Setting up your IBM Cloud account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started) and [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account).\n* A [Code Engine Project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) and an API Key. You can create these resources by using either the UI or the CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-cd-code-engine"},{"document_id":"ibmcld_00958-1652-3484","score":17.799927,"text":"\nTekton provides a set of shared components for building [continuous integration](https:\/\/www.ibm.com\/garage\/method\/practices\/code\/practice_continuous_integration\/) and [continuous delivery](https:\/\/www.ibm.com\/garage\/method\/practices\/deliver\/practice_continuous_delivery\/) systems. As an open source project, Tekton is managed by the [Continuous Delivery Foundation](https:\/\/cd.foundation\/). The goal is to modernize continuous delivery by providing industry specifications for pipelines, workflows, and other building blocks. With Tekton, you can build, test, and deploy across cloud providers or on-premises systems by abstracting the underlying implementation details. Tekton pipelines are built into [Continuous Delivery](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/build-and-deliver-using-tekton-enabled-pipelines). For more information about the IBM Cloud\u00ae Kubernetes Service, see [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/garage\/method\/practices\/run\/tool_ibm_container).\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https:\/\/cloud.ibm.com\/registration). Depending on your IBM Cloud account type, access to certain resources might be limited. Depending on your account plan limits, certain capabilities that are required by some of the deployment strategies might not be available. For more information about IBM Cloud accounts, see [Setting up your IBM Cloud account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started) and [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account).\n* A [Code Engine Project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) and an API Key. You can create these resources by using either the UI or the CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-code-engine"},{"document_id":"ibmcld_16729-91745-93601","score":17.763094,"text":"\n[Part 2: Set up a Continuous Integration (CI) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-ci-toolchain)Part 2: Set up a Continuous Integration (CI) toolchain\n\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-06-06\n\n\n\n[Part 1: Set up prerequisites](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cd-devsecops)Part 1: Set up prerequisites\n\nThis tutorial is part 1 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 1 of this tutorial series, you review some background information and set up prerequisites.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2022-07-14\n\n\n\n[Provisioning an IBM Cloud virtual server for classic infrastructure](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-sample_infrastructure_config)Provisioning an IBM Cloud virtual server for classic infrastructure\n\nYou can provision your virtual server for classic infrastructure by using the IBM Cloud Provider plug-in. Similar to the IBM Cloud virtual server for VPC provision that you provisioned.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_06128-7-1993","score":17.550344,"text":"\nMoving your environment to IBM Cloud Kubernetes Service \n\nWith IBM Cloud\u00ae Kubernetes Service, you can quickly and securely deploy container workloads for your apps in production. Learn more so that when you plan your cluster strategy, you optimize your setup to make the most of [Kubernetes](https:\/\/kubernetes.io\/) automated deploying, scaling, and orchestration management capabilities.\n\n\n\n Moving your workloads to the IBM Cloud \n\nYou have lots of reasons to move your workloads to IBM Cloud: reducing total cost of ownership, increasing high availability for your apps in a secure and compliant environment, scaling up and down in respond to your user demand, and many more. IBM Cloud Kubernetes Service combines container technology with open source tools, such as Kubernetes so that you can build a cloud-native app that can migrate across different cloud environments, avoiding vendor lock-in.\n\nBut how do you get to the cloud? What are your options along the way? And how do you manage your workloads after you get there?\n\nUse this page to learn some strategies for your Kubernetes deployments on IBM Cloud Kubernetes Service. And engage with our team on [Slack](https:\/\/ibm-cloud-success.slack.com).\n\nNot on slack yet? [!Request an invite](https:\/\/cloud.ibm.com\/kubernetes\/slack)\n\n\n\n What can I move to the IBM Cloud? \n\nWith IBM Cloud, you have flexibility to create Kubernetes clusters in [off-premises, on-premises, or hybrid cloud environments](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation). The following table provides some examples of what types of workloads that users typically move to the various types of clouds. You might also choose a hybrid approach where you have clusters that run in both environments.\n\n\n\nIBM Cloud implementations support your workloads\n\n Workload Kubernetes Service off-prem on-prem \n\n DevOps enablement tools Yes \n Developing and testing apps Yes \n Apps have major shifts in demand and need to scale rapidly Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09864-5103-6606","score":15.4739685,"text":"\n\"moreInformation\": \"https:\/\/example.com\",\n\"queueManagerLocation\": \"qm.us-south.mq.appdomain.cloud\",\n\"queueManagers\": [{\n\"hostname\": \"qm1-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM1\"\n}, {\n\"hostname\": \"qm2-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM2\"\n}],\n\"region\": \"us-south\",\n\"serviceInstance\": \"crn:v1:staging:public:mqcloud:region:a\/ab90cde12f345:ab5c678d-e90a-b5678c9::\"\n}\nShow more\n\nThe notification will contain the following keys:\n\n\n\n* datestamp: the date and time the notification was sent\n* description: an explanation of the problem and what action was taken\n* moreInformation: this may contain an external link to further explain the cause behind the DR\n* queueManagerLocation: the location of the cluster on which the queue manager is deployed\n* queueManagers: a list of hostnames and names of all affected queue managers\n* region: the physical location of your service instance\n* serviceInstance: the unique CRN of the containing service instance\n\n\n\n\n\n\n\n How to implement the endpoint handler \n\nThe instructions below demonstrate some sample code to implement an endpoint handler to send notifications via PagerDuty in an IBM Cloud Function, but you could also adapt this code to run in a location of your choice\n\nNote: the below function is written in Node.js\n\nconst https = require('https');\n\nfunction main(params) {\n\nreturn new Promise((resolve, reject) => {\n\n\/\/ Replace the string \"R4nd0m5tr1ng0fCh4r4ct3r5\" with your own value to secure access to your own specific endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_dr_notifications"},{"document_id":"ibmcld_09087-20594-21697","score":15.306412,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"AUTHORIZATIONS_NOT_MET\",\n\"message\": \"The key cannot be deleted because it failed the dual authorization request.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n Example Response 2 \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"The key cannot be deleted because the key has one or more associated resources.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n Example Response 3 \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_11422-12525-13454","score":14.747651,"text":"\n-t = deployment type of this VM (RHEL, RHEL-SAP, RHEL-SAP-NETWEAVER)\n\nb. For SLES, run the following command:\n\n. \/usr\/local\/bin\/sles-cloud-init.sh -s RMT_Server_address -p private_ip_of_proxy_vm:3128\n\n-s = the URL of the SLES Repository Mirroring Tool (RMT) server that you are using for registration\n\n-p = \"private_ip_of_powervs_vm\":3128\n\nIf the system is already registered, you need to de-register the system before registering again by running the following two commands: SUSEConnect --de-register\n\nSUSEConnect \u2013cleanup\n\nIf the registration fails and the following note appears in the logs:\n\nCould not register with SLES RMT servers, Please verify connection to the proxy server. If proxy is verified, it may be an issue with SLES RMT servers undergoing maintenance. If so, please try executing the command again within a few minutes\n\nThen it could be a network issue and you should attempt to register again at a later time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-set-full-Linux"},{"document_id":"ibmcld_05259-5125-6683","score":14.594757,"text":"\nNote that you cannot delete a job run without also deleting any associated pods. Any attempt to delete with the propagationPolicy=Orphan option is rejected.\n\n\n\n\n\n Serving CRD methods \n\n\n\nServing CRDs for Code Engine\n\n Group Version Kind \n\n serving.knative.dev v1 Configuration \n serving.knative.dev v1 Revision \n serving.knative.dev v1 Route \n serving.knative.dev v1 Service \n\n\n\nFor more information about these CRDs, see [Knative Serving API Specification](https:\/\/github.com\/knative\/specs\/blob\/main\/specs\/serving\/knative-api-specification-1.0.md).\n\n\n\n\n\n Source-to-image CRD methods \n\n\n\nSource-to-image CRDs for Code Engine\n\n Group Version Kind \n\n shipwright.io v1alpha1 Build \n shipwright.io v1alpha1 BuildRun \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Source-to-image CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='shipwright.io\/v1alpha1' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).\n\n\n\n\n\n\n\n Subscription CRD methods \n\n\n\nSubscription CRDs for Code Engine\n\n Group Version Kind \n\n sources.codeengine.cloud.ibm.com v1alpha1 CosSource \n sources.knative.dev v1 PingSource \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Subscription CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='sources.knative.dev\/<VERSION>' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-api"},{"document_id":"ibmcld_09087-24865-26001","score":14.206407,"text":"\nDisabling key: '69332...<redacted>...5dbf', in instance: 'a192...<redacted>...7411'...\nFAILED\nkp.Error:\ncorrelation_id='aca1...<redacted>...66e9',\nmsg='Conflict:\nKey is not in active state:\nKey could not be disabled.\nPlease see reasons for more details.',\nreasons='[KEY_ACTION_INVALID_STATE_ERR:\nKey is not in a valid state -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n this API request fails because the key is deleted a third time\n$ curl -X POST \"https:\/\/us-south.kms.cloud.ibm.com\/api\/v2\/keys\/$KEY_ID\/actions\/disable\" -H \"authorization: Bearer $ACCESS_TOKEN\" -H \"bluemix-instance: $KP_INSTANCE_ID\" -H \"content-type: application\/vnd.ibm.kms.key_action+json\"\nShow more\n\n\n\n JSON response \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key is not in active state: Key could not be disabled. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"KEY_ACTION_INVALID_STATE_ERR\",\n\"message\": \"Key is not in a valid state\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n Example 2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_09087-74131-75722","score":14.161107,"text":"\nkp.Error:\ncorrelation_id='59c343a7-c20f-43ea-9e50-da45cecbc8a6',\nmsg='Conflict:\nKey could not be enabled.\nPlease see reasons for more details.',\nreasons='[REQ_TOO_EARLY_ERR:\nThe key was updated recently.\nPlease wait and try again. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n this request succeeds because the key was disabled at least 30 seconds ago\n$ ibmcloud kp key enable $KEY_ID -i $KP_INSTANCE_ID\n\nEnabling key: '54f53384-b563-4466-860a-c42ce42f7ac9', in instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nShow more\n\n\n\n\n\n\n\n 27 - The provided ciphertext is invalid or... \n\n\n\n Message \n\nThe provided ciphertext is invalid or corrupted\n\nReason code: UNPROCESSABLE_CIPHERTEXT_ERR\n\n\n\n\n\n HTTP status code \n\n422 - Unprocessable Entity\n\nThe HTTP 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis typically means the hardware security module (HSM) could not process the data because the input was invalid.\n\nThis error is returned when there is an internal error.\n\nIf you get this error please contact [IBM support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter)\n\n\n\n\n\n\n\n 28 - The provided encrypted nonce was not... \n\n\n\n Message \n\nThe provided encrypted nonce was not encrypted with the key material given OR the provided IV does not match the encrypted nonce\n\nReason code: INCORRECT_NONCE_IV_ERR","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_09087-71963-73566","score":14.110532,"text":"\ncorrelation_id='3d941968-c599-43b3-b681-306422079412',\nmsg='Conflict:\nAction could not be performed on key.\nPlease see reasons for more details.',\nreasons='[NOT_DUAL_AUTH_ERR:\nThe key is not dual auth enabled and cannot be set for deletion -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n this request fails because the key DOES NOT have a dual authorization policy\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...\nFAILED\nkp.Error:\ncorrelation_id='5b04a667-573c-44d1-82d5-39730af56a75',\nmsg='Conflict:\nAction could not be performed on key.\nPlease see reasons for more details.',\nreasons='[NOT_DUAL_AUTH_ERR:\nThe key is not dual auth enabled and cannot be set for deletion -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\nShow more\n\n\n\n\n\n\n\n\n\n 26 - The key was updated recently \n\n\n\n Message \n\nThe key was updated recently: Please wait and try again\n\nReason code: REQ_TOO_EARLY_ERR\n\n\n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict response status code indicates a request conflict with current state of the server.\n\nConflicts are most likely to occur in response to a PUT request. For example, you may get a 409 response when uploading a file which is older than the one already on the server resulting in a version control conflict.\n\n\n\n\n\n Context \n\nThis error occurs when you enable or restore a key within 30 seconds of the last action.\n\nYou must wait at least 30 seconds between the last \"action\" and enabling or restoring a key.\n\nThis example fails because the key was enabled too soon after disabling a key.\n\n create a root key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_01595-1726-3663","score":14.082871,"text":"\ncurl https:\/\/sgmanager.<region>.securegateway.cloud.ibm.com\n* If there is error when accessing tunnel server:\n\n[DEBUG] The Secure Gateway tunnel is connecting for wss:\/\/<node>.securegateway.appdomain.cloud:9000\/ws\n[ERROR] The following error occurred on the Secure Gateway tunnel, <Error Code>\n[INFO] The Secure Gateway tunnel was disconnected\n\n\n\n* Please check whether your Secure Gateway Client have access to <node>.securegateway.appdomain.cloud:9000. For details, see [Network Requirements](https:\/\/cloud.ibm.com\/docs\/SecureGateway?topic=SecureGateway-client-requirementsnetwork-requirements).\n\n\n\ncurl https:\/\/<node>.securegateway.appdomain.cloud:9000\n* If you are using proxy option, please check with your proxy team to ensure the Secure Gateway Client could access above host and port via the proxy.\n\ncurl -x <proxy> https:\/\/sgmanager.<region>.securegateway.cloud.ibm.com\ncurl -x <proxy> https:\/\/<node>.securegateway.appdomain.cloud:9000\n\n\n\n\n\n\n\n Secure Gateway Client connection errors \n\n\n\n* Initiate the failing request from the requesting application, check the Secure Gateway Client logs\n* If the Secure Gateway Client is connecting to the tunnel but no client logs have been generated from the request, the issue is between the requesting application and the Secure Gateway Servers. This could range from network reliability to mismatched request protocols to an improper TLS mutual authentication handshake. For example:\n\n\n\n* If the destination have enabled iptables rules, please ensure the IP of the cloud application is in the range of the iptables rules\n* If the destination is set to use Mutual Auth, please ensure it is using associated certificate and key to connect\n\n\n\n* If the client has generated error level logs from the request, then the issue is between the SG Client and the on-prem resource. For example:\n\n[ERROR] Connection <connection ID> to destination <target host>:<target port> had error: '<Error Code>'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/SecureGateway?topic=SecureGateway-troubleshooting"},{"document_id":"ibmcld_09087-49200-50400","score":14.0094185,"text":"\nmsg='Bad Request:\nKey could not be restored.\nPlease see reasons for more details.',\nreasons='[KEY_IMPT_REQ_ERR:\nOnly imported keys may be restored. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n step 5 - this API request fails because you can only restore keys\n that were imported (created with a key material or an import token)\n$ curl -X POST \"https:\/\/us-south.kms.cloud.ibm.com\/api\/v2\/keys\/$KEY_ID\/restore\" -H \"authorization: Bearer $ACCESS_TOKEN\" -H \"bluemix-instance: $KP_INSTANCE_ID\" -H \"content-type: application\/vnd.ibm.kms.key_action+json\" -d '{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"payload\": \"'$KEY_MATERIAL'\"\n}\n]\n}'\nShow more\n\n\n\n JSON response \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Bad Request: Key could not be restored. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"KEY_IMPT_REQ_ERR\",\n\"message\": \"Only imported keys may be restored.\",\n\"status\": 400,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n\n\n\n\n 17 - Requested action can only be completed... \n\n\n\n Message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_16628-0-1541","score":13.822777,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05713-563203-564484","score":29.223494,"text":"\n* [osa](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorsosa)\n* [par](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorspar)\n* [sao](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorssao)\n* [sjc](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorssjc)\n* [sng](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorssng)\n* [syd](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorssyd)\n* [tok](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorstok)\n* [tor](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorstor)\n* [wdc](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-classic-flavorswdc)\n\n\n\n\n\n\n\n FAQs \n\n[FAQs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaqs)\n\n\n\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqskubernetes)\n* [How does IBM Cloud Kubernetes Service work?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqskubernetes_service)\n* [Why should I use IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_benefits)\n* [Can I get a free cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_free)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05248-1488-3339","score":27.861378,"text":"\n* Log out of IBM Cloud\u00ae. Clear your browser cache and cookies to remove your preferences and then log in again and open Cloud Shell.\n* Check whether [Concurrent sessions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-work-sessions&interface=uisessions-concurrent) is set. If so, ensure that the number of logged in sessions for the account does not exceed the Limit sessions value.\n\n\n\n\n\n\n\n Why can't I work with my Kubernetes clusters from my session? \n\n What\u2019s happening \n\nYou want to work with your IBM Cloud\u00ae Kubernetes Service clusters, but when you run a command such as kubectl get pods, the following error is displayed:\n\n$ kubectl get pods\nThe connection to the server localhost:8080 was refused - did you specify the correct host or port?\n\n Why it\u2019s happening \n\nThe cluster isn't currently set as the context. As with your local development environment, the cluster context must be set for each individual session.\n\n How to fix it \n\nSet the cluster as the context in your session as described in [Configuring the CLI to run kubectl](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_installcs_cli_configure).\n\n\n\n\n\n What do I do if I changed my .bashrc file and my sessions don't work? \n\n What\u2019s happening \n\nYou customized your Cloud Shell sessions by editing the .bashrc file, and now your sessions don't open. As a result, you can't work in Cloud Shell.\n\n Why it\u2019s happening \n\nSome code in your .bashrc file isn't working correctly, and it's interfering with your sessions' ability to initialize.\n\n How to fix it \n\nIf you're able to run commands from an existing open session, [download any files](https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-files) that you want to keep. Then, restart Cloud Shell by going to the Cloud Shell menu and clicking Restart.\n\n\n\n\n\n Why do I keep losing my connection to Cloud Shell?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-troubleshooting"},{"document_id":"ibmcld_07578-371958-373965","score":27.72008,"text":"\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n* Why should I use IBM Cloud Kubernetes Service?\n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-371932-373939","score":27.72008,"text":"\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n* Why should I use IBM Cloud Kubernetes Service?\n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10214-7-1980","score":26.439194,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10534-528379-529617","score":26.348766,"text":"\n* [tor](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorstor)\n* [wdc](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorswdc)\n\n\n\n\n\n\n\n FAQs \n\n[FAQs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaqs)\n\n\n\n* [How does Red Hat OpenShift on IBM Cloud work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqskubernetes_service)\n* [Why should I use Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_benefits)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscontainer_platforms)\n* [Does the service come with a managed Red Hat OpenShift master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_04083-26126-28048","score":26.345554,"text":"\nAs a best practice, you should have already stored your certificates and identities on your file system. If you happen to be using an incognito window, all the certificates are deleted from the browser local storage when you close the browser. After you log in again you will need to re-import your identities and certificates.\n\n\n\n\n\n Why am I getting a Cluster linking is taking too long error when I try to link my Kubernetes cluster in IBM Cloud to my IBM Blockchain Platform service instance? \n\n What\u2019s happening \n\nAfter attempting to link my Kubernetes cluster on IBM Cloud to my IBM Blockchain Platform service instance, it fails with the error Cluster linking is taking too long.\n\n Why it\u2019s happening \n\nThis issue can occur when your cluster is busy processing other requests and does not respond to the linking request in a timely matter.\n\n How to fix it \n\nTo resolve this problem you can run the helm reset command to delete the tiller and then try to link your cluster again. The tiller is the helm mechanism that the blockchain deployer uses to set up components on your cluster. Run the following command from your IBM Cloud CLI terminal:\n\nbx api cloud.ibm.com\nbx login\nbx cs clusters\n$(bx cs cluster-config <cluster_name> --export)\nkubectl get deployments test that the connection is working\nhelm reset\n\nAttempt to link your cluster again. If it continues to fail, you should [Contact Support](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-supportblockchain-support-cases).\n\n\n\n\n\n Why am I getting an error \u201call SubConns are in TransientFailure\u201d on the console? \n\n What\u2019s happening \n\nThe following error is shown on the console: \"All SubConns are in TransientFailutre.\"\n\n Why it\u2019s happening \n\nAn Out of Memory (OOM) situation can cause this error.\n\n How to fix it \n\nTo resolve this problem, you need to resize the peers and CouchDB containers to add more memory, such as 2000 MB memory each.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_04083-24472-26641","score":25.040491,"text":"\nThis error occurs when the value that you specified for the enroll secret is not valid for the enroll ID that you selected in the Generate organization admin certificate section of the panel.\n\n How to fix it \n\nVerify that you have selected the correct organization admin enroll ID from enroll ID drop down list and enter the correct value for the enroll secret.\n\n\n\n\n\n Why am I getting the error An error occurred when updating channel when I try to add an organization to my channel? \n\n What\u2019s happening \n\nWhen you attempt to add another organization to a channel, the update fails with the message An error occurred when updating channel.\n\n Why it\u2019s happening \n\nThis error occurs when the selected Channel Updater MSP ID on the Update channel panel is not an admin of the channel.\n\n How to fix it \n\nOn the Update channel panel, scroll down to the Channel Updater MSP ID and select the MSP ID that was specified when the channel was created or specify the MSP ID that is the admin of the channel.\n\n\n\n\n\n When I log in to my console, why am I getting a 401 Unauthorized error? \n\n What\u2019s happening \n\nWhen I try to log in to my console, I am unable to access the console from my browser. If I check the browser logs, I can find the error 401 unauthorized.\n\n Why it\u2019s happening \n\nYour browser console session times out after 8 hours of inactivity. If a session becomes inactive, the console will prevent the inactive user from performing any actions.\n\nIf your session has become inactive, you can try simply refreshing your browser. If that does not work, close the browser including all tabs and windows. Open the URL again. You will be required to log in.\n\nAs a best practice, you should have already stored your certificates and identities on your file system. If you happen to be using an incognito window, all the certificates are deleted from the browser local storage when you close the browser. After you log in again you will need to re-import your identities and certificates.\n\n\n\n\n\n Why am I getting a Cluster linking is taking too long error when I try to link my Kubernetes cluster in IBM Cloud to my IBM Blockchain Platform service instance? \n\n What\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_05713-564182-565630","score":24.766249,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqskubernetes_service)\n* [Why should I use IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_benefits)\n* [Can I get a free cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_free)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqscontainer_platforms)\n* [Does the service come with a managed Kubernetes master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_security_bulletins)\n* [Does the service offer support for bare metal and GPU?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsbare_metal_gpu)\n* [What is the smallest size cluster that I can make?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssmallest_cluster)\n* [Which Kubernetes versions does the service support?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_00433-0-661","score":24.716442,"text":"\n\n\n\n\n\n\n  Why doesn't my hostname load on the browser when IBM Cloud Object Storage (COS) is the origin? \n\nWhen your IBM Cloud\u00ae CDN is configured to use COS as the object storage, direct access to the website does not work.\n\n  Why it\u2019s happening \n\nThis behavior is caused by the index document limitation in IBM COS.\n\n  How to fix it \n\nYou must specify the complete request path in the browser's address bar (for example, www.example.com\/index.html). For an alternative solution, see [How do I use the ICOS default index page with CDN](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-configure-cdn-with-ibm-cloud-object-storageusing-icos-default-index-with-cdn).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-troubleshoot-cdn-hostname-does-not-load"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05713-564182-565630","score":35.469933,"text":"\n(https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqskubernetes_service)\n* [Why should I use IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_benefits)\n* [Can I get a free cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_free)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqscontainer_platforms)\n* [Does the service come with a managed Kubernetes master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsfaq_security_bulletins)\n* [Does the service offer support for bare metal and GPU?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqsbare_metal_gpu)\n* [What is the smallest size cluster that I can make?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssmallest_cluster)\n* [Which Kubernetes versions does the service support?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_07578-380995-382843","score":35.399246,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-380969-382817","score":35.399246,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05777-8738-10765","score":34.137306,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_10214-7502-9481","score":32.290504,"text":"\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference) or in the following table's links.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10534-528379-529617","score":31.528288,"text":"\n* [tor](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorstor)\n* [wdc](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-classic-flavorswdc)\n\n\n\n\n\n\n\n FAQs \n\n[FAQs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaqs)\n\n\n\n* [How does Red Hat OpenShift on IBM Cloud work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqskubernetes_service)\n* [Why should I use Red Hat OpenShift on IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_benefits)\n* [What container platforms are available for my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscontainer_platforms)\n* [Does the service come with a managed Red Hat OpenShift master and worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsmanaged_master_worker)\n* [Are the master and worker nodes highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_ha)\n* [What options do I have to secure my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqssecure_cluster)\n* [What access policies do I give my cluster users?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_access)\n* [Where can I find a list of security bulletins that affect my cluster?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-150513-152036","score":30.136135,"text":"\n* [Using a reservation in a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservationsri-use)\n* [Reviewing reservation usage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservationsri-review)\n\n\n\n\n\n\n\n Enhancing security \n\n[Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity)\n\n\n\n* [Overview of security threats for your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitythreats)\n* [Kubernetes API server and etcd](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityapiserver)\n\n\n\n* [How is access to my API server granted?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityapi-server-access)\n* [What does IBM Cloud Kubernetes Service do to secure my API server and etcd data store?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecure-api-server)\n* [What else can I do to secure my API server?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityapi-server-what-else)\n* [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate)\n\n\n\n* [Worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworkernodes)\n\n\n\n* [Who owns the worker node and am I responsible to secure it?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-owner)\n* [How does my worker node setup look?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworker-node-setup)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05777-10230-11885","score":27.717157,"text":"\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_06128-4245-6078","score":27.490122,"text":"\nFor more information about the kinds of apps that can run in IBM Cloud Kubernetes Service, see [Planning app deployments](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deployapp_types).\n\nIf you already have an app, you can [migrate it to IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploymigrate_containerize). If you want to develop a new app, check out the [guidelines for developing stateless, cloud-native apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy12factor).\n\n\n\n\n\n What about serverless apps? \n\nYou can run serverless apps and jobs through the [IBM Cloud Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started) service. Code Engine can also build your images for you. Code Engine is designed so that you don't need to interact with the underlying technology it is built upon. However, if you have existing tooling that is based upon Kubernetes or Knative, you can still use it with Code Engine. For more information, see [Using Kubernetes to interact with your application](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-kubernetes).\n\n\n\n\n\n What skills should I have before I move my apps to a cluster? \n\nKubernetes is designed to provide capabilities to two main personas, the cluster admin and the app developer. Each persona uses different technical skills to successfully run and deploy apps to a cluster.\n\nWhat are a cluster admin's main tasks and technical knowledge?\n: As a cluster admin, you are responsible to set up, operate, secure, and manage the IBM Cloud infrastructure of your cluster. Typical tasks include:\n\n\n\n* Size the cluster to provide enough capacity for your workloads.\n* Design a cluster to meet the high availability, disaster recovery, and compliance standards of your company.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_12297-98167-99510","score":27.2444,"text":"\n* [Key deletion or disable](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datakey-delete)\n* [Key enable or restore](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datakey-enable)\n\n\n\n* [What technical information is stored in Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datati-data)\n* [Where is my information stored?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datapi-location)\n* [How is my information encrypted?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datapi-encrypt)\n* [How can I delete my information?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datadelete-data)\n\n\n\n[Firewall access - allowed IP addresses](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-allowed-ipaddressesallowed-ipaddresses)\n\n\n\n* [Schematics IP addresses](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-allowed-ipaddressesipaddresses)\n\n\n\n\n\n\n\n Creating an IBM Cloud Kubernetes Service cluster on VPC infrastructure \n\n[Creating an IBM Cloud Kubernetes Service cluster on VPC infrastructure](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-provisioning-terraform-templateprovisioning-terraform-template)\n\n\n\n* [Description](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-provisioning-terraform-templateprovisioning-desc)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15992-0-1834","score":31.486889,"text":"\n\n\n\n\n\n\n  Troubleshooting Bare Metal Servers for VPC \n\nThe following topics cover common difficulties that you might encounter, and offers some helpful tips.\n\n\n\n  How do I fix a hardware issue? \n\nIf your bare metal server experiences a hardware issue, you can request support by creating a support case. Click [here](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add%C2%A0) to create a support case. For more information about creating a case, see [Support cases](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-helpsupport-tickets).\n\nAfter the operation team receives the case, the server goes into a maintenance state.\n\nYou must power off the bare metal server before it can go into the Maintenance state.\n\nYou can't start a bare metal server that's in a Maintenance state. The KVM console is also unavailable. You can't connect to the system over the network.\n\nDuring maintenance, IBM also has no access to your network and workloads. The data on the disks isn't examined. But we still recommend you use software encryption for added security.\n\nYou can delete the bare metal server that is in the Maintenance state.\n\nWhen the issues are fixed, the server is handed back to you and the state returns to Stopped.\n\n\n\n\n\n  How do I manage firmware updates? \n\nFirmware for bare metal servers is managed by IBM. Manual firmware changes aren\u2019t supported on the disk controller or disk drives without direction from IBM.\n\n\n\n\n\n  Why did my custom image fail to boot? \n\nIf your custom image fails to boot, open the console and debug the operating system boot sequence. The following are common issues that can cause a custom image boot failure.\n\n\n\n*  An unsigned operating system. Disable secure boot and try starting the system again.\n*  UEFI boot not support. Verify that the image has an EFI disk partition with an EFI boot loader.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshoot_bare_metal"},{"document_id":"ibmcld_16727-1072450-1074392","score":31.22151,"text":"\nFor more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1069800-1071727","score":30.654455,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01660-7-1957","score":29.888721,"text":"\nFAQs about accounts \n\nFAQs for your IBM Cloud\u00ae account might include questions about upgrading an account, reassigning users, resolving account errors, or tagging resources in an account. To find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n How do I create an IBM Cloud account? \n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n\n\n\n\n\n How is my credit card authorized? \n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\n\n\n\n\n How do I get help with issues with creating an account? \n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1034967-1036922","score":29.304209,"text":"\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud. These products, such as [Aspera on Cloud](https:\/\/www.ibm.com\/cloud\/aspera), are offered by IBM but aren't supported by the IBM Cloud platform. For support for these products, go to [IBM Support](https:\/\/www.ibm.com\/support\/home\/).\n\nSupport for third-party services is provided by the service provider.\n* Does IBM Cloud provide support for resources available through the IBM SkillsBuild Software Downloads?\n\nThe [IBM SkillsBuild Software Downloads](https:\/\/www.ibm.com\/academic\/home) is an IBM corporate program that provides access to the IBM Cloud Platform for faculty, students, and researchers at accredited academic institutions. Acceptance decisions, length of participation, awarding of credits, and any possible extensions are made by the IBM SkillsBuild Software Downloads Team and not IBM Cloud Support. IBM Cloud Support also does not provide technical support for accounts that are part of the IBM SkillsBuild Software Downloads Program. For more information about the program, see the [IBM SkillsBuild Software Downloads FAQ](https:\/\/www.ibm.com\/academic\/faqs\/faqs).\n* How do I ensure that users in my account get updates for a support case?\n\nAs the account owner or as an administrator or editor on the Support Center service, you can add users in the account to the watchlist. Users on the watchlist can view and follow the support case's progress. For more information, see [Updating your support case's watchlist](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-contact-watchlist).\n* Can I find support cases that are created by specific users?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1034838-1036793","score":29.304209,"text":"\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud. These products, such as [Aspera on Cloud](https:\/\/www.ibm.com\/cloud\/aspera), are offered by IBM but aren't supported by the IBM Cloud platform. For support for these products, go to [IBM Support](https:\/\/www.ibm.com\/support\/home\/).\n\nSupport for third-party services is provided by the service provider.\n* Does IBM Cloud provide support for resources available through the IBM SkillsBuild Software Downloads?\n\nThe [IBM SkillsBuild Software Downloads](https:\/\/www.ibm.com\/academic\/home) is an IBM corporate program that provides access to the IBM Cloud Platform for faculty, students, and researchers at accredited academic institutions. Acceptance decisions, length of participation, awarding of credits, and any possible extensions are made by the IBM SkillsBuild Software Downloads Team and not IBM Cloud Support. IBM Cloud Support also does not provide technical support for accounts that are part of the IBM SkillsBuild Software Downloads Program. For more information about the program, see the [IBM SkillsBuild Software Downloads FAQ](https:\/\/www.ibm.com\/academic\/faqs\/faqs).\n* How do I ensure that users in my account get updates for a support case?\n\nAs the account owner or as an administrator or editor on the Support Center service, you can add users in the account to the watchlist. Users on the watchlist can view and follow the support case's progress. For more information, see [Updating your support case's watchlist](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-contact-watchlist).\n* Can I find support cases that are created by specific users?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1033424-1035350","score":28.48783,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1033295-1035221","score":28.48783,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03068-7-1913","score":28.037575,"text":"\nTroubleshooting known issues \n\nGet help with solving issues that you might encounter while using Watson Assistant.\n\n\n\n 4.5.x \n\n\n\n Pod \"RESTARTS\" count stays at 0 after a 4.5.x upgrade even though a few assistant pods are restarting \n\n\n\n* Problem: After upgrading Watson Assistant, the pod \"RESTARTS\" count stays at 0 even though certain assistant pods are restarting.\n* Cause: During the upgrade, custom resources owned by Watson Assistant for the \"certificates.certmanager.k8s.io\" CRD are deleted using a script that runs in the background. Sometimes the CR deletion script completes before the assistant operator gets upgraded. In that case, the old assistant operator might recreate custom resources for the \"certificates.certmanager.k8s.io\" CRD. Leftover CRs might cause the certificate manager to continuously regenerate some certificate secrets, causing some assistant pods to restart recursively.\n* Solution: Run the following script to delete leftover custom resources for the \"certificates.certmanager.k8s.io\" CRD after setting INSTANCE (normally wa) and PROJECT_CPD_INSTANCE variables:\n\n\n\nfor i in oc get certificates.certmanager.k8s.io -l icpdsupport\/addOnId=assistant --namespace ${PROJECT_CPD_INSTANCE} | grep \"${INSTANCE}-\"| awk '{print $1}'; do oc delete certificates.certmanager.k8s.io $i --namespace ${PROJECT_CPD_INSTANCE}; done\n\n\n\n\n\n\n\n 4.5.0 \n\n\n\n Data Governor not healthy after installation \n\nAfter Watson Assistant is installed, the dataexhausttenant custom resource named wa-data-governor-ibm-data-governor-data-exhaust-internal gets stuck in the Topics phase. When this happens, errors in the Data Governor pods report that the service does not exist.\n\n\n\n1. Get the status of the wa-data-governor custom resource:\n\noc get DataExhaust\n2. Wait for the wa-data-governor custom resource to be in the Completed phase:\n\nNAME STATUS VERSION COMPLETED\nwa-data-governor Completed master 1s\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-troubleshoot"},{"document_id":"ibmcld_01660-1531-3476","score":28.025465,"text":"\nHow do I get help with issues with creating an account? \n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n\n\n\n\n\n Why is a VAT ID required when I create an account? \n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n\n\n\n\n\n How do I update my credit card? \n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07191-7-2252","score":26.654905,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07178-6197-7974","score":26.251806,"text":"\n[Example query structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/query_structure2.png)\n\nOperators that evaluate a field (<= , >=, <, >) require a number or date as the value. Using quotations around a value always makes it a string. Therefore score>=0.5 is a valid query and score>=\"0.5\" is not. See [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators) for a complete list of operators.\n\nConsiderations:\n\n\n\n* Not sure when to query on an entity, concept, or keyword? See [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).\n\n\n\nAfter you click Run query and open the JSON tab, query highlighting is turned on, by default. The setting adds a highlight field to your query results. Within the highlight field, the words that match your query are wrapped in HTML <em> (emphasis) tags. For more information, see the [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight).\n\n\n\n\n\n\n\n Building combined queries \n\nYou can combine query parameters together to build more targeted queries. For example, you can use the both the filter and query parameters together. For more information about filtering vs. querying, see [Differences between the filter and query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_15559-2851-5046","score":23.057083,"text":"\nExample message: The value provided for the expires_in field must be between 5 and 3600.\n\n\n\n\n\n missing_field \n\nUsed in any situation where a required header, query parameter, or property is not provided.\n\nmissing_field error code can accompany a 400 HTTP status code.\n\nExample message: A trusted profile ID was not passed in the request body.\n\n\n\n\n\n missing_value \n\nUsed for missing required headers, query parameters, or body properties (identified by the target).\n\nmissing_value error code can accompany a 400 HTTP status code.\n\nExample message: A value such as ibm must be provided in the Metadata-Flavor header.\n\n\n\n\n\n not_found \n\nUsed for headers, query parameters, path parameters, or body properties (identified by the target) that are syntactically valid but refer to a resource that does not exist.\n\nnot_found error code can accompany the following HTTP status codes:\n\n\n\n* 404 for path parameters\n* 400 for all other cases\n\n\n\nExample message: Placement group not found.\n\n\n\n\n\n profile_not_linked \n\nUsed when a trusted profile is not linked to a virtual server instance. This error code is returned only for the POST \/instance_identity\/v1\/iam_token method.\n\nprofile_not_linked error code can accompany a 400 HTTP status code.\n\nExample message: The virtual server instance is not linked to the specified trusted profile.\n\n\n\n\n\n service_error \n\nUsed when the client encounters a service-side issue.\n\nservice_error error code can accompany a 500 HTTP status code.\n\nExample message: An internal error occurred.\n\n\n\n\n\n unauthenticated \n\nUsed when a Bearer token is provided in the Authorization header, but the token is expired, malformed, or otherwise syntactically correct but not valid.\n\nunauthenticated error code can accompany a 401 HTTP status code.\n\nExample message: The provided token is invalid or expired.\n\n\n\n\n\n unauthorized \n\nUsed for headers, parameters, paths, or properties (identified by the target) that are syntactically valid but refer to a resource that you are not authorized to operate on in the requested manner.\n\nunauthorized error code can accompany a 403 HTTP status code.\n\nExample message: The metadata service is not enabled on the provided instance.\n\n\n\n\n\n unknown_field","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-metadata-error-codes"},{"document_id":"ibmcld_15559-1526-3315","score":22.073874,"text":"\n\"more_info\": \"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-configure-service\",\n\"target\": {\n\"name\": \"expires_in\",\n\"type\": \"field\",\n\"value\": \"7200\"\n}\n}\n],\n\"status_code\": 400,\n\"trace\": \"e37872f6-f9a4-4084-a1a8-e56a1c8c8d3d\"\n}\nShow more\n\nError codes can be added, removed, or modified in subsequent releases, with updates announced in the VPC Instance Metadata API change log. If you use error codes programmatically, we recommend that you code defensively. Any code that checks for specific error codes must always have a \"default\" or \"catch-all\" clause. So it can handle the case where the returned error code does not match any of the ones the code expected.\n\n\n\n invalid_request \n\nUsed when the request cannot be parsed, such as when the JSON request is malformed or the request body is too large.\n\ninvalid_request error code can accompany a 400 HTTP status code.\n\nExample message: The request body was malformed.\n\n\n\n\n\n invalid_value \n\nUsed for invalid values for headers, query parameters, path parameters, or properties (identified by the target). Includes integer values that are out of range, string values that have invalid characters, enumerations values out of the listed set, and so on.\n\ninvalid_value error code can accompany the following HTTP status codes:\n\n\n\n* 404 for path parameters\n* 400 for all other cases\n\n\n\nExample message: The value provided for the expires_in field must be between 5 and 3600.\n\n\n\n\n\n missing_field \n\nUsed in any situation where a required header, query parameter, or property is not provided.\n\nmissing_field error code can accompany a 400 HTTP status code.\n\nExample message: A trusted profile ID was not passed in the request body.\n\n\n\n\n\n missing_value \n\nUsed for missing required headers, query parameters, or body properties (identified by the target).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-metadata-error-codes"},{"document_id":"ibmcld_03285-5746-7932","score":21.607437,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":21.607437,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_07178-7488-9434","score":21.149769,"text":"\nFor more information about filtering vs. querying, see [Differences between the filter and query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations).\n\n![Example aggregation query structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/aggregation_structure.png)\n\nThis example aggregation finds all of the concepts in your collection. The delimiter in this query is . and the operator is (), see [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators) to learn about other operators available in the Discovery Query Language.\n\n\n\n Example aggregation queries \n\nThere are several types of ways you can aggregate results with Discovery News, including top values, sum, min, max, average, timeslice, and histogram. You can also add filters and nest aggregations.\n\n\n\n Filter aggregations \n\nThis example aggregation returns the number of articles found in Discovery News about the Pittsburgh Steelers and how many of those results have a positive, negative, or neutral sentiment.\n\n\n\n* filter(enriched_text.entities.text:\"Pittsburgh Steelers\").term(enriched_text.sentiment.document.label,count:3)\n\n\n\nThis example aggregation first filters a set of articles in Discovery News to only the ones that include the entities text of twitter. Next, the aggregation divides those articles by the document sentiment types. Only the top 3 document sentiment types (positive, negative, neutral) are returned.\n\n\n\n* filter(enriched_text.entities.text:twitter).term(enriched_text.sentiment.document.label,count:3)\n\n\n\n\n\n\n\n Nested aggregations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_07191-1691-3739","score":20.200603,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13369-9745-11531","score":19.846838,"text":"\nSee [Example 3: Interim results is true and low latency is false](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-low-latency-examples-three). \n interim_results=true low_latency=true The service returns interim results as it develops transcription hypotheses, and it sends final results for utterances as they become complete. The service delivers one or more interim results for each final result. The quality of interim results is identical to what you receive with previous-generation models. But because low_latency is true, the service returns interim and final results more quickly. See [Example 4: Interim results and low latency are both true](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-low-latency-examples-four). \n\n\n\n\n\n Interim results and low-latency examples \n\nThe following abbreviated WebSocket code shows how to request interim results, low-latency results, or both with the WebSocket interface. It specifies the following parameters:\n\n\n\n* The model query parameter of the \/v1\/recognize request passes the next-generation en-US_Telephony model, which supports low latency.\n* The inactivity_timeout parameter of the JSON start message sets the inactivity timeout to -1 (infinity), which prevents the request from timing out.\n* Both the interim_results and low_latency parameters are specified with the JSON start message of the request.\n\n\n\nTo show examples of results with all possible combinations of the parameters, the arguments for interim_results and low_latency are set to true or false in the examples in the following sections.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&model=en-US_Telephony';\nvar websocket = new WebSocket(wsURI);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interim"},{"document_id":"ibmcld_13455-13739-15986","score":19.655287,"text":"\n* By sending a JSON text message with the action parameter set to the value stop:\n\n{action: 'stop'}\n* By sending an empty binary message, one in which the specified blob is empty:\n\nwebsocket.send(blob)\n\n\n\nIf the client fails to signal that the transmission is complete, the connection can time out without the service sending final results. To receive final results between multiple recognition requests, the client must signal the end of transmission for the previous request before it sends a subsequent request. After it returns the final results for the first request, the service returns another {\"state\":\"listening\"} message to the client. This message indicates that the service is ready to receive another request.\n\n\n\n\n\n Send additional requests and modify request parameters \n\nWhile the WebSocket connection remains active, the client can continue to use the connection to send further recognition requests with new audio. By default, the service continues to use the parameters that were sent with the previous start message for all subsequent requests that are sent over the same connection.\n\nTo change the parameters for subsequent requests, the client can send another start message with the new parameters after it receives the final recognition results and a new {\"state\":\"listening\"} message from the service. The client can change any parameters except for those parameters that are specified when the connection is opened (model, language_customization_id, and so on).\n\nThe following example sends a start message with new parameters for subsequent recognition requests that are sent over the connection. The message specifies the same content-type as the previous example, but it directs the service to return confidence measures and timestamps for the words of the transcription.\n\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\nword_confidence: true,\ntimestamps: true\n};\nwebsocket.send(JSON.stringify(message));\n\n\n\n\n\n Keep a connection alive \n\nThe service terminates the session and closes the connection if an inactivity or session timeout occurs:\n\n\n\n* An inactivity timeout occurs if audio is being sent by the client but the service detects no speech. The inactivity timeout is 30 seconds by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-1284-2889","score":13.562641,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_07578-512956-514877","score":13.082429,"text":"\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-512910-514831","score":13.082429,"text":"\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13455-7-1568","score":12.756298,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13790-7-1700","score":12.716494,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13369-9745-11531","score":12.401477,"text":"\nSee [Example 3: Interim results is true and low latency is false](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-low-latency-examples-three). \n interim_results=true low_latency=true The service returns interim results as it develops transcription hypotheses, and it sends final results for utterances as they become complete. The service delivers one or more interim results for each final result. The quality of interim results is identical to what you receive with previous-generation models. But because low_latency is true, the service returns interim and final results more quickly. See [Example 4: Interim results and low latency are both true](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-low-latency-examples-four). \n\n\n\n\n\n Interim results and low-latency examples \n\nThe following abbreviated WebSocket code shows how to request interim results, low-latency results, or both with the WebSocket interface. It specifies the following parameters:\n\n\n\n* The model query parameter of the \/v1\/recognize request passes the next-generation en-US_Telephony model, which supports low latency.\n* The inactivity_timeout parameter of the JSON start message sets the inactivity timeout to -1 (infinity), which prevents the request from timing out.\n* Both the interim_results and low_latency parameters are specified with the JSON start message of the request.\n\n\n\nTo show examples of results with all possible combinations of the parameters, the arguments for interim_results and low_latency are set to true or false in the examples in the following sections.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&model=en-US_Telephony';\nvar websocket = new WebSocket(wsURI);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interim"},{"document_id":"ibmcld_13429-163247-165127","score":12.31228,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_10833-0-1231","score":12.002837,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_13455-1311-2796","score":11.969038,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10852-48513-49624","score":11.847894,"text":"\n* [Reading an object with the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.4684505202}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-781104-782945","score":15.134092,"text":"\n* Select the Classic infrastructure tab.\n* From the Permissions tab, expand the Account category.\n* Select Add\/Upgrade Services.\n* Click the Save button.\n\n\n\n* Why am I unable to reach my web page through my CDN after configuring Hotlink Protection with protectionType ALLOW?\n\nLet's consider an example in which your website's domain for users is configured to be your CDN's domain\/hostname: cdn.example.com. When someone attempts to reach a web page by navigating directly from the browser's navigation bar, the browser typically does not send Referer headers in its HTTP request. For example, when you directly navigate in this way to https:\/\/cdn.example.com\/, your CDN considers that the request contains a non-match against the specified refererValues. When the CDN evaluates the appropriate effect or response through your Hotlink Protection, it determines that a non-match occurred. Therefore, your CDN denies access, rather than 'ALLOW'.\n* Can I use private endpoint of object storage in CDN settings?\n\nNo, CDN can only connect to object storage on public endpoints.\n* Can I use the Brotli feature in the CDN service?\n\nNo, the Brotli feature is not supported by our CDN service with Akamai.\n* How do I create a CDN endpoint without using the domain?\n\nYou can create a CDN endpoint without using the domain, but ONLY for a CDN of type Wildcard HTTPS. While creating a CDN of type Wildcard HTTPS, your CNAME acts as the CDN endpoint, and the CNAME is used to serve the traffic.\n* Is HTTP\/2 supported by the IBM Cloud Content Delivery Network service?\n\nYes, HTTP\/2 is supported by Akamai's Edge servers.\n* Is WebSocket supported by the IBM Cloud Content Delivery Network service?\n\nNo, WebSocket is not supported by Akamai's Edge servers.\n* With multiple file purges, what's the difference between a favorite group and an unfavorite group?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00377-9961-11870","score":14.811392,"text":"\nFor example, when you directly navigate in this way to https:\/\/cdn.example.com\/, your CDN considers that the request contains a non-match against the specified refererValues. When the CDN evaluates the appropriate effect or response through your Hotlink Protection, it determines that a non-match occurred. Therefore, your CDN denies access, rather than 'ALLOW'.\n\n\n\n\n\n Can I use private endpoint of object storage in CDN settings? \n\nNo, CDN can only connect to object storage on public endpoints.\n\n\n\n\n\n Can I use the Brotli feature in the CDN service? \n\nNo, the Brotli feature is not supported by our CDN service with Akamai.\n\n\n\n\n\n How do I create a CDN endpoint without using the domain? \n\nYou can create a CDN endpoint without using the domain, but ONLY for a CDN of type Wildcard HTTPS. While creating a CDN of type Wildcard HTTPS, your CNAME acts as the CDN endpoint, and the CNAME is used to serve the traffic.\n\n\n\n\n\n Is HTTP\/2 supported by the IBM Cloud Content Delivery Network service? \n\nYes, HTTP\/2 is supported by Akamai's Edge servers.\n\n\n\n\n\n Is WebSocket supported by the IBM Cloud Content Delivery Network service? \n\nNo, WebSocket is not supported by Akamai's Edge servers.\n\n\n\n\n\n With multiple file purges, what's the difference between a favorite group and an unfavorite group? \n\nA favorite is a permanent group, which means that it will never be deleted unless you change it to an unfavorite group. An unfavorite group is a temporary group. This type of group is automatically deleted after 15 days of inactivity.\n\nFavorite groups names must be unique. Unfavorite groups do not have this limitation.\n\n\n\n\n\n In what status is a CDN allowed to perform multiple file purges? \n\nMultiple file purges are allowed in the following states:\n\n\n\n* Running\n* Running - HTTP only\n* CNAME configuration required\n* Stopped\n\n\n\n\n\n\n\n Is IBM CDN compliant with Payment Card Industry Data Security Standard (PCI DSS)?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faqs"},{"document_id":"ibmcld_07578-514606-516646","score":14.767235,"text":"\nTargeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level \n Locations London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney \n HA Regional Regional Regional \n Security End-to-end encryption RBAC End-to-end encryption RBAC End-to-end encryption RBAC \n Monitoring IBM Cloud Monitoring IBM Cloud Monitoring IBM Cloud Monitoring \n Audit IBM Cloud Activity Tracker IBM Cloud Activity Tracker IBM Cloud Activity Tracker \n Support per your IBM Cloud support plan per your IBM Cloud support plan per your IBM Cloud support plan \n Percentage rollout Supported Not Supported Supported \n Snapshots Not Supported Not Supported Supported \n KMS integration (BYOK and KYOK) Not Supported Not Supported Supported \n\n\n\nSee the App Configuration catalog page for current pricing.\n* How do I audit App Configuration activity?\n\nIf you need strict governance and accountability within your App Configuration instance, create an instance of IBM Cloud Activity Tracker from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console. Use that to record and audit App Configuration activity.\n* How do I archive App Configuration activity data?\n\nIf you would like to retain a long-term record of activity within your App Configuration instance, either for audit purposes or for post-processing and data analysis, including application of machine learning models, create an instance of IBM Cloud Activity Tracker from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console. Then archive events from an IBM Cloud Activity Tracker instance into a bucket in an IBM Cloud Object Storage (COS) instance. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving).\n* In what regions is App Configuration available?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-514560-516600","score":14.767235,"text":"\nTargeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level \n Locations London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney \n HA Regional Regional Regional \n Security End-to-end encryption RBAC End-to-end encryption RBAC End-to-end encryption RBAC \n Monitoring IBM Cloud Monitoring IBM Cloud Monitoring IBM Cloud Monitoring \n Audit IBM Cloud Activity Tracker IBM Cloud Activity Tracker IBM Cloud Activity Tracker \n Support per your IBM Cloud support plan per your IBM Cloud support plan per your IBM Cloud support plan \n Percentage rollout Supported Not Supported Supported \n Snapshots Not Supported Not Supported Supported \n KMS integration (BYOK and KYOK) Not Supported Not Supported Supported \n\n\n\nSee the App Configuration catalog page for current pricing.\n* How do I audit App Configuration activity?\n\nIf you need strict governance and accountability within your App Configuration instance, create an instance of IBM Cloud Activity Tracker from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console. Use that to record and audit App Configuration activity.\n* How do I archive App Configuration activity data?\n\nIf you would like to retain a long-term record of activity within your App Configuration instance, either for audit purposes or for post-processing and data analysis, including application of machine learning models, create an instance of IBM Cloud Activity Tracker from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console. Then archive events from an IBM Cloud Activity Tracker instance into a bucket in an IBM Cloud Object Storage (COS) instance. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-archiving).\n* In what regions is App Configuration available?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02665-11195-13233","score":14.698109,"text":"\nMonthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level \n Locations London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney London, Dallas, Washington DC, Sydney \n HA Regional Regional Regional \n Security End-to-end encryption RBAC End-to-end encryption RBAC End-to-end encryption RBAC \n Monitoring IBM Cloud Monitoring IBM Cloud Monitoring IBM Cloud Monitoring \n Audit IBM Cloud Activity Tracker IBM Cloud Activity Tracker IBM Cloud Activity Tracker \n Support per your IBM Cloud support plan per your IBM Cloud support plan per your IBM Cloud support plan \n Percentage rollout Supported Not Supported Supported \n Snapshots Not Supported Not Supported Supported \n KMS integration (BYOK and KYOK) Not Supported Not Supported Supported \n\n\n\nSee the App Configuration catalog page for current pricing.\n\n\n\n\n\n How do I audit App Configuration activity?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_16727-781134-783054","score":14.62354,"text":"\n* Why am I unable to reach my web page through my CDN after configuring Hotlink Protection with protectionType ALLOW?\n\nLet's consider an example in which your website's domain for users is configured to be your CDN's domain\/hostname: cdn.example.com. When someone attempts to reach a web page by navigating directly from the browser's navigation bar, the browser typically does not send Referer headers in its HTTP request. For example, when you directly navigate in this way to https:\/\/cdn.example.com\/, your CDN considers that the request contains a non-match against the specified refererValues. When the CDN evaluates the appropriate effect or response through your Hotlink Protection, it determines that a non-match occurred. Therefore, your CDN denies access, rather than 'ALLOW'.\n* Can I use private endpoint of object storage in CDN settings?\n\nNo, CDN can only connect to object storage on public endpoints.\n* Can I use the Brotli feature in the CDN service?\n\nNo, the Brotli feature is not supported by our CDN service with Akamai.\n* How do I create a CDN endpoint without using the domain?\n\nYou can create a CDN endpoint without using the domain, but ONLY for a CDN of type Wildcard HTTPS. While creating a CDN of type Wildcard HTTPS, your CNAME acts as the CDN endpoint, and the CNAME is used to serve the traffic.\n* Is HTTP\/2 supported by the IBM Cloud Content Delivery Network service?\n\nYes, HTTP\/2 is supported by Akamai's Edge servers.\n* Is WebSocket supported by the IBM Cloud Content Delivery Network service?\n\nNo, WebSocket is not supported by Akamai's Edge servers.\n* With multiple file purges, what's the difference between a favorite group and an unfavorite group?\n\nA favorite is a permanent group, which means that it will never be deleted unless you change it to an unfavorite group. An unfavorite group is a temporary group. This type of group is automatically deleted after 15 days of inactivity.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13790-7-1700","score":14.466501,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13706-1495-3144","score":14.332272,"text":"\nSome languages and voices are available only for IBM Cloud\u00ae, not for IBM Cloud Pak\u00ae for Data. For more information about the available voices for all languages, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n How does the service synthesize audio? \n\nThe Text to Speech service offers voices that rely on neural technology to synthesize text to speech. The topic of synthesizing text to speech is inherently complex. For more information, see\n\n\n\n* [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices)\n* [The science behind the service](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-science)\n\n\n\n\n\n\n\n What are the output audio formats? \n\nBy default, the Text to Speech service returns audio in Ogg format with the Opus codec (audio\/ogg;codecs=opus). The service supports many other audio formats to suit your application needs. For more information, see [Supported audio formats](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formatsformats-supported).\n\n\n\n\n\n How do I convert my text to speech? \n\nTo submit text to the service for synthesized audio output, you make an HTTP or WebSocket request. You can use the API directly or use one of the Watson SDKs. [Getting started](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) offers examples of both the HTTP POST \/v1\/synthesize and GET \/v1\/synthesize methods. The [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech) shows examples of all interfaces and methods.\n\nThere is no graphical user interface for submitting text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-faq-usage"},{"document_id":"ibmcld_13455-26115-26611","score":14.125168,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-13886-15581","score":14.10202,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1301266833}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02877-40592-41932","score":13.498406,"text":"\n\"input_length\": \"<? input.text.length() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"input_length\": 5\n}\n}\n\n\n\n\n\n String.matches(String regexp) \n\nThis method returns true if the string matches the input regular expression.\n\nFor this input:\n\n\"Hello\".\n\nThis syntax:\n\n{\n\"conditions\": \"input.text.matches('^Hello$')\"\n}\n\nResult: The condition is true because the input text matches the regular expression ^Hello$.\n\n\n\n\n\n String.startsWith(String) \n\nThis method returns true if the string starts with the input substring.\n\nFor this input:\n\n\"What is your name?\".\n\nThis syntax:\n\n{\n\"conditions\": \"input.text.startsWith('What')\"\n}\n\nResults: The condition is true.\n\n\n\n\n\n String.substring(Integer beginIndex, Integer endIndex) \n\nThis method gets a substring with the character at beginIndex and the last character set to index before endIndex. The endIndex character is not included.\n\nFor this Dialog runtime context:\n\n{\n\"context\": {\n\"my_text\": \"This is a text.\"\n}\n}\n\nThis syntax:\n\n{\n\"context\": {\n\"my_text\": \"<? $my_text.substring(5, $my_text.length()) ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"my_text\": \"is a text.\"\n}\n}\n\n\n\n\n\n String.toLowerCase() \n\nThis method returns the original String converted to lowercase letters.\n\nFor this input:\n\n\"This is A DOG!\"\n\nThis syntax:\n\n{\n\"context\": {\n\"input_lower_case\": \"<? input.text.toLowerCase() ?>\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"},{"document_id":"ibmcld_03191-45937-47364","score":13.195224,"text":"\ninput.text.getMatch('(b [A-Za-z]+)',2) ?>\n\nFor the same user input, this expression returns and.\n\n\n\n\n\n String.isEmpty() \n\nThis method returns true if the string is an empty string, but not null.\n\nFor this Dialog runtime context:\n\n{\n\"context\": {\n\"my_text_variable\": \"\"\n}\n}\n\nThis syntax:\n\n{\n\"conditions\": \"$my_text_variable.isEmpty()\"\n}\n\nResults: The condition is true.\n\n\n\n\n\n String.length() \n\nThis method returns the character length of the string.\n\nFor this input:\n\n\"Hello\"\n\nThis syntax:\n\n{\n\"context\": {\n\"input_length\": \"<? input.text.length() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"input_length\": 5\n}\n}\n\n\n\n\n\n String.matches(String regexp) \n\nThis method returns true if the string matches the input regular expression.\n\nFor this input:\n\n\"Hello\".\n\nThis syntax:\n\n{\n\"conditions\": \"input.text.matches('^Hello$')\"\n}\n\nResult: The condition is true because the input text matches the regular expression ^Hello$.\n\n\n\n\n\n String.startsWith(String) \n\nThis method returns true if the string starts with the input substring.\n\nFor this input:\n\n\"What is your name?\".\n\nThis syntax:\n\n{\n\"conditions\": \"input.text.startsWith('What')\"\n}\n\nResults: The condition is true.\n\n\n\n\n\n String.substring(Integer beginIndex, Integer endIndex) \n\nThis method gets a substring with the character at beginIndex and the last character set to index before endIndex. The endIndex character is not included.\n\nFor this Dialog runtime context:\n\n{\n\"context\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_13309-9345-11306","score":12.904837,"text":"\nFor a custom word, enter a commonly used notation that reflects the word's usage and pronunciation. This allows for more efficient customization. For instance, the following example does not reliably produce the string Artificial_Intelligence in response to the utterance \u30a8\u30fc\u30a2\u30a4 because Artificial_Intelligence and \u4eba\u5de5\u77e5\u80fd are not generally uttered as AI:\n\n{\"word\": \"Artificial_Intelligence\", \"sounds_like\": [\"\u30a8\u30fc\u30a2\u30a4\"], \"display_as\": \"Artificial_Intelligence\"},\n{\"word\": \"\u4eba\u5de5\u77e5\u80fd\", \"sounds_like\": [\"\u30a8\u30fc\u30a2\u30a4\"], \"display_as\": \"Artificial_Intelligence\"}\n\nBecause the context is typically something like \u3053\u308c\u304b\u3089\uff21\uff29\u306f\u307e\u3059\u307e\u3059\u767a\u5c55\u3057\u3066\u304d\u307e\u3059, \uff21\uff29 is the most appropriate notation for the sounds-like \u30a8\u30fc\u30a2\u30a4. The following example is therefore likely to yield better results:\n\n{\"word\": \"\uff21\uff29\", \"sounds_like\": [\"\u30a8\u30fc\u30a2\u30a4\"], \"display_as\": \"Artificial_Intelligence\"}\n\nFinally, in custom words, half-width alphabetic characters are converted to full-width characters. English uppercase and lowercase characters are treated as different characters.\n\n\n\n\n\n\n\n Working with corpora for next-generation models \n\nYou use the POST \/v1\/customizations\/{customization_id}\/corpora\/{corpus_name} method to add a corpus to a custom model. A corpus is a plain text file that contains sample sentences from your domain. The following example shows an abbreviated corpus for the healthcare domain. A corpus file is typically much longer.\n\nAm I at risk for health problems during travel?\nSome people are more likely to have health problems when traveling outside the United States.\nHow Is Coronary Microvascular Disease Treated?\nIf you're diagnosed with coronary MVD and also have anemia, you may benefit from treatment for that condition.\nAnemia is thought to slow the growth of cells needed to repair damaged blood vessels.\nWhat causes autoimmune hepatitis?\nA combination of autoimmunity, environmental triggers, and a genetic predisposition can lead to autoimmune hepatitis.\nWhat research is being done for Spinal Cord Injury?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ng"},{"document_id":"ibmcld_03191-47016-48329","score":12.688487,"text":"\n\"conditions\": \"input.text.startsWith('What')\"\n}\n\nResults: The condition is true.\n\n\n\n\n\n String.substring(Integer beginIndex, Integer endIndex) \n\nThis method gets a substring with the character at beginIndex and the last character set to index before endIndex. The endIndex character is not included.\n\nFor this Dialog runtime context:\n\n{\n\"context\": {\n\"my_text\": \"This is a text.\"\n}\n}\n\nThis syntax:\n\n{\n\"context\": {\n\"my_text\": \"<? $my_text.substring(5, $my_text.length()) ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"my_text\": \"is a text.\"\n}\n}\n\n\n\n\n\n String.toJson() \n\nThis method parses a string that contains JSON data and returns a JSON object or array, as in this example:\n\n${json_var}.toJson()\n\nIf the context variable ${json_var} contains the following string:\n\n\"{ \"firstname\": \"John\", \"lastname\": \"Doe\" }\"\n\nthe toJson() method returns the following object:\n\n{\n\"firstname\": \"John\",\n\"lastname\": \"Doe\"\n}\n\n\n\n\n\n String.toLowerCase() \n\nThis method returns the original String converted to lowercase letters.\n\nFor this input:\n\n\"This is A DOG!\"\n\nThis syntax:\n\n{\n\"context\": {\n\"input_lower_case\": \"<? input.text.toLowerCase() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"input_lower_case\": \"this is a dog!\"\n}\n}\n\n\n\n\n\n String.toUpperCase() \n\nThis method returns the original String converted to uppercase letters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_07578-47319-49349","score":12.610031,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-47304-49334","score":12.610031,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02934-21697-23312","score":12.574647,"text":"\n}\n}\n\nSee [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods) for other reformatting ideas.\n\n\n\n\n\n Dealing with zeros \n\nUsing @sys-number in a slot condition is helpful for capturing any numbers that users specify in their input. However, it does not behave as expected when users specify the number zero (0). Instead of treating zero as a valid number, the condition is evaluated to false, and your assistant prompts the user for a number again. To prevent this behavior, check for an @sys-number mention that is greater than or equal to zero in the slot condition.\n\nTo ensure that a slot condition that checks for number mentions deals with zeros properly, complete the following step:\n\n\n\n1. Add @sys-number >= 0 to the slot condition field, and then provide the context variable name and text prompt.\n\nWhat you check for in the input is also what is saved in the slot context variable. However, in this case, you want only the number (such as 5) to be saved. You do not want to save 5 > = 0. To change what is saved, you must edit the value of the context variable.\n2. Open the slot to edit it by clicking the Edit slot![Edit slot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/edit-slot.png) icon. From the Options![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) menu, open the JSON editor.\n3. Change the context variable value.\n\nThe value will look like this:\n\n{\n\"context\": {\n\"number\": \"@sys-number >= 0\"\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_07174-16707-18757","score":12.570869,"text":"\n* body_cells: An array of cells that are not table header or column header or row header cells, of the current table with corresponding row and column header associations. Each body cell is defined as a collection of the following items:\n\n\n\n* cell_id: The unique ID of the cell in the current table.\n* location: The location of the cell in the input document as defined by its begin and end indexes.\n* text: The textual contents of the cell from the input document without associated markup content.\n* row_index_begin: The begin index of this cell's row location in the current table.\n* row_index_end: The end index of this cell's row location in the current table.\n* column_index_begin: The begin index of this cell's column location in the current table.\n* column_index_end: The end index of this cell's column location in the current table.\n* row_header_ids: An array of values, each being the cell_id value of a row header that is applicable to this body cell.\n* row_header_texts: An array of values, each being the text value of a row header that is applicable to this body cell.\n* row_header_texts_normalized: If you provide customization input, the normalized version of the row header texts according to the customization; otherwise, the same value as row_header_texts.\n* column_header_ids: An array of values, each being the cell_id value of a column header that is applicable to this body cell.\n* column_header_texts: An array of values, each being the text value of a column header that is applicable to this body cell.\n* column_header_texts_normalized: If you provide customization input, the normalized version of the column header texts according to the customization; otherwise, the same value as column_header_texts.\n* attributes: An array that identifies document attributes. Each object in the array consists of three elements:\n\n\n\n* type: The type of attribute. Possible values are Address, Currency, DateTime, Duration, Location, Number, Organization, Percentage, and Person.\n* text: The text that is associated with the attribute.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-output_schema"},{"document_id":"ibmcld_13336-3083-5168","score":12.554298,"text":"\nAnd, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan? \n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n\n\n\n\n What does \"pricing per minute\" mean? \n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\n\n\n\n\n Do you round up to the nearest minute for every call to the API? \n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_16261-15807-17466","score":12.527925,"text":"\n\/\/ Prompt for the next round of input unless skip_user_input is true.\nlet newMessageFromUser = '';\nif (result.context.global.system.skip_user_input !== true) {\nnewMessageFromUser = prompt('>> ');\n}\n\nif (newMessageFromUser !== 'quit') {\nnewMessageInput = {\nmessageType: 'text',\ntext: newMessageFromUser,\n}\nsendMessage(newMessageInput, context);\n}\n}\n\nThe only change from the previous example is that we are now storing the context received from the assistant in a variable called context, and we're sending it back with the next round of user input:\n\nThe only change from the previous example is that we are now storing the context received from the assistant in a variable called context, and we're sending it back with the next round of user input:\n\n\n\n* Python\n* Node\n\n\n\nresponse = assistant.message_stateless(\nassistant_id,\ninput = message_input,\ncontext = context\n).get_result()\n\nassistant\n.messageStateless({\nassistantId,\ninput: messageInput,\ncontext: context,\n})\n\nThis ensures that the context is maintained from one turn to the next, so the Watson Assistant service no longer thinks every turn is the first:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nHi, Robert! How can I help you?\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":25.036194,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16280-3111-5196","score":22.25033,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_16291-7-1781","score":22.204563,"text":"\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https:\/\/www.nice.com\/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https:\/\/help.nice-incontact.com\/content\/resources\/images\/icons\/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03179-4-1759","score":21.97626,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16288-7-2218","score":21.40443,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16297-7-1893","score":21.349922,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_16337-27360-29109","score":21.1602,"text":"\nHow can I help you?\"\n}\n]\n}\n}\n],\n\"selection_policy\": \"sequential\"\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n text_to_speech \n\nSends a command to the Text to Speech service instance used by the phone integration. These commands can dynamically change the configuration or behavior of the service during a conversation.\n\n\n\n Integration channel support \n\n\n\n Phone \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string text_to_speech Y \n command_info object Information specifying the command to send to the Text to Speech. Y \n command_info.type string The command to send (configure, disable_barge_in, or enable_barge_in). Y \n command_info.parameters object See [Applying advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* configure: Dynamically updates the Text to Speech configuration. Configuration changes can be applied only to the next conversation turn, or for the rest of the session.\n* disable_barge_in: Disables speech barge-in so that playback from the phone integration is not interrupted when the customer speaks.\n* enable_barge_in: Enables speech barge-in so that the customer can interrupt playback from the phone integration by speaking.\n\n\n\nFor detailed information about how to use each of these commands, see [Applying advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced).\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_03157-4-2076","score":21.002098,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Deploying your assistant \n\nAfter you have built and tested your assistant, you can make it available for customers to use.\n\nThere are multiple options for deploying your assistant, depending on how you want your customers to interact with it. A channel is a communication platform through which you want to make your assistant available, such as a website or a telephone system; an assistant can be deployed to one or more channels. To deploy to a channel, you use an integration, which is essentially an adapter or interface that enables the assistant to communicate through a channel.\n\nIn most cases, an assistant is deployed using one of these integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone, using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n Other channels \n\nIn addition to the web chat and phone integrations, Watson Assistant provides integrations you can use to deploy your assistant to numerous other channels:\n\n\n\n* [Facebook Messenger](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-facebook)\n* [Intercom](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-intercom)\n* [Slack](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-overview"},{"document_id":"ibmcld_16321-19290-20983","score":20.854486,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03158-21896-24017","score":20.423468,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-6287-8401","score":52.432236,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03165-4477-6547","score":51.61674,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16321-1374-3426","score":48.431904,"text":"\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-1272-3273","score":47.691547,"text":"\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same dialog node or step. For more information, see [Defining a sequence of phone actions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sequence).\n\nFor reference information about phone-specific repsonse types and related context variables, see [Phone context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context).\n\n\n\n Adding phone-specific responses to your dialog or actions \n\nTo initiate a voice-specific interaction from a dialog node or a step in an action, add a response within the output.generic array using the appropriate response type.\n\nAlthough many response types can be specified using the Watson Assistant user interface, phone-specific response types must currently be added using the JSON editor.\n\nFor more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from a dialog node or action step, you can dynamically change the Speech to Text configuration during a conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03158-21896-24017","score":45.338547,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-15027-17056","score":44.905422,"text":"\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-troubleshootingphone-troubleshooting-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n5. If your SIP trunk provider is not already allowlisted with the Watson Assistant region you are migrating to, follow these [instructions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup) to get access to your SIP trunk.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16294-7-1981","score":43.8027,"text":"\nIntegrating with SMS \n\nIBM Cloud\n\nAdd a text messaging integration so your assistant can exchange messages with your customers.\n\nThe Short Messaging Service (SMS) supports text-only messages. Typically, SMS restricts the text message length to 160 characters. The Multimedia Messaging Service (MMS) supports sending images and text messages that are over 160 characters in length. When you create a phone number with Twilio, MMS message support is included automatically. IntelePeer MMS message support is not yet available.\n\nCustomers send text messages to your hosted phone number. Twilio and IntelePeer use a messaging webhook that you set up to send a POST request with the text message body to your assistant. Each response from the assistant is sent back to Twilio or IntelePeer to be converted to an outbound SMS message that is sent to the customer. The responses are sent to the SMS provider's API for processing. You provide your SMS provider's authentication token information, which serve as your API access credentials.\n\nRefer to the following sections to set up the integration for your SMS provider:\n\n\n\n* [Integrating SMS with Twilio](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-smsdeploy-sms-twilio)\n* [Integrating SMS with IntelePeer](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-smsdeploy-sms-intelepeer)\n\n\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone).\n\n\n\n Integrating SMS with Twilio \n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up an SMS with Twilio account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_03158-23545-25765","score":41.594757,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03165-1496-3390","score":41.112953,"text":"\n[Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n Migrating from Voice Agent with Watson \n\nIf you created an IBM\u00ae Voice Agent with Watson service instance in IBM Cloud to enable customers to exchange text messages with an assistant, use the SMS with Twilio integration instead.\n\nThe SMS with Twilio integration provides a more seamless integration with your assistant and supports as many Twilio phone numbers as needed. However, the integration currently does not support the following functions:\n\n\n\n* Starting an SMS-only interaction with an outgoing text\n* Configuring backup locations\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant SMS with Twilio integration, complete the following step:\n\n\n\n1. Do one of the following things:\n\n\n\n* If your Voice Agent with Watson service instance uses an SMS service provider other than Twilio, you cannot continue to use it. You must create an SMS account with Twilio first. Complete the [Before you begin](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-smsdeploy-sms-service-setup) steps to create the account. Next, set up the integration.\n* If your Voice Agent with Watson service instance uses Twilio as its SMS provider, you can go directly to setting up the integration.\n\n\n\n\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03158-8929-11062","score":40.49402,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16287-7751-9832","score":31.020546,"text":"\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images\/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03165-4477-6547","score":28.782211,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16287-6128-8192","score":27.28399,"text":"\nFor more information about language models, see [Languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models) in the Speech to Text documentation.\n\nClick Next.\n10. On the Text to Speech page, select the instance of the Text to Speech service you want to use for the phone integration.\n\n\n\n* If you have existing Text to Speech instances, select the instance you want to use from the list.\n* If you do not have any existing Text to Speech instances, click Create new instance to create a new Standard instance.\n\n\n\n11. In the Choose your Text to Speech voice field, select the voice you want to use.\n\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of speech instances that occurs outside of your assistant is charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03158-6114-8033","score":26.952122,"text":"\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges that are incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of the speech instances that occurs outside of your assistant are charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number so it is ready to use might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured using a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods to add phone numbers:\n\n\n\n* To add phone numbers one by one, type each number in the table, along with an optional description. Click the checkmark icon ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-21896-24017","score":26.512054,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_07578-1268470-1270517","score":25.872612,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1271119-1273166","score":25.872612,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02064-17718-19825","score":25.636307,"text":"\nHow do I determine how many policies exist in my account? \n\nYou can [check the number of policies in an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-policy-limits) by using the CLI to ensure that you don't exceed the limit for your account.\n\n\n\n\n\n What are verification methods and what they are used for? \n\nVerification methods are used to prove your identity and access the Verification methods and authentication factors page.\n\nThe first time that you log in to your account after MFA settings are updated, you also need to verify your identity by using two different verification methods. Verification methods include email, text, or phone call, and you can use any combination of those options to verify your identity. After you verify your identity, you set up and provide details for your authentication factor on the [Verification methods and authentication factors](https:\/\/iam.cloud.ibm.com\/mysecurity) page.\n\n\n\n\n\n What are authentication factors and what are they used for? \n\nThese factors can be something that you have, like a U2F security key, or that you receive, like a time-based one time passcode (TOTP) or OTP. If an administrator enables MFA in at least one of the accounts you are a member of, you must provide two or more factors each time you log in. If you are a member in multiple accounts and at least one of the accounts uses MFA, MFA is required each time that you log in. This applies regardless of the account that you are trying to access. For more information, see [Managing verification methods and MFA factors](https:\/\/cloud.ibm.com\/docs\/account?topic=account-verification-authentication).\n\n\n\n\n\n How do I reset a verification method? \n\nA verification method becomes inaccessible if a phone number or email address that's associated with your identity changes or you no longer have access to it. To reset a verification method, [open a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and add a verification method that you can use to access the Verification methods and authentication factors page.\n\n\n\n\n\n How can I get a new QR code for MFA setup?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamfaq"},{"document_id":"ibmcld_07578-1111048-1113137","score":25.636307,"text":"\n* How do I determine how many policies exist in my account?\n\nYou can [check the number of policies in an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-policy-limits) by using the CLI to ensure that you don't exceed the limit for your account.\n* What are verification methods and what they are used for?\n\nVerification methods are used to prove your identity and access the Verification methods and authentication factors page.\n\nThe first time that you log in to your account after MFA settings are updated, you also need to verify your identity by using two different verification methods. Verification methods include email, text, or phone call, and you can use any combination of those options to verify your identity. After you verify your identity, you set up and provide details for your authentication factor on the [Verification methods and authentication factors](https:\/\/iam.cloud.ibm.com\/mysecurity) page.\n* What are authentication factors and what are they used for?\n\nThese factors can be something that you have, like a U2F security key, or that you receive, like a time-based one time passcode (TOTP) or OTP. If an administrator enables MFA in at least one of the accounts you are a member of, you must provide two or more factors each time you log in. If you are a member in multiple accounts and at least one of the accounts uses MFA, MFA is required each time that you log in. This applies regardless of the account that you are trying to access. For more information, see [Managing verification methods and MFA factors](https:\/\/cloud.ibm.com\/docs\/account?topic=account-verification-authentication).\n* How do I reset a verification method?\n\nA verification method becomes inaccessible if a phone number or email address that's associated with your identity changes or you no longer have access to it. To reset a verification method, [open a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and add a verification method that you can use to access the Verification methods and authentication factors page.\n* How can I get a new QR code for MFA setup?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1113529-1115618","score":25.636307,"text":"\n* How do I determine how many policies exist in my account?\n\nYou can [check the number of policies in an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-policy-limits) by using the CLI to ensure that you don't exceed the limit for your account.\n* What are verification methods and what they are used for?\n\nVerification methods are used to prove your identity and access the Verification methods and authentication factors page.\n\nThe first time that you log in to your account after MFA settings are updated, you also need to verify your identity by using two different verification methods. Verification methods include email, text, or phone call, and you can use any combination of those options to verify your identity. After you verify your identity, you set up and provide details for your authentication factor on the [Verification methods and authentication factors](https:\/\/iam.cloud.ibm.com\/mysecurity) page.\n* What are authentication factors and what are they used for?\n\nThese factors can be something that you have, like a U2F security key, or that you receive, like a time-based one time passcode (TOTP) or OTP. If an administrator enables MFA in at least one of the accounts you are a member of, you must provide two or more factors each time you log in. If you are a member in multiple accounts and at least one of the accounts uses MFA, MFA is required each time that you log in. This applies regardless of the account that you are trying to access. For more information, see [Managing verification methods and MFA factors](https:\/\/cloud.ibm.com\/docs\/account?topic=account-verification-authentication).\n* How do I reset a verification method?\n\nA verification method becomes inaccessible if a phone number or email address that's associated with your identity changes or you no longer have access to it. To reset a verification method, [open a support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and add a verification method that you can use to access the Verification methods and authentication factors page.\n* How can I get a new QR code for MFA setup?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1223068-1225369","score":34.916428,"text":"\nThe application provider and consumer might be the same when the organization providing the application also consumes it (for example, a financial institution deploys an application for internal use by others in their company). Or, they can be different when a third-party ISV provides an application for a financial institution to use.\n\nApplication providers who are within financial institutions are not beholden to the IBM Cloud Framework for Financial Services control requirements.\n* What does it mean for a service to be IBM Cloud for Financial Services Validated?\n\nIBM Cloud for Financial Services Validated designates that an IBM Cloud service or ecosystem partner service has evidenced compliance to the controls of the IBM Cloud Framework for Financial Services and can be used to build solutions that might themselves be validated.\n* Should I only use IBM or third-party managed services that are IBM Cloud for Financial Services Validated?\n\nGenerally speaking, you should strive to use only services which are Financial Services Validated in your solutions. However, depending on your circumstance there may be exceptions. See the best practice [Use only services that are IBM Cloud for Financial Services Validated](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-financial-services-validated-services) for more details and potential exceptions.\n* What if I don't want to use managed services, but I want to install and manage my own software?\n\nSelf-installed (or \"bring your own\") software from third parties is permitted without special approval. Examples include databases, logging stacks, web application firewalls, and so on. But just like first-party software you might develop and deploy, self-installed third-party software must comply with all of the requirements of the IBM Cloud Framework for Financial Services. And, it is your responsibility to provide appropriate supporting evidence.\n\nFor more information, see [Ensure all usage of software meets IBM Cloud Framework for Financial Services controls](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-self-installed-software).\n\n\n\nLanding zone\n\n\n\n* What is a deployable architecture?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1225701-1228002","score":34.916428,"text":"\nThe application provider and consumer might be the same when the organization providing the application also consumes it (for example, a financial institution deploys an application for internal use by others in their company). Or, they can be different when a third-party ISV provides an application for a financial institution to use.\n\nApplication providers who are within financial institutions are not beholden to the IBM Cloud Framework for Financial Services control requirements.\n* What does it mean for a service to be IBM Cloud for Financial Services Validated?\n\nIBM Cloud for Financial Services Validated designates that an IBM Cloud service or ecosystem partner service has evidenced compliance to the controls of the IBM Cloud Framework for Financial Services and can be used to build solutions that might themselves be validated.\n* Should I only use IBM or third-party managed services that are IBM Cloud for Financial Services Validated?\n\nGenerally speaking, you should strive to use only services which are Financial Services Validated in your solutions. However, depending on your circumstance there may be exceptions. See the best practice [Use only services that are IBM Cloud for Financial Services Validated](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-financial-services-validated-services) for more details and potential exceptions.\n* What if I don't want to use managed services, but I want to install and manage my own software?\n\nSelf-installed (or \"bring your own\") software from third parties is permitted without special approval. Examples include databases, logging stacks, web application firewalls, and so on. But just like first-party software you might develop and deploy, self-installed third-party software must comply with all of the requirements of the IBM Cloud Framework for Financial Services. And, it is your responsibility to provide appropriate supporting evidence.\n\nFor more information, see [Ensure all usage of software meets IBM Cloud Framework for Financial Services controls](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-self-installed-software).\n\n\n\nLanding zone\n\n\n\n* What is a deployable architecture?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16288-10521-12298","score":33.543884,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-17978-19852","score":32.859554,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_07984-82875-84343","score":32.59451,"text":"\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-onboarding-to-catalognext-steps)\n\n\n\n\n\n\n\n FAQs for IBM Cloud for Financial Services \n\n[FAQs for IBM Cloud for Financial Services](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworkfaqs-framework)\n\n\n\n* [What are the supported reference architectures for the IBM Cloud for Financial Services?](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworkreference-architectures)\n* [What is a consumer and what is an application provider?](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworkconsumers-providers)\n* [What does it mean for a service to be IBM Cloud for Financial Services Validated?](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworkfinancial-services-validated)\n* [Should I only use IBM or third-party managed services that are IBM Cloud for Financial Services Validated?](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworknot-financial-services-validated)\n* [What if I don't want to use managed services, but I want to install and manage my own software?](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-frameworkself-installed-software)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-sitemap"},{"document_id":"ibmcld_07945-7-2453","score":32.50412,"text":"\nFAQs for IBM Cloud for Financial Services \n\nAnswers to common questions about IBM Cloud for Financial Services and the IBM Cloud Framework for Financial Services.\n\n\n\n What are the supported reference architectures for the IBM Cloud for Financial Services? \n\nSee [references architectures](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-reference-architecture-overview).\n\n\n\n\n\n What is a consumer and what is an application provider? \n\nWe refer to the entity that uses (consumes) the application as the consumer and the entity that deploys (provides) the application as the application provider. This documentation generally assumes that you are a an application provider.\n\nThe application provider and consumer might be the same when the organization providing the application also consumes it (for example, a financial institution deploys an application for internal use by others in their company). Or, they can be different when a third-party ISV provides an application for a financial institution to use.\n\nApplication providers who are within financial institutions are not beholden to the IBM Cloud Framework for Financial Services control requirements.\n\n\n\n\n\n What does it mean for a service to be IBM Cloud for Financial Services Validated? \n\nIBM Cloud for Financial Services Validated designates that an IBM Cloud service or ecosystem partner service has evidenced compliance to the controls of the IBM Cloud Framework for Financial Services and can be used to build solutions that might themselves be validated.\n\n\n\n\n\n Should I only use IBM or third-party managed services that are IBM Cloud for Financial Services Validated? \n\nGenerally speaking, you should strive to use only services which are Financial Services Validated in your solutions. However, depending on your circumstance there may be exceptions. See the best practice [Use only services that are IBM Cloud for Financial Services Validated](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-financial-services-validated-services) for more details and potential exceptions.\n\n\n\n\n\n What if I don't want to use managed services, but I want to install and manage my own software? \n\nSelf-installed (or \"bring your own\") software from third parties is permitted without special approval. Examples include databases, logging stacks, web application firewalls, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-faqs-framework"},{"document_id":"ibmcld_16321-19290-20983","score":31.850983,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13549-7-2081","score":30.94764,"text":"\nFAQs: SSL certificates \n\n\n\n Why doesn't the SSL certificate that I ordered automatically show up on the SSL certificates screen? \n\nSSL certificates are issued by a third-party certificate authority, which sends all of the certificate details directly to you in a confidential email. After receiving that email, you have the option to [import the SSL certificate](https:\/\/cloud.ibm.com\/docs\/infrastructure\/ssl-certificates?topic=ssl-certificates-importing-ssl-certificatesimporting-ssl-certificates) to the IBM Cloud\u00ae console should you choose to use the certificate with IBM Cloud products and services. Because IBM Cloud never receives the details for SSL certificate, data cannot be imported automatically.\n\n\n\n\n\n What is an SSL certificate? \n\nSSL certificates are enabled by websites as a security measure to protect the user. They are generally used when you are required to transmit confidential information to a website, such as name, address, credit card numbers, and other personal data or are managing data that requires authentication (such as in the IBM Cloud console). SSL certificates are requested by the company that runs the website but are issued by a trusted, third-party company that ensures the validity of the website. Secure websites are preceded by HTTPS in the URL, as opposed to the standard HTTP.\n\n\n\n\n\n How can I order an SHA2 SSL? \n\nIf you already ordered an SSL and it is showing errors that the SSL certificate is using SHA-1 instead of SHA-2, you need to request that the SSL is re-issued. You can do this by submitting a ticket.\n\nIf you have not yet ordered an SSL from IBM Cloud and need to order one with SHA-2, submit a ticket to manually order an SSL for the domain in question. IBM Cloud console still automatically creates SSL certificates using SHA-1, so if you do this, you will then need to have it re-issued.\n\n\n\n\n\n Why do I need to choose an email? \n\nTo create an SSL certificate, you need to verify that you own the domain where you are requesting the SSL certificate. You can verify that you own the domain in one of two ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ssl-certificates?topic=ssl-certificates-faqs-ssl-certificates"},{"document_id":"ibmcld_07578-1139013-1141076","score":30.464365,"text":"\n* Who has access to my project?\n\nAny user that is a member of your account that is assigned access to the IBM Cloud Projects service, Schematics, and the resource group for your project can access your project.\n\n\n\nSelling on IBM Cloud\n\n\n\n* What are the different metering options for plans?\n\nIBM Cloud\u00ae supports multiple models for aggregating service usage. Service providers measure various metrics on the created instances and submit those measures to the metering service. The rating service aggregates the submitted usage into different buckets (instance, resource group, and account) based on the model that service providers choose. The aggregation and rating models for all the metrics in a plan are contained in the metering and rating definition documents for the plan.\n\nYou're required to automate hourly usage submission by using the metering service API if you offer a metered plan.\n\nFor more information on metering, see [Metering integration](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-meteringinterameteringintera). For more information about submitting metered usage, see [Submitting usage for metered plans](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-submitusagesubmitusage).\n* How do I receive payments for my services?\n\nThird-party services that offer paid usage-based pricing plans receive disbursements through an Electronic Funds Transfer (EFT). To set up this method to receive disbursements in IBM Cloud Partner Center Sell, you must submit the EFT form when you set up your first usage-based pricing plan. You can download the form from the Payments to me page.\n* When are disbursements sent to me?\n\nIf any disbursements are due to a third-party provider, they are sent on the last business day of the second calendar month. For example, March activity would be paid on the last calendar day of May, unless the last day of the month falls on a weekend or holiday. In this case, disbursements are sent on the next business day. Disbursements are calculated from beginning of the month to the end of the month.\n* What is the fee structure?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1141646-1143709","score":30.464365,"text":"\n* Who has access to my project?\n\nAny user that is a member of your account that is assigned access to the IBM Cloud Projects service, Schematics, and the resource group for your project can access your project.\n\n\n\nSelling on IBM Cloud\n\n\n\n* What are the different metering options for plans?\n\nIBM Cloud\u00ae supports multiple models for aggregating service usage. Service providers measure various metrics on the created instances and submit those measures to the metering service. The rating service aggregates the submitted usage into different buckets (instance, resource group, and account) based on the model that service providers choose. The aggregation and rating models for all the metrics in a plan are contained in the metering and rating definition documents for the plan.\n\nYou're required to automate hourly usage submission by using the metering service API if you offer a metered plan.\n\nFor more information on metering, see [Metering integration](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-meteringinterameteringintera). For more information about submitting metered usage, see [Submitting usage for metered plans](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-submitusagesubmitusage).\n* How do I receive payments for my services?\n\nThird-party services that offer paid usage-based pricing plans receive disbursements through an Electronic Funds Transfer (EFT). To set up this method to receive disbursements in IBM Cloud Partner Center Sell, you must submit the EFT form when you set up your first usage-based pricing plan. You can download the form from the Payments to me page.\n* When are disbursements sent to me?\n\nIf any disbursements are due to a third-party provider, they are sent on the last business day of the second calendar month. For example, March activity would be paid on the last calendar day of May, unless the last day of the month falls on a weekend or holiday. In this case, disbursements are sent on the next business day. Disbursements are calculated from beginning of the month to the end of the month.\n* What is the fee structure?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-7-1778","score":24.258633,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_04621-58586-59933","score":18.360174,"text":"\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1\n: The SDK for Node.js buildpack v3.25.1 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.16.0, 8.11.4, 8.15.0, 10.10.0 and 10.15.0. The default is latest 6.x, so it is currently 6.16.0. The versions 6.15.0, 8.14.0 and 10.14.0 that were included in the last buildpack had a regression. The regressions has been fixed in 6.16.0, 8.15.0 and 10.15.0 which are now included instead.\n\n\n\n\n\n 7 January 2019 \n\nUpdated Node.js buildpack v3.25\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_04621-59443-60826","score":16.663557,"text":"\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.\n\n\n\n* The default Liberty runtime version was updated to the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n* The monthly Liberty runtime version was updated to the 2018.11.0.0 release.\n* The IBM JRE version was updated to 8 SR5 FP26.\n\n\n\n\n\n\n\n 12 December 2018 \n\nUpdated ASP.NET Core buildpack v2.1-20181205-1536\n: This release includes version 2.2.0 of the dotnet-core Cloud Foundry buildpack.\n\n\n\n* Add support for .NET ASP.NET Core 2.1.2\n* Add support for .NET ASP.NET Core 2.1.4\n* Add support for .NET ASP.NET Core 2.1.5\n* Add support for .NET Runtime 1.0.11\n* Add support for .NET Runtime 1.0.12\n* Add support for .NET Runtime 1.1.9\n* Add support for .NET Runtime 1.1.10\n* Add support for .NET Runtime 2.0.7\n* Add support for .NET Runtime 2.0.9\n* Add support for .NET Runtime 2.1.2\n* Add support for .NET Runtime 2.1.5\n* Add support for .NET SDK 1.0.4","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_08671-114654-115976","score":14.395985,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-hpcs-ibm-access)\n* [How does IBM offer a unique and secure process for service initialization (key ceremony)?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-hpcs-user-access)\n* [What is a 140-2 FIPS Level 4 Certification and how can I validate it?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-fips-level4-meaning)\n* [What is the difference between FIPS 140-2 Level 1, 2, 3, and Level 4?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-fips-levels)\n* [How to understand the key hierarchy for Hyper Protect Crypto Services KYOK?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-cryptographic-algorithms)\n\n[How does EP11 differ from PKCS #11?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-ep11-pkcs11)\n* [What EP11 mechanisms are supported by the GREP11 functions?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-EP11-mechanisms)\n* [What compliance standards does Hyper Protect Crypto Services meet?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-security-compliancefaq-compliance-standards)\n* [Can I monitor my service instance?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_07578-804493-806529","score":12.583831,"text":"\nDepending on how traffic is actually routed, what protocols the queries use, and other factors, the actual rate limit might vary around this number. After a DNS query rate exceeds this rate limit, DNS Services resolvers no longer respond to the excess DNS queries.\n\n\n\nDirect Link\n\n\n\n* How does the new Direct Link differ from Direct Link on Classic?\n\nThe Direct Link offering differs from Direct Link on Classic in that Direct Link is decoupled from classic IaaS, and exists only in the local cross-connect router (XCR). This design enables native connectivity to VPC and future capabilities without being forced into the classic IaaS network.\n\nDirect Link allows connectivity to both classic IaaS as well as VPCs, whereas IBM Cloud Direct Link on Classic always connects to the IaaS network and a global VRF first. IBM Cloud Direct Link on Classic can only reach the VPC on a limited basis using a feature named Classic Access and by adding global routing to the direct link. See [Setting up access to your Classic Infrastructure from VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) for more information.\n\nFor more information about the differences between the new Direct Link offering and the classic version (Direct Link on Classic), see [How do I know which Direct Link solution to order?](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-get-started-with-ibm-cloud-direct-linkget-started-solution-to-order).\n* Where can I find Direct Link pricing and what do I pay for?\n\nSee the following FAQs for details.\n\n\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-804366-806402","score":12.583831,"text":"\nDepending on how traffic is actually routed, what protocols the queries use, and other factors, the actual rate limit might vary around this number. After a DNS query rate exceeds this rate limit, DNS Services resolvers no longer respond to the excess DNS queries.\n\n\n\nDirect Link\n\n\n\n* How does the new Direct Link differ from Direct Link on Classic?\n\nThe Direct Link offering differs from Direct Link on Classic in that Direct Link is decoupled from classic IaaS, and exists only in the local cross-connect router (XCR). This design enables native connectivity to VPC and future capabilities without being forced into the classic IaaS network.\n\nDirect Link allows connectivity to both classic IaaS as well as VPCs, whereas IBM Cloud Direct Link on Classic always connects to the IaaS network and a global VRF first. IBM Cloud Direct Link on Classic can only reach the VPC on a limited basis using a feature named Classic Access and by adding global routing to the direct link. See [Setting up access to your Classic Infrastructure from VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) for more information.\n\nFor more information about the differences between the new Direct Link offering and the classic version (Direct Link on Classic), see [How do I know which Direct Link solution to order?](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-get-started-with-ibm-cloud-direct-linkget-started-solution-to-order).\n* Where can I find Direct Link pricing and what do I pay for?\n\nSee the following FAQs for details.\n\n\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_06908-7-1898","score":12.533075,"text":"\nFAQs for Direct Link on Classic \n\nYou can review answers to some frequently asked questions about IBM Cloud\u00ae Direct Link.\n\n\n\n How does Direct Link on Classic differ from the new Direct Link offering? \n\nThe new IBM Cloud Direct Link offering differs from \"Direct Link on Classic\" in that the new Direct Link is decoupled from classic IaaS, and exists only in the local cross-connect router (XCR). This design enables native connectivity to VPC and future capabilities without being forced into the classic IaaS network.\n\nThe zone-region model allows for multiple data centers to exist in a single zone.\n\nThe new Direct Link offering allows connectivity to both Classic IaaS as well as VPCs, whereas the Classic Direct Link always connects to IaaS network and a global VRF first. Classic Direct Link can only reach VPC on a limited basis utilizing a VPC feature called Classic Access and by adding global routing to the direct link. For more information, see [Setting up access to your Classic Infrastructure from VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure).\n\nFor information about the differences between the new Direct Link offerings and the \"on Classic\" versions, see [How do I know which Direct Link solution to order?](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-get-started-with-ibm-cloud-direct-linkget-started-solution-to-order) and [Getting started with IBM Cloud Direct Link Dedicated](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-get-started-with-ibm-cloud-dl).\n\n\n\n\n\n How does IBM Cloud Direct Link work? \n\nFor every Direct Link customer, the IBM Cloud\u00ae team assigns a small private subnet to build a point-to-point network between the IBM Cloud cross-connect router (XCR) and the customer's edge router (CER). Then, IBM Cloud and the customer configure Border Gateway Protocol (BGP) to exchange routes between the environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-faqs"},{"document_id":"ibmcld_01130-3870-5707","score":12.301335,"text":"\n![Serialization and deserialization diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry3.svg)\n\nSerializer and deserializer\n\nZoom\n\n![Compatibility and versions diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry4.svg)\n\nCompatibility and versions\n\n\n\n\n\n Versions and compatibility \n\nWhenever you add a schema, and any subsequent versions of the same schema, Event Streams can validate the format automatically and reject the schema if any issues exist. You can evolve your schemas over time to accommodate changing requirements. Create a new version of an existing schema, and the Schema Registry ensures that the new version is compatible with the existing version, meaning that producers and consumers that use the existing version are not broken by the new version.\n\nSchemas are compared to avoid creating duplicate schemas where the schemas differ only in a way that does not affect the semantics of the schema. In some cases, the ordering of the JSON properties within a schema can be crucial to how the schema is used for encoding and decoding data, but in other cases it might not be relevant.\n\nFor example, the name property of a record schema is not used as part of the encoding and decoding process so you can position it anywhere inside the record JSON object. All these variations are considered the same schema.\n\nThe fields property in the JSON of a record schema is a case where its ordering is important. The Avro specification requires that a record\u2019s fields are encoded and decoded in the order they appear in the schema that is used for the encode and decode operation.\n\nAs an example, consider the following three schemas.\n\n\n\n Schema 1 \n\n{\n\"type\": \"record\",\n\"name\": \"book\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-ES_schema_registry"},{"document_id":"ibmcld_07289-7-2048","score":12.185065,"text":"\nFAQs for Direct Link \n\nYou can review answers to some frequently asked questions about IBM Cloud\u00ae Direct Link.\n\n\n\n How does the new Direct Link differ from Direct Link on Classic? \n\nThe Direct Link offering differs from Direct Link on Classic in that Direct Link is decoupled from classic IaaS, and exists only in the local cross-connect router (XCR). This design enables native connectivity to VPC and future capabilities without being forced into the classic IaaS network.\n\nDirect Link allows connectivity to both classic IaaS as well as VPCs, whereas IBM Cloud Direct Link on Classic always connects to the IaaS network and a global VRF first. IBM Cloud Direct Link on Classic can only reach the VPC on a limited basis using a feature named Classic Access and by adding global routing to the direct link. See [Setting up access to your Classic Infrastructure from VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) for more information.\n\nFor more information about the differences between the new Direct Link offering and the classic version (Direct Link on Classic), see [How do I know which Direct Link solution to order?](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-get-started-with-ibm-cloud-direct-linkget-started-solution-to-order).\n\n\n\n\n\n Where can I find Direct Link pricing and what do I pay for? \n\nSee the following FAQs for details.\n\n\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-faqs"},{"document_id":"ibmcld_12326-3651-6018","score":12.148944,"text":"\nTo configure the specifics of your development, staging, and production environment, use [Terraform input variables](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-create-tf-configconfigure-variables) in your configuration files. Input variables are automatically loaded into IBM Cloud Schematics when you create your workspace. To customize your workspace, you enter the environment-specific values for your variables. This setup is useful if you have one team that manages the lifecycle of the microservice component and where the configuration of your environments does not differ drastically. \n One Git repo, use branches to distinguish between environments Create one Git repository for your microservice component, and use different Git branches to store the Terraform configuration files for each of your environments. With this setup, you have a clear distinction between your environments and more control over who can access and change a particular configuration. Make sure to set up how changes in one configuration file are populated across branches to avoid that you have different configurations in each environment. \n One Git repo, use directories to distinguish between environments For organizations that prefer short-lived branches, and where configurations differ drastically across environments, consider creating directories that represent the different configurations of your environments. With this setup, all your directories listen for changes that are committed to the master branch. Make sure to set up how changes in one configuration file are populated across directories to avoid having different configurations in each environment. \n Use one Git repo per environment Use one Git repository for each of your environments. With this setup, you have a 1:1 relationship between your workspace and Git repository and you can apply separate permissions for each of your Git repositories. Make sure that your team can manage multiple Git repositories and keep them in sync. \n\n\n\n\n\n\n\n How can I reuse configuration files across environments and workspaces? \n\nTry to minimize the number of Terraform configuration files that you need to manage by creating standardized Terraform templates and by using variables to customize the template to your needs.\n\nNow, you can use Terraform modules from the Terraform module registry for IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-plan"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-7-1778","score":29.302505,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_11439-13936-14359","score":21.44019,"text":"\n(https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqssnap-storage-req)\n* [Does the snapshot and volume clone supports any safeguard policy?](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqssnap-clone-safeguard)\n* [Can you tell me more about the backup process using the PowerHA Toolkit for IBM i?](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqspoweha-toolkit)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-volume-snapshot-clone"},{"document_id":"ibmcld_03403-2780-4346","score":21.11756,"text":"\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close![Close arrow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close_arrow.png) icon to finish adding the about_restaurant intent.\n\n\n\nYou added an intent and provided examples of utterances that real users might enter to trigger this intent.\n\n\n\n\n\n Add a dialog node that is triggered by the about_restaurant intent \n\nAdd a dialog node that recognizes when the user input maps to the intent that you created in the previous step, meaning its condition checks whether your assistant recognized the about_restaurant intent from the user input.\n\n\n\n1. Click the Dialog tab.\n2. Find the General_Greetings node in the dialog tree.\n\nYou will add a node that checks for questions about the restaurant after this initial greeting node to reflect the flow you might expect to encounter in a normal conversation. For example, Hello. then Tell me about yourself.\n3. Click the More![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the General_Greetings node, and then select Add node below.\n\n![Shows the Add node below menu opened from the #General_Greetings dialog node.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_16360-1493-3354","score":20.454115,"text":"\nAll phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download). The format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nwhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\nWhere is your nearest location?,find_location\nDo you have a store in Raleigh?,find_location\n2. From the main actions page, click the Upload icon ![Upload icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/upload.svg).\n3. Select the intents file that you downloaded.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\nThe intents in column 2 are created as new actions, and the phrases in column 1 are created as example phrases for the corresponding action. For example, if you upload the example from step 1, two new actions are created for the weather_conditions and find_location intents. The underscores (_) in the intent names are replaced with spaces, for example, the weather_conditions intent becomes the weather conditions action.\n\nIn this example, the weather_conditions action will have three example phrases: Tell me the current weather conditions., Is it raining?, and What's the temperature?. The find_location action will have two example phrases: Where is your nearest location? and Do you have a store in Raleigh?.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actions"},{"document_id":"ibmcld_00620-3589-4643","score":19.521189,"text":"\n\"id\": \"4eee973603bf77f30b1f880ed83df76a\",\n\"key\": \"4eee973603bf77f30b1f880ed83df76a\",\n\"value\": {\n\"rev\": \"1-3b5e6b73e57745787ad5627fe8f268c1\"\n}\n},\n{\n\"id\": \"4eee973603bf77f30b1f880ed83f469a\",\n\"key\": \"4eee973603bf77f30b1f880ed83f469a\",\n\"value\": {\n\"rev\": \"1-967a00dff5e02add41819138abb3284d\"\n}\n}\n...\nShow more\nIf you supply include_docs=true, then another doc attribute is added to each \"row\" in the result set that includes the document body.<-- <\/section \"id=\"section-what-is-the_all_docs_endpoint\" \"> --><-- <section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --> The limit, startkey, and endkey parameters To access data from _all_docs in reasonably sized pages, you must supply the limit parameter to tell IBM Cloudant how many documents to return: get me 5 documents\nGET $SERVICE_URL\/$DATABASE\/_all_docs?limit=5 HTTP\/1.1\nYou can also limit the range of document _ids that you want by supplying one or more values to startkey or endkey.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> get me 5 documents from _id order00057 onwards","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00620-3894-5347","score":19.470806,"text":"\nIf you supply include_docs=true, then another doc attribute is added to each \"row\" in the result set that includes the document body.<-- <\/section \"id=\"section-what-is-the_all_docs_endpoint\" \"> --><-- <section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --> The limit, startkey, and endkey parameters To access data from _all_docs in reasonably sized pages, you must supply the limit parameter to tell IBM Cloudant how many documents to return: get me 5 documents\nGET $SERVICE_URL\/$DATABASE\/_all_docs?limit=5 HTTP\/1.1\nYou can also limit the range of document _ids that you want by supplying one or more values to startkey or endkey.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> get me 5 documents from _id order00057 onwards\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&startkey=\"order00057\"\"\n get me 5 documents between _id order00057 --> order00077\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&startkey=\"order00057\"&endkey=\"order00077\"\"\n get me 5 documents up to _id order00077\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5&endkey=\"order00077\"\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\n\/\/ get me 5 documents from _id order00057 onwards","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_04621-58586-59933","score":19.19329,"text":"\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1\n: The SDK for Node.js buildpack v3.25.1 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.16.0, 8.11.4, 8.15.0, 10.10.0 and 10.15.0. The default is latest 6.x, so it is currently 6.16.0. The versions 6.15.0, 8.14.0 and 10.14.0 that were included in the last buildpack had a regression. The regressions has been fixed in 6.16.0, 8.15.0 and 10.15.0 which are now included instead.\n\n\n\n\n\n 7 January 2019 \n\nUpdated Node.js buildpack v3.25\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_05366-1384-2834","score":18.863634,"text":"\nTo see a list of your resource groups, run ibmcloud resource groups.\n\nibmcloud target -g <resource_group>\n\nExample output\n\nTargeted resource group default\n3. Create a project in Code Engine called sample.\n\nibmcloud ce project create --name sample\n\nExample output\n\nCreating project 'sample'...\nID for project 'sample' is 'abcdabcd-abcd-abcd-abcd-abcd12e3456f7'.\nWaiting for project 'sample' to be active...\nNow selecting project 'sample'.\nOK\n\nNotice that your project is also selected for context, so all subsequent application-related commands are within the scope of this new sample project.\n4. Become familiar with Functions commands by viewing the command options.\n\nibmcloud ce fn --help\n\n\n\n\n\n\n\n Step 2: Create the source code \n\nCreate a Node.js source file called funhello.js with the following sample code.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name) {\nmsg = Hello, ${params.name}!\n} else {\nmsg = Hello, Functions on CodeEngine!\n}\nreturn {\nheaders: { 'Content-Type': 'text\/html; charset=utf-8' },\nbody: <html><body><h3>${msg}<\/h3><\/body><\/html>\n}\n}\n\nmodule.exports.main = main;\n\n\n\n\n\n Step 3: Create your function \n\nCreate the Function from the funhello.js file.\n\nibmcloud ce fn create --name funhello --runtime nodejs-18 --build-source funhello.js\n\nCommand output\n\nPreparing function 'funhello' for build push...\nCreating function 'funhello'...\nPackaging files to upload from source path 'hello.js'...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-tutorial"},{"document_id":"ibmcld_16516-6223-8371","score":18.836613,"text":"\n: Admins and Project Managers can annotate document sets directly from the Ground Truth tab on the Annotations page.\n: Annotation tasks are still available. You can manage them from the Annotation Tasks tab on the Annotations page.\n: Annotations applied directly to ground truth are not applied to related active annotation tasks. It is recommended that you annotate document sets directly only when they are not associated with any active annotation tasks.\n: The Annotation Sets tab has been removed from the Documents page. You can manage annotation sets from the Annotation Tasks tab of the Annotations page.\n\n- To create new annotation sets, click Add task. Then, click Create Annotation Sets.\n- To manage existing annotation sets, click an existing annotation task, then click Edit.\n\n\n\n\n\n\n\n March 2019 \n\n\n\n New features and changes \n\nCustom categories workspace (Experimental)\n: Introduced an experimental custom categories workspace for Knowledge Studio service instances on Lite and Standard plans that are hosted in the Dallas location. With the new workspace, you can deploy your own custom text categorization model to Natural Language Understanding or Discovery.\n\n\n\n\n\n\n\n January 2019 \n\nMigrating Cloud Foundry service instances\n: You can now migrate Knowledge Studio Cloud Foundry service instances to a resource group.\n\n\n\n\n\n December 2018 \n\n\n\n New features and changes \n\nSupport to deploy same model to multiple instances\n: Introduced support to deploy the same machine learning model version to multiple service instances and general improvements to the Version History and Deployment page. For more information about deploying multiple instances of the same model version see [Deploying the same model version to multiple services](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_secdep)\n\nAdded models method\n: Added the models method to the Natural Language Understanding service allowing users to list deployed Knowledge Studio models.\n\n\n\n\n\n\n\n September 2018 \n\n\n\n New features and changes \n\nSupport for additional document types\n: Introduced support for HTML, DOC, DOCX, and PDF files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16369-4569-5779","score":17.940113,"text":"\n(For the complete function, see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/content-carousel).)\n\ncarouselData.forEach((cardData) => {\nconst { url, title, description, alt } = cardData;\nconst cardElement = document.createElement('div');\ncardElement.classList.add('swiper-slide');\n\ncardElement.innerHTML = \n<div class=\"bx--tile Carousel__Card\">\n<img class=\"Carousel__CardImage\" src=\"${url}\" alt=\"${alt}\" \/>\n<div class=\"Carousel__CardText\">\n<div class=\"Carousel__CardTitle\">${title}<\/div>\n<div class=\"Carousel__CardDescription\">${description}<\/div>\n<\/div>\n\n<a href=\"https:\/\/www.ibm.com\" class=\"Carousel__CardButton bx--btn bx--btn--primary\" target=\"_blank\">\nView more details\n<\/a>\n\n<button type=\"button\" class=\"Carousel__CardButton Carousel__CardButtonMessage bx--btn bx--btn--primary\">\nTell me more about this\n<\/button>\n<\/div>\n;\n\n...\n\n});\nShow more\n4. In your onLoad event handler, use the [on()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodson) instance method to subscribe to the customResponse event, registering the carouselCustomResponseHandler() function as the callback.\n\ninstance.on({","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-content-carousel"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-6657-8493","score":40.89833,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-26617-28366","score":40.764824,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":40.764824,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-5434-7003","score":38.900703,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":36.450077,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":36.450077,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15545-195860-197138","score":35.454914,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":35.454914,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":35.454914,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":35.454914,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.383649139,"ndcg_cut_10":0.550809594}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15646-25256-26940","score":44.39603,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":44.39603,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-8094-9618","score":44.356827,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-5434-7003","score":43.254143,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15647-27849-29558","score":42.83211,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-1716-3433","score":42.358067,"text":"\nFailed Image creation failed. \n Deleting The image is being deleted. \n Deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before the status changes to obsolete. \n Obsolete You can't use the image to a create an instance. If you try to use an obsolete image to create an instance, you receive a message that the image can't be used to create an instance. This status allows a reversible disabiling of an image before you delete the image. \n\n\n\n\n\n\n\n Scheduling an image from volume lifecycle status by using the UI \n\nYou can schedule either a single image lifecycle status change or schedule the status changes for the entire lifecycle of the image.\n\nUse the following steps to schedule a single status change:\n\nYou can schedule a single status change for an image.\n\n\n\n1. In [IBM Cloud console](https:\/\/cloud.ibm.com\/login), go to Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2. On the Custom images tab, click the Actions icon ![More Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/action-menu-icon.svg) for a specific image and select from the available options.\n3. Select Schedule lifecycle.\n4. In Image status, select the status change for the image.\n5. In Deprecation details, select whether to change status Immediately or to Schedule future date.\n6. If you selected Schedule future date, you need to fill out the following:\n\n\n\n* Select either By calendar date or By number of days.\n\n\n\n* If you selected By calendar date, enter the date and time information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-27823-29559","score":42.204372,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15646-29196-30599","score":40.696888,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-29235-30638","score":40.696888,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-2393-4239","score":38.405586,"text":"\nSchedule lifecycle Opens the Schedule image lifecycle panel. You can make an immediate status change or schedule a statue change for a future date and time. You can schedule a single status change or schedule the complete lifecycle of the images. The image statuses are:<br><br><br><br> * available: The image can be used to create an instance.<br> * deprecated: The image is still available to use to provision and instance. Using the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instancce.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by by using calendar date and time or number of days. The obsolescence dates must always be after the deprecation date. \n Delete Delete the custom image.<br><br>If you want to delete a custom image in a private catalog, see [Deleting a custom image in a private catalog](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-imagesdeleting-private-catalog-custom-image-vpc). \n\n\n\n\n\n\n\n Listing custom images by using the CLI \n\nYou can list all of the IBM Cloud VPC custom images in your region by using the command-line interface (CLI).\n\nTo list all custom images by using the CLI, use the ibmcloud is images command. Custom images are private to the account where they are created, so the --visibility option is private.\n\nibmcloud is images --visibility private\n\nFor more information, see [ibmcloud is images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-referenceimages) in the VPC CLI reference page.\n\n\n\n\n\n Listing all images by using the API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"}],"retriever_scores":{"recall_1":0.1428571429,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.2857142857,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.4483039899}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":25.732206,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-7569-8653","score":20.051157,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_12498-9696-11699","score":19.714977,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":19.387857,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_00020-4245-6252","score":19.313398,"text":"\n<br><br> * [Working with Spark SQL and an external metastore](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore)<br><br><br> \n Running applications with resource overcommitment There is a quota associated with each Analytics Engine Serverless instance. When applications are submitted on an instance, they are allocated resources from the instance quota. If an application requests resources beyond the available quota, the application will either not start or will run with less than the requested resources, which might result in the application running slower than expected or, in some cases, in the application failing. You should always monitor the current resource consumption on an instance to ensure that your applications are running comfortably within the given limits. You can adjust the limits through a support ticket if required. <br><br> * [Default limits and quotas](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits)<br> * [Get current resource consumption](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine\/ibm-analytics-engine-v3get-current-resource-consumption)<br><br><br> \n Static allocation of resources versus autoscaling When you submit applications, you can specify the number of executors upfront (static allocation) or use the autoscaling option (dynamic allocation). Before you decide whether to use static allocation or autoscaling, you might want to run a few benchmarking tests by varying different data sets with both static and autoscaling to find the right configuration. General considerations:<br><br><br><br> * If you know the number of resources (cores and memory) required by your application and it doesn't vary across different stages of the application run, it is recommended to allocate static resources for better performance.<br> * If you want to go for an optimized resource utilization, you can opt for autoscaling of executors where the executors are allotted based on the application's actual demand.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"},{"document_id":"ibmcld_12493-30887-32451","score":19.267284,"text":"\n\"password\": \"TYRodi\/HX7s095UpQ38)L1z(t4u003ccG6!2\",\n\"username\": \"my-username\"\n},\n\"secret_type\": \"USERNAME_PASSWORD\",\n\"state\": 1,\n\"state_description\": \"Active\"\n},\n\"warnings\": null\n}\n\n\n\n\n\n\n\n Delete a secret \n\nUse this command to delete a secret. Allowable values for SECRET_TYPE are: arbitrary, iam_credentials, imported_cert, kv, private_cert, public_cert, and username_password.\n\nDelete a secret in the default secret group.\n\nvault delete ibmcloud\/SECRET_TYPE\/secrets\/SECRET_ID\n\nDelete a secret in an existing secret group.\n\nvault delete ibmcloud\/SECRET_TYPE\/secrets\/groups\/SECRET_GROUP_ID\/SECRET_ID\n\n\n\n Prerequisites \n\nYou need the [Manager service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to delete secrets.\n\n\n\n\n\n Command options \n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n\n\n\n\n Examples \n\nDelete an arbitrary secret by its assigned ID.\n\nvault delete ibmcloud\/arbitrary\/secrets\/d26702aa-77ae-400e-4f25-9790a9cabf9c\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nSuccess! Data deleted (if it existed) at: ibmcloud\/arbitrary\/secrets\/d26702aa-77ae-400e-4f25-9790a9cabf9c\n\n\n\n\n\n\n\n\n\n Dynamic secrets \n\nDynamic secrets are single-use credentials that are generated only when they are read or accessed.\n\nTo create a dynamic secret by using the Vault CLI, use the role command to scope the secret with the wanted level of permissions in your IBM Cloud account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_07578-1213887-1215935","score":19.041334,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":19.041334,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12493-32071-33807","score":18.664085,"text":"\nData deleted (if it existed) at: ibmcloud\/arbitrary\/secrets\/d26702aa-77ae-400e-4f25-9790a9cabf9c\n\n\n\n\n\n\n\n\n\n Dynamic secrets \n\nDynamic secrets are single-use credentials that are generated only when they are read or accessed.\n\nTo create a dynamic secret by using the Vault CLI, use the role command to scope the secret with the wanted level of permissions in your IBM Cloud account. Then, use the creds command to generate credentials for the role.\n\n\n\n Create a role \n\nUse the following commands to register a role for a [secrets engine that supports dynamic secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types). After you create a role, you can [generate credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-iam-creds-for-role) for it. The configuration that you define for role, such as its name, lease duration, and access permissions, is inherited by the generated credentials.\n\nCreate a role in the default secret group.\n\nvault write [-format=FORMAT] ibmcloud\/SECRET_TYPE\/roles\/ROLE_NAME access_groups=ACCESS_GROUP_ID,ACCESS_GROUP_ID ttl=LEASE_DURATION [description=\"DESCRIPTION\"] [labels=LABEL,LABEL]\n\nCreate a role in a specified secret group.\n\nvault write [-format=FORMAT] ibmcloud\/SECRET_TYPE\/roles\/groups\/SECRET_GROUP_ID\/ROLE_NAME access_groups=ACCESS_GROUP_ID,ACCESS_GROUP_ID ttl=LEASE_DURATION [description=\"DESCRIPTION\"] [labels=LABEL,LABEL]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to create secrets.\n\n\n\n\n\n Command options \n\nSECRET_TYPE\n: The type of secret that you want to create. Currently, iam_credentials is supported.\n\nSECRET_GROUP_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_12493-7080-8333","score":17.872746,"text":"\ncreated_at 2020-10-05T17:43:49Z\ndescription An updated group of secrets.\nid 9c6d20ad-779e-27c5-3842-2a20b19abfcf\nname my-updated-secret-group\ntype application\/vnd.ibm.secrets-manager.secret.group+json\nupdated_at 2020-10-05T17:56:56Z\n\n\n\n\n\n\n\n Delete a secret group \n\nUse this command to delete a secret group.\n\nvault delete auth\/ibmcloud\/manage\/groups\/SECRET_GROUP_ID\n\n\n\n Prerequisites \n\nYou need the [Manager service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to delete secret groups.\n\n\n\n\n\n Examples \n\nDelete a secret group by its assigned ID.\n\nvault delete auth\/ibmcloud\/manage\/groups\/9c6d20ad-779e-27c5-3842-2a20b19abfcf\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nSuccess! Data deleted (if it existed) at: auth\/ibmcloud\/manage\/groups\/9c6d20ad-779e-27c5-3842-2a20b19abfcf\n\n\n\n\n\n\n\n\n\n Static secrets \n\n\n\n Create a secret \n\nUse the following commands to add a static secret, such as a user credential or an arbitrary secret, to your Secrets Manager instance. Allowable values for SECRET_TYPE are: arbitrary,imported_cert, [kv](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-manage-kv-cli), private_cert, public_cert, and username_password.\n\nCreate a secret in the default secret group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16696-7-2390","score":19.945614,"text":"\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-key-features"},{"document_id":"ibmcld_14389-3006-4736","score":18.59002,"text":"\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS\n* Open Web Application Security Project (OWASP) top 10 threats\n* Common application vulnerabilities\n\n\n\n\n\nBIG-IP Access Policy Manager\u2122 (APM) offers users secure, simplified access to applications located anywhere within a multicloud environment, incorporating features such as SSO (Single Sign-On) and MFA (Multifactor Authentication).\n\nYou cannot change the license model after service installation. To change the license model, you must delete the existing service and reinstall the service by choosing a different license model.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [F5 BIG-IP overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_considerations)\n* [Managing F5 BIG-IP](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing_f5)\n* [Ordering services for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservices)\n* [Contacting IBM\u00ae Support](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-trbl_support)\n* [FAQ](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)\n* [F5 Deployment Guides](https:\/\/www.f5.com\/services\/resources\/deployment-guides)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_ordering"},{"document_id":"ibmcld_16686-7-2263","score":18.437778,"text":"\nLearning about Workload Protection architecture and workload isolation \n\nReview the following sample architecture for IBM Cloud Security and Compliance Center Workload Protection, and learn more about the workload isolation level that the service offers in the cloud.\n\n\n\n IBM Cloud Security and Compliance Center Workload Protection architecture \n\nIBM Cloud Security and Compliance Center Workload Protection is a highly available, multi-tenant, regional service that is available in IBM Cloud. You can use it to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nZoom\n\n![IBM Cloud Security and Compliance Center Workload Protection](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/667adc0b8a7fdb0b349b1158d8e128640b5bc72b\/workload-protection\/images\/Monitoring-arch.svg)\n\nFigure 1. Workload Protection Architecture\n\nThe API server component provides a web and an API interface to the service.\n\nThe collector component ingests data that agents forward to the service.\n\nThe data store component stores all results, metadata, instance credentials, and environmental data.\n\nAn agent connects to one instance. The agent forwards data to the instance that is connected.\n\nThe UI is the front-end component where users can monitor and configure scans, postures, policies, and alerts.\n\n\n\n\n\n Workload Protection workload isolation \n\nEach regional deployment of the IBM Cloud Security and Compliance Center Workload Protection service serves multiple tenants that are identified by the IBM service instance.\n\n\n\n* A region that is responsible for running user workloads in the region has one deployment of the Workload Protection service in the region.\n* The Workload Protection service in a region is [highly available](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-ha-dr).\n* The data that is collected and processed by the Workload Protection service is associated with the instance and not visible to the other service instances by virtue of this association.\n* Data for all tenants is located in the same data stores and segmented by the tenant-specific metric tags that are associated with each metric to enforce access control policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-compute-isolation"},{"document_id":"ibmcld_16691-7674-9167","score":18.290285,"text":"\n[Configure a notification channel](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-notificationsnotifications_create) You can configure a notification channel to get notified about events, anomalies, or security incidents that require attention. \n [Scan container images](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-scan_kube) You can scan container images for vulnerabilities, and other violations. \n [Configure an image scanning alert](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-alert-config) You can set up a runtime Scanning Alert to detect if an image is impacted by newly discovered vulnerabilities. You can scan a repository that hosts container images for vulnerabilities, secrets, and license violations. Then, you can configure an alert on the repository to receive notifications on issues that need your attention. \n [Configure a rule](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-manage_rules) You can create a Detection Rule to detect and respond to anomalous runtime activity. <br>You can create a rule to specify which image versions can be used. \n [Define a policy](https:\/\/cloud.ibm.com\/docs\/docs\/workload-protection?topic=workload-protection-manage_policies) You can configure a policy on a resource and define what to do when 1 or more rules that are included in the policy are noncompliant. <br>Secure includes a number of pre-defined policies that you can use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-getting-started"},{"document_id":"ibmcld_12668-7-1884","score":18.062567,"text":"\nData Protection Services \n\nData Security Broker offers Data Protection services which enables the provisioning of Data Security Broker Manager and Data Security Broker Shield. It also helps in configuring encryption or decryption rules against the IBM Cloud Databases such as PostgreSQL to encrypt and decrypt the database records or columns on the fly. It also helps in migrating the existing database records, apply record or column level encryption rules.\n\nData Security Broker supports two types of Data Protection services. They are:\n\n\n\n1. [Data Encryption](https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_encrypt_data)\n2. [Data Masking](https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_masking)\n\n\n\n\n\n Procedure \n\nAfter you have completed setting up and configuring the Data Security Broker Manager, you can perform standard encryption or data masking by defining a Data Protection policy. Ensure that you complete the steps below before you can use the data protection services offered by Data Security Broker.\n\n\n\n1. You must add a Keystore, so that the Data Security Broker Manager can access and create data encryption keys (DEKs) that is used to protect your data. For more information, see [Adding a Keystore in Data Security Broker Manager](https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_add_keystore).\n2. Connect to a database in the Data Security Broker Manager. For more information, see [Connect to a Datastore in Data Security Broker Manager](https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_add_db).\n3. Enroll an Application in Data Security Broker Manager. For more information, see [Enrolling an application in Data Security Broker Manager](https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_enroll_app).\n4. Assign and customize a Default Data Protection Policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_encrypt_postgress"},{"document_id":"ibmcld_07899-3004-4915","score":17.889074,"text":"\nSI-2 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"},{"document_id":"ibmcld_11147-5374-7562","score":17.4317,"text":"\nIn such cases, auto scaling can help in keeping resources allocated according to the needs. Of course, the data across the two sites is continuously synced with some kind of replication mechanism.\n\n\n\n\n\n Site strategy \n\nSite strategy is the most predominant aspect of the overall resiliency solution because it determines what classes of physical events the solution is able to address, sets the requirements in terms of distances, and it also sets constraints on the technology side.\n\nIBM Cloud offers a redundant infrastructure with several layers of resiliency that can be summarized as:\n\nLocal\n: A physical and logical separation zone, for example an availability zone or availability set, within a cloud location, such as a data center, that is independent from other zones for what pertains to power supply, cooling, and networking.\n\nSite\n: Multiple sites in a region. Using different sites within the same region offers a better level of protection in case of a limited natural disaster, compared to two different zones on a single site. Sites in the same region are usually in close proximity (tens of miles).\n\nRegion\n: Using two sites in two regions in the same geography represents the highest level of protection against natural disasters as sites are generally over 400 kilometers or 250 miles apart.\n\nGeography\n: Selecting two sites in different geographies extends the level of protection against natural disasters. Geographies are generally over 1500 kilometers or 1000 miles apart, thus representing the optimal option in terms of wider protection requirements.\n\nThe analysis of the cloud sites for the DR of your cloud-enabled workloads is relevant to avoid problems because of latency. Multiple sites in the same region help to implement DR with near zero RPO. And, remote secondary sites far from the primary site might require asynchronous techniques to be evaluated in your design.\n\nFor more information, see [How IBM Cloud ensures high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime).\n\n\n\n\n\n Plan and design for the \u201cworst conditions\u201d \n\nWhen designing your resiliency solution, the key is in the word \u201cresiliency\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-understanding-dr"},{"document_id":"ibmcld_07899-4108-6235","score":17.355303,"text":"\nSI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain signs build artifacts to attest their provenance<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"},{"document_id":"ibmcld_09835-0-777","score":17.101034,"text":"\n\n\n\n\n--------------------\n\n\n\n  Identifying software vulnerabilities \n\nYou can also use the IBM Cloud Monitoring Workload Protection service to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nThe ability to monitor software vulnerabilities is included when you use the [Graduated Tier - Sysdig Secure + Monitor service plan](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-service_plans). This plan integrates IBM Cloud Security and Compliance Center Workload Protection as part of IBM Cloud Monitoring.\n\nFor more information, see the [IBM Cloud Security and Compliance Center Workload Protection documentation.](https:\/\/cloud.ibm.com\/docs\/workload-protection)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-workoad-protection"},{"document_id":"ibmcld_11652-13857-14689","score":16.973068,"text":"\n* [SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers](https:\/\/launchpad.support.sap.com\/\/notes\/171380)\n* [SAP Note 1380654 - SAP support in IaaS environments](https:\/\/launchpad.support.sap.com\/\/notes\/1380654)\n\n\n\nThis document is referenced by:\n\n\n\n* [SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment](https:\/\/launchpad.support.sap.com\/\/notes\/2927211)\n* [SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities](https:\/\/launchpad.support.sap.com\/\/notes\/2588225)\n* [SAP Note 1380654 - SAP support in IaaS environments](https:\/\/launchpad.support.sap.com\/\/notes\/1380654)\n* [SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment](https:\/\/launchpad.support.sap.com\/\/notes\/2414097)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-refarch-nw-db2"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":28.726645,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":26.513569,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_07578-1215486-1217535","score":24.441545,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1218119-1220168","score":24.441545,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12498-9696-11699","score":24.357786,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_16729-294066-295916","score":23.628542,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_12447-4-2115","score":22.79495,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Manually rotating secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can manually create new versions of a secret by using the UI or APIs.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. Rotating your credentials limits how long a protected resource can be accessed by a single secret, which can protect your business against the risks that are associated with compromised credentials. Rotate your secrets regularly, for example every 30 or 60 days, so that you're always meeting best practices around secrets management.\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAll the secrets that you store in Secrets Manager can be rotated and replaced on-demand. How Secrets Manager evaluates a request to rotate a secret depends on the secret type.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) Arbitrary secrets are immediately replaced with the data that you provide on rotation. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) IAM credentials, which consist of a service ID and API key, are immediately regenerated according to their initial configuration. If the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12447-23717-25820","score":22.563667,"text":"\n{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/versions\"\n\nTo have the service generate and assign a random password to your credential, you can pass an empty string on the password field. For example, { \"password\": \"\"}. Secrets Manager replaces the existing value with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API docs](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\n\n\n\n\n\n\n Manually rotating secrets with Terraform \n\nYou can manually rotate your arbitrary secrets, key-value secrets, or imported certificates by using Terraform for Secrets Manager. To manually rotate other types of secrets, you must use the UI, the API or the CLI.\n\n\n\n Rotating arbitrary secrets \n\nYou can rotate arbitrary secrets by using Terraform for Secrets Manager.\n\nTo rotate an arbitrary secret, modify the value of the payload attribute in your ibm_sm_arbitrary_secret resource configuration, and run terraform apply to apply the change. If you're using an input variable for the payload, modify its value in the variables.tf file.\n\nYou can also modify other attributes of the arbitrary secret at the same time, including metadata attributes such as description, custom_metadata, or version_custom_metadata.\n\n\n\n\n\n Rotating key-value secrets \n\nTo rotate a key-value secret by using Terraform for Secrets Manager, modify the value of the data attribute in your ibm_sm_kv_secret resource configuration, and run terraform apply to apply the change. If you're using an input variable for the payload, modify its value in the variables.tf file.\n\nYou can also modify other attributes of the key-value secret at the same time, including metadata attributes such as description, custom_metadata or version_custom_metadata.\n\n\n\n\n\n Rotating imported certificates \n\nYou can rotate imported certificates by using Terraform for Secrets Manager.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_06836-7569-8653","score":22.461653,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_12447-18572-20357","score":22.453152,"text":"\nReplace new lines in the certificate, intermediate, and private key data with n.\n\nThe command outputs the value of the secret, along with other metadata. For more information about the command options, see [ibmcloud secrets-manager secret-version-create](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-version-create-command).\n\n\n\n\n\n Rotating KV secrets \n\nTo rotate a KV secret by using the Secrets Manager CLI plug-in, run the [ibmcloud secrets-manager secret-version-create](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-version-create-command) command. For example, the following command rotates a secret and assigns new-secret-data as its new version.\n\nibmcloud secrets-manager secret-version-create \n--secret-id=SECRET_ID \n--secret-version-prototype='{\"data\": {\"key\":\"value\"}, \"custom_metadata\": {\"anyKey\": \"anyValue\"}, \"version_custom_metadata\": {\"anyKey\": \"anyValue\"}}'\n\nThe command outputs the value of the secret, along with other metadata. For more information about the command options, see [ibmcloud secrets-manager secret-version-create](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-version-create-command).\n\n\n\n\n\n\n\n Manually rotating secrets with the API \n\nYou can manually rotate your secrets and certificates by using the Secrets Manager API.\n\n\n\n Rotating arbitrary secrets \n\nYou can rotate arbitrary secrets by calling the Secrets Manager API.\n\nThe following example request creates a new version of your secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12415-7-1973","score":34.203533,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_07578-1213887-1215935","score":34.172657,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":34.172657,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":31.543377,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1218119-1220168","score":31.543377,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12479-7-1826","score":31.272253,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"},{"document_id":"ibmcld_12498-8087-10171","score":29.990047,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12438-0-1298","score":28.537714,"text":"\n\n\n\n\n\n\n  Why can't I read a locked IAM credentials secret? \n\nYou try to read or access an IAM credentials secret that you manage in IBM Cloud\u00ae Secrets Manager, but you get a 412 Precondition Failed response.\n\n  What\u2019s happening \n\nYou have an IAM credentials secret that you want to regenerate for your application. But when you use the Secrets Manager APIs, SDKs, or CLI to get the secret, you see the following 412 Precondition Failed error:\n\nThe requested action can't be completed because the secret version is locked.\n\n  Why it\u2019s happening \n\nA lock on a secret prevents it from being modified or deleted from your instance. IAM credentials are\n\ndynamic secrets. By default, each request to read an IAM credential (for example, a GET request) generates a new service ID API key, deletes the old credentials, and returns the new credentials. Locking the secret overrides this default behavior and returns a 412 Precondition Failed error to indicate that the secret data is locked. A locked IAM credential can't be read, because doing so modifies its secret data.\n\n  How to fix it \n\nTo regenerate your IAM credentials, you can remove all the locks that are associated with your secret, and try again. To delete locks from the Secrets Manager UI, go to Secrets > secret name > Locks > Delete.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials"},{"document_id":"ibmcld_16729-294066-295916","score":27.187756,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-887513-889443","score":26.961824,"text":"\nCan I port them to the VPC?\n\n I have volumes on the Classic infrastructure. Can I port them to the VPC? \n\nNo. The VPC provides access to new availability zones in multi-zone regions. Compute, network, and storage resources are designed to function in the VPC.\n* What is image from volume and how does it relate to Block Storage for VPC volumes?\n\n What is image from volume and how does it relate to Block Storage for VPC volumes? \n\nWith the image from volume feature, you can create a custom image directly from a Block Storage for VPC boot volume. Then, you can use the custom image to provision other virtual server instances. For more information, see [About creating an image from a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc).\n* How is the boot disk created for an instance and how does it relate to the virtual machine image?\n\n How is the boot disk created for an instance and how does it relate to the virtual machine image? \n\nThe boot disk, also called a boot volume, is created when you provision a virtual server instance. The boot disk of an instance is a cloned image of the virtual machine image. For stock images, the boot volume capacity is 100 GB. If you are importing a custom image, the boot volume capacity can be 10 GB to 250 GB, depending on what the image requires. Images smaller than 10 GB are rounded up to 10 GB. The boot volume is deleted when you delete the instance to which it is attached.\n* When can I delete a Block Storage for VPC data volume?\n\n When can I delete a Block Storage for VPC data volume? \n\nYou can delete a Block Storage for VPC data volume only when it isn't attached to a virtual server instance. [Detach the volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagedetach) before you delete it. Boot volumes are detached and deleted when the instance is deleted.\n* What happens to my data when I delete a Block Storage for VPC data volume?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-112910-114676","score":24.857952,"text":"\nFor details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https:\/\/cloud.ibm.com\/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-112889-114655","score":24.857952,"text":"\nFor details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https:\/\/cloud.ibm.com\/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08056-3796-5774","score":23.354845,"text":"\nTo upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https:\/\/cloud.ibm.com\/user\/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-get-supportfaq"},{"document_id":"ibmcld_02064-12843-15134","score":22.755348,"text":"\n* Service roles define the ability to perform actions on a service and are specific to every service such as performing API calls or accessing the UI. Service roles are: manager, writer, and reader. For more information about how these roles apply, refer to the specific service's documentation.\n\n\n\n\n\n\n\n How do I assign a user full access as an account administrator? \n\nTo assign a user in your account full administrator access, go to Manage > Access (IAM) in the console, select the user's name, and assign the following access:\n\n\n\n* An IAM policy with Administrator and Manager roles on All Identity and Access enabled services, which enable a user to create service instances and assign users access to all resources in the account.\n* An IAM policy with Administrator role on All account management services, which enables a user to complete tasks like inviting and removing users, managing access groups, managing service IDs, managing private catalog products, and track billing and usage.\n* The Super user permission set for classic infrastructure, which includes all of the available classic infrastructure permissions\n* A trusted profile set as the alternative account owner has the highest level of classic infrastructure permissions and has both IAM policies that grant full access. For more information, see [Setting an alternative account owner](https:\/\/cloud.ibm.com\/docs\/account?topic=account-classic-infra-owner&interface=ui).\n\n\n\n\n\n\n\n Can every user in my account see all the other users? \n\nAn account owner can view all users in the account and choose how users can view other users in the account on the Users page. An account owner can adjust the [user list visibility setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-user-setting) on the Settings page by selecting one of the following options:\n\n\n\n* Unrestricted view: All users in your account can view everyone else in the account.\n* Restricted view: Limits the ability to view users on the Users page to only those who have been granted explicit access, along with those who have visibility of other users through a classic infrastructure user hierarchy relationship.\n\n\n\n\n\n\n\n Do I need to assign access to a user when I invite them to the account? \n\nNo. You can invite users, and then assign access later.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamfaq"},{"document_id":"ibmcld_07578-1106210-1108489","score":22.755348,"text":"\n* Service roles define the ability to perform actions on a service and are specific to every service such as performing API calls or accessing the UI. Service roles are: manager, writer, and reader. For more information about how these roles apply, refer to the specific service's documentation.\n\n\n\n* How do I assign a user full access as an account administrator?\n\nTo assign a user in your account full administrator access, go to Manage > Access (IAM) in the console, select the user's name, and assign the following access:\n\n\n\n* An IAM policy with Administrator and Manager roles on All Identity and Access enabled services, which enable a user to create service instances and assign users access to all resources in the account.\n* An IAM policy with Administrator role on All account management services, which enables a user to complete tasks like inviting and removing users, managing access groups, managing service IDs, managing private catalog products, and track billing and usage.\n* The Super user permission set for classic infrastructure, which includes all of the available classic infrastructure permissions\n* A trusted profile set as the alternative account owner has the highest level of classic infrastructure permissions and has both IAM policies that grant full access. For more information, see [Setting an alternative account owner](https:\/\/cloud.ibm.com\/docs\/account?topic=account-classic-infra-owner&interface=ui).\n\n\n\n* Can every user in my account see all the other users?\n\nAn account owner can view all users in the account and choose how users can view other users in the account on the Users page. An account owner can adjust the [user list visibility setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-user-setting) on the Settings page by selecting one of the following options:\n\n\n\n* Unrestricted view: All users in your account can view everyone else in the account.\n* Restricted view: Limits the ability to view users on the Users page to only those who have been granted explicit access, along with those who have visibility of other users through a classic infrastructure user hierarchy relationship.\n\n\n\n* Do I need to assign access to a user when I invite them to the account?\n\nNo. You can invite users, and then assign access later.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1108691-1110970","score":22.755348,"text":"\n* Service roles define the ability to perform actions on a service and are specific to every service such as performing API calls or accessing the UI. Service roles are: manager, writer, and reader. For more information about how these roles apply, refer to the specific service's documentation.\n\n\n\n* How do I assign a user full access as an account administrator?\n\nTo assign a user in your account full administrator access, go to Manage > Access (IAM) in the console, select the user's name, and assign the following access:\n\n\n\n* An IAM policy with Administrator and Manager roles on All Identity and Access enabled services, which enable a user to create service instances and assign users access to all resources in the account.\n* An IAM policy with Administrator role on All account management services, which enables a user to complete tasks like inviting and removing users, managing access groups, managing service IDs, managing private catalog products, and track billing and usage.\n* The Super user permission set for classic infrastructure, which includes all of the available classic infrastructure permissions\n* A trusted profile set as the alternative account owner has the highest level of classic infrastructure permissions and has both IAM policies that grant full access. For more information, see [Setting an alternative account owner](https:\/\/cloud.ibm.com\/docs\/account?topic=account-classic-infra-owner&interface=ui).\n\n\n\n* Can every user in my account see all the other users?\n\nAn account owner can view all users in the account and choose how users can view other users in the account on the Users page. An account owner can adjust the [user list visibility setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-user-setting) on the Settings page by selecting one of the following options:\n\n\n\n* Unrestricted view: All users in your account can view everyone else in the account.\n* Restricted view: Limits the ability to view users on the Users page to only those who have been granted explicit access, along with those who have visibility of other users through a classic infrastructure user hierarchy relationship.\n\n\n\n* Do I need to assign access to a user when I invite them to the account?\n\nNo. You can invite users, and then assign access later.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09979-1428-3421","score":22.228659,"text":"\n* password: xxxx - Specifies the password that you must use when logging in to your instance as admin.\n\n\n\nAfter you log in to your instance for the first time, change your admin password.\n\n\n\nTo view credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https:\/\/cloud.ibm.com\/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Expand the credential entry that is associated with the credentials that you generated previously.\n\n\n\n* username: admin - Specifies a local database admin user that was created for you to access the instance.\n* password: xxxx - Specifies the password that you must use when logging in to your instance as admin.\n\n\n\nAfter you log in to your instance for the first time, change your admin password.\n\n\n\n\n\n\n\n Now that I've generated credentials, how do I access my Netezza Performance Server instance? \n\nYou can access your Netezza Performance Server instance several ways, including a dedicated web console and a REST API.\n\nFor more information, see [Connecting to Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-connecting-overview).\n\n\n\n\n\n Can I set up spending notifications for my Netezza Performance Server instance to keep track of my credit usage? \n\nIf you have an IBM Cloud\u00ae Pay-As-You-Go or Subscription account, you can set up email spending notifications. After your account is configured, you can configure spending thresholds and choose to receive notifications when you reach 80%, 90%, and 100% of the thresholds.\nFor more information, see [Setting spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending&interface=ui)\n\n\n\n\n\n What's managed for me with Netezza Performance Server? \n\nIBM handles all of the software upgrades, operating system updates, and hardware maintenance for your Netezza Performance Server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-netezza-faqs"},{"document_id":"ibmcld_12613-7-2387","score":21.945803,"text":"\nIBM Cloud IAM roles \n\nAll services that are organized in a resource group in your account are managed by using IBM Cloud Identity and Access Management (IAM). Account owners are automatically assigned the account administrator role. As the account administrator, you can assign and manage access for users, create resource groups, create access groups, create trusted profiles, view billing details and track usage, and create service instances. You provide access for users, service IDs, access groups, and trusted profiles by creating policies that set a target for the subject of the policy to access and a role that defines what type of access that is allowed.\n\n\n\n IAM roles \n\nYou can manage and define access based on specific roles for users and resources in your account.\n\n\n\n* Platform management roles cover a range of actions, including the ability to create and delete instances, manage aliases, bindings, and credentials, and manage access. The platform roles are administrator, editor, operator, viewer. Platform management roles also apply to [account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles) that enable users to invite users, manage service IDs, access policies, catalog entries, and track billing and usage depending on their assigned role on an account management service.\n* Service access roles define a user or service\u2019s ability to perform actions on a service instance, such as accessing the console or performing API calls. The most common service access roles are manager, writer, and reader. Each service maps particular actions for working with the service to each of these roles.\n\nYou might not see all of the roles that are listed here as options when you assign policies in the UI because only the roles available for the service that you chose are displayed. For more information on what roles are enabled and what actions each access role allows for each service, see the documentation for that service.\n* Custom roles for a service can be created on the IAM Roles page by the account owner or a user assigned the administrator role on the role management service.\n\nYou can review the available roles and associated actions for a particular service by going to the [Roles](https:\/\/cloud.ibm.com\/iam\/roles) page, and selecting the service that you want to learn more about.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-userroles"},{"document_id":"ibmcld_07578-1340295-1342245","score":21.551445,"text":"\nYou can get the encryption details using IBM Cloud UI\/CLI. For details, see [Cloud Storage Encryption](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption).\n* How can I list all permissions of a bucket?\n\nThe IAM feature creates a report at the instance level which may extend to their buckets. It does not specifically report at the bucket level. For details, see [Account Access Report](https:\/\/cloud.ibm.com\/docs\/account?topic=account-access-report).\n* How can I monitor bucket changes in the public cloud without using the cloud functions?\n\nYou must use cloud functions to get notifications for object changes.\n* How can I monitor Object Storage resources?\n\nUse the Activity Tracker service to capture and record Object Storage activities and monitor the activity of your IBM Cloud account. Activity Tracker is used to track how users and applications interact with Object Storage.\n* Does an object in a bucket get overwritten if the same object name is used again in the same bucket?\n\nYes, the object is overwritten.\n* How do I get bucket information without using the web console?\n\nUse the Object Storage Resource Configuration API to get bucket information. For details, see [COS configuration](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) and [COS Integration](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration).\n* How can I manage service credentials for Object Storage instances?\n\nWhen a service credential is created, the underlying Service ID is granted a role on the entire instance of Object Storage. For details, see [Managing Service credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-credentials).\n* Why are parts of my credentials hidden or not viewable?\n\nThere may be an issue where the viewer does not have sufficient roles to view the credential information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1342960-1344910","score":21.551445,"text":"\nYou can get the encryption details using IBM Cloud UI\/CLI. For details, see [Cloud Storage Encryption](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption).\n* How can I list all permissions of a bucket?\n\nThe IAM feature creates a report at the instance level which may extend to their buckets. It does not specifically report at the bucket level. For details, see [Account Access Report](https:\/\/cloud.ibm.com\/docs\/account?topic=account-access-report).\n* How can I monitor bucket changes in the public cloud without using the cloud functions?\n\nYou must use cloud functions to get notifications for object changes.\n* How can I monitor Object Storage resources?\n\nUse the Activity Tracker service to capture and record Object Storage activities and monitor the activity of your IBM Cloud account. Activity Tracker is used to track how users and applications interact with Object Storage.\n* Does an object in a bucket get overwritten if the same object name is used again in the same bucket?\n\nYes, the object is overwritten.\n* How do I get bucket information without using the web console?\n\nUse the Object Storage Resource Configuration API to get bucket information. For details, see [COS configuration](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) and [COS Integration](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration).\n* How can I manage service credentials for Object Storage instances?\n\nWhen a service credential is created, the underlying Service ID is granted a role on the entire instance of Object Storage. For details, see [Managing Service credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-credentials).\n* Why are parts of my credentials hidden or not viewable?\n\nThere may be an issue where the viewer does not have sufficient roles to view the credential information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00007-7-2159","score":15.392519,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00064-7-2200","score":14.703772,"text":"\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00042-4304-6393","score":14.47169,"text":"\nFor details on how to use the log_forwarding_config API, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n\n\n 13 May 2022 \n\nSupport for Python 3.9\n: You can now run Spark applications using Python 3.9. on your IBM Analytics Engine serverless instances.\n\n\n\n\n\n 04 April 2022 \n\nLimitation on how long Spark applications can run\n: Spark applications can run for a maximum period of 3 days (72 hours). Any applications that run beyond this period will be auto-cleaned in order to adhere to the security and compliance patch management processes for applications in Analytics Engine.\n\n\n\n\n\n 30 March 2022 \n\nStart using the Analytics Engine serverless CLI\n: Use this tutorial to help you get started quickly and simply with provisioning an Analytics Engine serverless instance, and submitting and monitoring Spark applications. See [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).\n\n\n\n\n\n 9 September 2021 \n\nIntroducing IBM Analytics Engine Standard serverless plan for Apache Spark\n: The IBM Analytics Engine Standard serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nNew: The IBM Analytics Engine Standard serverless plan for Apache Spark is now GA in the Dallas IBM Cloud service region.\n: This plan offers a new consumption model using Apache Spark whereby resources are allocated and consumed only when Spark workloads are running.\n\nCapabilities available in the IBM Analytics Engine Standard serverless plan for Apache Spark include:\n\n\n\n* Running Spark batch and streaming applications\n* Creating and working with Jupyter kernels for interactive use cases\n* Running Spark batch applications through an Apache Livy like interface\n* Customizing instance with your own libraries\n* Autoscaling Spark workloads\n* Aggregating logs of your Spark workloads to the Log Analysis server","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes"},{"document_id":"ibmcld_00007-1713-3490","score":14.467551,"text":"\nSee [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https:\/\/cloud.ibm.com\/docs\/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00020-7-2287","score":14.368452,"text":"\nBest practices \n\nUse the following set of recommended guidelines when provisioning and managing your serverless instances and when running Spark applications.\n\n\n\nTable 1. Best practices when using serverless instances including detailed descriptions and reference links\n\n Best Practice Description Reference Link \n\n Use separate IBM Analytics Engine service instances for your development and production environments. This is a general best practice. By creating separate IBM Analytics Engine instances for different environments, you can test any configuration and code changes before applying them on the production instance. NA \n Upgrade to the latest Spark version As open source Spark versions are released, they are made available in IBM Analytics Engine after a time interval required for internal testing. Watch out for the announcement of a new Spark versions in the Release Notes section and upgrade the runtime of your instance to move your applications to latest Spark runtime. Older runtimes are be deprecated and eventually removed as newer versions are released. Make sure you test your applications on the new runtime before making changes on the production instances. <br><br> * [Release notes for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes)<br><br><br> \n Grant role-based access You should grant role-based access to all users on the IBM Analytics Engine instances based on their requirements. For example, only your automation team should have permissions to submit applications because it has access to secrets and your DevOps team should only be able to see the list of all applications and their states. <br><br> * [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless)<br><br><br> \n Choose the right IBM Cloud Object Storage configuration <br><br> * Disaster Recovery (DR) Resiliency: You should use the IBM Cloud Object Storage Cross Regional resiliency option that backs up your data across several different cities in a region. In contrast, the Regional resiliency option back ups data in a single data center.<br> * Encryption: IBM Cloud Object Storage comes with default built-in encryption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"},{"document_id":"ibmcld_00055-7-1864","score":14.210559,"text":"\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_00064-1629-4081","score":14.15795,"text":"\nArchitecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities. Services usually do not require installation or maintenance and can be combined to create applications. An instance of a service is an entity that consists of resources that are reserved for a particular application or a service.\n\nWhen you create an IBM Analytics Engine from the catalog, you will give the service instance a name of your choice, select the default Spark runtime you want to associate with the instance and provide the default Spark configuration to use with the instance. Additionally, you need have to specify the Instance home, which is the storage attached to the instance for instance related data only.\n\nNote:\n\n\n\n* When you create an IBM Analytics Engine service instance, no costs are incurred unless you have Spark applications running or the Spark history server is accessed.\n* Costs are incurred if IBM Cloud Object Storage if accessed through public endpoints, and when you enable forwarding IBM Analytics Engine logs to IBM Log Analysis.\n* There is a default limit on the number of service instances permitted per IBM Cloud\u00ae account and on the amount of CPU and memory that can be used in any given IBM Analytics Engine service instance. See [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits). If you need to adjust these limits, open an IBM Support ticket.\n* There is no limit on the number of Spark applications that can be run in an IBM Analytics Engine service instance.\n\n\n\n\n\n\n\n Default Spark runtime \n\nYou can select which Spark version to use when the instance is provisioned. Currently, you can choose between Spark 3.1 and Spark 3.3. If you don't select a Spark runtime version, Spark 3.1 is taken by default.\n\nThe runtime contains only open source Spark binaries and is configured to help you to quickly get started to create and run Spark applications in the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00008-7-1613","score":13.998701,"text":"\nIBM Analytics Engine CLI plug-in for serverless instances \n\nThe IBM Analytics Engine v3 CLI provides command line options to interact with Standard Serverless Spark instances. You can manage instances and Spark applications with the CLI. For more information about serverless Analytics Engine instances, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo run IBM Analytics Engine v3 CLI commands, use ibmcloud analytics-engine-v3 or ibmcloud ae-v3.\n\n\n\n Prerequisites \n\nDownload and install the IBM Cloud CLI on your local system. See [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cloud-cli-install-ibmcloud-cli) to install the CLI.\n\n\n\n\n\n Install the IBM Analytics Engine v3 CLI \n\nInstall the IBM Analytics Engine v3 CLI by running the following command:\n\nibmcloud plugin install analytics-engine-v3\n\nThe following help CLI command shows that the v3 CLI supports CLI commands for:\n\n\n\n* [Setting a target instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-CLI_analytics_engineanalytics-engine-v3-target-cli)\n* [Instance management](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-CLI_analytics_engineanalytics-engine-v3-instance-cli)\n* [Spark application management](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-CLI_analytics_engineanalytics-engine-v3-spark-app-cli)\n* [Log forwarding configuration](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-CLI_analytics_engineanalytics-engine-v3-log-forwarding-config-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-CLI_analytics_engine"},{"document_id":"ibmcld_02554-7-1520","score":13.998701,"text":"\nIBM Analytics Engine CLI plug-in for serverless instances \n\nThe IBM Analytics Engine v3 CLI provides command line options to interact with Standard Serverless Spark instances. You can manage instances and Spark applications with the CLI. For more information about serverless Analytics Engine instances, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo run IBM Analytics Engine v3 CLI commands, use ibmcloud analytics-engine-v3 or ibmcloud ae-v3.\n\n\n\n Prerequisites \n\nDownload and install the IBM Cloud CLI on your local system. See [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cloud-cli-install-ibmcloud-cli) to install the CLI.\n\n\n\n\n\n Install the IBM Analytics Engine v3 CLI \n\nInstall the IBM Analytics Engine v3 CLI by running the following command:\n\nibmcloud plugin install analytics-engine-v3\n\nThe following help CLI command shows that the v3 CLI supports CLI commands for:\n\n\n\n* [Setting a target instance](https:\/\/cloud.ibm.com\/docs\/analytics-engine-cli-plugin?topic=analytics-engine-cli-plugin-CLI_analytics_engineanalytics-engine-v3-target-cli)\n* [Instance management](https:\/\/cloud.ibm.com\/docs\/analytics-engine-cli-plugin?topic=analytics-engine-cli-plugin-CLI_analytics_engineanalytics-engine-v3-instance-cli)\n* [Spark application management](https:\/\/cloud.ibm.com\/docs\/analytics-engine-cli-plugin?topic=analytics-engine-cli-plugin-CLI_analytics_engineanalytics-engine-v3-spark-app-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/analytics-engine-cli-plugin?topic=analytics-engine-cli-plugin-CLI_analytics_engine"},{"document_id":"ibmcld_04327-7-1517","score":13.998701,"text":"\nIBM Analytics Engine CLI plug-in for serverless instances \n\nThe IBM Analytics Engine v3 CLI provides command line options to interact with Standard Serverless Spark instances. You can manage instances and Spark applications with the CLI. For more information about serverless Analytics Engine instances, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo run IBM Analytics Engine v3 CLI commands, use ibmcloud analytics-engine-v3 or ibmcloud ae-v3.\n\n\n\n Prerequisites \n\nDownload and install the IBM Cloud CLI on your local system. See [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cloud-cli-install-ibmcloud-cli) to install the CLI.\n\n\n\n\n\n Install the IBM Analytics Engine v3 CLI \n\nInstall the IBM Analytics Engine v3 CLI by running the following command:\n\nibmcloud plugin install analytics-engine-v3\n\nThe following help CLI command shows that the v3 CLI supports CLI commands for:\n\n\n\n* [Setting a target instance](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI_analytics_engineanalytics-engine-v3-target-cli)\n* [Instance management](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI_analytics_engineanalytics-engine-v3-instance-cli)\n* [Spark application management](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI_analytics_engineanalytics-engine-v3-spark-app-cli)\n* [Log forwarding configuration](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI_analytics_engineanalytics-engine-v3-log-forwarding-config-cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI_analytics_engine"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00032-0-1390","score":15.6432,"text":"\n\n\n\n\n\n\n  Working with Spark SQL and an external metastore \n\nSpark SQL uses Hive metastore to manage the metadata of a user's applications tables, columns, partition information.\n\nBy default, the database that powers this metastore is an embedded Derby instance that comes with the Spark cluster. You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n\nPlacing your metadata outside of the Spark cluster will enable you to reference the tables in different applications across your IBM Analytics Engine instances. This, in combination with storing your data in IBM Cloud Object Storage, helps persisting data and metadata and allows you to work with this data seamlessly across different Spark workloads.\n\n\n\n  Enabling and testing an external metastore with IBM Analytics Engine \n\nTo enable and test an external metastore with IBM Analytics Engine, you need to perform the following steps:\n\n\n\n1.  Create a metastore to store the metadata. You can choose to provision either an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n2.  Configure IBM Analytics Engine to work with the database instance.\n3.  Create a table in one Spark application and then access this table from another Spark application.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore"},{"document_id":"ibmcld_09864-5103-6606","score":15.4739685,"text":"\n\"moreInformation\": \"https:\/\/example.com\",\n\"queueManagerLocation\": \"qm.us-south.mq.appdomain.cloud\",\n\"queueManagers\": [{\n\"hostname\": \"qm1-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM1\"\n}, {\n\"hostname\": \"qm2-abcd.qm.us-south.mq.appdomain.cloud\",\n\"name\": \"QM2\"\n}],\n\"region\": \"us-south\",\n\"serviceInstance\": \"crn:v1:staging:public:mqcloud:region:a\/ab90cde12f345:ab5c678d-e90a-b5678c9::\"\n}\nShow more\n\nThe notification will contain the following keys:\n\n\n\n* datestamp: the date and time the notification was sent\n* description: an explanation of the problem and what action was taken\n* moreInformation: this may contain an external link to further explain the cause behind the DR\n* queueManagerLocation: the location of the cluster on which the queue manager is deployed\n* queueManagers: a list of hostnames and names of all affected queue managers\n* region: the physical location of your service instance\n* serviceInstance: the unique CRN of the containing service instance\n\n\n\n\n\n\n\n How to implement the endpoint handler \n\nThe instructions below demonstrate some sample code to implement an endpoint handler to send notifications via PagerDuty in an IBM Cloud Function, but you could also adapt this code to run in a location of your choice\n\nNote: the below function is written in Node.js\n\nconst https = require('https');\n\nfunction main(params) {\n\nreturn new Promise((resolve, reject) => {\n\n\/\/ Replace the string \"R4nd0m5tr1ng0fCh4r4ct3r5\" with your own value to secure access to your own specific endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_dr_notifications"},{"document_id":"ibmcld_00042-2867-4770","score":15.380071,"text":"\nSee [Use the Spark history server](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless).\n\n\n\n\n\n September 2022 \n\n\n\n 21 September 2022 \n\nSupport for Spark 3.3\n: You can now provision IBM\u00ae Analytics Engine severless plan instances with the default Spark runtime set to Spark 3.3, which enables you to run Spark applications on Spark 3.3.\n\n\n\n\n\n 09 September 2022 \n\nYou can now use Hive metastore to manage the metadata related to your applications tables, columns, and partition information when working with Spark SQL.\n: You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Data Engine (previously SQL Query) or an IBM Cloud Databases for PostgreSQL instance. For details, see [Working with Spark SQL and an external metastore](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore).\n\n\n\n\n\n\n\n July 2022 \n\n\n\n 12 July 2022 \n\nYou can now provision IBM\u00ae Analytics Engine serverless instances in a new region.\n: In addition to the IBM Cloud\u00ae us-south (Dallas) region, you can now also provision serverless instances in the eu-de (Frankurt) region.\n\n\n\n\n\n 08 July 2022 \n\nNew API for platform logging\n: Start using the log_forwarding_config API to forward platform logs from an IBM Analytics Engine instance to IBM Log Analysis. Although you can still use the logging API, it is deprecated and will be removed in the near future. For details on how to use the log_forwarding_config API, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n\n\n 13 May 2022 \n\nSupport for Python 3.9\n: You can now run Spark applications using Python 3.9. on your IBM Analytics Engine serverless instances.\n\n\n\n\n\n 04 April 2022 \n\nLimitation on how long Spark applications can run\n: Spark applications can run for a maximum period of 3 days (72 hours).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes"},{"document_id":"ibmcld_00033-7-2292","score":14.951037,"text":"\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_07578-107943-110247","score":14.951037,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-107922-110226","score":14.951037,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00064-3561-5813","score":14.513509,"text":"\n* There is no limit on the number of Spark applications that can be run in an IBM Analytics Engine service instance.\n\n\n\n\n\n\n\n Default Spark runtime \n\nYou can select which Spark version to use when the instance is provisioned. Currently, you can choose between Spark 3.1 and Spark 3.3. If you don't select a Spark runtime version, Spark 3.1 is taken by default.\n\nThe runtime contains only open source Spark binaries and is configured to help you to quickly get started to create and run Spark applications in the instance. In addition to the Spark binaries, the runtime also includes the geospatial, data skipping, and Parquet modular encryption libraries.\n\nOn a Spark 3.1 or Spark 3.3 runtime, you can submit Spark applications written in the following languages: Scala 2.12, Python 3.9, and R 3.6.3.\n\nNote that the language versions are upgraded periodically to keep the runtime free from any security vulnerabilities.\n\nYou can always override the Spark runtime version when you submit an application. For details on what to add to the payload, see [Passing the runtime Spark version when submitting an application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apipass-spark-version).\n\n\n\n\n\n Instance home \n\nInstance home is the storage attached to the instance for instance related data only, such as custom application libraries and Spark history events. Currently, only IBM Cloud Object Storage is accepted for instance home. This instance can be an instance in your IBM Cloud\u00ae account or an instance from a different account.\n\nWhen you provision an instance using the IBM Cloud console, the IBM Cloud Object Storage instances in your IBM Cloud\u00ae account are auto discovered and displayed in a list for you to select from. If no IBM Cloud Object Storage instances are found in your account, you can use the REST APIs to update instance home after instance creation.\n\nYou can't change instance home after instance creation. You can only edit the access keys.\n\n\n\n\n\n Default Spark configuration \n\nYou can specify default Spark configurations at the instance level and let that be inherited by Spark applications created on the instance. This is an optional section that you can specify at the time of instance creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_16628-0-1541","score":13.822777,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_00027-0-2510","score":13.821911,"text":"\n\n\n\n\n\n\n  Customization overview \n\nYou can customize a serverless instance specifically to suit your application needs, over and above what is provisioned on a default basis.\n\nFor example, you might want to install custom analytics third-party libraries or you might want to fine-tune some cluster configurations, for example, the Spark default configurations.\n\nYou can customize an instance at any point of its lifecycle. The customizations are applied only to those applications that are submitted after you added the customization. They are not applied to an currently running applications.\n\n\n\n  Customization options \n\nYou can customize your instance by:\n\n\n\n*  Specifying configuration values that are inherited by all Spark applications that run in the instance\n*  Making Python, R, Scala or custom libraries available to your Spark applications\n\n\n\nWhen you create an instance you can:\n\n\n\n*  Specify default values for configuration properties and environment variables supported by the Apache Spark configuration. You can specify configuration properties and environment variables as name-value pairs that are saved at the instance level and passed to all Spark applications that run in the instance. These default configuration parameters can simplify the payload that is passed when submitting a Spark application. You can also override these values at the time a Spark application is submitted.\n\nFor a list of the default Spark configurations and environment variables, see [Spark configurations](https:\/\/spark.apache.org\/docs\/latest\/configuration.html).\n*  Customize the instance with libraries required by your Spark applications after instance creation. You can create a library set that packages all libraries to be made available to all Spark applications that run in the instance, and then refer to this defined library set at the time the Spark application is submitted.\n\nTo create a library set, see [Creating a library set](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-create-lib-set).\n\n\n\nNote:\n\n\n\n*  The maximum size limit of a customization library set is 2 GB.\n*  The start time of your Spark application or the time taken for additional executors to get added in an autoscaling scenario, is proportional to the size of the custom library set. Therefore it is a best practice to limit a library set to only the files that are needed for a specific application. If other applications require different sets of files, it is better to use different library sets.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-instance"},{"document_id":"ibmcld_02718-7-2113","score":13.536152,"text":"\nVideos \n\nYou can watch the videos to learn more about App Configuration service.\n\n\n\n* Video transcript\n\nWhat are Feature Flags?\n\nBefore you begin playing the video: In this video, the narrator draws representational images on the display board to explain the concept. [Draw] is used to represent when the narrator draws the representational image. [Writing] is used to represent when the narrator writes some text.\n\nWhat if you could release a feature to different groups of users without deployment? Is there a way to effectively test features in production, and immediately roll them back if needed?\n\nHi, my name is Dilan Orrino with IBM Cloud. I'll be answering those questions by discussing feature flags, or sometimes referred to as feature toggle, or switches.\n\nFeature flags are conditions that encompass feature code that allow you to flip them on and off at will. Okay, let's use an example. [Draw] Let's say we've got an ice cream shop franchise that's looking to expand to a new city and we've got a [Draw] banner that we want to display on our website. We'll call this open banner. We only want to display this banner to users that are [Draw] nearby our new ice cream shop we can do this by using feature flags.\n\nThere's a couple benefits to using feature flags. [Writing] Number one is we can actually turn these on or off without deployment. [Writing] Number two is we can actually test directly in production. [Writing] And number three we can segment our users based on different attributes.\n\nOkay, there's a couple ways you can do this one way is by using properties in JSON files or config maps. There's a better way however by using a feature flag service.\n\n[Writing] There's a couple benefits to using a feature flag service. Number one is you can have essentially managed place for your features, or excuse me your feature flags. [Writing] Number two is you can turn these on and off without modifying your properties in your future, in your apps or web pages. [Writing] And number three is you get audit and usage data. It's harder to get the audit and usage data by using JSON files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-6212-7871","score":30.09555,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-7-1988","score":29.940632,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-5443-6857","score":29.382198,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-1627-2985","score":25.32083,"text":"\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine. It also includes the convenience library to configure the connection to the Hive metastore. The following example shows a Spark batch job for a show tables example in Python:\n\nimport sys\nfrom dataengine import SparkSessionWithDataengine\n\nif __name__ == '__main__':\ncrn = sys.argv[1]\napikey = sys.argv[2]\n\nprint(\" Start SparkSessionWithDataengine example\")\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\n\nprint(\" Setup IBM Cloud Object Storage access\")\nspark = session_builder.appName(\"AnalyticEngine DataEngine integration\") \n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.getOrCreate()\n\nprint(\" Got a spark session, listing all tables\")\nspark.sql('show tables').show()\n\nspark.stop()\nShow more\n\nPrepare a JSON file to start that program, as in the following example (listTablesExample.json):\n\n{\n\"application_details\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00054-2517-3996","score":24.728012,"text":"\nNote that the library set name certificate_library_set must match the value of the Databases for PostgreSQL metastore connection parameter ae.spark.librarysets that you specified.\n\n\n\n4. Specify the following Databases for PostgreSQL metastore connection parameters as part of the Spark application payload or as instance defaults. Make sure that you use the private endpoint for the \"spark.hadoop.javax.jdo.option.ConnectionURL\" parameter below:\n\n\"spark.hadoop.javax.jdo.option.ConnectionDriverName\": \"org.postgresql.Driver\",\n\"spark.hadoop.javax.jdo.option.ConnectionUserName\": \"ibm_cloud_<CHANGEME>\",\n\"spark.hadoop.javax.jdo.option.ConnectionPassword\": \"<CHANGEME>\",\n\"spark.sql.catalogImplementation\": \"hive\",\n\"spark.hadoop.hive.metastore.schema.verification\": \"false\",\n\"spark.hadoop.hive.metastore.schema.verification.record.version\": \"false\",\n\"spark.hadoop.datanucleus.schema.autoCreateTables\":\"true\",\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql:\/\/<CHANGEME>.databases.appdomain.CHANGEME\/ibmclouddb?sslmode=verify-ca&sslrootcert=\/home\/spark\/shared\/user-libs\/certificate_library_set\/custom\/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_16641-7595-8514","score":24.61641,"text":"\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-password-from-watsonx.Data: The watsonx.data password. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n\n\n\nTo view logs of Spark application ran on IBM Analytics Engine you have to enable logging. For more information, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00020-2739-4633","score":24.416597,"text":"\nThis applies to the IBM Cloud Object Storage home instance as well as endpoints used from your applications (either your code or what you pass as parameters in the configurations at instance level or application level). Direct endpoints provide better performance than public endpoints and do not incur charges for any outgoing or incoming bandwidth.<br><br><br> <br><br> * Disaster Recovery (DR) Resiliency: [IBM Cloud Object Storage documentation.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/info?topic=cloud-object-storage-endpointsendpoints)<br> * Encryption: [Getting started with encryption keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-getting-started-tutorialgetting-started-tutorial) and [Object Storage manage encryption](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-encryptionencryption)<br> * Service credentials: [Service credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentialsservice-credentials)<br> * Direct endpoints for IBM Cloud Object Storage: [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-endpoints)<br><br><br> \n Use private endpoints for the external Hive metastore If you are using Spark SQL and want to use an external metastore such as use IBM Cloud Databases for PostgreSQL as your Hive metastore, you must use the private endpoint for the database connection for better performance and cost savings. <br><br> * [Working with Spark SQL and an external metastore](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore)<br><br><br> \n Running applications with resource overcommitment There is a quota associated with each Analytics Engine Serverless instance. When applications are submitted on an instance, they are allocated resources from the instance quota.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"},{"document_id":"ibmcld_16635-0-1693","score":24.349789,"text":"\n\n\n\n\n\n\n  HMS Overview \n\n\n\n  Hive Metastore \n\nHive Metastore (HMS) is a service that stores metadata related to Presto and other services in a backend Relational Database Management System (RDBMS) or Hadoop Distributed File System (HDFS).\n\nWhen you create a new table, information related to the schema such as column names, data types etc is stored in the metastore relational database. A metastore enables the user to see the data files in the HDFS object storage as if they are stored in tables with HMS.\n\nMetastore acts as a bridge between the schema of the table and the data files stored in object storages. HMS holds the definitions, schema, and other metadata for each table and maps the data files and directories to the table representation which is viewed by the user. Therefore, HMS is used as a storage location for the schema and tables. HMS is a metastore server that connects to the object storage to store data and keeps its related metadata on PostgreSQL.\n\nAny database with a JDBC driver can be used as a metastore. Presto makes requests through thrift protocol to HMS. The Presto instance reads and writes data to HMS. HMS supports 5 backend databases as follows. In IBM\u00ae watsonx.data, PostgreSQL database is used.\n\n\n\n*  Derby\n*  MySQL\n*  MS SQL Server\n*  Oracle\n*  PostgreSQL\n\n\n\nCurrently HMS in watsonx.data supports Iceberg table format.\n\nFollowing three modes of deployment are supported for HMS. In watsonx.data the remote mode is used.\n\n\n\n*  Embedded Metastore - Derby with singe session.\n*  Local Metastore - MySQl with multiple session accessible locally.\n*  Remote Metastore - metastore runs on its own separate JVM and accessible via thrift network APIs.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms_overview"},{"document_id":"ibmcld_00029-9508-11158","score":22.81057,"text":"\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083. For more information about the applicable endpoints(thrift), see [Thrift endpoint](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n* CRN-DATA-ENGINE-INSTANCE: specify the crn of the data engine instance.\n\n\n\nMake sure that you select the standard aliases.\n\n\n\n\n\n Read Data from table using simpler Convenience API \n\nIf you want to do a quick test of the Hive metastore by specifying IBM Cloud Data Engine connection API in your application, you can use the convenience API shown in the following PySpark example.\n\nIn this example, there is no need to pass any IBM Cloud Data Engine Hive metastore parameters to your application. The call to SparkSessionWithDataengine.enableDataengine initializes the connections to IBM Cloud Data Engine without the additional IBM Cloud Data Engine Hive metastore parameters.\n\ndataengine-job-convenience_api.py:\n\nfrom dataengine import SparkSessionWithDataengine\nfrom pyspark.sql import SQLContext\nimport sys\n\u00a0from pyspark.sql import SparkSession\nimport time\n\ndef dataengine_table_test(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 statesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\n\u00a0 statesDF.show()\n\ndef main():\n\u00a0 if __name__ == '__main__':\n\u00a0\u00a0\u00a0 if len (sys.argv) < 2:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 exit(1)\n\u00a0\u00a0\u00a0 else:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00054-3422-4901","score":22.168972,"text":"\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql:\/\/<CHANGEME>.databases.appdomain.CHANGEME\/ibmclouddb?sslmode=verify-ca&sslrootcert=\/home\/spark\/shared\/user-libs\/certificate_library_set\/custom\/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them. After running the following Spark application called postgres-create-schema.py, you will see the Hive metadata tables created against the \"public\" schema of the instance.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-schema\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef create_schema(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 time.sleep(30)\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 create_schema(spark,sc)\nif __name__ == '__main__':\n\u00a0 main()\n6. Now run the following script called postgres-parquet-table-create.py to create a Parquet table with metadata from IBM Cloud Object Storage in the Databases for PostgreSQL database.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-parquet-table-test\").getOrCreate()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":25.404873,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_02597-1689-3678","score":23.3405,"text":"\nThe following diagram demonstrates where the LoopBack application, API, and Product are deployed to after they are published from the developer toolkit CLI or UI.\n\n![Diagram to show what is contained within a LoopBack project](images\/loopback_project.png \"A LoopBack project)\n\n\n\n* IBM Cloud run time: The LoopBack app is deployed to the IBM Cloud run time of your choice.\n* Gateway: The API is deployed to the gateway.\n\n\n\nAPI Manager: The product is deployed to the API Manager where you can specify how it is used.\n\n![Diagram showing where the LoopBack app, API, and product are deployed](images\/Deployed.png\" \"LoopBack app, API, and product)\n\nFor more information about the tasks that are required to create APIs, see [Creating APIs](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-creating_apis).\n\n\n\n\n\n API management overview \n\nAfter a Product is staged and published, you can open the API Manager to manage security, rate limits, policies, and billing information, and then publish the Product to a Developer Portal.\n\nAs displayed in the following diagram, a Product contains a plan, which contains one or more APIs.\n\n![Diagram showing what is contained in a Product](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/Product.png)\n\n\n\n Plans \n\nTo make an API available to a customer, it must be included in a Plan. Plans are used to differentiate between different offerings. Plans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_04709-7-2265","score":22.585945,"text":"\nComparing IBM Cloud Classic and VPC infrastructure environments \n\nCompare the key differences between IBM Cloud\u00ae infrastructure environments to decide which one is best for your workloads and applications. Check out this [video](https:\/\/mediacenter.ibm.com\/media\/IBM%20Bare%20Metal%20Servers%20-%20Classic%20vs.%20VPC%20Infrastructure%20Explainer%20Video\/1_hn1d69nn) to learn more about the differences between the Classic and VPC infrastructures.\n\nIf you aren't familiar with the environment types, review the following descriptions.\n\n\n\n* Classic infrastructure is our existing IaaS platform. This environment is best for lift and shift workloads so you can move applications quickly and keep the same architecture.\n* VPC infrastructure is our new IaaS platform, based on software-defined networking and ideal for cloud-native applications.\n\n\n\nClassic infrastructure and VPC infrastructure are cost neutral, so you can focus on what environment best meets your needs.\n\n\n\n Compute differentiators \n\nSee the following table for the compute differences between classic and VPC.\n\n\n\nTable 1. Compute comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, go to the row and find the details for the feature that you're interested in.\n\n Category Classic Infrastructure VPC Infrastructure \n\n Services Full catalog of services, such as Bare Metal Servers, Virtual Servers instances, VMware, SAP Virtual Servers and Bare Metal Servers \n Performance and availability Better availability achievable through zone architecture \n Pricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"},{"document_id":"ibmcld_02361-7-2094","score":21.956774,"text":"\nAdoption guidelines for regulated and highly available workloads \n\nFor regulated and highly available workloads, consider the following adoption guidelines when using the IBM Cloud\u00ae Activity Tracker (AT) service:\n\n\n\n Define resources naming standards for compliance \n\nWhen you create resources in the IBM Cloud, you can choose how to name them, what information to include in their description fields, which tags to use to group them, associate metadata, and more.\n\nDefine naming standards that do not include PII and other sensitive information for all resources that are created in the IBM Cloud.\n\n\n\n\n\n Define the account management strategy \n\nIn IBM Cloud, you can have 1 or more stand-alone accounts. You can manage each account individually or within an enterprise by configuring a multitiered hierarchy of accounts.\n\nWithin an enterprise account, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level. [Learn more](https:\/\/cloud.ibm.com\/docs\/account?topic=account-what-is-enterprise).\n\n\n\n* The enterprise account serves as the parent account to all other accounts in the enterprise.\n* Users and access management is isolated between the enterprise and its child accounts. No access is automatically inherited between the two types of accounts.\n* Resources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups.\n\n\n\nAn enterprise can contain up to 5 tiers of accounts and account groups. In its most basic form, an enterprise has two tiers: the enterprise account, and a single child account.\n\nThe following table highlights some of the key features per account management strategy:\n\n\n\nTable 1. Types of accounts\n\n Feature Stand-alone account management Enterprise account management \n\n Multitiered hierarchy of accounts ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/checkmark-icon.svg) \n Billing and payments managed from 1 account !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09275-7-2097","score":21.956774,"text":"\nAdoption guidelines for regulated and highly available workloads \n\nFor regulated and highly available workloads, consider the following adoption guidelines when using the IBM Log Analysis service:\n\n\n\n Define resources naming standards for compliance \n\nWhen you create resources in the IBM Cloud, you can choose how to name them, what information to include in their description fields, which tags to use to group them, associate metadata, and more.\n\nDefine naming standards that do not include PII and other sensitive information across all resources that are created in the IBM Cloud.\n\n\n\n\n\n Define the account management strategy \n\nIn IBM Cloud, you can have 1 or more stand-alone accounts. You can manage each account individually or within an enterprise by configuring a multitiered hierarchy of accounts.\n\nWithin an enterprise account, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level. [Learn more](https:\/\/cloud.ibm.com\/docs\/account?topic=account-what-is-enterprise).\n\n\n\n* The root enterprise account serves as the parent account to all other accounts in the enterprise.\n* Users and access management is isolated between the enterprise and its child accounts. No access is automatically inherited between the two types of accounts.\n* Resources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups.\n\n\n\nNotice that an enterprise can contain up to 5 tiers of accounts and account groups. In its most basic form, an enterprise has two tiers: the enterprise account, and a single child account.\n\nThe following table highlights some of the key features per account management strategy:\n\n\n\nTable 1. Types of accounts\n\n Feature Stand-alone account management Enterprise account management \n\n Multitiered hierarchy of accounts NO ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) \n Billing and payments managed from 1 account !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_02597-3131-5174","score":21.555323,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_14006-7-2487","score":21.055925,"text":"\nFAQs: Dedicated hosts and instances \n\n\n\n What is a dedicated host? \n\nIBM Cloud\u00ae dedicated hosts are physical servers that are committed to a group of users. Dedicated hosts offer virtual server provisioning capacity and maximum placement control.\n\n\n\n\n\n What are the benefits of using dedicated hosts over dedicated instances? \n\nBoth offerings are guaranteed single tenancy. Dedicated hosts provide the flexibility to specify on which host to provision dedicated host instances, and these other benefits:\n\n\n\n* Control over which IBM Cloud data center the server is placed\n* Ability to manage your servers as workload requirements change; for example, migrate virtual servers between your dedicated hosts on the same POD\n\n\n\n\n\n\n\n Can I keep my existing dedicated instances or do I need to set up a dedicated host and dedicated host instances? \n\nYes, you can keep your existing dedicated instances.\n\n\n\n\n\n Can I interchange provisioning of dedicated instances (auto\u2013assigned) and dedicated host instances? \n\nNo. Existing auto-assigned dedicated instances cannot be reprovisioned on dedicated hosts. If you require virtual server placement, you need to provision them on dedicated hosts as dedicated host instances.\n\n\n\n\n\n What type of server, virtual or bare metal, supports the dedicated host offering? \n\nThe offering is supported on virtual servers; IBM Cloud does have a bare metal offering. The differences between virtual hosts and bare metal servers are the time to provision and virtualization management.\n\n\n\n\n\n What is the provisioning lifecycle of a dedicated host? \n\nDedicated hosts are allocated to users when provisioned. They persist to the account until it is reclaimed. Dedicated hosts are offered in only on-demand pricing, hourly or monthly, so when reclaimed, billing models charge as either hourly or monthly IBM Cloud offerings.\n\n\n\n\n\n How is the dedicated host offering billed? \n\nYou can purchase dedicated hosts on-demand with hourly or monthly billing. Hourly only hosts allow only hourly instances to be provisioned; monthly only hosts allow provisioning of monthly and hourly instances. Pricing for dedicated hosts includes core, RAM, local SSD storage, and network port speeds. Premium operating systems, storage area network (SAN) storage, and software add-on prices and licensing are charged based on the instance deployed\u2014hourly or monthly\u2014on the dedicated host. The same pricing model as IBM Cloud public and dedicated instances is followed for these items.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-dedicated-hosts-and-instances"},{"document_id":"ibmcld_07578-874737-876784","score":20.581427,"text":"\nIf you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n* What's the difference between Bare Metal Servers (Classic infrastructure) and Bare Metal Servers for VPC?\n\nCompared to the classic bare metal infrastructure, Bare Metal Servers for VPC provides the following advantages:\n\n\n\n* Security and performance of the private cloud with the flexibility and scalability that you expect of the public cloud.\n* Integrates with other VPC services such as virtual server, security groups, networking, and more.\n* Faster provisioning and deployment and simple hourly billing.\n\n\n\nKeep in mind that Bare Metal Servers for VPC is less customizable than classic bare metal servers.\n\nFor more information about the differences between the Classic infrastructure and VPC, see [ Comparing IBM Cloud Classic and VPC infrastructure environments](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure).\n* What operating systems are supported?\n\nCurrently, VMware ESXi, Windows, RHEL, RHELfor SAP, Debian GNU, SUSE Linux Enterprise, Ubuntu Linux, and custom images are supported.\n* What storage options are available?\n\nTwo storage options are available that include secondary local NVMe drives.\n\n\n\n* The bx2-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage only.\n* The bx2d-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage and 16 3.2 TB U.2 NVMe SSDs as secondary local storage to support vSAN, or user-managed RAID.\n\n\n\nVPC Block Storage is not supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-874614-876661","score":20.581427,"text":"\nIf you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n* What's the difference between Bare Metal Servers (Classic infrastructure) and Bare Metal Servers for VPC?\n\nCompared to the classic bare metal infrastructure, Bare Metal Servers for VPC provides the following advantages:\n\n\n\n* Security and performance of the private cloud with the flexibility and scalability that you expect of the public cloud.\n* Integrates with other VPC services such as virtual server, security groups, networking, and more.\n* Faster provisioning and deployment and simple hourly billing.\n\n\n\nKeep in mind that Bare Metal Servers for VPC is less customizable than classic bare metal servers.\n\nFor more information about the differences between the Classic infrastructure and VPC, see [ Comparing IBM Cloud Classic and VPC infrastructure environments](https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure).\n* What operating systems are supported?\n\nCurrently, VMware ESXi, Windows, RHEL, RHELfor SAP, Debian GNU, SUSE Linux Enterprise, Ubuntu Linux, and custom images are supported.\n* What storage options are available?\n\nTwo storage options are available that include secondary local NVMe drives.\n\n\n\n* The bx2-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage only.\n* The bx2d-metal-192x768 profile provides mirrored 960 GB SATA M.2 drives as boot storage and 16 3.2 TB U.2 NVMe SSDs as secondary local storage to support vSAN, or user-managed RAID.\n\n\n\nVPC Block Storage is not supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01447-3317-5285","score":20.193146,"text":"\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics. For more information about how billing works and what happens when you exceed service plan limits, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing).\n\n\n\nTable 2. Container Registry plans\n\n Characteristics Free Standard \n\n Description. Try out Container Registry to store and share your Docker images. This plan is the default service plan when you set up your first namespace in Container Registry. Benefit from unlimited storage and pull traffic usage to manage the Docker images for all namespaces in your IBM Cloud account. \n Amount of storage for images. 500 MB Unlimited \n Pull traffic. 5 GB per month Unlimited \n Billing. If you exceed your storage or pull traffic limits, you cannot push or pull images to and from your namespace. For more information, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing). Storage. You are charged by Gigabyte-Months of usage. The first 0.5 GB-Months are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog).<br><br>Pull traffic. You are charged by Gigabyte usage per month. The first 5 GB are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog). If you exceed your storage or pull traffic limits, you can't push or pull images to and from your namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11857-1988-2975","score":32.563484,"text":"\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"},{"document_id":"ibmcld_08056-3796-5774","score":31.504984,"text":"\nTo upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https:\/\/cloud.ibm.com\/user\/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-get-supportfaq"},{"document_id":"ibmcld_11730-5345-7171","score":31.257696,"text":"\nMany extra software packages require access to or from the host, so extra software packages are not allowed to be installed.\n\nMaintenance: IBM provides software updates that you choose when to apply to the host. Because IBM is responsible for providing these updates, you cannot install extra software that is not managed by IBM. Extra software also uses mores CPU, memory, and disk storage resources on the host, which impacts the amount available to your Satellite-enabled IBM Cloud services and applications that run on the hosts.\n\n\n\n\n\n What am I charged for when I use IBM Cloud Satellite? \n\nIBM Cloud Satellite provides a convenient way for you to consume IBM Cloud services in any location that you want, with visibility across your locations. For more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\n\n\n What are the terms of the service level agreement? \n\nSee the [IBM Cloud terms of service](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) and the [Satellite additional service description](http:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm-8913-01).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqs"},{"document_id":"ibmcld_07578-1033424-1035350","score":30.782907,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1033295-1035221","score":30.782907,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-275933-277579","score":29.886812,"text":"\nFor more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n* Can I estimate my costs?\n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n* What are the terms of the service level agreement?\n\nSee the [IBM Cloud terms of service](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) and the [Satellite additional service description](http:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm-8913-01).\n\nSatellite Infrastructure Service is IBM-operated and as such, is covered in the IBM Cloud Satellite cloud service terms with additional information outlined in the [IBM Cloud Additional Services Description](http:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=i126-8979).\n* What compliance standards does the service meet?\n\nIBM Cloud is built by following many data, finance, health, insurance, privacy, security, technology, and other international compliance standards. For more information, see [IBM Cloud compliance](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-compliance).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-275907-277553","score":29.886812,"text":"\nFor more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n* Can I estimate my costs?\n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n* What are the terms of the service level agreement?\n\nSee the [IBM Cloud terms of service](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) and the [Satellite additional service description](http:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm-8913-01).\n\nSatellite Infrastructure Service is IBM-operated and as such, is covered in the IBM Cloud Satellite cloud service terms with additional information outlined in the [IBM Cloud Additional Services Description](http:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=i126-8979).\n* What compliance standards does the service meet?\n\nIBM Cloud is built by following many data, finance, health, insurance, privacy, security, technology, and other international compliance standards. For more information, see [IBM Cloud compliance](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-compliance).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-278658-280528","score":28.01739,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-278632-280502","score":28.01739,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-276996-279076","score":27.454813,"text":"\nSatellite Infrastructure Service is IBM-operated and as such, is covered in the IBM Cloud Satellite cloud service terms with additional information outlined in the [IBM Cloud Additional Services Description](http:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=i126-8979).\n* What compliance standards does the service meet?\n\nIBM Cloud is built by following many data, finance, health, insurance, privacy, security, technology, and other international compliance standards. For more information, see [IBM Cloud compliance](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-compliance).\n\nTo view detailed system requirements, you can run a [software product compatibility report for IBM Cloud Satellite](https:\/\/www.ibm.com\/software\/reports\/compatibility\/clarity\/softwareReqsForProduct.html).\n\nNote that compliance also might depend on the setup of the underlying infrastructure provider that you use for the Satellite location control plane and other resources.\n\nIBM Cloud Satellite implements controls commensurate with the following security standards:\n\n\n\n* International Organization for Standardization (ISO 27001, ISO 27017, ISO 27018)\n\n\n\n* What IBM Cloud services can I use with Satellite?\n\nFor a complete list of IBM Cloud services that you can deploy to your Satellite location, see Satellite-enabled IBM Cloud services.\n\nKeep in mind that each service might:\n\n\n\n* Be available for Satellite locations that are managed from select IBM Cloud regions only, such as from Washington, DC or London.\n* Have its own [limitations for use in Satellite](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-requirementsreqs-services).\n\n\n\n* Can I estimate my costs?\n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-7-2197","score":24.972855,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_08671-108191-109525","score":24.348646,"text":"\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs-uko)\n* [Is there a free trial for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-free-trial)\n\n\n\n[FAQs: Provisioning and operations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-provisioning-operations)\n\n\n\n* [Are there any prerequisites for using Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-hpcs-prerequisites)\n* [How to initialize Hyper Protect Crypto Services service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-how-to-initialize)\n* [Can I initialize my service instance through the TKE CLI plug-in by using a proxy?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-tke-proxy)\n* [Are there any recommendations on how to set up smart cards?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_07578-882118-884014","score":22.94035,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-881995-883891","score":22.94035,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14006-1976-4300","score":22.511583,"text":"\nHourly only hosts allow only hourly instances to be provisioned; monthly only hosts allow provisioning of monthly and hourly instances. Pricing for dedicated hosts includes core, RAM, local SSD storage, and network port speeds. Premium operating systems, storage area network (SAN) storage, and software add-on prices and licensing are charged based on the instance deployed\u2014hourly or monthly\u2014on the dedicated host. The same pricing model as IBM Cloud public and dedicated instances is followed for these items.\n\n\n\n\n\n I\u2019m running an on-demand dedicated host; how am I billed? \n\nYou are billed at the hourly or monthly on-demand rate for dedicated hosts. Dedicated host instances that are provisioned on dedicated hosts might incur instances charges as noted in the answer to [How is a dedicated host offering billed](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-dedicated-hosts-and-instanceshow-is-the-dedicated-host-offering-billed-).\n\n\n\n\n\n How is tenancy specified when you provision dedicated hosts and dedicated host instances? \n\nThe default tenancy for dedicated instances is single tenant. You can provision dedicated instances on either a dedicated host (dedicated host instances) or an auto-assigned host (dedicated instances). Dedicated instances on auto-assigned hosts do not offer the same management level as those hosts that are on a dedicated host.\n\n\n\n\n\n Can I mix and match different dedicated host instance configurations on my dedicated host? \n\nYes. You can provision different virtual server sizes on dedicated hosts within its capacity allotments.\n\n\n\n\n\n How do I know how many dedicated host instances I can run on each dedicated host? \n\nEach dedicated host has a specific allotment of core, RAM, and local SSD storage. You are able to view resource allocations on the host Allocations tab to know how many dedicated host instances are provisioned, current host capacity that is used, and what is available.\n\n\n\n\n\n What images can be provisioned on dedicated hosts? \n\nYou can provision IBM Cloud virtual server stock images or import your own images as indicated in the third-party agreement.\n\n\n\n\n\n Is there a limit as to how many dedicated hosts can be allocated to a single account? \n\nYes, resource limitations are per account as defined for all IBM Cloud as a Service resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-dedicated-hosts-and-instances"},{"document_id":"ibmcld_06206-0-1702","score":22.447598,"text":"\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud ks cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud ks cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts_storage_clean_volume"},{"document_id":"ibmcld_10640-0-1702","score":22.447598,"text":"\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud oc cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud oc cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts_storage_clean_volume"},{"document_id":"ibmcld_11730-5345-7171","score":21.27068,"text":"\nMany extra software packages require access to or from the host, so extra software packages are not allowed to be installed.\n\nMaintenance: IBM provides software updates that you choose when to apply to the host. Because IBM is responsible for providing these updates, you cannot install extra software that is not managed by IBM. Extra software also uses mores CPU, memory, and disk storage resources on the host, which impacts the amount available to your Satellite-enabled IBM Cloud services and applications that run on the hosts.\n\n\n\n\n\n What am I charged for when I use IBM Cloud Satellite? \n\nIBM Cloud Satellite provides a convenient way for you to consume IBM Cloud services in any location that you want, with visibility across your locations. For more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\n\n\n What are the terms of the service level agreement? \n\nSee the [IBM Cloud terms of service](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) and the [Satellite additional service description](http:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm-8913-01).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-faqs"},{"document_id":"ibmcld_12746-0-1760","score":20.942936,"text":"\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https:\/\/cloud.ibm.com\/security-compliance\/catalog) or [plan page](https:\/\/cloud.ibm.com\/security-compliance\/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scc-pricing"},{"document_id":"ibmcld_10392-218624-220182","score":20.848454,"text":"\n4 December 2019 \n\nExposing apps with load balancers or Ingress ALBs\n: Added quick start pages to help you get up and running with [load balancers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer-qs) and [Ingress ALBs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-managed-ingress-about).\n\nRed Hat OpenShift charges\n: Now when you create Red Hat OpenShift clusters, you are not charged for the Red Hat Enterprise Linux operating system that is installed on the worker nodes. For more information, see [What am I charged for when I use Red Hat OpenShift clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges).\n\nRed Hat OpenShift routes\n: Added steps for [bringing your own hostname](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesroutes-setup) for public routes and steps for [setting up private routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesprivate-routes-setup-43).\n\nUse the internal KVDB in Portworx\n: Automatically set up a key-value database (KVDB) during the Portworx installation to store your Portworx metadata. For more information, see [Using the Portworx KVDB](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_kv_store).\n\n\n\n\n\n\n\n November 2019 \n\n\n\n 26 November 2019 \n\nCLI change log\n: Updated the IBM Cloud Kubernetes Service CLI plug-in change log page for the [release of version 0.4.61](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog).\n\nDiagnostics and Debug Tool add-on for Red Hat OpenShift clusters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":37.112125,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-1672-3956","score":36.396385,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_10116-7-2157","score":29.587997,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-7-2151","score":29.587997,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_03776-5228-7163","score":29.142778,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-7-2197","score":28.925646,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-3313-5682","score":23.15103,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07578-807740-809746","score":22.153656,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-807613-809619","score":22.153656,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07289-1587-3853","score":21.567318,"text":"\nFor example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n\n\n\n\n What is planned for Direct Link on Classic Exchange? \n\nThe marketplace has evolved since Direct Link Exchange was established. With data center operators now blurring the lines as network service providers, IBM will be combining the Exchange offering with Connect on the new \"next generation\" platform to reflect both this change and simplify the Direct Link portfolio. Direct Link Exchange will service only the Direct Link classic infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.932521092}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00536-0-2049","score":31.615429,"text":"\n\n\n\n\n\n\n  Pricing FAQ \n\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing).\n\n\n\n  Can I change my capacity setting? \n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\n  How do I know I exceeded the capacity limit that I set? \n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\n  Where can I see my usage data? \n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-pricing"},{"document_id":"ibmcld_05012-4837-6709","score":30.513424,"text":"\nSimilarly, a bucket in ca-tor will incur archive pricing for ca-tor.\n\n\n\n\n\n Can I move my existing buckets from Standard plan to One-Rate plan? \n\nExisting buckets in the Standard plan cannot be moved to the One-rate plan. Clients must first enroll in the One-Rate plan, create a new service instance and new buckets before data can be populated.\n\n\n\n\n\n Can I upgrade my Cloud Object Storage Lite plan instance to One-Rate plan? \n\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n\n\n\n\n\n Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan? \n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n\n\n\n\n\n What is the cost of data retrieval from One Rate Active buckets? \n\nThere is no data retrieval charge for the One Rate Active buckets.\n\n\n\n\n\n What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests? \n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n\n\n\n\n\n Is the overage pricing tiered for Outbound bandwidth and Operational requests? \n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n\n\n\n\n\n I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads? \n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-onerate"},{"document_id":"ibmcld_07578-1061453-1063204","score":30.446802,"text":"\n* How do I view my commitment usage?\n\nTo view your commitment usage, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Commitments & subscriptions.\n\n\n\n* Click the tabs to view information on active or upcoming commitments.\n* Use the graph to view what you've spent toward your overall committed amount.\n* View monthly breakdown of the spending history for the commitment in the table.\n\n\n\n* How do I view my commitment terms?\n\nAfter you consult with a sales representative to sign up for IBM Cloud Enterprise Savings Plan, the sales team will email you a copy of your quote and information about IBM Cloud's Terms and Conditions.\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_11893-163543-165078","score":30.03551,"text":"\n(https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-regionssupported-regions-why-location)\n* [What IBM Cloud multizone metro do I choose for my Satellite location?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-regionssupported-regions-what-multizone-metro)\n* [Can my hosts reside anywhere?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-regionssupported-regions-limitations)\n* [How can I deploy in an EU Cloud Certified Location?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-regionseu-certified)\n* [What about latency requirements?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-regionssupported-regions-latency)\n\n\n\n\n\n\n\n\n\n Pricing \n\n[Pricing](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricingsat-pricing)\n\n\n\n* [Satellite locations](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricingpricing-satloc)\n* [Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricingpricing-services)\n* [Can I estimate my costs?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricingpricing-include-cost-estimate)\n* [Can I view and control my current usage?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricingpricing-include-usage)\n\n\n\n\n\n\n\n Your responsibilities \n\n[Your responsibilities](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-responsibilitiesresponsibilities)\n\n\n\n* [Overview of shared responsibilities](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-responsibilitiesoverview-by-resource)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sitemap&interface=cli"},{"document_id":"ibmcld_16727-1064600-1066235","score":29.165546,"text":"\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1145394-1147163","score":28.877708,"text":"\n* Can I update an Operator that was onboarded from the Red Hat registry?\n\nYes, see the following links for more information:\n\n\n\n* [Adding a new version of software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-add-version-software).\n* [Reloading a software version](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-software-reload).\n\n\n\n* How do I upload a version from my GitHub repository?\n\nSee [Managing releases in a repository](https:\/\/docs.github.com\/en\/github\/administering-a-repository\/managing-releases-in-a-repository).\n* How do I view my account ID and type?\n\nGo to Manage > Account > Account settings in the console. Your account ID is the alphanumeric value in the Account section. Your account type is included in the Account type section.\n* Can I include a pricing plan with my software?\n\nCurrently, software products in the IBM Cloud catalog don't include pricing plans. You can bring your own licenses or deliver your third-party software for free.\n* What account do I use to onboard my product?\n\nUse your own account to onboard your software. If an IBM representative is helping you with the onboarding process, you can add them to your account if you feel comfortable doing so. See [Inviting team members](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-invite-team) for more information.\n* Can I remove a team member's access to my account?\n\nIf you're the account owner, or if you have the required access, you can remove users. For more information, see [Removing users from an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-remove).\n* Can I view my assigned roles and permissions?\n\nYes, go to Manage > Access (IAM) in the console, and select your name on the Users page. Then, depending on the access you're looking for, select the different tabs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1148027-1149796","score":28.877708,"text":"\n* Can I update an Operator that was onboarded from the Red Hat registry?\n\nYes, see the following links for more information:\n\n\n\n* [Adding a new version of software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-add-version-software).\n* [Reloading a software version](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-software-reload).\n\n\n\n* How do I upload a version from my GitHub repository?\n\nSee [Managing releases in a repository](https:\/\/docs.github.com\/en\/github\/administering-a-repository\/managing-releases-in-a-repository).\n* How do I view my account ID and type?\n\nGo to Manage > Account > Account settings in the console. Your account ID is the alphanumeric value in the Account section. Your account type is included in the Account type section.\n* Can I include a pricing plan with my software?\n\nCurrently, software products in the IBM Cloud catalog don't include pricing plans. You can bring your own licenses or deliver your third-party software for free.\n* What account do I use to onboard my product?\n\nUse your own account to onboard your software. If an IBM representative is helping you with the onboarding process, you can add them to your account if you feel comfortable doing so. See [Inviting team members](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-invite-team) for more information.\n* Can I remove a team member's access to my account?\n\nIf you're the account owner, or if you have the required access, you can remove users. For more information, see [Removing users from an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-remove).\n* Can I view my assigned roles and permissions?\n\nYes, go to Manage > Access (IAM) in the console, and select your name on the Users page. Then, depending on the access you're looking for, select the different tabs:","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1320438-1322384","score":28.722673,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1323103-1325049","score":28.722673,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-474233-476319","score":27.917452,"text":"\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12561-5237-7143","score":18.086935,"text":"\nIf you want to view usage for a specific account group or account, find the name or ID by running the ibmcloud enterprise command.\n\nFor example, the following command displays all account groups in an enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. View usage by running the ibmcloud billing command as shown in the following examples.\n\n\n\n* View usage for the entire enterprise for the current month.\n\nibmcloud billing enterprise-usage\n* View usage for the Development account group for July 2019.\n\nibmcloud billing enterprise-usage --account-group Development --month 2019-07\n* View the usage for the account groups and accounts that are directly under the enterprise.\n\nibmcloud billing enterprise-usage --children\n\n\n\n\n\nBy default, the commands output the usage report for the current month in the following format. Most costs are listed as billable costs. Non-billable costs are listed only in rare cases, such as for the month when you add a trial account to the enterprise.\n\nName Type Billable Cost Non-billable Cost Currency Month\nExample Corp account 123.45 0 USD 2019-07\nDevelopment account_group 234.56 0 USD 2019-07\nMarketing account_group 345.67 0 USD 2019-07\nSales account_group 456.78 0 USD 2019-07\n\nYou can output the report in JSON format by specifying the --output JSON option.\n\n\n\n\n\n Viewing enterprise usage by using the API \n\nYou can get usage reports from an enterprise and its accounts by calling the [Enterprise Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports). You can base the query in your API call on an enterprise, an account group, or an account and specify whether to view the entity or its children.\n\nThe following examples show queries that you can use to get different usage reports. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_08067-0-1736","score":16.12599,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_03776-3313-5682","score":15.933916,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03787-5002-7004","score":15.759338,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_12544-8261-10509","score":15.123566,"text":"\n* Better discounts on usage costs because subscriptions are larger\n* Fewer expiration dates to track and manage after existing subscriptions expire\n\n\n\nIn an enterprise, subscriptions are managed from the enterprise account the same way as for a stand-alone account. For more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_03749-8477-10695","score":14.657939,"text":"\nFor more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_03776-1678-3763","score":14.500116,"text":"\nIf you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page. You can download your latest invoice with all discounts and charges here or from the Invoices page.\n\nNow that you've walked through the common billing options and how to delegate billing administrator capabilities, track usage, and pay your bill, you're ready to start deciding what is best for your account. As always, if you need more information, check out the documentation for IBM Cloud billing and usage.\n\n\n\n\n\n How does billing work in IBM Cloud? \n\nIBM Cloud has two billable account types, Pay-As-You-Go and Subscription accounts. With a billable account, you can use IBM Cloud resources and services that incur costs. The account type that you choose impacts how you're billed for your resource usage.\n\nWhen you have a Pay-As-You-Go account, you're billed monthly for your resource usage. You pay only for what you use, with no long-term contracts. As your resource usage changes, so does your invoice, similar to a utility bill. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads.\n\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_01705-4111-6013","score":13.455591,"text":"\nIf you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends. To reactivate your account, log in to your account and upgrade it to a Pay-As-You-Go account.\n\nIf you import a trial account into an enterprise, it's automatically upgraded to a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nSupport for a trial account is limited to nontechnical support issues that are related to account access and billing. Users with trial accounts can view the [IBM Cloud documentation](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar), Chat with Watson, and use [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).\n\n\n\n\n\n Pay-As-You-Go account \n\nWith a Pay-As-You-Go account, you can access the full IBM Cloud catalog, including all Free and Lite plans. You pay only for billable services that you use and monthly commitments, with no long-term contracts or commitments. When you register with IBM Cloud, you get a Pay-As-You-Go account, and you receive a [$200 credit](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) to help get you started. You can use the $200 credit on IBM Cloud products.\n\nYour resource usage consists of recurring and fluctuating costs. If you purchase classic infrastructure services, you're billed on an hourly or monthly recurring basis in advance of use, like a rent bill. If you purchase platform services, your invoice fluctuates as your resource usage fluctuates, similar to a utility bill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12623-6811-8811","score":13.440502,"text":"\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan. For more information about the support experience, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport_level_enterprise).\n\n\n\n\n\n Resource management \n\nResources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups. Account groups can't contain resources. For more information, see [Managing resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage_resource).\n\nZoom\n\n![A diagram that shows that resources are contained in accounts in the enterprise.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/images\/enterprise-resources.svg)\n\nFigure 3. Resources in an enterprise\n\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"},{"document_id":"ibmcld_05646-7-1791","score":12.814078,"text":"\nPreparing to create clusters \n\nCreate a cluster in IBM Cloud\u00ae Kubernetes Service.\n\nAfter [getting started](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started), you might want to create a cluster that is customized to your use case and different public and private cloud environments. Consider the following steps to create the correct cluster each time.\n\n\n\n1. [Prepare your account to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusterscluster_prepare). This step includes creating a billable account, setting up an API key with infrastructure permissions, making sure that you have Administrator access in IBM Cloud IAM, planning resource groups, and setting up account networking.\n2. [Decide on your cluster setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersprepare_cluster_level). This step includes planning cluster network and HA setup, estimating costs, and if applicable, allowing network traffic through a firewall.\n3. Create your [VPC Gen2](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2) or [classic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic) cluster by following the steps in the IBM Cloud console or CLI.\n\n\n\n\n\n Preparing to create clusters at the account level \n\nPrepare your IBM Cloud account for IBM Cloud Kubernetes Service. After the account administrator makes these preparations, you might not need to change them each time that you create a cluster. However, each time that you create a cluster, you still want to verify that the current account-level state is what you need it to be.\n\n\n\n1. [Create or upgrade your account to a billable account (IBM Cloud Pay-As-You-Go or Subscription)](https:\/\/cloud.ibm.com\/registration).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1044428-1046278","score":21.47701,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":21.47701,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03713-3269-5168","score":21.010717,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":20.248636,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":20.125559,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":19.63733,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03704-4411-6289","score":19.607985,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1045891-1047755","score":19.607985,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":19.607985,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03765-2725-4571","score":18.60098,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16727-1066874-1068548","score":27.467886,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1061453-1063204","score":27.299232,"text":"\n* How do I view my commitment usage?\n\nTo view your commitment usage, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Commitments & subscriptions.\n\n\n\n* Click the tabs to view information on active or upcoming commitments.\n* Use the graph to view what you've spent toward your overall committed amount.\n* View monthly breakdown of the spending history for the commitment in the table.\n\n\n\n* How do I view my commitment terms?\n\nAfter you consult with a sales representative to sign up for IBM Cloud Enterprise Savings Plan, the sales team will email you a copy of your quote and information about IBM Cloud's Terms and Conditions.\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1064084-1065746","score":27.13513,"text":"\nFor more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1062822-1064465","score":27.00216,"text":"\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1065299-1067188","score":26.748615,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1064600-1066235","score":26.517029,"text":"\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03764-2220-3440","score":26.482733,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_03764-7-1642","score":26.42763,"text":"\nFAQs for invoices \n\nReview the following FAQs to find helpful information about invoices. To find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Where can I access my invoice? \n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n\n\n\n\n\n Why does my usage not match my invoice? \n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I manage my invoices? \n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_16727-1065700-1067235","score":25.795822,"text":"\n(https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":25.625576,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12597-0-804","score":32.274765,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03710-0-838","score":29.965124,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_03704-8977-10890","score":23.628803,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":23.628803,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":23.628803,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03786-1684-3421","score":23.392757,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_07578-1066746-1068772","score":22.546886,"text":"\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?\n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n* What happens if I spend my entire subscription amount before my term ends?\n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to sign up for a new subscription.\n* Is there a monthly minimum amount required for Subscription accounts?\n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n* Can I cancel my Subscription account before the end of my term commitment?\n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03785-7-2010","score":22.207783,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_05444-191740-193167","score":21.993917,"text":"\n(https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-sb-cosredactedts-sb-cosredacted)\n\n[Why does my service binding to a Db2 Enterprise instance fail?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-sb-db2createfailsts-sb-db2createfails)\n\n[Why can't I display details of my configured service binding operations?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-sb-projsettings-nodetailsts-sb-projsettings-nodetails)\n\n\n\n\n\n Troubleshooting subscriptions \n\n[Debugging subscriptions](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-troubleshoot-subscriptionstroubleshoot-subscriptions)\n\n\n\n* [Subscription limits to consider](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-troubleshoot-subscriptionsts-subscription-limits)\n* [Subscription logs](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-troubleshoot-subscriptionsts-subscription-cos-logs)\n\n\n\n[Why does my subscription show errors when it delivers events?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-subscription-deliveryerrorsts-subscription-deliveryerrors)\n\n[Why is my subscription cos create command failing?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-cossub-createts-cossub-create)\n\n[Why does my Object Storage subscription never become ready?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-cossub-notreadyts-cossub-notready)\n\n[Why is my subscription cron create command failing?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-sitemap"},{"document_id":"ibmcld_07578-1065299-1067188","score":21.325447,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":27.081356,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_12597-0-804","score":23.910965,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03711-0-822","score":23.890089,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"},{"document_id":"ibmcld_03710-0-838","score":22.726278,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_03704-8977-10890","score":22.415358,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":22.415358,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":22.415358,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08391-12093-14208","score":21.803951,"text":"\nWhen the Ansible provisioner tries to SSH to these nodes to se the Spectrum Scale feature, the nodes go to an unreachable state.\n\nTo fix the issue, you can:\n\n How to fix it \n\n\n\n1. Try to destroy the resources from the workspace and deploy again.\n2. If this issue is observed on all of the deployments, raise a support issue with the IBM Cloud support team to investigate if there is an infrastructure issue.\n3. If there are no issues with the infrastructure, report this issue to the automation team who can investigate further.\n\n\n\n\n\n\n\n Why am I receiving an error that the image is not found? \n\n What\u2019s happening \n\nYou are receiving the following error when you try to either generate or apply a plan to your workspace: Apply failed due to \"Error: [ERROR] No image found with name hpcc-symp731-scale5151-rhel84-v1-4\".\n\nEither during generating or applying a plan, Terraform tries to validate if the provided image name and its image ID is present in the image_map.tf file. If Terraform finds the correct image details, it provisions the instances, but if the correct image details can't be found, Terraform tries to fetch the image details from IBM Cloud through data_source.\n\n Why it\u2019s happening \n\nEven if the provided image is not present in the cloud from that specific region, you still might receive the error.\n\n How to fix it \n\nYou need to check whether the provided image name has any spaces and if that image is present in the region where you want to do the deployment.\n\n\n\n\n\n Why am I receiving a cannot_start_capacity error? \n\n What\u2019s happening \n\nYou are receiving the following error when you try to apply a plan to your workspace: Apply failed due to \"code : cannot_start_capacity : message : Can't start instance because resource capacity is unavailable.\n\n Why it\u2019s happening \n\nDuring the apply plan process, Terraform initiates the virtual server instance provisioning or bare metal server process based on the selected deployment values. If there is a resource capacity issue or a quota issue from the region where you are trying to deploy, the resources won't provision as expected.\n\n How to fix it","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-troubleshooting-spectrum-symphony"},{"document_id":"ibmcld_02713-0-440","score":20.705093,"text":"\n\n\n\n\n\n\n  Why can't I toggle a newly created feature flag? \n\n  What\u2019s happening \n\nFeature flag is disabled and cannot be toggled.\n\n  Why it\u2019s happening \n\nA Feature flag is linked to a collection and the flag is toggled per environment.\n\nIf a feature flag is not linked to any collection, it is disabled by default.\n\n  How to fix it \n\nLink the feature flag with an existing collection. This allows you to toggle between ON or OFF state.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-troubleshooting-one"},{"document_id":"ibmcld_01660-4245-6093","score":19.941856,"text":"\nIn the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account. However, if you want to use the capabilities that are not available in a service's Lite plan, you must [upgrade the plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing) for the specific service. After you change a service plan, it might be necessary to restage your application.\n\n\n\n\n\n Can I convert my account? \n\nYes, the following options are available depending on your account type:\n\n\n\n* If you have a feature code from an online course or educational event, you can use it to convert your Lite account to a trial account. Go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code to your account.\n* To convert your Pay-As-You-Go account to a Subscription account, contact [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule).\n\n\n\n\n\n\n\n Can I convert my Pay-As-You-Go account to a trial account? \n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account.\n\n\n\n\n\n Can I add an educational feature code to an account after I have added a credit card? \n\nWhen you add a credit card to your trial account, your account is upgraded to a Pay-As-You-Go account. Educational feature codes can't be used in a Pay-As-You-Go account. In addition, a Pay-As-You-Go account can't be converted back to a trial account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1071351-1073249","score":27.172066,"text":"\nSome countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03704-1531-3564","score":27.143147,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03713-1710-3705","score":27.05268,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_01660-2990-4730","score":26.777569,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n\n\n\n\n\n How do I upgrade my account? \n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1073973-1075745","score":26.777569,"text":"\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03713-7896-8949","score":26.774118,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03704-3030-4892","score":26.522848,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":26.522848,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":26.522848,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1068305-1070191","score":26.356308,"text":"\nYou can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqscancelaccount).\n\n\n\nManaging your account, resources, and access\n\n\n\n* How do I create an IBM Cloud account?\n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n* How is my credit card authorized?\n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.195190025,"ndcg_cut_10":0.3342462045}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":134.46109,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-3269-5168","score":133.12785,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":127.08849,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":92.01353,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":91.51034,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":88.22243,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03704-3030-4892","score":75.355705,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":74.00821,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":74.00821,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03794-0-812","score":72.97162,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
